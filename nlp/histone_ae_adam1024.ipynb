{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "histone_ae_adam1024.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM3g+XbVwpcG+XBnaQUvGH9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/csy99/dna-nn-theory/blob/master/histone_ae_adam1024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sX2CBzgbb0Mr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45adcf88-20ad-4412-ae4e-2906e2978bc3"
      },
      "source": [
        "!pip install -q biopython"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▏                               | 10kB 20.5MB/s eta 0:00:01\r\u001b[K     |▎                               | 20kB 25.5MB/s eta 0:00:01\r\u001b[K     |▍                               | 30kB 28.4MB/s eta 0:00:01\r\u001b[K     |▋                               | 40kB 11.7MB/s eta 0:00:01\r\u001b[K     |▊                               | 51kB 13.4MB/s eta 0:00:01\r\u001b[K     |▉                               | 61kB 15.1MB/s eta 0:00:01\r\u001b[K     |█                               | 71kB 12.9MB/s eta 0:00:01\r\u001b[K     |█▏                              | 81kB 13.6MB/s eta 0:00:01\r\u001b[K     |█▎                              | 92kB 13.1MB/s eta 0:00:01\r\u001b[K     |█▌                              | 102kB 12.8MB/s eta 0:00:01\r\u001b[K     |█▋                              | 112kB 12.8MB/s eta 0:00:01\r\u001b[K     |█▊                              | 122kB 12.8MB/s eta 0:00:01\r\u001b[K     |██                              | 133kB 12.8MB/s eta 0:00:01\r\u001b[K     |██                              | 143kB 12.8MB/s eta 0:00:01\r\u001b[K     |██▏                             | 153kB 12.8MB/s eta 0:00:01\r\u001b[K     |██▎                             | 163kB 12.8MB/s eta 0:00:01\r\u001b[K     |██▌                             | 174kB 12.8MB/s eta 0:00:01\r\u001b[K     |██▋                             | 184kB 12.8MB/s eta 0:00:01\r\u001b[K     |██▊                             | 194kB 12.8MB/s eta 0:00:01\r\u001b[K     |███                             | 204kB 12.8MB/s eta 0:00:01\r\u001b[K     |███                             | 215kB 12.8MB/s eta 0:00:01\r\u001b[K     |███▏                            | 225kB 12.8MB/s eta 0:00:01\r\u001b[K     |███▍                            | 235kB 12.8MB/s eta 0:00:01\r\u001b[K     |███▌                            | 245kB 12.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 256kB 12.8MB/s eta 0:00:01\r\u001b[K     |███▉                            | 266kB 12.8MB/s eta 0:00:01\r\u001b[K     |████                            | 276kB 12.8MB/s eta 0:00:01\r\u001b[K     |████                            | 286kB 12.8MB/s eta 0:00:01\r\u001b[K     |████▏                           | 296kB 12.8MB/s eta 0:00:01\r\u001b[K     |████▍                           | 307kB 12.8MB/s eta 0:00:01\r\u001b[K     |████▌                           | 317kB 12.8MB/s eta 0:00:01\r\u001b[K     |████▋                           | 327kB 12.8MB/s eta 0:00:01\r\u001b[K     |████▉                           | 337kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 348kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 358kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 368kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 378kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 389kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 399kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 409kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 419kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 430kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 440kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 450kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 460kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 471kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 481kB 12.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 491kB 12.8MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 501kB 12.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 512kB 12.8MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 522kB 12.8MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 532kB 12.8MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 542kB 12.8MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 552kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 563kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 573kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 583kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 593kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 604kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 614kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 624kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 634kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 645kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 655kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 665kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 675kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 686kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 696kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 706kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 716kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 727kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 737kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 747kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 757kB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 768kB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 778kB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 788kB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 798kB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 808kB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 819kB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 829kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 839kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 849kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 860kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 870kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 880kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 890kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 901kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 911kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 921kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 931kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 942kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 952kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 962kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 972kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 983kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 993kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 1.0MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 1.0MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 1.0MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 1.0MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 1.0MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.1MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 1.1MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 1.1MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 1.1MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 1.1MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 1.1MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 1.1MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.1MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 1.1MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 1.1MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 1.2MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 1.2MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 1.2MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 1.2MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.2MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 1.2MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.2MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 1.2MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.2MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.2MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.3MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.3MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.3MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.3MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.3MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.3MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.3MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.3MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.3MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.4MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.4MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.4MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.4MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.4MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.4MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.4MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.4MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.4MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.4MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.5MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.5MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.5MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.5MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.5MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.5MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.5MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.5MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.5MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.5MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.6MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.6MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.6MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.6MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.6MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.6MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.6MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.6MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.6MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.6MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.7MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.7MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.7MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.7MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.7MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.7MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.7MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.7MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.7MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.8MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.8MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.8MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.8MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.8MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.8MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.8MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.8MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.8MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.8MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.9MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.9MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.9MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.9MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.9MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.9MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.9MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.9MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.9MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.9MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 2.0MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.0MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.0MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 2.0MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 2.0MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 2.0MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 2.0MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 2.0MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 2.0MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 2.0MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 2.1MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 2.1MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 2.1MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 2.1MB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 2.1MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 2.1MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 2.1MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 2.1MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 2.1MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 2.2MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 2.2MB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 2.2MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 2.2MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 2.2MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 2.2MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 2.2MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 2.2MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 2.2MB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 2.2MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.3MB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.3MB 12.8MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ju-L3fnb9Z_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa8f70a6-2d7b-41c6-8714-32f45fa71566"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "\r\n",
        "# module auto reload\r\n",
        "%load_ext autoreload\r\n",
        "%autoreload 2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfD_sMuadGg-",
        "outputId": "2af517a2-35fd-4afc-917f-cde919939ee6"
      },
      "source": [
        "# copy modules\r\n",
        "!cp -r '/content/drive/My Drive/dna_NN_theory/reading_dna_scripts' .\r\n",
        "!ls reading_dna_scripts"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "download.py  load.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72WFD4aSdBIO"
      },
      "source": [
        "import re\r\n",
        "import time\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from itertools import product\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import sklearn.metrics as metrics\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.data import Dataset\r\n",
        "\r\n",
        "from reading_dna_scripts.load import read_fasta"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8zhPdvZb9cP"
      },
      "source": [
        "DIR = '/content/drive/My Drive/'\r\n",
        "DATA_DIR = DIR + 'dna_NN_theory/histone/'\r\n",
        "MODEL_DIR = DIR + 'dna_NN_theory/models/'\r\n",
        "DATE = '_20210313'\r\n",
        "SUFFIX = \"ae_histone_adam1024\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7vvQ89Gb9eK",
        "outputId": "2f16f7da-baed-4609-ca13-2787bae115bd"
      },
      "source": [
        "file = DIR + 'H3.fasta'\r\n",
        "sequences, labels = read_fasta(file)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14963 samples loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ealq1NGb9gY",
        "outputId": "54c895a9-dfa6-44ab-912b-b604d5de2426"
      },
      "source": [
        "# split\r\n",
        "SEED = 3264\r\n",
        "test_size = 0.15\r\n",
        "val_size = 0.15\r\n",
        "\r\n",
        "split_options = dict(test_size=test_size, stratify=labels, random_state=SEED)\r\n",
        "x_train_val, xtest, y_train_val, ytest = train_test_split(sequences, labels, **split_options)\r\n",
        "# normalize val_size and update options\r\n",
        "split_options.update(dict(test_size=val_size/(1-test_size), stratify=y_train_val))\r\n",
        "xtrain, xval, ytrain, yval = train_test_split(x_train_val, y_train_val, **split_options)\r\n",
        "del x_train_val, y_train_val\r\n",
        "seq_len = len(xtrain[0])\r\n",
        "print('train size:', len(xtrain))\r\n",
        "print('val size: ', len(xval))\r\n",
        "print('test size: ', len(xtest))\r\n",
        "print(\"The length of the sequence is\", seq_len)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train size: 10473\n",
            "val size:  2245\n",
            "test size:  2245\n",
            "The length of the sequence is 500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Wu5WD98b9kp",
        "outputId": "7a9c3568-b34d-40ee-d9b6-b77ee7a23bd6"
      },
      "source": [
        "word_size = 1\r\n",
        "neucleotides = 'ACGT'\r\n",
        "vocab = [''.join(p) for p in product(neucleotides, repeat=word_size)]\r\n",
        "# word_to_idx = {word: i for i, word in enumerate(vocab)}\r\n",
        "vocab_size = len(neucleotides)\r\n",
        "print('vocab_size:', vocab_size)\r\n",
        "# print(\"word_to_idx\", word_to_idx)\r\n",
        "create1gram = keras.layers.experimental.preprocessing.TextVectorization(\r\n",
        "  standardize=lambda x: tf.strings.regex_replace(x, '(.)', '\\\\1 '), ngrams=1\r\n",
        ")\r\n",
        "create1gram.adapt(vocab)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab_size: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZHkrTPmRCwb"
      },
      "source": [
        "# the first two index of TextVectorization has been reserved to EOS and OOV\r\n",
        "def index_preprocess(x):\r\n",
        "  x_index = tf.subtract(create1gram(x), 2)\r\n",
        "  return x_index, x_index\r\n",
        "\r\n",
        "def ds_preprocess(x, y):\r\n",
        "  x_index = tf.subtract(create1gram(x), 2)\r\n",
        "  return x_index, y\r\n",
        "\r\n",
        "def save_hist(hist, suf=\"_history.csv\"):\r\n",
        "  filename = DIR + 'dna_NN_theory/histone/' + SUFFIX + suf\r\n",
        "  hist_df = pd.DataFrame(hist.history) \r\n",
        "  with open(filename, mode='w') as f:\r\n",
        "    hist_df.to_csv(f)\r\n",
        "\r\n",
        "def save_prediction():\r\n",
        "  res = [ytrain, ytrain_pred, yval, yval_pred, ytest, ytest_pred]\r\n",
        "  i = 0\r\n",
        "  for ds in ['train', 'val', 'test']:\r\n",
        "    filename = DIR + 'dna_NN_theory/histone/' + SUFFIX + \"_\" + ds + \"_prediction.csv\"\r\n",
        "    df = pd.DataFrame()\r\n",
        "    df[ds] = res[i]\r\n",
        "    i += 1\r\n",
        "    df[ds+'_pred'] = res[i]\r\n",
        "    i += 1\r\n",
        "    with open(filename, mode='w') as f:\r\n",
        "      df.to_csv(f)\r\n",
        "  \r\n",
        "### ref: https://stackoverflow.com/questions/25009284/how-to-plot-roc-curve-in-python\r\n",
        "def plot_ROC(label, pred, title=\"ROC\"):\r\n",
        "  fpr, tpr, threshold = metrics.roc_curve(label, pred)\r\n",
        "  roc_auc = metrics.auc(fpr, tpr)\r\n",
        "\r\n",
        "  plt.title(title)\r\n",
        "  plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\r\n",
        "  plt.legend(loc='lower right')\r\n",
        "  plt.plot([0, 1], [0, 1],'r--')\r\n",
        "  plt.xlim([0, 1])\r\n",
        "  plt.ylim([0, 1])\r\n",
        "  plt.ylabel('True Positive Rate')\r\n",
        "  plt.xlabel('False Positive Rate')\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "### ref: https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/\r\n",
        "def plot_recall_precision(label, pred, title=\"RP\"):\r\n",
        "  precision, recall, thresholds = metrics.precision_recall_curve(label, pred)\r\n",
        "  no_skill = np.sum(label) / len(label)\r\n",
        "  plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='random')\r\n",
        "  plt.plot(recall, precision, marker='.', label='model')\r\n",
        "  plt.xlabel('Recall')\r\n",
        "  plt.ylabel('Precision')\r\n",
        "  plt.legend()\r\n",
        "  plt.show()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kySE9izuRCy-"
      },
      "source": [
        "BATCH_SIZE = 1024\r\n",
        "xtrain_seq = tf.data.Dataset.from_tensor_slices(xtrain).map(index_preprocess).batch(BATCH_SIZE)\r\n",
        "xval_seq = tf.data.Dataset.from_tensor_slices(xval).map(index_preprocess).batch(BATCH_SIZE)\r\n",
        "xtest_seq = tf.data.Dataset.from_tensor_slices(xtest).map(index_preprocess).batch(BATCH_SIZE)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLpl_zASRC1H",
        "outputId": "0a669f9a-62c7-4fba-9f5e-dfc89f4eb3a1"
      },
      "source": [
        "latent_size = 100\r\n",
        "\r\n",
        "encoder = keras.Sequential([\r\n",
        "    keras.Input(shape=(seq_len,)),\r\n",
        "    keras.layers.Embedding(seq_len, latent_size),\r\n",
        "    keras.layers.LSTM(latent_size, return_sequences=False),\r\n",
        "])\r\n",
        "\r\n",
        "decoder = keras.Sequential([\r\n",
        "    keras.layers.RepeatVector(seq_len, input_shape=[latent_size]),\r\n",
        "    keras.layers.LSTM(latent_size, return_sequences=True),\r\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(4, activation='softmax'))  # ACTG\r\n",
        "])\r\n",
        "\r\n",
        "recurrent_ae = keras.Sequential([encoder, decoder])\r\n",
        "recurrent_ae.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential (Sequential)      (None, 100)               130400    \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    (None, 500, 4)            80804     \n",
            "=================================================================\n",
            "Total params: 211,204\n",
            "Trainable params: 211,204\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaYGGPu9RC3G",
        "outputId": "989442aa-7391-4ee0-b550-9d517b83b967"
      },
      "source": [
        "recurrent_ae.compile(optimizer=tf.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics='accuracy')\r\n",
        "es_cb = keras.callbacks.EarlyStopping(patience=200, restore_best_weights=True)\r\n",
        "ae_hist = recurrent_ae.fit(xtrain_seq, validation_data=xval_seq, epochs=4000, callbacks=[es_cb])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4000\n",
            "11/11 [==============================] - 43s 1s/step - loss: 1.3739 - accuracy: 0.3016 - val_loss: 1.3609 - val_accuracy: 0.3063\n",
            "Epoch 2/4000\n",
            "11/11 [==============================] - 10s 918ms/step - loss: 1.3602 - accuracy: 0.3109 - val_loss: 1.3589 - val_accuracy: 0.3147\n",
            "Epoch 3/4000\n",
            "11/11 [==============================] - 11s 918ms/step - loss: 1.3589 - accuracy: 0.3141 - val_loss: 1.3586 - val_accuracy: 0.3147\n",
            "Epoch 4/4000\n",
            "11/11 [==============================] - 11s 923ms/step - loss: 1.3587 - accuracy: 0.3155 - val_loss: 1.3585 - val_accuracy: 0.3165\n",
            "Epoch 5/4000\n",
            "11/11 [==============================] - 10s 917ms/step - loss: 1.3584 - accuracy: 0.3172 - val_loss: 1.3581 - val_accuracy: 0.3239\n",
            "Epoch 6/4000\n",
            "11/11 [==============================] - 11s 925ms/step - loss: 1.3576 - accuracy: 0.3240 - val_loss: 1.3558 - val_accuracy: 0.3320\n",
            "Epoch 7/4000\n",
            "11/11 [==============================] - 11s 922ms/step - loss: 1.3558 - accuracy: 0.3311 - val_loss: 1.3552 - val_accuracy: 0.3316\n",
            "Epoch 8/4000\n",
            "11/11 [==============================] - 11s 926ms/step - loss: 1.3552 - accuracy: 0.3311 - val_loss: 1.3548 - val_accuracy: 0.3313\n",
            "Epoch 9/4000\n",
            "11/11 [==============================] - 11s 925ms/step - loss: 1.3551 - accuracy: 0.3294 - val_loss: 1.3575 - val_accuracy: 0.3247\n",
            "Epoch 10/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3574 - accuracy: 0.3232 - val_loss: 1.3570 - val_accuracy: 0.3247\n",
            "Epoch 11/4000\n",
            "11/11 [==============================] - 11s 928ms/step - loss: 1.3566 - accuracy: 0.3243 - val_loss: 1.3563 - val_accuracy: 0.3203\n",
            "Epoch 12/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3555 - accuracy: 0.3217 - val_loss: 1.3549 - val_accuracy: 0.3248\n",
            "Epoch 13/4000\n",
            "11/11 [==============================] - 11s 926ms/step - loss: 1.3549 - accuracy: 0.3232 - val_loss: 1.3554 - val_accuracy: 0.3213\n",
            "Epoch 14/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3549 - accuracy: 0.3221 - val_loss: 1.3539 - val_accuracy: 0.3250\n",
            "Epoch 15/4000\n",
            "11/11 [==============================] - 11s 928ms/step - loss: 1.3540 - accuracy: 0.3239 - val_loss: 1.3541 - val_accuracy: 0.3271\n",
            "Epoch 16/4000\n",
            "11/11 [==============================] - 11s 932ms/step - loss: 1.3550 - accuracy: 0.3234 - val_loss: 1.3549 - val_accuracy: 0.3238\n",
            "Epoch 17/4000\n",
            "11/11 [==============================] - 11s 930ms/step - loss: 1.3548 - accuracy: 0.3222 - val_loss: 1.3541 - val_accuracy: 0.3234\n",
            "Epoch 18/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3553 - accuracy: 0.3206 - val_loss: 1.3610 - val_accuracy: 0.3089\n",
            "Epoch 19/4000\n",
            "11/11 [==============================] - 11s 930ms/step - loss: 1.3598 - accuracy: 0.3132 - val_loss: 1.3586 - val_accuracy: 0.3168\n",
            "Epoch 20/4000\n",
            "11/11 [==============================] - 11s 925ms/step - loss: 1.3588 - accuracy: 0.3155 - val_loss: 1.3582 - val_accuracy: 0.3184\n",
            "Epoch 21/4000\n",
            "11/11 [==============================] - 11s 926ms/step - loss: 1.3583 - accuracy: 0.3172 - val_loss: 1.3579 - val_accuracy: 0.3187\n",
            "Epoch 22/4000\n",
            "11/11 [==============================] - 11s 928ms/step - loss: 1.3580 - accuracy: 0.3178 - val_loss: 1.3576 - val_accuracy: 0.3193\n",
            "Epoch 23/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3574 - accuracy: 0.3195 - val_loss: 1.3562 - val_accuracy: 0.3236\n",
            "Epoch 24/4000\n",
            "11/11 [==============================] - 11s 929ms/step - loss: 1.3559 - accuracy: 0.3231 - val_loss: 1.3553 - val_accuracy: 0.3234\n",
            "Epoch 25/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3551 - accuracy: 0.3230 - val_loss: 1.3547 - val_accuracy: 0.3234\n",
            "Epoch 26/4000\n",
            "11/11 [==============================] - 11s 923ms/step - loss: 1.3549 - accuracy: 0.3229 - val_loss: 1.3545 - val_accuracy: 0.3225\n",
            "Epoch 27/4000\n",
            "11/11 [==============================] - 10s 921ms/step - loss: 1.3548 - accuracy: 0.3223 - val_loss: 1.3549 - val_accuracy: 0.3225\n",
            "Epoch 28/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3547 - accuracy: 0.3224 - val_loss: 1.3546 - val_accuracy: 0.3236\n",
            "Epoch 29/4000\n",
            "11/11 [==============================] - 11s 930ms/step - loss: 1.3545 - accuracy: 0.3234 - val_loss: 1.3545 - val_accuracy: 0.3239\n",
            "Epoch 30/4000\n",
            "11/11 [==============================] - 11s 929ms/step - loss: 1.3551 - accuracy: 0.3222 - val_loss: 1.3543 - val_accuracy: 0.3237\n",
            "Epoch 31/4000\n",
            "11/11 [==============================] - 11s 932ms/step - loss: 1.3547 - accuracy: 0.3220 - val_loss: 1.3542 - val_accuracy: 0.3226\n",
            "Epoch 32/4000\n",
            "11/11 [==============================] - 11s 928ms/step - loss: 1.3542 - accuracy: 0.3225 - val_loss: 1.3539 - val_accuracy: 0.3235\n",
            "Epoch 33/4000\n",
            "11/11 [==============================] - 11s 927ms/step - loss: 1.3542 - accuracy: 0.3227 - val_loss: 1.3539 - val_accuracy: 0.3234\n",
            "Epoch 34/4000\n",
            "11/11 [==============================] - 11s 928ms/step - loss: 1.3562 - accuracy: 0.3202 - val_loss: 1.3572 - val_accuracy: 0.3212\n",
            "Epoch 35/4000\n",
            "11/11 [==============================] - 11s 926ms/step - loss: 1.3569 - accuracy: 0.3212 - val_loss: 1.3640 - val_accuracy: 0.3128\n",
            "Epoch 36/4000\n",
            "11/11 [==============================] - 11s 930ms/step - loss: 1.3629 - accuracy: 0.3134 - val_loss: 1.3587 - val_accuracy: 0.3193\n",
            "Epoch 37/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3590 - accuracy: 0.3151 - val_loss: 1.3583 - val_accuracy: 0.3184\n",
            "Epoch 38/4000\n",
            "11/11 [==============================] - 11s 925ms/step - loss: 1.3583 - accuracy: 0.3169 - val_loss: 1.3579 - val_accuracy: 0.3192\n",
            "Epoch 39/4000\n",
            "11/11 [==============================] - 11s 930ms/step - loss: 1.3576 - accuracy: 0.3180 - val_loss: 1.3561 - val_accuracy: 0.3229\n",
            "Epoch 40/4000\n",
            "11/11 [==============================] - 11s 930ms/step - loss: 1.3579 - accuracy: 0.3156 - val_loss: 1.3588 - val_accuracy: 0.3146\n",
            "Epoch 41/4000\n",
            "11/11 [==============================] - 11s 927ms/step - loss: 1.3589 - accuracy: 0.3122 - val_loss: 1.3585 - val_accuracy: 0.3169\n",
            "Epoch 42/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3584 - accuracy: 0.3167 - val_loss: 1.3581 - val_accuracy: 0.3180\n",
            "Epoch 43/4000\n",
            "11/11 [==============================] - 11s 927ms/step - loss: 1.3580 - accuracy: 0.3176 - val_loss: 1.3576 - val_accuracy: 0.3196\n",
            "Epoch 44/4000\n",
            "11/11 [==============================] - 11s 924ms/step - loss: 1.3574 - accuracy: 0.3189 - val_loss: 1.3559 - val_accuracy: 0.3210\n",
            "Epoch 45/4000\n",
            "11/11 [==============================] - 11s 932ms/step - loss: 1.3556 - accuracy: 0.3215 - val_loss: 1.3547 - val_accuracy: 0.3250\n",
            "Epoch 46/4000\n",
            "11/11 [==============================] - 11s 928ms/step - loss: 1.3549 - accuracy: 0.3224 - val_loss: 1.3587 - val_accuracy: 0.3136\n",
            "Epoch 47/4000\n",
            "11/11 [==============================] - 11s 926ms/step - loss: 1.3584 - accuracy: 0.3146 - val_loss: 1.3583 - val_accuracy: 0.3164\n",
            "Epoch 48/4000\n",
            "11/11 [==============================] - 11s 928ms/step - loss: 1.3582 - accuracy: 0.3158 - val_loss: 1.3579 - val_accuracy: 0.3171\n",
            "Epoch 49/4000\n",
            "11/11 [==============================] - 11s 926ms/step - loss: 1.3579 - accuracy: 0.3169 - val_loss: 1.3577 - val_accuracy: 0.3177\n",
            "Epoch 50/4000\n",
            "11/11 [==============================] - 11s 930ms/step - loss: 1.3575 - accuracy: 0.3173 - val_loss: 1.3570 - val_accuracy: 0.3191\n",
            "Epoch 51/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3564 - accuracy: 0.3181 - val_loss: 1.3548 - val_accuracy: 0.3204\n",
            "Epoch 52/4000\n",
            "11/11 [==============================] - 11s 929ms/step - loss: 1.3550 - accuracy: 0.3185 - val_loss: 1.3546 - val_accuracy: 0.3197\n",
            "Epoch 53/4000\n",
            "11/11 [==============================] - 11s 930ms/step - loss: 1.3547 - accuracy: 0.3184 - val_loss: 1.3543 - val_accuracy: 0.3199\n",
            "Epoch 54/4000\n",
            "11/11 [==============================] - 11s 932ms/step - loss: 1.3545 - accuracy: 0.3183 - val_loss: 1.3542 - val_accuracy: 0.3190\n",
            "Epoch 55/4000\n",
            "11/11 [==============================] - 11s 930ms/step - loss: 1.3547 - accuracy: 0.3186 - val_loss: 1.3547 - val_accuracy: 0.3189\n",
            "Epoch 56/4000\n",
            "11/11 [==============================] - 11s 929ms/step - loss: 1.3555 - accuracy: 0.3185 - val_loss: 1.3547 - val_accuracy: 0.3186\n",
            "Epoch 57/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3547 - accuracy: 0.3184 - val_loss: 1.3539 - val_accuracy: 0.3201\n",
            "Epoch 58/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3541 - accuracy: 0.3192 - val_loss: 1.3536 - val_accuracy: 0.3212\n",
            "Epoch 59/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3538 - accuracy: 0.3200 - val_loss: 1.3531 - val_accuracy: 0.3224\n",
            "Epoch 60/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3532 - accuracy: 0.3228 - val_loss: 1.3522 - val_accuracy: 0.3283\n",
            "Epoch 61/4000\n",
            "11/11 [==============================] - 11s 929ms/step - loss: 1.3564 - accuracy: 0.3234 - val_loss: 1.3589 - val_accuracy: 0.3137\n",
            "Epoch 62/4000\n",
            "11/11 [==============================] - 11s 930ms/step - loss: 1.3586 - accuracy: 0.3165 - val_loss: 1.3583 - val_accuracy: 0.3198\n",
            "Epoch 63/4000\n",
            "11/11 [==============================] - 11s 930ms/step - loss: 1.3583 - accuracy: 0.3199 - val_loss: 1.3578 - val_accuracy: 0.3212\n",
            "Epoch 64/4000\n",
            "11/11 [==============================] - 11s 925ms/step - loss: 1.3578 - accuracy: 0.3215 - val_loss: 1.3569 - val_accuracy: 0.3256\n",
            "Epoch 65/4000\n",
            "11/11 [==============================] - 11s 932ms/step - loss: 1.3565 - accuracy: 0.3276 - val_loss: 1.3555 - val_accuracy: 0.3339\n",
            "Epoch 66/4000\n",
            "11/11 [==============================] - 11s 929ms/step - loss: 1.3565 - accuracy: 0.3284 - val_loss: 1.3554 - val_accuracy: 0.3319\n",
            "Epoch 67/4000\n",
            "11/11 [==============================] - 11s 925ms/step - loss: 1.3555 - accuracy: 0.3312 - val_loss: 1.3549 - val_accuracy: 0.3334\n",
            "Epoch 68/4000\n",
            "11/11 [==============================] - 11s 926ms/step - loss: 1.3549 - accuracy: 0.3334 - val_loss: 1.3545 - val_accuracy: 0.3347\n",
            "Epoch 69/4000\n",
            "11/11 [==============================] - 11s 923ms/step - loss: 1.3555 - accuracy: 0.3315 - val_loss: 1.3547 - val_accuracy: 0.3346\n",
            "Epoch 70/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3553 - accuracy: 0.3329 - val_loss: 1.3545 - val_accuracy: 0.3350\n",
            "Epoch 71/4000\n",
            "11/11 [==============================] - 11s 927ms/step - loss: 1.3547 - accuracy: 0.3339 - val_loss: 1.3544 - val_accuracy: 0.3349\n",
            "Epoch 72/4000\n",
            "11/11 [==============================] - 11s 925ms/step - loss: 1.3542 - accuracy: 0.3345 - val_loss: 1.3536 - val_accuracy: 0.3345\n",
            "Epoch 73/4000\n",
            "11/11 [==============================] - 11s 929ms/step - loss: 1.3535 - accuracy: 0.3331 - val_loss: 1.3543 - val_accuracy: 0.3326\n",
            "Epoch 74/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3541 - accuracy: 0.3308 - val_loss: 1.3539 - val_accuracy: 0.3302\n",
            "Epoch 75/4000\n",
            "11/11 [==============================] - 11s 926ms/step - loss: 1.3535 - accuracy: 0.3317 - val_loss: 1.3522 - val_accuracy: 0.3333\n",
            "Epoch 76/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3525 - accuracy: 0.3316 - val_loss: 1.3517 - val_accuracy: 0.3336\n",
            "Epoch 77/4000\n",
            "11/11 [==============================] - 11s 925ms/step - loss: 1.3516 - accuracy: 0.3327 - val_loss: 1.3548 - val_accuracy: 0.3244\n",
            "Epoch 78/4000\n",
            "11/11 [==============================] - 11s 930ms/step - loss: 1.3547 - accuracy: 0.3266 - val_loss: 1.3544 - val_accuracy: 0.3266\n",
            "Epoch 79/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3547 - accuracy: 0.3253 - val_loss: 1.3568 - val_accuracy: 0.3224\n",
            "Epoch 80/4000\n",
            "11/11 [==============================] - 11s 928ms/step - loss: 1.3570 - accuracy: 0.3218 - val_loss: 1.3586 - val_accuracy: 0.3242\n",
            "Epoch 81/4000\n",
            "11/11 [==============================] - 10s 919ms/step - loss: 1.3586 - accuracy: 0.3208 - val_loss: 1.3564 - val_accuracy: 0.3274\n",
            "Epoch 82/4000\n",
            "11/11 [==============================] - 11s 922ms/step - loss: 1.3563 - accuracy: 0.3290 - val_loss: 1.3548 - val_accuracy: 0.3334\n",
            "Epoch 83/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3549 - accuracy: 0.3328 - val_loss: 1.3544 - val_accuracy: 0.3335\n",
            "Epoch 84/4000\n",
            "11/11 [==============================] - 11s 928ms/step - loss: 1.3545 - accuracy: 0.3328 - val_loss: 1.3543 - val_accuracy: 0.3340\n",
            "Epoch 85/4000\n",
            "11/11 [==============================] - 11s 925ms/step - loss: 1.3544 - accuracy: 0.3328 - val_loss: 1.3558 - val_accuracy: 0.3288\n",
            "Epoch 86/4000\n",
            "11/11 [==============================] - 11s 925ms/step - loss: 1.3564 - accuracy: 0.3267 - val_loss: 1.3567 - val_accuracy: 0.3241\n",
            "Epoch 87/4000\n",
            "11/11 [==============================] - 11s 926ms/step - loss: 1.3572 - accuracy: 0.3226 - val_loss: 1.3569 - val_accuracy: 0.3245\n",
            "Epoch 88/4000\n",
            "11/11 [==============================] - 11s 932ms/step - loss: 1.3565 - accuracy: 0.3250 - val_loss: 1.3548 - val_accuracy: 0.3316\n",
            "Epoch 89/4000\n",
            "11/11 [==============================] - 11s 930ms/step - loss: 1.3549 - accuracy: 0.3311 - val_loss: 1.3541 - val_accuracy: 0.3341\n",
            "Epoch 90/4000\n",
            "11/11 [==============================] - 11s 930ms/step - loss: 1.3544 - accuracy: 0.3329 - val_loss: 1.3540 - val_accuracy: 0.3330\n",
            "Epoch 91/4000\n",
            "11/11 [==============================] - 11s 932ms/step - loss: 1.3540 - accuracy: 0.3316 - val_loss: 1.3536 - val_accuracy: 0.3331\n",
            "Epoch 92/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3537 - accuracy: 0.3320 - val_loss: 1.3537 - val_accuracy: 0.3308\n",
            "Epoch 93/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3548 - accuracy: 0.3291 - val_loss: 1.3587 - val_accuracy: 0.3098\n",
            "Epoch 94/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3586 - accuracy: 0.3084 - val_loss: 1.3580 - val_accuracy: 0.3096\n",
            "Epoch 95/4000\n",
            "11/11 [==============================] - 11s 926ms/step - loss: 1.3578 - accuracy: 0.3101 - val_loss: 1.3568 - val_accuracy: 0.3126\n",
            "Epoch 96/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3564 - accuracy: 0.3134 - val_loss: 1.3553 - val_accuracy: 0.3157\n",
            "Epoch 97/4000\n",
            "11/11 [==============================] - 11s 923ms/step - loss: 1.3553 - accuracy: 0.3145 - val_loss: 1.3549 - val_accuracy: 0.3140\n",
            "Epoch 98/4000\n",
            "11/11 [==============================] - 11s 926ms/step - loss: 1.3550 - accuracy: 0.3140 - val_loss: 1.3546 - val_accuracy: 0.3159\n",
            "Epoch 99/4000\n",
            "11/11 [==============================] - 11s 925ms/step - loss: 1.3547 - accuracy: 0.3150 - val_loss: 1.3544 - val_accuracy: 0.3159\n",
            "Epoch 100/4000\n",
            "11/11 [==============================] - 11s 928ms/step - loss: 1.3546 - accuracy: 0.3150 - val_loss: 1.3569 - val_accuracy: 0.3132\n",
            "Epoch 101/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3591 - accuracy: 0.3121 - val_loss: 1.3593 - val_accuracy: 0.3148\n",
            "Epoch 102/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3592 - accuracy: 0.3138 - val_loss: 1.3589 - val_accuracy: 0.3105\n",
            "Epoch 103/4000\n",
            "11/11 [==============================] - 11s 928ms/step - loss: 1.3589 - accuracy: 0.3127 - val_loss: 1.3586 - val_accuracy: 0.3142\n",
            "Epoch 104/4000\n",
            "11/11 [==============================] - 11s 925ms/step - loss: 1.3587 - accuracy: 0.3146 - val_loss: 1.3586 - val_accuracy: 0.3150\n",
            "Epoch 105/4000\n",
            "11/11 [==============================] - 11s 925ms/step - loss: 1.3586 - accuracy: 0.3151 - val_loss: 1.3585 - val_accuracy: 0.3148\n",
            "Epoch 106/4000\n",
            "11/11 [==============================] - 11s 932ms/step - loss: 1.3585 - accuracy: 0.3152 - val_loss: 1.3584 - val_accuracy: 0.3148\n",
            "Epoch 107/4000\n",
            "11/11 [==============================] - 11s 927ms/step - loss: 1.3585 - accuracy: 0.3152 - val_loss: 1.3584 - val_accuracy: 0.3148\n",
            "Epoch 108/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3584 - accuracy: 0.3153 - val_loss: 1.3583 - val_accuracy: 0.3149\n",
            "Epoch 109/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3583 - accuracy: 0.3154 - val_loss: 1.3583 - val_accuracy: 0.3153\n",
            "Epoch 110/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3583 - accuracy: 0.3154 - val_loss: 1.3582 - val_accuracy: 0.3154\n",
            "Epoch 111/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3582 - accuracy: 0.3153 - val_loss: 1.3581 - val_accuracy: 0.3155\n",
            "Epoch 112/4000\n",
            "11/11 [==============================] - 11s 929ms/step - loss: 1.3581 - accuracy: 0.3154 - val_loss: 1.3581 - val_accuracy: 0.3156\n",
            "Epoch 113/4000\n",
            "11/11 [==============================] - 11s 932ms/step - loss: 1.3581 - accuracy: 0.3157 - val_loss: 1.3580 - val_accuracy: 0.3158\n",
            "Epoch 114/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3580 - accuracy: 0.3157 - val_loss: 1.3579 - val_accuracy: 0.3158\n",
            "Epoch 115/4000\n",
            "11/11 [==============================] - 11s 930ms/step - loss: 1.3578 - accuracy: 0.3160 - val_loss: 1.3577 - val_accuracy: 0.3160\n",
            "Epoch 116/4000\n",
            "11/11 [==============================] - 11s 929ms/step - loss: 1.3577 - accuracy: 0.3160 - val_loss: 1.3574 - val_accuracy: 0.3165\n",
            "Epoch 117/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3572 - accuracy: 0.3163 - val_loss: 1.3556 - val_accuracy: 0.3177\n",
            "Epoch 118/4000\n",
            "11/11 [==============================] - 10s 920ms/step - loss: 1.3555 - accuracy: 0.3166 - val_loss: 1.3548 - val_accuracy: 0.3165\n",
            "Epoch 119/4000\n",
            "11/11 [==============================] - 11s 924ms/step - loss: 1.3548 - accuracy: 0.3169 - val_loss: 1.3544 - val_accuracy: 0.3186\n",
            "Epoch 120/4000\n",
            "11/11 [==============================] - 11s 925ms/step - loss: 1.3549 - accuracy: 0.3171 - val_loss: 1.3582 - val_accuracy: 0.3188\n",
            "Epoch 121/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3564 - accuracy: 0.3168 - val_loss: 1.3548 - val_accuracy: 0.3190\n",
            "Epoch 122/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3548 - accuracy: 0.3178 - val_loss: 1.3544 - val_accuracy: 0.3188\n",
            "Epoch 123/4000\n",
            "11/11 [==============================] - 11s 929ms/step - loss: 1.3545 - accuracy: 0.3179 - val_loss: 1.3540 - val_accuracy: 0.3191\n",
            "Epoch 124/4000\n",
            "11/11 [==============================] - 11s 928ms/step - loss: 1.3541 - accuracy: 0.3186 - val_loss: 1.3536 - val_accuracy: 0.3203\n",
            "Epoch 125/4000\n",
            "11/11 [==============================] - 11s 923ms/step - loss: 1.3537 - accuracy: 0.3191 - val_loss: 1.3538 - val_accuracy: 0.3184\n",
            "Epoch 126/4000\n",
            "11/11 [==============================] - 11s 930ms/step - loss: 1.3542 - accuracy: 0.3188 - val_loss: 1.3572 - val_accuracy: 0.3156\n",
            "Epoch 127/4000\n",
            "11/11 [==============================] - 10s 920ms/step - loss: 1.3562 - accuracy: 0.3163 - val_loss: 1.3550 - val_accuracy: 0.3177\n",
            "Epoch 128/4000\n",
            "11/11 [==============================] - 11s 924ms/step - loss: 1.3554 - accuracy: 0.3173 - val_loss: 1.3555 - val_accuracy: 0.3171\n",
            "Epoch 129/4000\n",
            "11/11 [==============================] - 11s 925ms/step - loss: 1.3550 - accuracy: 0.3176 - val_loss: 1.3542 - val_accuracy: 0.3185\n",
            "Epoch 130/4000\n",
            "11/11 [==============================] - 11s 928ms/step - loss: 1.3542 - accuracy: 0.3180 - val_loss: 1.3538 - val_accuracy: 0.3196\n",
            "Epoch 131/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3539 - accuracy: 0.3187 - val_loss: 1.3532 - val_accuracy: 0.3201\n",
            "Epoch 132/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3533 - accuracy: 0.3195 - val_loss: 1.3523 - val_accuracy: 0.3220\n",
            "Epoch 133/4000\n",
            "11/11 [==============================] - 11s 930ms/step - loss: 1.3528 - accuracy: 0.3227 - val_loss: 1.3526 - val_accuracy: 0.3252\n",
            "Epoch 134/4000\n",
            "11/11 [==============================] - 11s 925ms/step - loss: 1.3527 - accuracy: 0.3258 - val_loss: 1.3517 - val_accuracy: 0.3294\n",
            "Epoch 135/4000\n",
            "11/11 [==============================] - 11s 924ms/step - loss: 1.3534 - accuracy: 0.3258 - val_loss: 1.3535 - val_accuracy: 0.3243\n",
            "Epoch 136/4000\n",
            "11/11 [==============================] - 11s 926ms/step - loss: 1.3535 - accuracy: 0.3239 - val_loss: 1.3517 - val_accuracy: 0.3319\n",
            "Epoch 137/4000\n",
            "11/11 [==============================] - 11s 930ms/step - loss: 1.3517 - accuracy: 0.3309 - val_loss: 1.3519 - val_accuracy: 0.3299\n",
            "Epoch 138/4000\n",
            "11/11 [==============================] - 11s 930ms/step - loss: 1.3516 - accuracy: 0.3303 - val_loss: 1.3508 - val_accuracy: 0.3340\n",
            "Epoch 139/4000\n",
            "11/11 [==============================] - 10s 921ms/step - loss: 1.3516 - accuracy: 0.3311 - val_loss: 1.3545 - val_accuracy: 0.3244\n",
            "Epoch 140/4000\n",
            "11/11 [==============================] - 11s 930ms/step - loss: 1.3546 - accuracy: 0.3235 - val_loss: 1.3538 - val_accuracy: 0.3190\n",
            "Epoch 141/4000\n",
            "11/11 [==============================] - 11s 930ms/step - loss: 1.3540 - accuracy: 0.3203 - val_loss: 1.3535 - val_accuracy: 0.3209\n",
            "Epoch 142/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3535 - accuracy: 0.3202 - val_loss: 1.3530 - val_accuracy: 0.3238\n",
            "Epoch 143/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3532 - accuracy: 0.3221 - val_loss: 1.3531 - val_accuracy: 0.3236\n",
            "Epoch 144/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3536 - accuracy: 0.3233 - val_loss: 1.3519 - val_accuracy: 0.3259\n",
            "Epoch 145/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3520 - accuracy: 0.3272 - val_loss: 1.3505 - val_accuracy: 0.3334\n",
            "Epoch 146/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3512 - accuracy: 0.3325 - val_loss: 1.3516 - val_accuracy: 0.3317\n",
            "Epoch 147/4000\n",
            "11/11 [==============================] - 11s 926ms/step - loss: 1.3518 - accuracy: 0.3324 - val_loss: 1.3516 - val_accuracy: 0.3312\n",
            "Epoch 148/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3539 - accuracy: 0.3313 - val_loss: 1.3557 - val_accuracy: 0.3277\n",
            "Epoch 149/4000\n",
            "11/11 [==============================] - 11s 927ms/step - loss: 1.3559 - accuracy: 0.3276 - val_loss: 1.3573 - val_accuracy: 0.3225\n",
            "Epoch 150/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3575 - accuracy: 0.3213 - val_loss: 1.3567 - val_accuracy: 0.3244\n",
            "Epoch 151/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3562 - accuracy: 0.3252 - val_loss: 1.3551 - val_accuracy: 0.3283\n",
            "Epoch 152/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3546 - accuracy: 0.3290 - val_loss: 1.3543 - val_accuracy: 0.3303\n",
            "Epoch 153/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3540 - accuracy: 0.3293 - val_loss: 1.3535 - val_accuracy: 0.3289\n",
            "Epoch 154/4000\n",
            "11/11 [==============================] - 11s 930ms/step - loss: 1.3532 - accuracy: 0.3284 - val_loss: 1.3518 - val_accuracy: 0.3300\n",
            "Epoch 155/4000\n",
            "11/11 [==============================] - 11s 927ms/step - loss: 1.3519 - accuracy: 0.3310 - val_loss: 1.3539 - val_accuracy: 0.3353\n",
            "Epoch 156/4000\n",
            "11/11 [==============================] - 11s 932ms/step - loss: 1.3548 - accuracy: 0.3322 - val_loss: 1.3538 - val_accuracy: 0.3331\n",
            "Epoch 157/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3537 - accuracy: 0.3320 - val_loss: 1.3539 - val_accuracy: 0.3266\n",
            "Epoch 158/4000\n",
            "11/11 [==============================] - 11s 932ms/step - loss: 1.3532 - accuracy: 0.3279 - val_loss: 1.3521 - val_accuracy: 0.3307\n",
            "Epoch 159/4000\n",
            "11/11 [==============================] - 11s 924ms/step - loss: 1.3520 - accuracy: 0.3313 - val_loss: 1.3509 - val_accuracy: 0.3317\n",
            "Epoch 160/4000\n",
            "11/11 [==============================] - 11s 924ms/step - loss: 1.3511 - accuracy: 0.3319 - val_loss: 1.3502 - val_accuracy: 0.3338\n",
            "Epoch 161/4000\n",
            "11/11 [==============================] - 11s 928ms/step - loss: 1.3507 - accuracy: 0.3334 - val_loss: 1.3504 - val_accuracy: 0.3350\n",
            "Epoch 162/4000\n",
            "11/11 [==============================] - 11s 928ms/step - loss: 1.3507 - accuracy: 0.3342 - val_loss: 1.3498 - val_accuracy: 0.3355\n",
            "Epoch 163/4000\n",
            "11/11 [==============================] - 11s 929ms/step - loss: 1.3499 - accuracy: 0.3350 - val_loss: 1.3495 - val_accuracy: 0.3357\n",
            "Epoch 164/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3497 - accuracy: 0.3347 - val_loss: 1.3503 - val_accuracy: 0.3344\n",
            "Epoch 165/4000\n",
            "11/11 [==============================] - 11s 926ms/step - loss: 1.3505 - accuracy: 0.3330 - val_loss: 1.3498 - val_accuracy: 0.3340\n",
            "Epoch 166/4000\n",
            "11/11 [==============================] - 11s 929ms/step - loss: 1.3500 - accuracy: 0.3335 - val_loss: 1.3499 - val_accuracy: 0.3342\n",
            "Epoch 167/4000\n",
            "11/11 [==============================] - 11s 929ms/step - loss: 1.3502 - accuracy: 0.3339 - val_loss: 1.3504 - val_accuracy: 0.3355\n",
            "Epoch 168/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3530 - accuracy: 0.3302 - val_loss: 1.3540 - val_accuracy: 0.3291\n",
            "Epoch 169/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3538 - accuracy: 0.3273 - val_loss: 1.3519 - val_accuracy: 0.3346\n",
            "Epoch 170/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3518 - accuracy: 0.3337 - val_loss: 1.3503 - val_accuracy: 0.3362\n",
            "Epoch 171/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3506 - accuracy: 0.3352 - val_loss: 1.3500 - val_accuracy: 0.3350\n",
            "Epoch 172/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3502 - accuracy: 0.3349 - val_loss: 1.3496 - val_accuracy: 0.3363\n",
            "Epoch 173/4000\n",
            "11/11 [==============================] - 11s 928ms/step - loss: 1.3499 - accuracy: 0.3356 - val_loss: 1.3495 - val_accuracy: 0.3366\n",
            "Epoch 174/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3499 - accuracy: 0.3356 - val_loss: 1.3497 - val_accuracy: 0.3364\n",
            "Epoch 175/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3528 - accuracy: 0.3291 - val_loss: 1.3584 - val_accuracy: 0.3158\n",
            "Epoch 176/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3582 - accuracy: 0.3148 - val_loss: 1.3580 - val_accuracy: 0.3151\n",
            "Epoch 177/4000\n",
            "11/11 [==============================] - 11s 925ms/step - loss: 1.3579 - accuracy: 0.3153 - val_loss: 1.3574 - val_accuracy: 0.3148\n",
            "Epoch 178/4000\n",
            "11/11 [==============================] - 11s 928ms/step - loss: 1.3571 - accuracy: 0.3157 - val_loss: 1.3556 - val_accuracy: 0.3163\n",
            "Epoch 179/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3556 - accuracy: 0.3160 - val_loss: 1.3541 - val_accuracy: 0.3173\n",
            "Epoch 180/4000\n",
            "11/11 [==============================] - 11s 930ms/step - loss: 1.3543 - accuracy: 0.3169 - val_loss: 1.3539 - val_accuracy: 0.3175\n",
            "Epoch 181/4000\n",
            "11/11 [==============================] - 11s 929ms/step - loss: 1.3540 - accuracy: 0.3171 - val_loss: 1.3536 - val_accuracy: 0.3181\n",
            "Epoch 182/4000\n",
            "11/11 [==============================] - 11s 932ms/step - loss: 1.3537 - accuracy: 0.3175 - val_loss: 1.3533 - val_accuracy: 0.3190\n",
            "Epoch 183/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3535 - accuracy: 0.3184 - val_loss: 1.3537 - val_accuracy: 0.3188\n",
            "Epoch 184/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3546 - accuracy: 0.3184 - val_loss: 1.3542 - val_accuracy: 0.3186\n",
            "Epoch 185/4000\n",
            "11/11 [==============================] - 11s 928ms/step - loss: 1.3544 - accuracy: 0.3184 - val_loss: 1.3539 - val_accuracy: 0.3189\n",
            "Epoch 186/4000\n",
            "11/11 [==============================] - 11s 932ms/step - loss: 1.3538 - accuracy: 0.3191 - val_loss: 1.3533 - val_accuracy: 0.3194\n",
            "Epoch 187/4000\n",
            "11/11 [==============================] - 11s 930ms/step - loss: 1.3533 - accuracy: 0.3197 - val_loss: 1.3526 - val_accuracy: 0.3215\n",
            "Epoch 188/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3527 - accuracy: 0.3222 - val_loss: 1.3517 - val_accuracy: 0.3266\n",
            "Epoch 189/4000\n",
            "11/11 [==============================] - 11s 926ms/step - loss: 1.3518 - accuracy: 0.3277 - val_loss: 1.3547 - val_accuracy: 0.3328\n",
            "Epoch 190/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3539 - accuracy: 0.3299 - val_loss: 1.3522 - val_accuracy: 0.3296\n",
            "Epoch 191/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3521 - accuracy: 0.3319 - val_loss: 1.3510 - val_accuracy: 0.3350\n",
            "Epoch 192/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3513 - accuracy: 0.3340 - val_loss: 1.3505 - val_accuracy: 0.3360\n",
            "Epoch 193/4000\n",
            "11/11 [==============================] - 11s 927ms/step - loss: 1.3507 - accuracy: 0.3347 - val_loss: 1.3520 - val_accuracy: 0.3269\n",
            "Epoch 194/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3518 - accuracy: 0.3291 - val_loss: 1.3513 - val_accuracy: 0.3327\n",
            "Epoch 195/4000\n",
            "11/11 [==============================] - 10s 919ms/step - loss: 1.3515 - accuracy: 0.3334 - val_loss: 1.3504 - val_accuracy: 0.3352\n",
            "Epoch 196/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3507 - accuracy: 0.3347 - val_loss: 1.3502 - val_accuracy: 0.3360\n",
            "Epoch 197/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3504 - accuracy: 0.3353 - val_loss: 1.3499 - val_accuracy: 0.3362\n",
            "Epoch 198/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3503 - accuracy: 0.3353 - val_loss: 1.3510 - val_accuracy: 0.3333\n",
            "Epoch 199/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3508 - accuracy: 0.3340 - val_loss: 1.3519 - val_accuracy: 0.3323\n",
            "Epoch 200/4000\n",
            "11/11 [==============================] - 11s 925ms/step - loss: 1.3520 - accuracy: 0.3326 - val_loss: 1.3524 - val_accuracy: 0.3316\n",
            "Epoch 201/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3532 - accuracy: 0.3256 - val_loss: 1.3523 - val_accuracy: 0.3288\n",
            "Epoch 202/4000\n",
            "11/11 [==============================] - 11s 930ms/step - loss: 1.3520 - accuracy: 0.3306 - val_loss: 1.3507 - val_accuracy: 0.3349\n",
            "Epoch 203/4000\n",
            "11/11 [==============================] - 11s 932ms/step - loss: 1.3509 - accuracy: 0.3347 - val_loss: 1.3501 - val_accuracy: 0.3366\n",
            "Epoch 204/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3503 - accuracy: 0.3352 - val_loss: 1.3494 - val_accuracy: 0.3369\n",
            "Epoch 205/4000\n",
            "11/11 [==============================] - 11s 929ms/step - loss: 1.3497 - accuracy: 0.3360 - val_loss: 1.3490 - val_accuracy: 0.3371\n",
            "Epoch 206/4000\n",
            "11/11 [==============================] - 11s 932ms/step - loss: 1.3493 - accuracy: 0.3359 - val_loss: 1.3491 - val_accuracy: 0.3358\n",
            "Epoch 207/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3492 - accuracy: 0.3356 - val_loss: 1.3511 - val_accuracy: 0.3333\n",
            "Epoch 208/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3534 - accuracy: 0.3280 - val_loss: 1.3534 - val_accuracy: 0.3272\n",
            "Epoch 209/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3533 - accuracy: 0.3252 - val_loss: 1.3523 - val_accuracy: 0.3254\n",
            "Epoch 210/4000\n",
            "11/11 [==============================] - 11s 928ms/step - loss: 1.3522 - accuracy: 0.3247 - val_loss: 1.3527 - val_accuracy: 0.3245\n",
            "Epoch 211/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3522 - accuracy: 0.3281 - val_loss: 1.3505 - val_accuracy: 0.3334\n",
            "Epoch 212/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3507 - accuracy: 0.3327 - val_loss: 1.3500 - val_accuracy: 0.3351\n",
            "Epoch 213/4000\n",
            "11/11 [==============================] - 11s 928ms/step - loss: 1.3502 - accuracy: 0.3346 - val_loss: 1.3540 - val_accuracy: 0.3195\n",
            "Epoch 214/4000\n",
            "11/11 [==============================] - 11s 929ms/step - loss: 1.3547 - accuracy: 0.3215 - val_loss: 1.3592 - val_accuracy: 0.3090\n",
            "Epoch 215/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3586 - accuracy: 0.3143 - val_loss: 1.3579 - val_accuracy: 0.3197\n",
            "Epoch 216/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3581 - accuracy: 0.3188 - val_loss: 1.3574 - val_accuracy: 0.3227\n",
            "Epoch 217/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3574 - accuracy: 0.3229 - val_loss: 1.3559 - val_accuracy: 0.3305\n",
            "Epoch 218/4000\n",
            "11/11 [==============================] - 11s 926ms/step - loss: 1.3556 - accuracy: 0.3297 - val_loss: 1.3545 - val_accuracy: 0.3318\n",
            "Epoch 219/4000\n",
            "11/11 [==============================] - 11s 927ms/step - loss: 1.3547 - accuracy: 0.3307 - val_loss: 1.3542 - val_accuracy: 0.3314\n",
            "Epoch 220/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3543 - accuracy: 0.3300 - val_loss: 1.3538 - val_accuracy: 0.3310\n",
            "Epoch 221/4000\n",
            "11/11 [==============================] - 11s 930ms/step - loss: 1.3540 - accuracy: 0.3295 - val_loss: 1.3538 - val_accuracy: 0.3295\n",
            "Epoch 222/4000\n",
            "11/11 [==============================] - 11s 929ms/step - loss: 1.3552 - accuracy: 0.3267 - val_loss: 1.3558 - val_accuracy: 0.3298\n",
            "Epoch 223/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3558 - accuracy: 0.3262 - val_loss: 1.3556 - val_accuracy: 0.3245\n",
            "Epoch 224/4000\n",
            "11/11 [==============================] - 11s 932ms/step - loss: 1.3568 - accuracy: 0.3216 - val_loss: 1.3566 - val_accuracy: 0.3234\n",
            "Epoch 225/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3560 - accuracy: 0.3234 - val_loss: 1.3548 - val_accuracy: 0.3284\n",
            "Epoch 226/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3549 - accuracy: 0.3275 - val_loss: 1.3544 - val_accuracy: 0.3299\n",
            "Epoch 227/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3545 - accuracy: 0.3281 - val_loss: 1.3541 - val_accuracy: 0.3288\n",
            "Epoch 228/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3542 - accuracy: 0.3272 - val_loss: 1.3539 - val_accuracy: 0.3278\n",
            "Epoch 229/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3540 - accuracy: 0.3267 - val_loss: 1.3537 - val_accuracy: 0.3281\n",
            "Epoch 230/4000\n",
            "11/11 [==============================] - 11s 930ms/step - loss: 1.3538 - accuracy: 0.3267 - val_loss: 1.3535 - val_accuracy: 0.3284\n",
            "Epoch 231/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3540 - accuracy: 0.3258 - val_loss: 1.3547 - val_accuracy: 0.3248\n",
            "Epoch 232/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3546 - accuracy: 0.3243 - val_loss: 1.3539 - val_accuracy: 0.3281\n",
            "Epoch 233/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3539 - accuracy: 0.3262 - val_loss: 1.3534 - val_accuracy: 0.3271\n",
            "Epoch 234/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3535 - accuracy: 0.3265 - val_loss: 1.3531 - val_accuracy: 0.3277\n",
            "Epoch 235/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3533 - accuracy: 0.3266 - val_loss: 1.3529 - val_accuracy: 0.3287\n",
            "Epoch 236/4000\n",
            "11/11 [==============================] - 11s 930ms/step - loss: 1.3531 - accuracy: 0.3272 - val_loss: 1.3528 - val_accuracy: 0.3293\n",
            "Epoch 237/4000\n",
            "11/11 [==============================] - 11s 932ms/step - loss: 1.3533 - accuracy: 0.3270 - val_loss: 1.3530 - val_accuracy: 0.3278\n",
            "Epoch 238/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3552 - accuracy: 0.3227 - val_loss: 1.3547 - val_accuracy: 0.3223\n",
            "Epoch 239/4000\n",
            "11/11 [==============================] - 11s 932ms/step - loss: 1.3548 - accuracy: 0.3213 - val_loss: 1.3530 - val_accuracy: 0.3259\n",
            "Epoch 240/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3531 - accuracy: 0.3259 - val_loss: 1.3519 - val_accuracy: 0.3324\n",
            "Epoch 241/4000\n",
            "11/11 [==============================] - 11s 930ms/step - loss: 1.3516 - accuracy: 0.3332 - val_loss: 1.3505 - val_accuracy: 0.3361\n",
            "Epoch 242/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3506 - accuracy: 0.3352 - val_loss: 1.3502 - val_accuracy: 0.3360\n",
            "Epoch 243/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3505 - accuracy: 0.3345 - val_loss: 1.3501 - val_accuracy: 0.3362\n",
            "Epoch 244/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3505 - accuracy: 0.3348 - val_loss: 1.3495 - val_accuracy: 0.3364\n",
            "Epoch 245/4000\n",
            "11/11 [==============================] - 11s 932ms/step - loss: 1.3500 - accuracy: 0.3354 - val_loss: 1.3498 - val_accuracy: 0.3357\n",
            "Epoch 246/4000\n",
            "11/11 [==============================] - 11s 930ms/step - loss: 1.3505 - accuracy: 0.3336 - val_loss: 1.3502 - val_accuracy: 0.3362\n",
            "Epoch 247/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3504 - accuracy: 0.3345 - val_loss: 1.3536 - val_accuracy: 0.3335\n",
            "Epoch 248/4000\n",
            "11/11 [==============================] - 11s 926ms/step - loss: 1.3553 - accuracy: 0.3280 - val_loss: 1.3544 - val_accuracy: 0.3296\n",
            "Epoch 249/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3548 - accuracy: 0.3286 - val_loss: 1.3539 - val_accuracy: 0.3293\n",
            "Epoch 250/4000\n",
            "11/11 [==============================] - 11s 940ms/step - loss: 1.3538 - accuracy: 0.3288 - val_loss: 1.3531 - val_accuracy: 0.3319\n",
            "Epoch 251/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3532 - accuracy: 0.3299 - val_loss: 1.3523 - val_accuracy: 0.3332\n",
            "Epoch 252/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3522 - accuracy: 0.3328 - val_loss: 1.3506 - val_accuracy: 0.3350\n",
            "Epoch 253/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3506 - accuracy: 0.3345 - val_loss: 1.3500 - val_accuracy: 0.3350\n",
            "Epoch 254/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3507 - accuracy: 0.3334 - val_loss: 1.3497 - val_accuracy: 0.3360\n",
            "Epoch 255/4000\n",
            "11/11 [==============================] - 11s 932ms/step - loss: 1.3500 - accuracy: 0.3353 - val_loss: 1.3495 - val_accuracy: 0.3359\n",
            "Epoch 256/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3498 - accuracy: 0.3354 - val_loss: 1.3501 - val_accuracy: 0.3361\n",
            "Epoch 257/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3502 - accuracy: 0.3352 - val_loss: 1.3497 - val_accuracy: 0.3344\n",
            "Epoch 258/4000\n",
            "11/11 [==============================] - 11s 932ms/step - loss: 1.3498 - accuracy: 0.3346 - val_loss: 1.3492 - val_accuracy: 0.3361\n",
            "Epoch 259/4000\n",
            "11/11 [==============================] - 11s 932ms/step - loss: 1.3496 - accuracy: 0.3352 - val_loss: 1.3497 - val_accuracy: 0.3369\n",
            "Epoch 260/4000\n",
            "11/11 [==============================] - 11s 940ms/step - loss: 1.3497 - accuracy: 0.3354 - val_loss: 1.3497 - val_accuracy: 0.3363\n",
            "Epoch 261/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3495 - accuracy: 0.3353 - val_loss: 1.3484 - val_accuracy: 0.3362\n",
            "Epoch 262/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3486 - accuracy: 0.3357 - val_loss: 1.3478 - val_accuracy: 0.3372\n",
            "Epoch 263/4000\n",
            "11/11 [==============================] - 11s 930ms/step - loss: 1.3482 - accuracy: 0.3359 - val_loss: 1.3477 - val_accuracy: 0.3371\n",
            "Epoch 264/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3479 - accuracy: 0.3365 - val_loss: 1.3478 - val_accuracy: 0.3376\n",
            "Epoch 265/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3479 - accuracy: 0.3367 - val_loss: 1.3479 - val_accuracy: 0.3358\n",
            "Epoch 266/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3482 - accuracy: 0.3360 - val_loss: 1.3476 - val_accuracy: 0.3373\n",
            "Epoch 267/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3496 - accuracy: 0.3339 - val_loss: 1.3527 - val_accuracy: 0.3282\n",
            "Epoch 268/4000\n",
            "11/11 [==============================] - 11s 940ms/step - loss: 1.3523 - accuracy: 0.3297 - val_loss: 1.3507 - val_accuracy: 0.3336\n",
            "Epoch 269/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3508 - accuracy: 0.3334 - val_loss: 1.3494 - val_accuracy: 0.3368\n",
            "Epoch 270/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3497 - accuracy: 0.3358 - val_loss: 1.3491 - val_accuracy: 0.3363\n",
            "Epoch 271/4000\n",
            "11/11 [==============================] - 11s 928ms/step - loss: 1.3494 - accuracy: 0.3358 - val_loss: 1.3493 - val_accuracy: 0.3376\n",
            "Epoch 272/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3494 - accuracy: 0.3363 - val_loss: 1.3490 - val_accuracy: 0.3362\n",
            "Epoch 273/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3494 - accuracy: 0.3356 - val_loss: 1.3483 - val_accuracy: 0.3376\n",
            "Epoch 274/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3485 - accuracy: 0.3363 - val_loss: 1.3475 - val_accuracy: 0.3377\n",
            "Epoch 275/4000\n",
            "11/11 [==============================] - 11s 928ms/step - loss: 1.3478 - accuracy: 0.3366 - val_loss: 1.3474 - val_accuracy: 0.3370\n",
            "Epoch 276/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3478 - accuracy: 0.3362 - val_loss: 1.3473 - val_accuracy: 0.3371\n",
            "Epoch 277/4000\n",
            "11/11 [==============================] - 11s 928ms/step - loss: 1.3475 - accuracy: 0.3367 - val_loss: 1.3472 - val_accuracy: 0.3378\n",
            "Epoch 278/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3478 - accuracy: 0.3365 - val_loss: 1.3478 - val_accuracy: 0.3375\n",
            "Epoch 279/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3490 - accuracy: 0.3351 - val_loss: 1.3501 - val_accuracy: 0.3341\n",
            "Epoch 280/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3505 - accuracy: 0.3337 - val_loss: 1.3501 - val_accuracy: 0.3320\n",
            "Epoch 281/4000\n",
            "11/11 [==============================] - 11s 932ms/step - loss: 1.3502 - accuracy: 0.3328 - val_loss: 1.3486 - val_accuracy: 0.3359\n",
            "Epoch 282/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3489 - accuracy: 0.3354 - val_loss: 1.3478 - val_accuracy: 0.3372\n",
            "Epoch 283/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3479 - accuracy: 0.3365 - val_loss: 1.3471 - val_accuracy: 0.3378\n",
            "Epoch 284/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3475 - accuracy: 0.3370 - val_loss: 1.3469 - val_accuracy: 0.3379\n",
            "Epoch 285/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3473 - accuracy: 0.3370 - val_loss: 1.3468 - val_accuracy: 0.3380\n",
            "Epoch 286/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3472 - accuracy: 0.3371 - val_loss: 1.3468 - val_accuracy: 0.3380\n",
            "Epoch 287/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3473 - accuracy: 0.3370 - val_loss: 1.3511 - val_accuracy: 0.3374\n",
            "Epoch 288/4000\n",
            "11/11 [==============================] - 11s 932ms/step - loss: 1.3537 - accuracy: 0.3286 - val_loss: 1.3537 - val_accuracy: 0.3265\n",
            "Epoch 289/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3530 - accuracy: 0.3276 - val_loss: 1.3513 - val_accuracy: 0.3320\n",
            "Epoch 290/4000\n",
            "11/11 [==============================] - 11s 932ms/step - loss: 1.3512 - accuracy: 0.3319 - val_loss: 1.3496 - val_accuracy: 0.3351\n",
            "Epoch 291/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3499 - accuracy: 0.3345 - val_loss: 1.3493 - val_accuracy: 0.3359\n",
            "Epoch 292/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3496 - accuracy: 0.3350 - val_loss: 1.3490 - val_accuracy: 0.3362\n",
            "Epoch 293/4000\n",
            "11/11 [==============================] - 11s 940ms/step - loss: 1.3493 - accuracy: 0.3353 - val_loss: 1.3488 - val_accuracy: 0.3360\n",
            "Epoch 294/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3491 - accuracy: 0.3352 - val_loss: 1.3486 - val_accuracy: 0.3361\n",
            "Epoch 295/4000\n",
            "11/11 [==============================] - 11s 927ms/step - loss: 1.3489 - accuracy: 0.3354 - val_loss: 1.3484 - val_accuracy: 0.3365\n",
            "Epoch 296/4000\n",
            "11/11 [==============================] - 11s 941ms/step - loss: 1.3487 - accuracy: 0.3356 - val_loss: 1.3486 - val_accuracy: 0.3360\n",
            "Epoch 297/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3487 - accuracy: 0.3355 - val_loss: 1.3476 - val_accuracy: 0.3377\n",
            "Epoch 298/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3478 - accuracy: 0.3366 - val_loss: 1.3476 - val_accuracy: 0.3379\n",
            "Epoch 299/4000\n",
            "11/11 [==============================] - 11s 940ms/step - loss: 1.3478 - accuracy: 0.3369 - val_loss: 1.3470 - val_accuracy: 0.3379\n",
            "Epoch 300/4000\n",
            "11/11 [==============================] - 11s 932ms/step - loss: 1.3475 - accuracy: 0.3369 - val_loss: 1.3471 - val_accuracy: 0.3380\n",
            "Epoch 301/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3475 - accuracy: 0.3367 - val_loss: 1.3481 - val_accuracy: 0.3351\n",
            "Epoch 302/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3484 - accuracy: 0.3342 - val_loss: 1.3475 - val_accuracy: 0.3366\n",
            "Epoch 303/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3481 - accuracy: 0.3361 - val_loss: 1.3488 - val_accuracy: 0.3377\n",
            "Epoch 304/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3497 - accuracy: 0.3356 - val_loss: 1.3498 - val_accuracy: 0.3328\n",
            "Epoch 305/4000\n",
            "11/11 [==============================] - 11s 932ms/step - loss: 1.3498 - accuracy: 0.3349 - val_loss: 1.3485 - val_accuracy: 0.3372\n",
            "Epoch 306/4000\n",
            "11/11 [==============================] - 11s 943ms/step - loss: 1.3489 - accuracy: 0.3353 - val_loss: 1.3480 - val_accuracy: 0.3372\n",
            "Epoch 307/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3482 - accuracy: 0.3363 - val_loss: 1.3477 - val_accuracy: 0.3367\n",
            "Epoch 308/4000\n",
            "11/11 [==============================] - 11s 929ms/step - loss: 1.3478 - accuracy: 0.3362 - val_loss: 1.3474 - val_accuracy: 0.3362\n",
            "Epoch 309/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3480 - accuracy: 0.3354 - val_loss: 1.3478 - val_accuracy: 0.3370\n",
            "Epoch 310/4000\n",
            "11/11 [==============================] - 11s 932ms/step - loss: 1.3481 - accuracy: 0.3361 - val_loss: 1.3476 - val_accuracy: 0.3377\n",
            "Epoch 311/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3483 - accuracy: 0.3359 - val_loss: 1.3493 - val_accuracy: 0.3364\n",
            "Epoch 312/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3503 - accuracy: 0.3340 - val_loss: 1.3501 - val_accuracy: 0.3305\n",
            "Epoch 313/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3501 - accuracy: 0.3311 - val_loss: 1.3484 - val_accuracy: 0.3359\n",
            "Epoch 314/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3489 - accuracy: 0.3352 - val_loss: 1.3505 - val_accuracy: 0.3362\n",
            "Epoch 315/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3508 - accuracy: 0.3352 - val_loss: 1.3492 - val_accuracy: 0.3361\n",
            "Epoch 316/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3495 - accuracy: 0.3357 - val_loss: 1.3486 - val_accuracy: 0.3372\n",
            "Epoch 317/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3489 - accuracy: 0.3359 - val_loss: 1.3478 - val_accuracy: 0.3368\n",
            "Epoch 318/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3481 - accuracy: 0.3361 - val_loss: 1.3479 - val_accuracy: 0.3369\n",
            "Epoch 319/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3482 - accuracy: 0.3357 - val_loss: 1.3481 - val_accuracy: 0.3368\n",
            "Epoch 320/4000\n",
            "11/11 [==============================] - 11s 930ms/step - loss: 1.3490 - accuracy: 0.3340 - val_loss: 1.3485 - val_accuracy: 0.3364\n",
            "Epoch 321/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3502 - accuracy: 0.3333 - val_loss: 1.3505 - val_accuracy: 0.3306\n",
            "Epoch 322/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3507 - accuracy: 0.3296 - val_loss: 1.3495 - val_accuracy: 0.3341\n",
            "Epoch 323/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3498 - accuracy: 0.3338 - val_loss: 1.3489 - val_accuracy: 0.3361\n",
            "Epoch 324/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3493 - accuracy: 0.3349 - val_loss: 1.3491 - val_accuracy: 0.3346\n",
            "Epoch 325/4000\n",
            "11/11 [==============================] - 11s 925ms/step - loss: 1.3500 - accuracy: 0.3330 - val_loss: 1.3488 - val_accuracy: 0.3361\n",
            "Epoch 326/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3490 - accuracy: 0.3355 - val_loss: 1.3476 - val_accuracy: 0.3376\n",
            "Epoch 327/4000\n",
            "11/11 [==============================] - 11s 929ms/step - loss: 1.3479 - accuracy: 0.3367 - val_loss: 1.3473 - val_accuracy: 0.3379\n",
            "Epoch 328/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3475 - accuracy: 0.3369 - val_loss: 1.3470 - val_accuracy: 0.3379\n",
            "Epoch 329/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3474 - accuracy: 0.3369 - val_loss: 1.3470 - val_accuracy: 0.3379\n",
            "Epoch 330/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3474 - accuracy: 0.3368 - val_loss: 1.3475 - val_accuracy: 0.3364\n",
            "Epoch 331/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3477 - accuracy: 0.3362 - val_loss: 1.3472 - val_accuracy: 0.3376\n",
            "Epoch 332/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3476 - accuracy: 0.3364 - val_loss: 1.3472 - val_accuracy: 0.3378\n",
            "Epoch 333/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3475 - accuracy: 0.3367 - val_loss: 1.3469 - val_accuracy: 0.3379\n",
            "Epoch 334/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3472 - accuracy: 0.3370 - val_loss: 1.3467 - val_accuracy: 0.3380\n",
            "Epoch 335/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3472 - accuracy: 0.3371 - val_loss: 1.3469 - val_accuracy: 0.3381\n",
            "Epoch 336/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3474 - accuracy: 0.3371 - val_loss: 1.3476 - val_accuracy: 0.3371\n",
            "Epoch 337/4000\n",
            "11/11 [==============================] - 11s 932ms/step - loss: 1.3479 - accuracy: 0.3364 - val_loss: 1.3485 - val_accuracy: 0.3360\n",
            "Epoch 338/4000\n",
            "11/11 [==============================] - 11s 941ms/step - loss: 1.3493 - accuracy: 0.3343 - val_loss: 1.3484 - val_accuracy: 0.3372\n",
            "Epoch 339/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3489 - accuracy: 0.3360 - val_loss: 1.3486 - val_accuracy: 0.3353\n",
            "Epoch 340/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3487 - accuracy: 0.3356 - val_loss: 1.3475 - val_accuracy: 0.3376\n",
            "Epoch 341/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3478 - accuracy: 0.3364 - val_loss: 1.3473 - val_accuracy: 0.3374\n",
            "Epoch 342/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3475 - accuracy: 0.3367 - val_loss: 1.3469 - val_accuracy: 0.3378\n",
            "Epoch 343/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3473 - accuracy: 0.3370 - val_loss: 1.3467 - val_accuracy: 0.3382\n",
            "Epoch 344/4000\n",
            "11/11 [==============================] - 11s 930ms/step - loss: 1.3471 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 345/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 346/4000\n",
            "11/11 [==============================] - 11s 943ms/step - loss: 1.3472 - accuracy: 0.3369 - val_loss: 1.3498 - val_accuracy: 0.3324\n",
            "Epoch 347/4000\n",
            "11/11 [==============================] - 11s 932ms/step - loss: 1.3507 - accuracy: 0.3297 - val_loss: 1.3509 - val_accuracy: 0.3337\n",
            "Epoch 348/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3513 - accuracy: 0.3326 - val_loss: 1.3516 - val_accuracy: 0.3304\n",
            "Epoch 349/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3524 - accuracy: 0.3270 - val_loss: 1.3514 - val_accuracy: 0.3340\n",
            "Epoch 350/4000\n",
            "11/11 [==============================] - 11s 932ms/step - loss: 1.3516 - accuracy: 0.3319 - val_loss: 1.3501 - val_accuracy: 0.3349\n",
            "Epoch 351/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3501 - accuracy: 0.3342 - val_loss: 1.3494 - val_accuracy: 0.3359\n",
            "Epoch 352/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3496 - accuracy: 0.3355 - val_loss: 1.3494 - val_accuracy: 0.3356\n",
            "Epoch 353/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3500 - accuracy: 0.3341 - val_loss: 1.3501 - val_accuracy: 0.3350\n",
            "Epoch 354/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3499 - accuracy: 0.3345 - val_loss: 1.3489 - val_accuracy: 0.3370\n",
            "Epoch 355/4000\n",
            "11/11 [==============================] - 11s 930ms/step - loss: 1.3492 - accuracy: 0.3359 - val_loss: 1.3488 - val_accuracy: 0.3371\n",
            "Epoch 356/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3490 - accuracy: 0.3362 - val_loss: 1.3485 - val_accuracy: 0.3372\n",
            "Epoch 357/4000\n",
            "11/11 [==============================] - 11s 930ms/step - loss: 1.3487 - accuracy: 0.3363 - val_loss: 1.3479 - val_accuracy: 0.3370\n",
            "Epoch 358/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3481 - accuracy: 0.3365 - val_loss: 1.3470 - val_accuracy: 0.3378\n",
            "Epoch 359/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3473 - accuracy: 0.3370 - val_loss: 1.3469 - val_accuracy: 0.3381\n",
            "Epoch 360/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3472 - accuracy: 0.3372 - val_loss: 1.3468 - val_accuracy: 0.3381\n",
            "Epoch 361/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3472 - accuracy: 0.3372 - val_loss: 1.3468 - val_accuracy: 0.3380\n",
            "Epoch 362/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3472 - accuracy: 0.3371 - val_loss: 1.3480 - val_accuracy: 0.3355\n",
            "Epoch 363/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3485 - accuracy: 0.3345 - val_loss: 1.3518 - val_accuracy: 0.3239\n",
            "Epoch 364/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3526 - accuracy: 0.3287 - val_loss: 1.3512 - val_accuracy: 0.3341\n",
            "Epoch 365/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3513 - accuracy: 0.3324 - val_loss: 1.3497 - val_accuracy: 0.3361\n",
            "Epoch 366/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3497 - accuracy: 0.3349 - val_loss: 1.3483 - val_accuracy: 0.3363\n",
            "Epoch 367/4000\n",
            "11/11 [==============================] - 11s 930ms/step - loss: 1.3484 - accuracy: 0.3358 - val_loss: 1.3474 - val_accuracy: 0.3376\n",
            "Epoch 368/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3477 - accuracy: 0.3368 - val_loss: 1.3476 - val_accuracy: 0.3373\n",
            "Epoch 369/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3478 - accuracy: 0.3364 - val_loss: 1.3470 - val_accuracy: 0.3378\n",
            "Epoch 370/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3473 - accuracy: 0.3370 - val_loss: 1.3468 - val_accuracy: 0.3381\n",
            "Epoch 371/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3472 - accuracy: 0.3371 - val_loss: 1.3467 - val_accuracy: 0.3381\n",
            "Epoch 372/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3471 - accuracy: 0.3371 - val_loss: 1.3468 - val_accuracy: 0.3380\n",
            "Epoch 373/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3474 - accuracy: 0.3370 - val_loss: 1.3483 - val_accuracy: 0.3376\n",
            "Epoch 374/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3486 - accuracy: 0.3362 - val_loss: 1.3474 - val_accuracy: 0.3375\n",
            "Epoch 375/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3477 - accuracy: 0.3367 - val_loss: 1.3469 - val_accuracy: 0.3379\n",
            "Epoch 376/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3473 - accuracy: 0.3370 - val_loss: 1.3469 - val_accuracy: 0.3379\n",
            "Epoch 377/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3472 - accuracy: 0.3370 - val_loss: 1.3467 - val_accuracy: 0.3380\n",
            "Epoch 378/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3471 - accuracy: 0.3371 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 379/4000\n",
            "11/11 [==============================] - 11s 925ms/step - loss: 1.3471 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 380/4000\n",
            "11/11 [==============================] - 11s 941ms/step - loss: 1.3470 - accuracy: 0.3372 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 381/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3471 - accuracy: 0.3372 - val_loss: 1.3470 - val_accuracy: 0.3374\n",
            "Epoch 382/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3475 - accuracy: 0.3368 - val_loss: 1.3473 - val_accuracy: 0.3379\n",
            "Epoch 383/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3481 - accuracy: 0.3363 - val_loss: 1.3503 - val_accuracy: 0.3338\n",
            "Epoch 384/4000\n",
            "11/11 [==============================] - 11s 942ms/step - loss: 1.3502 - accuracy: 0.3336 - val_loss: 1.3488 - val_accuracy: 0.3360\n",
            "Epoch 385/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3494 - accuracy: 0.3353 - val_loss: 1.3489 - val_accuracy: 0.3360\n",
            "Epoch 386/4000\n",
            "11/11 [==============================] - 11s 942ms/step - loss: 1.3487 - accuracy: 0.3357 - val_loss: 1.3477 - val_accuracy: 0.3371\n",
            "Epoch 387/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3479 - accuracy: 0.3365 - val_loss: 1.3470 - val_accuracy: 0.3379\n",
            "Epoch 388/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3473 - accuracy: 0.3371 - val_loss: 1.3468 - val_accuracy: 0.3380\n",
            "Epoch 389/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3471 - accuracy: 0.3371 - val_loss: 1.3467 - val_accuracy: 0.3381\n",
            "Epoch 390/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 391/4000\n",
            "11/11 [==============================] - 11s 940ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 392/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3381\n",
            "Epoch 393/4000\n",
            "11/11 [==============================] - 11s 943ms/step - loss: 1.3470 - accuracy: 0.3372 - val_loss: 1.3466 - val_accuracy: 0.3381\n",
            "Epoch 394/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3471 - accuracy: 0.3372 - val_loss: 1.3469 - val_accuracy: 0.3375\n",
            "Epoch 395/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3479 - accuracy: 0.3356 - val_loss: 1.3506 - val_accuracy: 0.3311\n",
            "Epoch 396/4000\n",
            "11/11 [==============================] - 11s 940ms/step - loss: 1.3503 - accuracy: 0.3304 - val_loss: 1.3510 - val_accuracy: 0.3275\n",
            "Epoch 397/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3510 - accuracy: 0.3283 - val_loss: 1.3505 - val_accuracy: 0.3345\n",
            "Epoch 398/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3505 - accuracy: 0.3329 - val_loss: 1.3498 - val_accuracy: 0.3362\n",
            "Epoch 399/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3498 - accuracy: 0.3350 - val_loss: 1.3491 - val_accuracy: 0.3361\n",
            "Epoch 400/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3494 - accuracy: 0.3350 - val_loss: 1.3488 - val_accuracy: 0.3361\n",
            "Epoch 401/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3491 - accuracy: 0.3355 - val_loss: 1.3486 - val_accuracy: 0.3364\n",
            "Epoch 402/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3488 - accuracy: 0.3356 - val_loss: 1.3482 - val_accuracy: 0.3362\n",
            "Epoch 403/4000\n",
            "11/11 [==============================] - 11s 932ms/step - loss: 1.3485 - accuracy: 0.3356 - val_loss: 1.3478 - val_accuracy: 0.3371\n",
            "Epoch 404/4000\n",
            "11/11 [==============================] - 11s 941ms/step - loss: 1.3481 - accuracy: 0.3364 - val_loss: 1.3475 - val_accuracy: 0.3377\n",
            "Epoch 405/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3485 - accuracy: 0.3360 - val_loss: 1.3487 - val_accuracy: 0.3366\n",
            "Epoch 406/4000\n",
            "11/11 [==============================] - 11s 943ms/step - loss: 1.3487 - accuracy: 0.3358 - val_loss: 1.3475 - val_accuracy: 0.3379\n",
            "Epoch 407/4000\n",
            "11/11 [==============================] - 11s 932ms/step - loss: 1.3480 - accuracy: 0.3364 - val_loss: 1.3473 - val_accuracy: 0.3378\n",
            "Epoch 408/4000\n",
            "11/11 [==============================] - 11s 941ms/step - loss: 1.3476 - accuracy: 0.3369 - val_loss: 1.3470 - val_accuracy: 0.3380\n",
            "Epoch 409/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3473 - accuracy: 0.3371 - val_loss: 1.3467 - val_accuracy: 0.3381\n",
            "Epoch 410/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3471 - accuracy: 0.3372 - val_loss: 1.3466 - val_accuracy: 0.3381\n",
            "Epoch 411/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3471 - accuracy: 0.3372 - val_loss: 1.3466 - val_accuracy: 0.3381\n",
            "Epoch 412/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 413/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 414/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3381\n",
            "Epoch 415/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3472 - accuracy: 0.3371 - val_loss: 1.3491 - val_accuracy: 0.3322\n",
            "Epoch 416/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3497 - accuracy: 0.3320 - val_loss: 1.3496 - val_accuracy: 0.3324\n",
            "Epoch 417/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3496 - accuracy: 0.3328 - val_loss: 1.3483 - val_accuracy: 0.3371\n",
            "Epoch 418/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3484 - accuracy: 0.3362 - val_loss: 1.3473 - val_accuracy: 0.3378\n",
            "Epoch 419/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3476 - accuracy: 0.3367 - val_loss: 1.3471 - val_accuracy: 0.3374\n",
            "Epoch 420/4000\n",
            "11/11 [==============================] - 11s 940ms/step - loss: 1.3474 - accuracy: 0.3368 - val_loss: 1.3468 - val_accuracy: 0.3378\n",
            "Epoch 421/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3472 - accuracy: 0.3371 - val_loss: 1.3467 - val_accuracy: 0.3381\n",
            "Epoch 422/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3472 - accuracy: 0.3370 - val_loss: 1.3467 - val_accuracy: 0.3380\n",
            "Epoch 423/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3471 - accuracy: 0.3372 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 424/4000\n",
            "11/11 [==============================] - 11s 941ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 425/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 426/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 427/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3471 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 428/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3471 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3381\n",
            "Epoch 429/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3472 - accuracy: 0.3372 - val_loss: 1.3477 - val_accuracy: 0.3377\n",
            "Epoch 430/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3492 - accuracy: 0.3360 - val_loss: 1.3504 - val_accuracy: 0.3333\n",
            "Epoch 431/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3503 - accuracy: 0.3330 - val_loss: 1.3489 - val_accuracy: 0.3366\n",
            "Epoch 432/4000\n",
            "11/11 [==============================] - 11s 940ms/step - loss: 1.3488 - accuracy: 0.3357 - val_loss: 1.3473 - val_accuracy: 0.3378\n",
            "Epoch 433/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3479 - accuracy: 0.3365 - val_loss: 1.3471 - val_accuracy: 0.3379\n",
            "Epoch 434/4000\n",
            "11/11 [==============================] - 11s 940ms/step - loss: 1.3474 - accuracy: 0.3371 - val_loss: 1.3468 - val_accuracy: 0.3381\n",
            "Epoch 435/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3472 - accuracy: 0.3372 - val_loss: 1.3467 - val_accuracy: 0.3381\n",
            "Epoch 436/4000\n",
            "11/11 [==============================] - 11s 941ms/step - loss: 1.3471 - accuracy: 0.3372 - val_loss: 1.3468 - val_accuracy: 0.3376\n",
            "Epoch 437/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3473 - accuracy: 0.3367 - val_loss: 1.3467 - val_accuracy: 0.3380\n",
            "Epoch 438/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3472 - accuracy: 0.3370 - val_loss: 1.3467 - val_accuracy: 0.3381\n",
            "Epoch 439/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3471 - accuracy: 0.3372 - val_loss: 1.3467 - val_accuracy: 0.3381\n",
            "Epoch 440/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3471 - accuracy: 0.3372 - val_loss: 1.3466 - val_accuracy: 0.3381\n",
            "Epoch 441/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 442/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 443/4000\n",
            "11/11 [==============================] - 11s 932ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3465 - val_accuracy: 0.3382\n",
            "Epoch 444/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3465 - val_accuracy: 0.3382\n",
            "Epoch 445/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3465 - val_accuracy: 0.3382\n",
            "Epoch 446/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3465 - val_accuracy: 0.3382\n",
            "Epoch 447/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3465 - val_accuracy: 0.3382\n",
            "Epoch 448/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 449/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 450/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3473 - accuracy: 0.3367 - val_loss: 1.3512 - val_accuracy: 0.3341\n",
            "Epoch 451/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3515 - accuracy: 0.3308 - val_loss: 1.3497 - val_accuracy: 0.3342\n",
            "Epoch 452/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3502 - accuracy: 0.3338 - val_loss: 1.3494 - val_accuracy: 0.3367\n",
            "Epoch 453/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3498 - accuracy: 0.3356 - val_loss: 1.3492 - val_accuracy: 0.3366\n",
            "Epoch 454/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3494 - accuracy: 0.3357 - val_loss: 1.3490 - val_accuracy: 0.3369\n",
            "Epoch 455/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3493 - accuracy: 0.3360 - val_loss: 1.3491 - val_accuracy: 0.3366\n",
            "Epoch 456/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3493 - accuracy: 0.3360 - val_loss: 1.3489 - val_accuracy: 0.3367\n",
            "Epoch 457/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3492 - accuracy: 0.3360 - val_loss: 1.3488 - val_accuracy: 0.3369\n",
            "Epoch 458/4000\n",
            "11/11 [==============================] - 11s 943ms/step - loss: 1.3491 - accuracy: 0.3361 - val_loss: 1.3487 - val_accuracy: 0.3369\n",
            "Epoch 459/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3491 - accuracy: 0.3361 - val_loss: 1.3487 - val_accuracy: 0.3370\n",
            "Epoch 460/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3491 - accuracy: 0.3361 - val_loss: 1.3487 - val_accuracy: 0.3370\n",
            "Epoch 461/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3490 - accuracy: 0.3361 - val_loss: 1.3487 - val_accuracy: 0.3369\n",
            "Epoch 462/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3490 - accuracy: 0.3361 - val_loss: 1.3487 - val_accuracy: 0.3369\n",
            "Epoch 463/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3490 - accuracy: 0.3361 - val_loss: 1.3486 - val_accuracy: 0.3368\n",
            "Epoch 464/4000\n",
            "11/11 [==============================] - 11s 932ms/step - loss: 1.3490 - accuracy: 0.3362 - val_loss: 1.3485 - val_accuracy: 0.3369\n",
            "Epoch 465/4000\n",
            "11/11 [==============================] - 11s 940ms/step - loss: 1.3489 - accuracy: 0.3361 - val_loss: 1.3491 - val_accuracy: 0.3350\n",
            "Epoch 466/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3528 - accuracy: 0.3293 - val_loss: 1.3579 - val_accuracy: 0.3201\n",
            "Epoch 467/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3579 - accuracy: 0.3187 - val_loss: 1.3575 - val_accuracy: 0.3170\n",
            "Epoch 468/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3574 - accuracy: 0.3186 - val_loss: 1.3567 - val_accuracy: 0.3196\n",
            "Epoch 469/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3565 - accuracy: 0.3196 - val_loss: 1.3548 - val_accuracy: 0.3216\n",
            "Epoch 470/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3546 - accuracy: 0.3217 - val_loss: 1.3533 - val_accuracy: 0.3259\n",
            "Epoch 471/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3536 - accuracy: 0.3253 - val_loss: 1.3530 - val_accuracy: 0.3283\n",
            "Epoch 472/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3541 - accuracy: 0.3248 - val_loss: 1.3527 - val_accuracy: 0.3290\n",
            "Epoch 473/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3525 - accuracy: 0.3283 - val_loss: 1.3507 - val_accuracy: 0.3319\n",
            "Epoch 474/4000\n",
            "11/11 [==============================] - 11s 941ms/step - loss: 1.3508 - accuracy: 0.3316 - val_loss: 1.3499 - val_accuracy: 0.3327\n",
            "Epoch 475/4000\n",
            "11/11 [==============================] - 11s 940ms/step - loss: 1.3500 - accuracy: 0.3325 - val_loss: 1.3493 - val_accuracy: 0.3358\n",
            "Epoch 476/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3495 - accuracy: 0.3350 - val_loss: 1.3489 - val_accuracy: 0.3368\n",
            "Epoch 477/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3498 - accuracy: 0.3347 - val_loss: 1.3505 - val_accuracy: 0.3342\n",
            "Epoch 478/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3505 - accuracy: 0.3339 - val_loss: 1.3491 - val_accuracy: 0.3360\n",
            "Epoch 479/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3497 - accuracy: 0.3347 - val_loss: 1.3487 - val_accuracy: 0.3367\n",
            "Epoch 480/4000\n",
            "11/11 [==============================] - 11s 942ms/step - loss: 1.3498 - accuracy: 0.3346 - val_loss: 1.3495 - val_accuracy: 0.3362\n",
            "Epoch 481/4000\n",
            "11/11 [==============================] - 11s 941ms/step - loss: 1.3494 - accuracy: 0.3356 - val_loss: 1.3485 - val_accuracy: 0.3369\n",
            "Epoch 482/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3487 - accuracy: 0.3362 - val_loss: 1.3479 - val_accuracy: 0.3374\n",
            "Epoch 483/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3480 - accuracy: 0.3367 - val_loss: 1.3471 - val_accuracy: 0.3379\n",
            "Epoch 484/4000\n",
            "11/11 [==============================] - 11s 943ms/step - loss: 1.3475 - accuracy: 0.3369 - val_loss: 1.3470 - val_accuracy: 0.3376\n",
            "Epoch 485/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3476 - accuracy: 0.3367 - val_loss: 1.3486 - val_accuracy: 0.3363\n",
            "Epoch 486/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3495 - accuracy: 0.3347 - val_loss: 1.3479 - val_accuracy: 0.3376\n",
            "Epoch 487/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3484 - accuracy: 0.3361 - val_loss: 1.3481 - val_accuracy: 0.3369\n",
            "Epoch 488/4000\n",
            "11/11 [==============================] - 11s 942ms/step - loss: 1.3484 - accuracy: 0.3354 - val_loss: 1.3476 - val_accuracy: 0.3371\n",
            "Epoch 489/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3484 - accuracy: 0.3353 - val_loss: 1.3494 - val_accuracy: 0.3347\n",
            "Epoch 490/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3499 - accuracy: 0.3342 - val_loss: 1.3484 - val_accuracy: 0.3357\n",
            "Epoch 491/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3484 - accuracy: 0.3354 - val_loss: 1.3474 - val_accuracy: 0.3373\n",
            "Epoch 492/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3477 - accuracy: 0.3367 - val_loss: 1.3469 - val_accuracy: 0.3380\n",
            "Epoch 493/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3473 - accuracy: 0.3371 - val_loss: 1.3468 - val_accuracy: 0.3379\n",
            "Epoch 494/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3472 - accuracy: 0.3372 - val_loss: 1.3467 - val_accuracy: 0.3382\n",
            "Epoch 495/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3471 - accuracy: 0.3372 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 496/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 497/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3383\n",
            "Epoch 498/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3471 - accuracy: 0.3373 - val_loss: 1.3470 - val_accuracy: 0.3382\n",
            "Epoch 499/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3479 - accuracy: 0.3364 - val_loss: 1.3500 - val_accuracy: 0.3356\n",
            "Epoch 500/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3516 - accuracy: 0.3306 - val_loss: 1.3509 - val_accuracy: 0.3341\n",
            "Epoch 501/4000\n",
            "11/11 [==============================] - 11s 942ms/step - loss: 1.3511 - accuracy: 0.3337 - val_loss: 1.3500 - val_accuracy: 0.3367\n",
            "Epoch 502/4000\n",
            "11/11 [==============================] - 11s 946ms/step - loss: 1.3501 - accuracy: 0.3363 - val_loss: 1.3492 - val_accuracy: 0.3374\n",
            "Epoch 503/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3496 - accuracy: 0.3361 - val_loss: 1.3504 - val_accuracy: 0.3317\n",
            "Epoch 504/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3502 - accuracy: 0.3338 - val_loss: 1.3500 - val_accuracy: 0.3354\n",
            "Epoch 505/4000\n",
            "11/11 [==============================] - 11s 941ms/step - loss: 1.3508 - accuracy: 0.3333 - val_loss: 1.3509 - val_accuracy: 0.3343\n",
            "Epoch 506/4000\n",
            "11/11 [==============================] - 11s 942ms/step - loss: 1.3506 - accuracy: 0.3348 - val_loss: 1.3494 - val_accuracy: 0.3366\n",
            "Epoch 507/4000\n",
            "11/11 [==============================] - 11s 944ms/step - loss: 1.3498 - accuracy: 0.3361 - val_loss: 1.3491 - val_accuracy: 0.3372\n",
            "Epoch 508/4000\n",
            "11/11 [==============================] - 11s 944ms/step - loss: 1.3493 - accuracy: 0.3364 - val_loss: 1.3487 - val_accuracy: 0.3374\n",
            "Epoch 509/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3492 - accuracy: 0.3362 - val_loss: 1.3487 - val_accuracy: 0.3370\n",
            "Epoch 510/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3489 - accuracy: 0.3365 - val_loss: 1.3483 - val_accuracy: 0.3376\n",
            "Epoch 511/4000\n",
            "11/11 [==============================] - 11s 945ms/step - loss: 1.3486 - accuracy: 0.3365 - val_loss: 1.3478 - val_accuracy: 0.3374\n",
            "Epoch 512/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3493 - accuracy: 0.3334 - val_loss: 1.3525 - val_accuracy: 0.3170\n",
            "Epoch 513/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3535 - accuracy: 0.3198 - val_loss: 1.3545 - val_accuracy: 0.3252\n",
            "Epoch 514/4000\n",
            "11/11 [==============================] - 11s 944ms/step - loss: 1.3551 - accuracy: 0.3216 - val_loss: 1.3537 - val_accuracy: 0.3282\n",
            "Epoch 515/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3528 - accuracy: 0.3285 - val_loss: 1.3513 - val_accuracy: 0.3325\n",
            "Epoch 516/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3511 - accuracy: 0.3320 - val_loss: 1.3504 - val_accuracy: 0.3340\n",
            "Epoch 517/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3505 - accuracy: 0.3336 - val_loss: 1.3499 - val_accuracy: 0.3349\n",
            "Epoch 518/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3500 - accuracy: 0.3344 - val_loss: 1.3494 - val_accuracy: 0.3361\n",
            "Epoch 519/4000\n",
            "11/11 [==============================] - 11s 930ms/step - loss: 1.3497 - accuracy: 0.3353 - val_loss: 1.3492 - val_accuracy: 0.3363\n",
            "Epoch 520/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3495 - accuracy: 0.3352 - val_loss: 1.3494 - val_accuracy: 0.3356\n",
            "Epoch 521/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3496 - accuracy: 0.3349 - val_loss: 1.3492 - val_accuracy: 0.3363\n",
            "Epoch 522/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3494 - accuracy: 0.3351 - val_loss: 1.3490 - val_accuracy: 0.3364\n",
            "Epoch 523/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3493 - accuracy: 0.3353 - val_loss: 1.3489 - val_accuracy: 0.3364\n",
            "Epoch 524/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3493 - accuracy: 0.3353 - val_loss: 1.3489 - val_accuracy: 0.3365\n",
            "Epoch 525/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3492 - accuracy: 0.3355 - val_loss: 1.3488 - val_accuracy: 0.3365\n",
            "Epoch 526/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3492 - accuracy: 0.3355 - val_loss: 1.3487 - val_accuracy: 0.3366\n",
            "Epoch 527/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3491 - accuracy: 0.3355 - val_loss: 1.3488 - val_accuracy: 0.3363\n",
            "Epoch 528/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3491 - accuracy: 0.3355 - val_loss: 1.3487 - val_accuracy: 0.3366\n",
            "Epoch 529/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3490 - accuracy: 0.3357 - val_loss: 1.3487 - val_accuracy: 0.3366\n",
            "Epoch 530/4000\n",
            "11/11 [==============================] - 11s 940ms/step - loss: 1.3490 - accuracy: 0.3356 - val_loss: 1.3486 - val_accuracy: 0.3366\n",
            "Epoch 531/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3489 - accuracy: 0.3360 - val_loss: 1.3486 - val_accuracy: 0.3366\n",
            "Epoch 532/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3489 - accuracy: 0.3358 - val_loss: 1.3484 - val_accuracy: 0.3365\n",
            "Epoch 533/4000\n",
            "11/11 [==============================] - 11s 929ms/step - loss: 1.3502 - accuracy: 0.3324 - val_loss: 1.3523 - val_accuracy: 0.3346\n",
            "Epoch 534/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3527 - accuracy: 0.3294 - val_loss: 1.3531 - val_accuracy: 0.3279\n",
            "Epoch 535/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3537 - accuracy: 0.3247 - val_loss: 1.3531 - val_accuracy: 0.3233\n",
            "Epoch 536/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3534 - accuracy: 0.3221 - val_loss: 1.3530 - val_accuracy: 0.3212\n",
            "Epoch 537/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3530 - accuracy: 0.3222 - val_loss: 1.3525 - val_accuracy: 0.3248\n",
            "Epoch 538/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3525 - accuracy: 0.3247 - val_loss: 1.3517 - val_accuracy: 0.3269\n",
            "Epoch 539/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3518 - accuracy: 0.3264 - val_loss: 1.3520 - val_accuracy: 0.3268\n",
            "Epoch 540/4000\n",
            "11/11 [==============================] - 11s 941ms/step - loss: 1.3528 - accuracy: 0.3274 - val_loss: 1.3513 - val_accuracy: 0.3303\n",
            "Epoch 541/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3512 - accuracy: 0.3301 - val_loss: 1.3493 - val_accuracy: 0.3337\n",
            "Epoch 542/4000\n",
            "11/11 [==============================] - 11s 944ms/step - loss: 1.3495 - accuracy: 0.3336 - val_loss: 1.3484 - val_accuracy: 0.3368\n",
            "Epoch 543/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3485 - accuracy: 0.3358 - val_loss: 1.3477 - val_accuracy: 0.3372\n",
            "Epoch 544/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3479 - accuracy: 0.3366 - val_loss: 1.3472 - val_accuracy: 0.3377\n",
            "Epoch 545/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3476 - accuracy: 0.3369 - val_loss: 1.3469 - val_accuracy: 0.3380\n",
            "Epoch 546/4000\n",
            "11/11 [==============================] - 11s 940ms/step - loss: 1.3474 - accuracy: 0.3368 - val_loss: 1.3473 - val_accuracy: 0.3368\n",
            "Epoch 547/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3495 - accuracy: 0.3327 - val_loss: 1.3516 - val_accuracy: 0.3286\n",
            "Epoch 548/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3524 - accuracy: 0.3285 - val_loss: 1.3529 - val_accuracy: 0.3332\n",
            "Epoch 549/4000\n",
            "11/11 [==============================] - 11s 941ms/step - loss: 1.3526 - accuracy: 0.3316 - val_loss: 1.3511 - val_accuracy: 0.3328\n",
            "Epoch 550/4000\n",
            "11/11 [==============================] - 11s 944ms/step - loss: 1.3510 - accuracy: 0.3326 - val_loss: 1.3497 - val_accuracy: 0.3352\n",
            "Epoch 551/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3499 - accuracy: 0.3349 - val_loss: 1.3492 - val_accuracy: 0.3360\n",
            "Epoch 552/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3493 - accuracy: 0.3354 - val_loss: 1.3487 - val_accuracy: 0.3363\n",
            "Epoch 553/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3490 - accuracy: 0.3355 - val_loss: 1.3484 - val_accuracy: 0.3368\n",
            "Epoch 554/4000\n",
            "11/11 [==============================] - 11s 940ms/step - loss: 1.3487 - accuracy: 0.3358 - val_loss: 1.3480 - val_accuracy: 0.3368\n",
            "Epoch 555/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3482 - accuracy: 0.3359 - val_loss: 1.3472 - val_accuracy: 0.3374\n",
            "Epoch 556/4000\n",
            "11/11 [==============================] - 11s 941ms/step - loss: 1.3474 - accuracy: 0.3367 - val_loss: 1.3470 - val_accuracy: 0.3380\n",
            "Epoch 557/4000\n",
            "11/11 [==============================] - 11s 940ms/step - loss: 1.3476 - accuracy: 0.3367 - val_loss: 1.3496 - val_accuracy: 0.3349\n",
            "Epoch 558/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3513 - accuracy: 0.3341 - val_loss: 1.3507 - val_accuracy: 0.3342\n",
            "Epoch 559/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3502 - accuracy: 0.3351 - val_loss: 1.3490 - val_accuracy: 0.3369\n",
            "Epoch 560/4000\n",
            "11/11 [==============================] - 11s 941ms/step - loss: 1.3493 - accuracy: 0.3359 - val_loss: 1.3482 - val_accuracy: 0.3371\n",
            "Epoch 561/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3483 - accuracy: 0.3364 - val_loss: 1.3472 - val_accuracy: 0.3377\n",
            "Epoch 562/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3475 - accuracy: 0.3369 - val_loss: 1.3469 - val_accuracy: 0.3380\n",
            "Epoch 563/4000\n",
            "11/11 [==============================] - 11s 931ms/step - loss: 1.3472 - accuracy: 0.3372 - val_loss: 1.3467 - val_accuracy: 0.3380\n",
            "Epoch 564/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3471 - accuracy: 0.3372 - val_loss: 1.3467 - val_accuracy: 0.3381\n",
            "Epoch 565/4000\n",
            "11/11 [==============================] - 11s 941ms/step - loss: 1.3471 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3381\n",
            "Epoch 566/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 567/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 568/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 569/4000\n",
            "11/11 [==============================] - 11s 940ms/step - loss: 1.3470 - accuracy: 0.3372 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 570/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 571/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3467 - val_accuracy: 0.3382\n",
            "Epoch 572/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3471 - accuracy: 0.3372 - val_loss: 1.3476 - val_accuracy: 0.3370\n",
            "Epoch 573/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3480 - accuracy: 0.3365 - val_loss: 1.3497 - val_accuracy: 0.3356\n",
            "Epoch 574/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3554 - accuracy: 0.3262 - val_loss: 1.3590 - val_accuracy: 0.3172\n",
            "Epoch 575/4000\n",
            "11/11 [==============================] - 11s 932ms/step - loss: 1.3588 - accuracy: 0.3161 - val_loss: 1.3585 - val_accuracy: 0.3184\n",
            "Epoch 576/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3585 - accuracy: 0.3174 - val_loss: 1.3583 - val_accuracy: 0.3181\n",
            "Epoch 577/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3582 - accuracy: 0.3177 - val_loss: 1.3580 - val_accuracy: 0.3179\n",
            "Epoch 578/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3579 - accuracy: 0.3179 - val_loss: 1.3576 - val_accuracy: 0.3182\n",
            "Epoch 579/4000\n",
            "11/11 [==============================] - 11s 943ms/step - loss: 1.3575 - accuracy: 0.3181 - val_loss: 1.3569 - val_accuracy: 0.3185\n",
            "Epoch 580/4000\n",
            "11/11 [==============================] - 11s 941ms/step - loss: 1.3568 - accuracy: 0.3178 - val_loss: 1.3560 - val_accuracy: 0.3190\n",
            "Epoch 581/4000\n",
            "11/11 [==============================] - 11s 943ms/step - loss: 1.3560 - accuracy: 0.3184 - val_loss: 1.3549 - val_accuracy: 0.3202\n",
            "Epoch 582/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3545 - accuracy: 0.3201 - val_loss: 1.3541 - val_accuracy: 0.3202\n",
            "Epoch 583/4000\n",
            "11/11 [==============================] - 11s 942ms/step - loss: 1.3539 - accuracy: 0.3207 - val_loss: 1.3536 - val_accuracy: 0.3215\n",
            "Epoch 584/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3541 - accuracy: 0.3209 - val_loss: 1.3537 - val_accuracy: 0.3225\n",
            "Epoch 585/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3539 - accuracy: 0.3212 - val_loss: 1.3528 - val_accuracy: 0.3226\n",
            "Epoch 586/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3530 - accuracy: 0.3227 - val_loss: 1.3524 - val_accuracy: 0.3255\n",
            "Epoch 587/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3526 - accuracy: 0.3253 - val_loss: 1.3519 - val_accuracy: 0.3283\n",
            "Epoch 588/4000\n",
            "11/11 [==============================] - 11s 943ms/step - loss: 1.3520 - accuracy: 0.3289 - val_loss: 1.3511 - val_accuracy: 0.3330\n",
            "Epoch 589/4000\n",
            "11/11 [==============================] - 11s 941ms/step - loss: 1.3512 - accuracy: 0.3330 - val_loss: 1.3510 - val_accuracy: 0.3369\n",
            "Epoch 590/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3523 - accuracy: 0.3332 - val_loss: 1.3525 - val_accuracy: 0.3359\n",
            "Epoch 591/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3531 - accuracy: 0.3333 - val_loss: 1.3543 - val_accuracy: 0.3185\n",
            "Epoch 592/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3543 - accuracy: 0.3197 - val_loss: 1.3538 - val_accuracy: 0.3252\n",
            "Epoch 593/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3539 - accuracy: 0.3219 - val_loss: 1.3533 - val_accuracy: 0.3238\n",
            "Epoch 594/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3533 - accuracy: 0.3230 - val_loss: 1.3526 - val_accuracy: 0.3257\n",
            "Epoch 595/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3526 - accuracy: 0.3256 - val_loss: 1.3522 - val_accuracy: 0.3295\n",
            "Epoch 596/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3521 - accuracy: 0.3288 - val_loss: 1.3508 - val_accuracy: 0.3333\n",
            "Epoch 597/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3512 - accuracy: 0.3326 - val_loss: 1.3526 - val_accuracy: 0.3257\n",
            "Epoch 598/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3524 - accuracy: 0.3282 - val_loss: 1.3509 - val_accuracy: 0.3354\n",
            "Epoch 599/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3514 - accuracy: 0.3343 - val_loss: 1.3505 - val_accuracy: 0.3362\n",
            "Epoch 600/4000\n",
            "11/11 [==============================] - 11s 941ms/step - loss: 1.3504 - accuracy: 0.3356 - val_loss: 1.3499 - val_accuracy: 0.3368\n",
            "Epoch 601/4000\n",
            "11/11 [==============================] - 11s 943ms/step - loss: 1.3500 - accuracy: 0.3360 - val_loss: 1.3493 - val_accuracy: 0.3373\n",
            "Epoch 602/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3496 - accuracy: 0.3364 - val_loss: 1.3492 - val_accuracy: 0.3367\n",
            "Epoch 603/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3497 - accuracy: 0.3358 - val_loss: 1.3494 - val_accuracy: 0.3367\n",
            "Epoch 604/4000\n",
            "11/11 [==============================] - 11s 949ms/step - loss: 1.3498 - accuracy: 0.3352 - val_loss: 1.3494 - val_accuracy: 0.3367\n",
            "Epoch 605/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3495 - accuracy: 0.3362 - val_loss: 1.3490 - val_accuracy: 0.3373\n",
            "Epoch 606/4000\n",
            "11/11 [==============================] - 11s 945ms/step - loss: 1.3492 - accuracy: 0.3365 - val_loss: 1.3488 - val_accuracy: 0.3375\n",
            "Epoch 607/4000\n",
            "11/11 [==============================] - 11s 945ms/step - loss: 1.3492 - accuracy: 0.3365 - val_loss: 1.3487 - val_accuracy: 0.3376\n",
            "Epoch 608/4000\n",
            "11/11 [==============================] - 11s 942ms/step - loss: 1.3493 - accuracy: 0.3360 - val_loss: 1.3511 - val_accuracy: 0.3362\n",
            "Epoch 609/4000\n",
            "11/11 [==============================] - 11s 942ms/step - loss: 1.3510 - accuracy: 0.3348 - val_loss: 1.3499 - val_accuracy: 0.3356\n",
            "Epoch 610/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3501 - accuracy: 0.3351 - val_loss: 1.3493 - val_accuracy: 0.3371\n",
            "Epoch 611/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3495 - accuracy: 0.3362 - val_loss: 1.3488 - val_accuracy: 0.3369\n",
            "Epoch 612/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3493 - accuracy: 0.3359 - val_loss: 1.3488 - val_accuracy: 0.3369\n",
            "Epoch 613/4000\n",
            "11/11 [==============================] - 11s 941ms/step - loss: 1.3491 - accuracy: 0.3361 - val_loss: 1.3484 - val_accuracy: 0.3372\n",
            "Epoch 614/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3488 - accuracy: 0.3364 - val_loss: 1.3488 - val_accuracy: 0.3364\n",
            "Epoch 615/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3495 - accuracy: 0.3345 - val_loss: 1.3495 - val_accuracy: 0.3326\n",
            "Epoch 616/4000\n",
            "11/11 [==============================] - 11s 940ms/step - loss: 1.3510 - accuracy: 0.3306 - val_loss: 1.3527 - val_accuracy: 0.3305\n",
            "Epoch 617/4000\n",
            "11/11 [==============================] - 11s 935ms/step - loss: 1.3531 - accuracy: 0.3308 - val_loss: 1.3516 - val_accuracy: 0.3344\n",
            "Epoch 618/4000\n",
            "11/11 [==============================] - 11s 941ms/step - loss: 1.3516 - accuracy: 0.3345 - val_loss: 1.3506 - val_accuracy: 0.3362\n",
            "Epoch 619/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3505 - accuracy: 0.3355 - val_loss: 1.3497 - val_accuracy: 0.3365\n",
            "Epoch 620/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3497 - accuracy: 0.3356 - val_loss: 1.3491 - val_accuracy: 0.3366\n",
            "Epoch 621/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3493 - accuracy: 0.3360 - val_loss: 1.3487 - val_accuracy: 0.3369\n",
            "Epoch 622/4000\n",
            "11/11 [==============================] - 11s 940ms/step - loss: 1.3490 - accuracy: 0.3365 - val_loss: 1.3486 - val_accuracy: 0.3374\n",
            "Epoch 623/4000\n",
            "11/11 [==============================] - 11s 943ms/step - loss: 1.3489 - accuracy: 0.3366 - val_loss: 1.3483 - val_accuracy: 0.3374\n",
            "Epoch 624/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3486 - accuracy: 0.3366 - val_loss: 1.3480 - val_accuracy: 0.3373\n",
            "Epoch 625/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3484 - accuracy: 0.3362 - val_loss: 1.3495 - val_accuracy: 0.3355\n",
            "Epoch 626/4000\n",
            "11/11 [==============================] - 11s 940ms/step - loss: 1.3494 - accuracy: 0.3350 - val_loss: 1.3490 - val_accuracy: 0.3336\n",
            "Epoch 627/4000\n",
            "11/11 [==============================] - 11s 946ms/step - loss: 1.3490 - accuracy: 0.3344 - val_loss: 1.3478 - val_accuracy: 0.3374\n",
            "Epoch 628/4000\n",
            "11/11 [==============================] - 11s 940ms/step - loss: 1.3487 - accuracy: 0.3347 - val_loss: 1.3476 - val_accuracy: 0.3368\n",
            "Epoch 629/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3479 - accuracy: 0.3362 - val_loss: 1.3471 - val_accuracy: 0.3379\n",
            "Epoch 630/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3475 - accuracy: 0.3368 - val_loss: 1.3474 - val_accuracy: 0.3378\n",
            "Epoch 631/4000\n",
            "11/11 [==============================] - 11s 933ms/step - loss: 1.3479 - accuracy: 0.3366 - val_loss: 1.3498 - val_accuracy: 0.3348\n",
            "Epoch 632/4000\n",
            "11/11 [==============================] - 11s 930ms/step - loss: 1.3507 - accuracy: 0.3332 - val_loss: 1.3511 - val_accuracy: 0.3352\n",
            "Epoch 633/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3516 - accuracy: 0.3337 - val_loss: 1.3509 - val_accuracy: 0.3346\n",
            "Epoch 634/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3508 - accuracy: 0.3330 - val_loss: 1.3499 - val_accuracy: 0.3348\n",
            "Epoch 635/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3500 - accuracy: 0.3349 - val_loss: 1.3490 - val_accuracy: 0.3363\n",
            "Epoch 636/4000\n",
            "11/11 [==============================] - 11s 944ms/step - loss: 1.3494 - accuracy: 0.3357 - val_loss: 1.3487 - val_accuracy: 0.3368\n",
            "Epoch 637/4000\n",
            "11/11 [==============================] - 11s 943ms/step - loss: 1.3491 - accuracy: 0.3360 - val_loss: 1.3486 - val_accuracy: 0.3368\n",
            "Epoch 638/4000\n",
            "11/11 [==============================] - 11s 937ms/step - loss: 1.3488 - accuracy: 0.3361 - val_loss: 1.3484 - val_accuracy: 0.3371\n",
            "Epoch 639/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3487 - accuracy: 0.3363 - val_loss: 1.3483 - val_accuracy: 0.3363\n",
            "Epoch 640/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3487 - accuracy: 0.3357 - val_loss: 1.3497 - val_accuracy: 0.3356\n",
            "Epoch 641/4000\n",
            "11/11 [==============================] - 11s 936ms/step - loss: 1.3499 - accuracy: 0.3338 - val_loss: 1.3487 - val_accuracy: 0.3369\n",
            "Epoch 642/4000\n",
            "11/11 [==============================] - 11s 934ms/step - loss: 1.3488 - accuracy: 0.3358 - val_loss: 1.3479 - val_accuracy: 0.3373\n",
            "Epoch 643/4000\n",
            "11/11 [==============================] - 11s 939ms/step - loss: 1.3482 - accuracy: 0.3365 - val_loss: 1.3474 - val_accuracy: 0.3375\n",
            "Epoch 644/4000\n",
            "11/11 [==============================] - 11s 944ms/step - loss: 1.3478 - accuracy: 0.3367 - val_loss: 1.3472 - val_accuracy: 0.3379\n",
            "Epoch 645/4000\n",
            "11/11 [==============================] - 11s 938ms/step - loss: 1.3475 - accuracy: 0.3369 - val_loss: 1.3470 - val_accuracy: 0.3377\n",
            "Epoch 646/4000\n",
            "11/11 [==============================] - 11s 940ms/step - loss: 1.3473 - accuracy: 0.3369 - val_loss: 1.3470 - val_accuracy: 0.3380\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1NviSfffwTI"
      },
      "source": [
        "recurrent_ae.save(MODEL_DIR+SUFFIX+'_ae'+DATE+\".h5\")\r\n",
        "save_hist(ae_hist, '_reconstruction_history.csv')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhRvZBPYa0zL"
      },
      "source": [
        "recurrent_ae = tf.keras.models.load_model(MODEL_DIR+SUFFIX+'_ae'+DATE+\".h5\")\r\n",
        "encoder = recurrent_ae.layers[0]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjpwA4BRhMuJ",
        "outputId": "a8ac10d9-119b-4abb-f8d0-6262ca1115c6"
      },
      "source": [
        "xtrain_vec = encoder.predict(xtrain_seq)\r\n",
        "xval_vec = encoder.predict(xval_seq)\r\n",
        "xtest_vec = encoder.predict(xtest_seq)\r\n",
        "print('The shape of xtrain/xval/xtest_seq is', xtrain_vec.shape, xval_vec.shape, xtest_vec.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of xtrain/xval/xtest_seq is (10473, 100) (2245, 100) (2245, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uf3ED6f9hQpW"
      },
      "source": [
        "model = keras.models.Sequential([\r\n",
        "  keras.layers.Dense(128, activation=\"relu\", input_shape=[latent_size]),\r\n",
        "  keras.layers.Dropout(0.2),\r\n",
        "  keras.layers.Dense(64, activation=\"relu\"),    \r\n",
        "  keras.layers.Dropout(0.2),\r\n",
        "  keras.layers.Dense(32, activation=\"relu\"),  \r\n",
        "  keras.layers.Dropout(0.2), \r\n",
        "  keras.layers.Dense(16, activation=\"relu\"), \r\n",
        "  keras.layers.Dropout(0.2),   \r\n",
        "  keras.layers.Dense(1, activation=\"sigmoid\")                               \r\n",
        "])\r\n",
        "model.compile(keras.optimizers.SGD(learning_rate=0.001, momentum=0.9), loss=keras.losses.BinaryCrossentropy(), metrics=['accuracy'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iySJD_bsHw4i"
      },
      "source": [
        "ytrain = np.array(ytrain)\r\n",
        "yval = np.array(yval)\r\n",
        "ytest = np.array(ytest)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzwDfPnwhSx2",
        "outputId": "f90ec1fc-adcd-4b40-a862-773961e114a2"
      },
      "source": [
        "es_cb = keras.callbacks.EarlyStopping(patience=200, restore_best_weights=True)\r\n",
        "model_hist = model.fit(xtrain_vec, ytrain, validation_data=(xval_vec, yval), epochs=1500, callbacks=[es_cb])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1500\n",
            "328/328 [==============================] - 4s 3ms/step - loss: 0.6879 - accuracy: 0.6004 - val_loss: 0.6686 - val_accuracy: 0.7595\n",
            "Epoch 2/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.6664 - accuracy: 0.6903 - val_loss: 0.6305 - val_accuracy: 0.7675\n",
            "Epoch 3/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.6289 - accuracy: 0.7270 - val_loss: 0.5717 - val_accuracy: 0.7661\n",
            "Epoch 4/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5787 - accuracy: 0.7419 - val_loss: 0.5253 - val_accuracy: 0.7693\n",
            "Epoch 5/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5468 - accuracy: 0.7559 - val_loss: 0.5051 - val_accuracy: 0.7702\n",
            "Epoch 6/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5317 - accuracy: 0.7563 - val_loss: 0.4968 - val_accuracy: 0.7719\n",
            "Epoch 7/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5247 - accuracy: 0.7585 - val_loss: 0.4933 - val_accuracy: 0.7733\n",
            "Epoch 8/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5116 - accuracy: 0.7634 - val_loss: 0.4922 - val_accuracy: 0.7733\n",
            "Epoch 9/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5168 - accuracy: 0.7567 - val_loss: 0.4896 - val_accuracy: 0.7724\n",
            "Epoch 10/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5325 - accuracy: 0.7518 - val_loss: 0.4895 - val_accuracy: 0.7710\n",
            "Epoch 11/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5169 - accuracy: 0.7592 - val_loss: 0.4886 - val_accuracy: 0.7715\n",
            "Epoch 12/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5187 - accuracy: 0.7542 - val_loss: 0.4886 - val_accuracy: 0.7719\n",
            "Epoch 13/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5145 - accuracy: 0.7597 - val_loss: 0.4889 - val_accuracy: 0.7742\n",
            "Epoch 14/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5120 - accuracy: 0.7665 - val_loss: 0.4888 - val_accuracy: 0.7697\n",
            "Epoch 15/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5120 - accuracy: 0.7645 - val_loss: 0.4910 - val_accuracy: 0.7679\n",
            "Epoch 16/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5098 - accuracy: 0.7579 - val_loss: 0.4902 - val_accuracy: 0.7666\n",
            "Epoch 17/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5131 - accuracy: 0.7614 - val_loss: 0.4891 - val_accuracy: 0.7675\n",
            "Epoch 18/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5070 - accuracy: 0.7704 - val_loss: 0.4891 - val_accuracy: 0.7657\n",
            "Epoch 19/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5138 - accuracy: 0.7676 - val_loss: 0.4883 - val_accuracy: 0.7710\n",
            "Epoch 20/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5100 - accuracy: 0.7648 - val_loss: 0.4889 - val_accuracy: 0.7679\n",
            "Epoch 21/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5048 - accuracy: 0.7653 - val_loss: 0.4877 - val_accuracy: 0.7710\n",
            "Epoch 22/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5067 - accuracy: 0.7765 - val_loss: 0.4874 - val_accuracy: 0.7746\n",
            "Epoch 23/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5100 - accuracy: 0.7699 - val_loss: 0.4867 - val_accuracy: 0.7746\n",
            "Epoch 24/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5047 - accuracy: 0.7721 - val_loss: 0.4865 - val_accuracy: 0.7746\n",
            "Epoch 25/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4989 - accuracy: 0.7755 - val_loss: 0.4867 - val_accuracy: 0.7737\n",
            "Epoch 26/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5100 - accuracy: 0.7640 - val_loss: 0.4864 - val_accuracy: 0.7719\n",
            "Epoch 27/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5106 - accuracy: 0.7637 - val_loss: 0.4881 - val_accuracy: 0.7719\n",
            "Epoch 28/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5058 - accuracy: 0.7658 - val_loss: 0.4867 - val_accuracy: 0.7715\n",
            "Epoch 29/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5050 - accuracy: 0.7640 - val_loss: 0.4873 - val_accuracy: 0.7657\n",
            "Epoch 30/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5026 - accuracy: 0.7661 - val_loss: 0.4859 - val_accuracy: 0.7719\n",
            "Epoch 31/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5050 - accuracy: 0.7720 - val_loss: 0.4858 - val_accuracy: 0.7715\n",
            "Epoch 32/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5038 - accuracy: 0.7688 - val_loss: 0.4857 - val_accuracy: 0.7693\n",
            "Epoch 33/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5120 - accuracy: 0.7618 - val_loss: 0.4852 - val_accuracy: 0.7706\n",
            "Epoch 34/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5086 - accuracy: 0.7656 - val_loss: 0.4880 - val_accuracy: 0.7657\n",
            "Epoch 35/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5012 - accuracy: 0.7667 - val_loss: 0.4851 - val_accuracy: 0.7710\n",
            "Epoch 36/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5088 - accuracy: 0.7658 - val_loss: 0.4853 - val_accuracy: 0.7706\n",
            "Epoch 37/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5039 - accuracy: 0.7647 - val_loss: 0.4855 - val_accuracy: 0.7715\n",
            "Epoch 38/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4981 - accuracy: 0.7730 - val_loss: 0.4847 - val_accuracy: 0.7715\n",
            "Epoch 39/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5014 - accuracy: 0.7723 - val_loss: 0.4850 - val_accuracy: 0.7719\n",
            "Epoch 40/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4937 - accuracy: 0.7751 - val_loss: 0.4847 - val_accuracy: 0.7702\n",
            "Epoch 41/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4992 - accuracy: 0.7759 - val_loss: 0.4849 - val_accuracy: 0.7719\n",
            "Epoch 42/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5059 - accuracy: 0.7688 - val_loss: 0.4851 - val_accuracy: 0.7710\n",
            "Epoch 43/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5001 - accuracy: 0.7729 - val_loss: 0.4850 - val_accuracy: 0.7710\n",
            "Epoch 44/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4999 - accuracy: 0.7669 - val_loss: 0.4846 - val_accuracy: 0.7715\n",
            "Epoch 45/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5058 - accuracy: 0.7706 - val_loss: 0.4845 - val_accuracy: 0.7702\n",
            "Epoch 46/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5096 - accuracy: 0.7618 - val_loss: 0.4844 - val_accuracy: 0.7688\n",
            "Epoch 47/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5084 - accuracy: 0.7592 - val_loss: 0.4844 - val_accuracy: 0.7706\n",
            "Epoch 48/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5082 - accuracy: 0.7631 - val_loss: 0.4845 - val_accuracy: 0.7697\n",
            "Epoch 49/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5025 - accuracy: 0.7662 - val_loss: 0.4843 - val_accuracy: 0.7693\n",
            "Epoch 50/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4990 - accuracy: 0.7730 - val_loss: 0.4843 - val_accuracy: 0.7715\n",
            "Epoch 51/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4954 - accuracy: 0.7724 - val_loss: 0.4843 - val_accuracy: 0.7693\n",
            "Epoch 52/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4947 - accuracy: 0.7709 - val_loss: 0.4838 - val_accuracy: 0.7719\n",
            "Epoch 53/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5039 - accuracy: 0.7680 - val_loss: 0.4833 - val_accuracy: 0.7728\n",
            "Epoch 54/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5014 - accuracy: 0.7651 - val_loss: 0.4845 - val_accuracy: 0.7693\n",
            "Epoch 55/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5056 - accuracy: 0.7674 - val_loss: 0.4836 - val_accuracy: 0.7715\n",
            "Epoch 56/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4938 - accuracy: 0.7782 - val_loss: 0.4844 - val_accuracy: 0.7697\n",
            "Epoch 57/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5048 - accuracy: 0.7685 - val_loss: 0.4834 - val_accuracy: 0.7710\n",
            "Epoch 58/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4943 - accuracy: 0.7726 - val_loss: 0.4839 - val_accuracy: 0.7688\n",
            "Epoch 59/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5018 - accuracy: 0.7733 - val_loss: 0.4837 - val_accuracy: 0.7710\n",
            "Epoch 60/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4929 - accuracy: 0.7717 - val_loss: 0.4836 - val_accuracy: 0.7733\n",
            "Epoch 61/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4911 - accuracy: 0.7822 - val_loss: 0.4834 - val_accuracy: 0.7733\n",
            "Epoch 62/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5019 - accuracy: 0.7683 - val_loss: 0.4833 - val_accuracy: 0.7728\n",
            "Epoch 63/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4839 - accuracy: 0.7813 - val_loss: 0.4849 - val_accuracy: 0.7679\n",
            "Epoch 64/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5042 - accuracy: 0.7633 - val_loss: 0.4837 - val_accuracy: 0.7715\n",
            "Epoch 65/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5028 - accuracy: 0.7660 - val_loss: 0.4832 - val_accuracy: 0.7719\n",
            "Epoch 66/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5013 - accuracy: 0.7734 - val_loss: 0.4849 - val_accuracy: 0.7715\n",
            "Epoch 67/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4995 - accuracy: 0.7678 - val_loss: 0.4836 - val_accuracy: 0.7742\n",
            "Epoch 68/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4928 - accuracy: 0.7793 - val_loss: 0.4834 - val_accuracy: 0.7697\n",
            "Epoch 69/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4980 - accuracy: 0.7703 - val_loss: 0.4830 - val_accuracy: 0.7702\n",
            "Epoch 70/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4993 - accuracy: 0.7665 - val_loss: 0.4827 - val_accuracy: 0.7728\n",
            "Epoch 71/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5061 - accuracy: 0.7664 - val_loss: 0.4835 - val_accuracy: 0.7737\n",
            "Epoch 72/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4940 - accuracy: 0.7736 - val_loss: 0.4829 - val_accuracy: 0.7697\n",
            "Epoch 73/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4967 - accuracy: 0.7759 - val_loss: 0.4832 - val_accuracy: 0.7706\n",
            "Epoch 74/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4923 - accuracy: 0.7758 - val_loss: 0.4827 - val_accuracy: 0.7702\n",
            "Epoch 75/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4993 - accuracy: 0.7672 - val_loss: 0.4828 - val_accuracy: 0.7719\n",
            "Epoch 76/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4928 - accuracy: 0.7727 - val_loss: 0.4828 - val_accuracy: 0.7702\n",
            "Epoch 77/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4995 - accuracy: 0.7750 - val_loss: 0.4849 - val_accuracy: 0.7697\n",
            "Epoch 78/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5092 - accuracy: 0.7616 - val_loss: 0.4831 - val_accuracy: 0.7728\n",
            "Epoch 79/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5016 - accuracy: 0.7712 - val_loss: 0.4824 - val_accuracy: 0.7719\n",
            "Epoch 80/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4926 - accuracy: 0.7712 - val_loss: 0.4823 - val_accuracy: 0.7724\n",
            "Epoch 81/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5027 - accuracy: 0.7641 - val_loss: 0.4825 - val_accuracy: 0.7719\n",
            "Epoch 82/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4943 - accuracy: 0.7731 - val_loss: 0.4836 - val_accuracy: 0.7679\n",
            "Epoch 83/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5006 - accuracy: 0.7681 - val_loss: 0.4826 - val_accuracy: 0.7751\n",
            "Epoch 84/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4985 - accuracy: 0.7668 - val_loss: 0.4841 - val_accuracy: 0.7679\n",
            "Epoch 85/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4876 - accuracy: 0.7786 - val_loss: 0.4825 - val_accuracy: 0.7733\n",
            "Epoch 86/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5147 - accuracy: 0.7640 - val_loss: 0.4823 - val_accuracy: 0.7710\n",
            "Epoch 87/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5023 - accuracy: 0.7690 - val_loss: 0.4825 - val_accuracy: 0.7715\n",
            "Epoch 88/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4890 - accuracy: 0.7738 - val_loss: 0.4834 - val_accuracy: 0.7697\n",
            "Epoch 89/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5059 - accuracy: 0.7628 - val_loss: 0.4819 - val_accuracy: 0.7724\n",
            "Epoch 90/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5008 - accuracy: 0.7691 - val_loss: 0.4816 - val_accuracy: 0.7742\n",
            "Epoch 91/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5029 - accuracy: 0.7708 - val_loss: 0.4827 - val_accuracy: 0.7719\n",
            "Epoch 92/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5037 - accuracy: 0.7697 - val_loss: 0.4820 - val_accuracy: 0.7728\n",
            "Epoch 93/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4924 - accuracy: 0.7771 - val_loss: 0.4823 - val_accuracy: 0.7715\n",
            "Epoch 94/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4977 - accuracy: 0.7702 - val_loss: 0.4826 - val_accuracy: 0.7733\n",
            "Epoch 95/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5047 - accuracy: 0.7592 - val_loss: 0.4823 - val_accuracy: 0.7710\n",
            "Epoch 96/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4995 - accuracy: 0.7709 - val_loss: 0.4820 - val_accuracy: 0.7733\n",
            "Epoch 97/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4989 - accuracy: 0.7694 - val_loss: 0.4821 - val_accuracy: 0.7733\n",
            "Epoch 98/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4980 - accuracy: 0.7661 - val_loss: 0.4818 - val_accuracy: 0.7715\n",
            "Epoch 99/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4998 - accuracy: 0.7695 - val_loss: 0.4821 - val_accuracy: 0.7728\n",
            "Epoch 100/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5041 - accuracy: 0.7659 - val_loss: 0.4816 - val_accuracy: 0.7706\n",
            "Epoch 101/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5012 - accuracy: 0.7689 - val_loss: 0.4815 - val_accuracy: 0.7728\n",
            "Epoch 102/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4980 - accuracy: 0.7689 - val_loss: 0.4822 - val_accuracy: 0.7724\n",
            "Epoch 103/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5018 - accuracy: 0.7646 - val_loss: 0.4824 - val_accuracy: 0.7724\n",
            "Epoch 104/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5058 - accuracy: 0.7646 - val_loss: 0.4820 - val_accuracy: 0.7715\n",
            "Epoch 105/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4980 - accuracy: 0.7689 - val_loss: 0.4815 - val_accuracy: 0.7724\n",
            "Epoch 106/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4991 - accuracy: 0.7677 - val_loss: 0.4815 - val_accuracy: 0.7706\n",
            "Epoch 107/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4924 - accuracy: 0.7710 - val_loss: 0.4820 - val_accuracy: 0.7728\n",
            "Epoch 108/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4905 - accuracy: 0.7746 - val_loss: 0.4820 - val_accuracy: 0.7728\n",
            "Epoch 109/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4945 - accuracy: 0.7727 - val_loss: 0.4816 - val_accuracy: 0.7693\n",
            "Epoch 110/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4911 - accuracy: 0.7750 - val_loss: 0.4816 - val_accuracy: 0.7728\n",
            "Epoch 111/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4904 - accuracy: 0.7768 - val_loss: 0.4815 - val_accuracy: 0.7710\n",
            "Epoch 112/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5022 - accuracy: 0.7679 - val_loss: 0.4811 - val_accuracy: 0.7706\n",
            "Epoch 113/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4945 - accuracy: 0.7707 - val_loss: 0.4813 - val_accuracy: 0.7742\n",
            "Epoch 114/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4859 - accuracy: 0.7791 - val_loss: 0.4838 - val_accuracy: 0.7702\n",
            "Epoch 115/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4965 - accuracy: 0.7685 - val_loss: 0.4814 - val_accuracy: 0.7733\n",
            "Epoch 116/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4828 - accuracy: 0.7846 - val_loss: 0.4821 - val_accuracy: 0.7719\n",
            "Epoch 117/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4918 - accuracy: 0.7697 - val_loss: 0.4819 - val_accuracy: 0.7693\n",
            "Epoch 118/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4928 - accuracy: 0.7743 - val_loss: 0.4812 - val_accuracy: 0.7710\n",
            "Epoch 119/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4976 - accuracy: 0.7693 - val_loss: 0.4816 - val_accuracy: 0.7710\n",
            "Epoch 120/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5046 - accuracy: 0.7674 - val_loss: 0.4809 - val_accuracy: 0.7728\n",
            "Epoch 121/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4886 - accuracy: 0.7750 - val_loss: 0.4824 - val_accuracy: 0.7728\n",
            "Epoch 122/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4979 - accuracy: 0.7688 - val_loss: 0.4815 - val_accuracy: 0.7733\n",
            "Epoch 123/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4977 - accuracy: 0.7651 - val_loss: 0.4814 - val_accuracy: 0.7715\n",
            "Epoch 124/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4897 - accuracy: 0.7762 - val_loss: 0.4811 - val_accuracy: 0.7742\n",
            "Epoch 125/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5040 - accuracy: 0.7619 - val_loss: 0.4812 - val_accuracy: 0.7710\n",
            "Epoch 126/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5007 - accuracy: 0.7606 - val_loss: 0.4814 - val_accuracy: 0.7715\n",
            "Epoch 127/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4956 - accuracy: 0.7719 - val_loss: 0.4810 - val_accuracy: 0.7742\n",
            "Epoch 128/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4954 - accuracy: 0.7711 - val_loss: 0.4831 - val_accuracy: 0.7715\n",
            "Epoch 129/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4990 - accuracy: 0.7707 - val_loss: 0.4817 - val_accuracy: 0.7728\n",
            "Epoch 130/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4921 - accuracy: 0.7739 - val_loss: 0.4807 - val_accuracy: 0.7715\n",
            "Epoch 131/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4975 - accuracy: 0.7706 - val_loss: 0.4809 - val_accuracy: 0.7693\n",
            "Epoch 132/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4975 - accuracy: 0.7725 - val_loss: 0.4811 - val_accuracy: 0.7724\n",
            "Epoch 133/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5003 - accuracy: 0.7663 - val_loss: 0.4810 - val_accuracy: 0.7746\n",
            "Epoch 134/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4901 - accuracy: 0.7768 - val_loss: 0.4814 - val_accuracy: 0.7702\n",
            "Epoch 135/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4959 - accuracy: 0.7759 - val_loss: 0.4817 - val_accuracy: 0.7702\n",
            "Epoch 136/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5015 - accuracy: 0.7678 - val_loss: 0.4805 - val_accuracy: 0.7746\n",
            "Epoch 137/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5028 - accuracy: 0.7674 - val_loss: 0.4811 - val_accuracy: 0.7737\n",
            "Epoch 138/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4917 - accuracy: 0.7734 - val_loss: 0.4808 - val_accuracy: 0.7728\n",
            "Epoch 139/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4968 - accuracy: 0.7708 - val_loss: 0.4805 - val_accuracy: 0.7715\n",
            "Epoch 140/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4991 - accuracy: 0.7694 - val_loss: 0.4803 - val_accuracy: 0.7706\n",
            "Epoch 141/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5009 - accuracy: 0.7713 - val_loss: 0.4800 - val_accuracy: 0.7719\n",
            "Epoch 142/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5040 - accuracy: 0.7650 - val_loss: 0.4809 - val_accuracy: 0.7706\n",
            "Epoch 143/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4955 - accuracy: 0.7664 - val_loss: 0.4807 - val_accuracy: 0.7728\n",
            "Epoch 144/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4920 - accuracy: 0.7739 - val_loss: 0.4808 - val_accuracy: 0.7702\n",
            "Epoch 145/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5031 - accuracy: 0.7655 - val_loss: 0.4826 - val_accuracy: 0.7688\n",
            "Epoch 146/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4895 - accuracy: 0.7793 - val_loss: 0.4808 - val_accuracy: 0.7742\n",
            "Epoch 147/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4981 - accuracy: 0.7675 - val_loss: 0.4816 - val_accuracy: 0.7697\n",
            "Epoch 148/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4971 - accuracy: 0.7742 - val_loss: 0.4817 - val_accuracy: 0.7702\n",
            "Epoch 149/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4943 - accuracy: 0.7746 - val_loss: 0.4804 - val_accuracy: 0.7702\n",
            "Epoch 150/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4938 - accuracy: 0.7749 - val_loss: 0.4808 - val_accuracy: 0.7719\n",
            "Epoch 151/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4878 - accuracy: 0.7731 - val_loss: 0.4810 - val_accuracy: 0.7710\n",
            "Epoch 152/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4914 - accuracy: 0.7713 - val_loss: 0.4809 - val_accuracy: 0.7746\n",
            "Epoch 153/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4956 - accuracy: 0.7765 - val_loss: 0.4810 - val_accuracy: 0.7733\n",
            "Epoch 154/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4837 - accuracy: 0.7800 - val_loss: 0.4808 - val_accuracy: 0.7715\n",
            "Epoch 155/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4954 - accuracy: 0.7713 - val_loss: 0.4799 - val_accuracy: 0.7751\n",
            "Epoch 156/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4992 - accuracy: 0.7695 - val_loss: 0.4798 - val_accuracy: 0.7746\n",
            "Epoch 157/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4889 - accuracy: 0.7725 - val_loss: 0.4807 - val_accuracy: 0.7706\n",
            "Epoch 158/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4978 - accuracy: 0.7704 - val_loss: 0.4806 - val_accuracy: 0.7728\n",
            "Epoch 159/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4996 - accuracy: 0.7661 - val_loss: 0.4800 - val_accuracy: 0.7728\n",
            "Epoch 160/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5085 - accuracy: 0.7652 - val_loss: 0.4807 - val_accuracy: 0.7719\n",
            "Epoch 161/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4897 - accuracy: 0.7711 - val_loss: 0.4800 - val_accuracy: 0.7755\n",
            "Epoch 162/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4942 - accuracy: 0.7696 - val_loss: 0.4809 - val_accuracy: 0.7702\n",
            "Epoch 163/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4813 - accuracy: 0.7774 - val_loss: 0.4822 - val_accuracy: 0.7693\n",
            "Epoch 164/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4993 - accuracy: 0.7678 - val_loss: 0.4799 - val_accuracy: 0.7755\n",
            "Epoch 165/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4869 - accuracy: 0.7752 - val_loss: 0.4800 - val_accuracy: 0.7733\n",
            "Epoch 166/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4917 - accuracy: 0.7759 - val_loss: 0.4802 - val_accuracy: 0.7737\n",
            "Epoch 167/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4885 - accuracy: 0.7719 - val_loss: 0.4801 - val_accuracy: 0.7693\n",
            "Epoch 168/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5037 - accuracy: 0.7666 - val_loss: 0.4802 - val_accuracy: 0.7706\n",
            "Epoch 169/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4924 - accuracy: 0.7701 - val_loss: 0.4802 - val_accuracy: 0.7746\n",
            "Epoch 170/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4967 - accuracy: 0.7660 - val_loss: 0.4802 - val_accuracy: 0.7710\n",
            "Epoch 171/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4901 - accuracy: 0.7748 - val_loss: 0.4800 - val_accuracy: 0.7728\n",
            "Epoch 172/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4918 - accuracy: 0.7745 - val_loss: 0.4798 - val_accuracy: 0.7737\n",
            "Epoch 173/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4905 - accuracy: 0.7759 - val_loss: 0.4820 - val_accuracy: 0.7710\n",
            "Epoch 174/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4938 - accuracy: 0.7723 - val_loss: 0.4800 - val_accuracy: 0.7742\n",
            "Epoch 175/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4952 - accuracy: 0.7774 - val_loss: 0.4803 - val_accuracy: 0.7742\n",
            "Epoch 176/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4863 - accuracy: 0.7807 - val_loss: 0.4820 - val_accuracy: 0.7706\n",
            "Epoch 177/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4903 - accuracy: 0.7724 - val_loss: 0.4801 - val_accuracy: 0.7715\n",
            "Epoch 178/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4946 - accuracy: 0.7706 - val_loss: 0.4809 - val_accuracy: 0.7724\n",
            "Epoch 179/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4919 - accuracy: 0.7727 - val_loss: 0.4807 - val_accuracy: 0.7706\n",
            "Epoch 180/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4969 - accuracy: 0.7672 - val_loss: 0.4801 - val_accuracy: 0.7733\n",
            "Epoch 181/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4976 - accuracy: 0.7677 - val_loss: 0.4800 - val_accuracy: 0.7710\n",
            "Epoch 182/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4889 - accuracy: 0.7734 - val_loss: 0.4807 - val_accuracy: 0.7733\n",
            "Epoch 183/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4984 - accuracy: 0.7694 - val_loss: 0.4802 - val_accuracy: 0.7724\n",
            "Epoch 184/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4894 - accuracy: 0.7722 - val_loss: 0.4803 - val_accuracy: 0.7759\n",
            "Epoch 185/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5038 - accuracy: 0.7598 - val_loss: 0.4797 - val_accuracy: 0.7724\n",
            "Epoch 186/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4908 - accuracy: 0.7713 - val_loss: 0.4813 - val_accuracy: 0.7746\n",
            "Epoch 187/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4930 - accuracy: 0.7702 - val_loss: 0.4800 - val_accuracy: 0.7764\n",
            "Epoch 188/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4955 - accuracy: 0.7770 - val_loss: 0.4800 - val_accuracy: 0.7710\n",
            "Epoch 189/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5008 - accuracy: 0.7630 - val_loss: 0.4801 - val_accuracy: 0.7759\n",
            "Epoch 190/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5020 - accuracy: 0.7709 - val_loss: 0.4798 - val_accuracy: 0.7764\n",
            "Epoch 191/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4965 - accuracy: 0.7702 - val_loss: 0.4797 - val_accuracy: 0.7755\n",
            "Epoch 192/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4878 - accuracy: 0.7789 - val_loss: 0.4808 - val_accuracy: 0.7710\n",
            "Epoch 193/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5042 - accuracy: 0.7630 - val_loss: 0.4803 - val_accuracy: 0.7746\n",
            "Epoch 194/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4919 - accuracy: 0.7742 - val_loss: 0.4803 - val_accuracy: 0.7697\n",
            "Epoch 195/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4928 - accuracy: 0.7720 - val_loss: 0.4798 - val_accuracy: 0.7719\n",
            "Epoch 196/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4892 - accuracy: 0.7753 - val_loss: 0.4829 - val_accuracy: 0.7684\n",
            "Epoch 197/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4915 - accuracy: 0.7689 - val_loss: 0.4819 - val_accuracy: 0.7706\n",
            "Epoch 198/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4918 - accuracy: 0.7736 - val_loss: 0.4794 - val_accuracy: 0.7751\n",
            "Epoch 199/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4967 - accuracy: 0.7752 - val_loss: 0.4795 - val_accuracy: 0.7746\n",
            "Epoch 200/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4917 - accuracy: 0.7750 - val_loss: 0.4805 - val_accuracy: 0.7733\n",
            "Epoch 201/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4968 - accuracy: 0.7676 - val_loss: 0.4820 - val_accuracy: 0.7693\n",
            "Epoch 202/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4831 - accuracy: 0.7802 - val_loss: 0.4798 - val_accuracy: 0.7751\n",
            "Epoch 203/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4918 - accuracy: 0.7701 - val_loss: 0.4799 - val_accuracy: 0.7751\n",
            "Epoch 204/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4873 - accuracy: 0.7793 - val_loss: 0.4807 - val_accuracy: 0.7733\n",
            "Epoch 205/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5020 - accuracy: 0.7666 - val_loss: 0.4808 - val_accuracy: 0.7733\n",
            "Epoch 206/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4878 - accuracy: 0.7764 - val_loss: 0.4808 - val_accuracy: 0.7706\n",
            "Epoch 207/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4998 - accuracy: 0.7710 - val_loss: 0.4803 - val_accuracy: 0.7742\n",
            "Epoch 208/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4914 - accuracy: 0.7758 - val_loss: 0.4794 - val_accuracy: 0.7751\n",
            "Epoch 209/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5039 - accuracy: 0.7662 - val_loss: 0.4799 - val_accuracy: 0.7755\n",
            "Epoch 210/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4909 - accuracy: 0.7750 - val_loss: 0.4796 - val_accuracy: 0.7724\n",
            "Epoch 211/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4998 - accuracy: 0.7690 - val_loss: 0.4796 - val_accuracy: 0.7746\n",
            "Epoch 212/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4915 - accuracy: 0.7719 - val_loss: 0.4799 - val_accuracy: 0.7742\n",
            "Epoch 213/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4977 - accuracy: 0.7705 - val_loss: 0.4803 - val_accuracy: 0.7746\n",
            "Epoch 214/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4976 - accuracy: 0.7709 - val_loss: 0.4805 - val_accuracy: 0.7742\n",
            "Epoch 215/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4919 - accuracy: 0.7719 - val_loss: 0.4810 - val_accuracy: 0.7742\n",
            "Epoch 216/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4869 - accuracy: 0.7764 - val_loss: 0.4803 - val_accuracy: 0.7710\n",
            "Epoch 217/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4939 - accuracy: 0.7685 - val_loss: 0.4798 - val_accuracy: 0.7746\n",
            "Epoch 218/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4934 - accuracy: 0.7761 - val_loss: 0.4796 - val_accuracy: 0.7755\n",
            "Epoch 219/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4940 - accuracy: 0.7703 - val_loss: 0.4800 - val_accuracy: 0.7733\n",
            "Epoch 220/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4876 - accuracy: 0.7733 - val_loss: 0.4798 - val_accuracy: 0.7724\n",
            "Epoch 221/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4888 - accuracy: 0.7751 - val_loss: 0.4799 - val_accuracy: 0.7751\n",
            "Epoch 222/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4947 - accuracy: 0.7694 - val_loss: 0.4805 - val_accuracy: 0.7710\n",
            "Epoch 223/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4995 - accuracy: 0.7734 - val_loss: 0.4801 - val_accuracy: 0.7728\n",
            "Epoch 224/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4861 - accuracy: 0.7767 - val_loss: 0.4802 - val_accuracy: 0.7746\n",
            "Epoch 225/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4910 - accuracy: 0.7706 - val_loss: 0.4794 - val_accuracy: 0.7746\n",
            "Epoch 226/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4921 - accuracy: 0.7724 - val_loss: 0.4807 - val_accuracy: 0.7693\n",
            "Epoch 227/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4929 - accuracy: 0.7766 - val_loss: 0.4793 - val_accuracy: 0.7733\n",
            "Epoch 228/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4765 - accuracy: 0.7820 - val_loss: 0.4793 - val_accuracy: 0.7737\n",
            "Epoch 229/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4890 - accuracy: 0.7735 - val_loss: 0.4797 - val_accuracy: 0.7710\n",
            "Epoch 230/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4986 - accuracy: 0.7676 - val_loss: 0.4793 - val_accuracy: 0.7715\n",
            "Epoch 231/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4983 - accuracy: 0.7717 - val_loss: 0.4797 - val_accuracy: 0.7768\n",
            "Epoch 232/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4942 - accuracy: 0.7650 - val_loss: 0.4801 - val_accuracy: 0.7742\n",
            "Epoch 233/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4940 - accuracy: 0.7707 - val_loss: 0.4797 - val_accuracy: 0.7737\n",
            "Epoch 234/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4970 - accuracy: 0.7714 - val_loss: 0.4798 - val_accuracy: 0.7733\n",
            "Epoch 235/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5011 - accuracy: 0.7715 - val_loss: 0.4794 - val_accuracy: 0.7728\n",
            "Epoch 236/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4896 - accuracy: 0.7738 - val_loss: 0.4801 - val_accuracy: 0.7733\n",
            "Epoch 237/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4885 - accuracy: 0.7732 - val_loss: 0.4812 - val_accuracy: 0.7710\n",
            "Epoch 238/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4907 - accuracy: 0.7729 - val_loss: 0.4802 - val_accuracy: 0.7715\n",
            "Epoch 239/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4857 - accuracy: 0.7759 - val_loss: 0.4814 - val_accuracy: 0.7737\n",
            "Epoch 240/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4923 - accuracy: 0.7730 - val_loss: 0.4796 - val_accuracy: 0.7746\n",
            "Epoch 241/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4979 - accuracy: 0.7714 - val_loss: 0.4796 - val_accuracy: 0.7702\n",
            "Epoch 242/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4948 - accuracy: 0.7703 - val_loss: 0.4802 - val_accuracy: 0.7759\n",
            "Epoch 243/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4951 - accuracy: 0.7747 - val_loss: 0.4803 - val_accuracy: 0.7706\n",
            "Epoch 244/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4924 - accuracy: 0.7685 - val_loss: 0.4793 - val_accuracy: 0.7710\n",
            "Epoch 245/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4876 - accuracy: 0.7751 - val_loss: 0.4813 - val_accuracy: 0.7728\n",
            "Epoch 246/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4868 - accuracy: 0.7745 - val_loss: 0.4800 - val_accuracy: 0.7742\n",
            "Epoch 247/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4960 - accuracy: 0.7698 - val_loss: 0.4797 - val_accuracy: 0.7737\n",
            "Epoch 248/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4907 - accuracy: 0.7708 - val_loss: 0.4800 - val_accuracy: 0.7697\n",
            "Epoch 249/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4898 - accuracy: 0.7757 - val_loss: 0.4806 - val_accuracy: 0.7697\n",
            "Epoch 250/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4827 - accuracy: 0.7783 - val_loss: 0.4814 - val_accuracy: 0.7715\n",
            "Epoch 251/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4883 - accuracy: 0.7716 - val_loss: 0.4812 - val_accuracy: 0.7719\n",
            "Epoch 252/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4995 - accuracy: 0.7711 - val_loss: 0.4797 - val_accuracy: 0.7742\n",
            "Epoch 253/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4975 - accuracy: 0.7698 - val_loss: 0.4791 - val_accuracy: 0.7719\n",
            "Epoch 254/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4929 - accuracy: 0.7736 - val_loss: 0.4793 - val_accuracy: 0.7737\n",
            "Epoch 255/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4966 - accuracy: 0.7700 - val_loss: 0.4794 - val_accuracy: 0.7688\n",
            "Epoch 256/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4879 - accuracy: 0.7809 - val_loss: 0.4801 - val_accuracy: 0.7737\n",
            "Epoch 257/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4976 - accuracy: 0.7658 - val_loss: 0.4798 - val_accuracy: 0.7719\n",
            "Epoch 258/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4868 - accuracy: 0.7773 - val_loss: 0.4797 - val_accuracy: 0.7755\n",
            "Epoch 259/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4915 - accuracy: 0.7690 - val_loss: 0.4799 - val_accuracy: 0.7733\n",
            "Epoch 260/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4908 - accuracy: 0.7703 - val_loss: 0.4816 - val_accuracy: 0.7715\n",
            "Epoch 261/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4816 - accuracy: 0.7777 - val_loss: 0.4806 - val_accuracy: 0.7755\n",
            "Epoch 262/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4893 - accuracy: 0.7732 - val_loss: 0.4793 - val_accuracy: 0.7742\n",
            "Epoch 263/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4809 - accuracy: 0.7804 - val_loss: 0.4798 - val_accuracy: 0.7733\n",
            "Epoch 264/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4909 - accuracy: 0.7768 - val_loss: 0.4788 - val_accuracy: 0.7737\n",
            "Epoch 265/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4966 - accuracy: 0.7684 - val_loss: 0.4810 - val_accuracy: 0.7719\n",
            "Epoch 266/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4925 - accuracy: 0.7689 - val_loss: 0.4791 - val_accuracy: 0.7746\n",
            "Epoch 267/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4970 - accuracy: 0.7711 - val_loss: 0.4793 - val_accuracy: 0.7746\n",
            "Epoch 268/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4870 - accuracy: 0.7782 - val_loss: 0.4791 - val_accuracy: 0.7702\n",
            "Epoch 269/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4995 - accuracy: 0.7654 - val_loss: 0.4796 - val_accuracy: 0.7728\n",
            "Epoch 270/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4851 - accuracy: 0.7731 - val_loss: 0.4793 - val_accuracy: 0.7719\n",
            "Epoch 271/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4986 - accuracy: 0.7677 - val_loss: 0.4791 - val_accuracy: 0.7759\n",
            "Epoch 272/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4894 - accuracy: 0.7731 - val_loss: 0.4794 - val_accuracy: 0.7710\n",
            "Epoch 273/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4948 - accuracy: 0.7670 - val_loss: 0.4790 - val_accuracy: 0.7724\n",
            "Epoch 274/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4942 - accuracy: 0.7698 - val_loss: 0.4791 - val_accuracy: 0.7751\n",
            "Epoch 275/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4902 - accuracy: 0.7733 - val_loss: 0.4795 - val_accuracy: 0.7737\n",
            "Epoch 276/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4936 - accuracy: 0.7738 - val_loss: 0.4809 - val_accuracy: 0.7724\n",
            "Epoch 277/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4900 - accuracy: 0.7730 - val_loss: 0.4801 - val_accuracy: 0.7697\n",
            "Epoch 278/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4935 - accuracy: 0.7733 - val_loss: 0.4796 - val_accuracy: 0.7719\n",
            "Epoch 279/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4858 - accuracy: 0.7793 - val_loss: 0.4793 - val_accuracy: 0.7751\n",
            "Epoch 280/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4807 - accuracy: 0.7753 - val_loss: 0.4800 - val_accuracy: 0.7715\n",
            "Epoch 281/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4930 - accuracy: 0.7678 - val_loss: 0.4795 - val_accuracy: 0.7728\n",
            "Epoch 282/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5000 - accuracy: 0.7674 - val_loss: 0.4790 - val_accuracy: 0.7702\n",
            "Epoch 283/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4935 - accuracy: 0.7720 - val_loss: 0.4791 - val_accuracy: 0.7733\n",
            "Epoch 284/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4823 - accuracy: 0.7829 - val_loss: 0.4792 - val_accuracy: 0.7742\n",
            "Epoch 285/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5021 - accuracy: 0.7630 - val_loss: 0.4797 - val_accuracy: 0.7724\n",
            "Epoch 286/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4950 - accuracy: 0.7731 - val_loss: 0.4798 - val_accuracy: 0.7697\n",
            "Epoch 287/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4954 - accuracy: 0.7715 - val_loss: 0.4794 - val_accuracy: 0.7742\n",
            "Epoch 288/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4996 - accuracy: 0.7688 - val_loss: 0.4794 - val_accuracy: 0.7733\n",
            "Epoch 289/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4880 - accuracy: 0.7780 - val_loss: 0.4808 - val_accuracy: 0.7688\n",
            "Epoch 290/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4879 - accuracy: 0.7797 - val_loss: 0.4798 - val_accuracy: 0.7746\n",
            "Epoch 291/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4881 - accuracy: 0.7709 - val_loss: 0.4798 - val_accuracy: 0.7746\n",
            "Epoch 292/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4903 - accuracy: 0.7754 - val_loss: 0.4793 - val_accuracy: 0.7764\n",
            "Epoch 293/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4888 - accuracy: 0.7753 - val_loss: 0.4793 - val_accuracy: 0.7737\n",
            "Epoch 294/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4861 - accuracy: 0.7769 - val_loss: 0.4790 - val_accuracy: 0.7737\n",
            "Epoch 295/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4938 - accuracy: 0.7701 - val_loss: 0.4794 - val_accuracy: 0.7728\n",
            "Epoch 296/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4901 - accuracy: 0.7755 - val_loss: 0.4802 - val_accuracy: 0.7719\n",
            "Epoch 297/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4857 - accuracy: 0.7735 - val_loss: 0.4798 - val_accuracy: 0.7728\n",
            "Epoch 298/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4972 - accuracy: 0.7667 - val_loss: 0.4795 - val_accuracy: 0.7733\n",
            "Epoch 299/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4908 - accuracy: 0.7760 - val_loss: 0.4791 - val_accuracy: 0.7742\n",
            "Epoch 300/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4946 - accuracy: 0.7717 - val_loss: 0.4807 - val_accuracy: 0.7715\n",
            "Epoch 301/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4804 - accuracy: 0.7807 - val_loss: 0.4796 - val_accuracy: 0.7737\n",
            "Epoch 302/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4897 - accuracy: 0.7808 - val_loss: 0.4795 - val_accuracy: 0.7737\n",
            "Epoch 303/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4968 - accuracy: 0.7643 - val_loss: 0.4801 - val_accuracy: 0.7724\n",
            "Epoch 304/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4943 - accuracy: 0.7719 - val_loss: 0.4802 - val_accuracy: 0.7737\n",
            "Epoch 305/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4923 - accuracy: 0.7704 - val_loss: 0.4801 - val_accuracy: 0.7737\n",
            "Epoch 306/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4901 - accuracy: 0.7752 - val_loss: 0.4802 - val_accuracy: 0.7719\n",
            "Epoch 307/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4941 - accuracy: 0.7669 - val_loss: 0.4796 - val_accuracy: 0.7715\n",
            "Epoch 308/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4972 - accuracy: 0.7766 - val_loss: 0.4798 - val_accuracy: 0.7737\n",
            "Epoch 309/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4923 - accuracy: 0.7752 - val_loss: 0.4797 - val_accuracy: 0.7742\n",
            "Epoch 310/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4862 - accuracy: 0.7765 - val_loss: 0.4790 - val_accuracy: 0.7742\n",
            "Epoch 311/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4958 - accuracy: 0.7661 - val_loss: 0.4795 - val_accuracy: 0.7719\n",
            "Epoch 312/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4926 - accuracy: 0.7704 - val_loss: 0.4792 - val_accuracy: 0.7737\n",
            "Epoch 313/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4842 - accuracy: 0.7842 - val_loss: 0.4798 - val_accuracy: 0.7751\n",
            "Epoch 314/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4894 - accuracy: 0.7758 - val_loss: 0.4809 - val_accuracy: 0.7737\n",
            "Epoch 315/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4966 - accuracy: 0.7665 - val_loss: 0.4790 - val_accuracy: 0.7733\n",
            "Epoch 316/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4924 - accuracy: 0.7673 - val_loss: 0.4792 - val_accuracy: 0.7755\n",
            "Epoch 317/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5011 - accuracy: 0.7692 - val_loss: 0.4793 - val_accuracy: 0.7755\n",
            "Epoch 318/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4885 - accuracy: 0.7723 - val_loss: 0.4795 - val_accuracy: 0.7751\n",
            "Epoch 319/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4952 - accuracy: 0.7686 - val_loss: 0.4791 - val_accuracy: 0.7751\n",
            "Epoch 320/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4860 - accuracy: 0.7748 - val_loss: 0.4797 - val_accuracy: 0.7742\n",
            "Epoch 321/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4943 - accuracy: 0.7705 - val_loss: 0.4797 - val_accuracy: 0.7724\n",
            "Epoch 322/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4982 - accuracy: 0.7711 - val_loss: 0.4790 - val_accuracy: 0.7715\n",
            "Epoch 323/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4951 - accuracy: 0.7731 - val_loss: 0.4796 - val_accuracy: 0.7742\n",
            "Epoch 324/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4822 - accuracy: 0.7788 - val_loss: 0.4793 - val_accuracy: 0.7759\n",
            "Epoch 325/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4924 - accuracy: 0.7770 - val_loss: 0.4805 - val_accuracy: 0.7733\n",
            "Epoch 326/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4930 - accuracy: 0.7708 - val_loss: 0.4793 - val_accuracy: 0.7737\n",
            "Epoch 327/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4769 - accuracy: 0.7817 - val_loss: 0.4787 - val_accuracy: 0.7755\n",
            "Epoch 328/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4894 - accuracy: 0.7742 - val_loss: 0.4789 - val_accuracy: 0.7751\n",
            "Epoch 329/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4927 - accuracy: 0.7722 - val_loss: 0.4793 - val_accuracy: 0.7737\n",
            "Epoch 330/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4907 - accuracy: 0.7731 - val_loss: 0.4791 - val_accuracy: 0.7724\n",
            "Epoch 331/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4937 - accuracy: 0.7719 - val_loss: 0.4797 - val_accuracy: 0.7697\n",
            "Epoch 332/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4946 - accuracy: 0.7717 - val_loss: 0.4790 - val_accuracy: 0.7755\n",
            "Epoch 333/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4883 - accuracy: 0.7706 - val_loss: 0.4796 - val_accuracy: 0.7737\n",
            "Epoch 334/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4883 - accuracy: 0.7717 - val_loss: 0.4787 - val_accuracy: 0.7746\n",
            "Epoch 335/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4868 - accuracy: 0.7774 - val_loss: 0.4788 - val_accuracy: 0.7742\n",
            "Epoch 336/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4872 - accuracy: 0.7740 - val_loss: 0.4794 - val_accuracy: 0.7737\n",
            "Epoch 337/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4917 - accuracy: 0.7713 - val_loss: 0.4791 - val_accuracy: 0.7737\n",
            "Epoch 338/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4785 - accuracy: 0.7826 - val_loss: 0.4806 - val_accuracy: 0.7697\n",
            "Epoch 339/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4854 - accuracy: 0.7736 - val_loss: 0.4789 - val_accuracy: 0.7733\n",
            "Epoch 340/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4968 - accuracy: 0.7679 - val_loss: 0.4787 - val_accuracy: 0.7764\n",
            "Epoch 341/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4813 - accuracy: 0.7757 - val_loss: 0.4794 - val_accuracy: 0.7737\n",
            "Epoch 342/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4842 - accuracy: 0.7824 - val_loss: 0.4788 - val_accuracy: 0.7728\n",
            "Epoch 343/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4918 - accuracy: 0.7727 - val_loss: 0.4797 - val_accuracy: 0.7719\n",
            "Epoch 344/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4944 - accuracy: 0.7725 - val_loss: 0.4795 - val_accuracy: 0.7719\n",
            "Epoch 345/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4860 - accuracy: 0.7799 - val_loss: 0.4798 - val_accuracy: 0.7728\n",
            "Epoch 346/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4913 - accuracy: 0.7734 - val_loss: 0.4794 - val_accuracy: 0.7733\n",
            "Epoch 347/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4950 - accuracy: 0.7727 - val_loss: 0.4792 - val_accuracy: 0.7728\n",
            "Epoch 348/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4965 - accuracy: 0.7694 - val_loss: 0.4801 - val_accuracy: 0.7737\n",
            "Epoch 349/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4883 - accuracy: 0.7736 - val_loss: 0.4794 - val_accuracy: 0.7742\n",
            "Epoch 350/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4911 - accuracy: 0.7727 - val_loss: 0.4787 - val_accuracy: 0.7724\n",
            "Epoch 351/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4907 - accuracy: 0.7723 - val_loss: 0.4783 - val_accuracy: 0.7755\n",
            "Epoch 352/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4920 - accuracy: 0.7700 - val_loss: 0.4784 - val_accuracy: 0.7742\n",
            "Epoch 353/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4987 - accuracy: 0.7689 - val_loss: 0.4795 - val_accuracy: 0.7724\n",
            "Epoch 354/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4940 - accuracy: 0.7704 - val_loss: 0.4798 - val_accuracy: 0.7715\n",
            "Epoch 355/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4994 - accuracy: 0.7749 - val_loss: 0.4799 - val_accuracy: 0.7697\n",
            "Epoch 356/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4849 - accuracy: 0.7744 - val_loss: 0.4785 - val_accuracy: 0.7755\n",
            "Epoch 357/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4909 - accuracy: 0.7702 - val_loss: 0.4785 - val_accuracy: 0.7742\n",
            "Epoch 358/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4855 - accuracy: 0.7745 - val_loss: 0.4788 - val_accuracy: 0.7728\n",
            "Epoch 359/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4917 - accuracy: 0.7739 - val_loss: 0.4792 - val_accuracy: 0.7751\n",
            "Epoch 360/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4879 - accuracy: 0.7746 - val_loss: 0.4790 - val_accuracy: 0.7737\n",
            "Epoch 361/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4896 - accuracy: 0.7741 - val_loss: 0.4788 - val_accuracy: 0.7773\n",
            "Epoch 362/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4842 - accuracy: 0.7731 - val_loss: 0.4792 - val_accuracy: 0.7706\n",
            "Epoch 363/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4947 - accuracy: 0.7737 - val_loss: 0.4800 - val_accuracy: 0.7715\n",
            "Epoch 364/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4985 - accuracy: 0.7681 - val_loss: 0.4788 - val_accuracy: 0.7737\n",
            "Epoch 365/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4910 - accuracy: 0.7711 - val_loss: 0.4788 - val_accuracy: 0.7724\n",
            "Epoch 366/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4869 - accuracy: 0.7731 - val_loss: 0.4790 - val_accuracy: 0.7737\n",
            "Epoch 367/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4909 - accuracy: 0.7744 - val_loss: 0.4786 - val_accuracy: 0.7733\n",
            "Epoch 368/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5012 - accuracy: 0.7733 - val_loss: 0.4790 - val_accuracy: 0.7719\n",
            "Epoch 369/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4880 - accuracy: 0.7761 - val_loss: 0.4786 - val_accuracy: 0.7746\n",
            "Epoch 370/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4819 - accuracy: 0.7808 - val_loss: 0.4805 - val_accuracy: 0.7706\n",
            "Epoch 371/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4807 - accuracy: 0.7793 - val_loss: 0.4802 - val_accuracy: 0.7702\n",
            "Epoch 372/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4833 - accuracy: 0.7782 - val_loss: 0.4797 - val_accuracy: 0.7724\n",
            "Epoch 373/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4884 - accuracy: 0.7732 - val_loss: 0.4797 - val_accuracy: 0.7742\n",
            "Epoch 374/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4831 - accuracy: 0.7783 - val_loss: 0.4787 - val_accuracy: 0.7715\n",
            "Epoch 375/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4891 - accuracy: 0.7687 - val_loss: 0.4797 - val_accuracy: 0.7719\n",
            "Epoch 376/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4841 - accuracy: 0.7773 - val_loss: 0.4784 - val_accuracy: 0.7742\n",
            "Epoch 377/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4952 - accuracy: 0.7693 - val_loss: 0.4786 - val_accuracy: 0.7733\n",
            "Epoch 378/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4876 - accuracy: 0.7783 - val_loss: 0.4786 - val_accuracy: 0.7751\n",
            "Epoch 379/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4981 - accuracy: 0.7640 - val_loss: 0.4797 - val_accuracy: 0.7742\n",
            "Epoch 380/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4939 - accuracy: 0.7785 - val_loss: 0.4793 - val_accuracy: 0.7742\n",
            "Epoch 381/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4921 - accuracy: 0.7737 - val_loss: 0.4791 - val_accuracy: 0.7759\n",
            "Epoch 382/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4932 - accuracy: 0.7706 - val_loss: 0.4795 - val_accuracy: 0.7742\n",
            "Epoch 383/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4963 - accuracy: 0.7715 - val_loss: 0.4789 - val_accuracy: 0.7728\n",
            "Epoch 384/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4954 - accuracy: 0.7675 - val_loss: 0.4787 - val_accuracy: 0.7724\n",
            "Epoch 385/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4864 - accuracy: 0.7791 - val_loss: 0.4785 - val_accuracy: 0.7755\n",
            "Epoch 386/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4941 - accuracy: 0.7728 - val_loss: 0.4788 - val_accuracy: 0.7746\n",
            "Epoch 387/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4854 - accuracy: 0.7757 - val_loss: 0.4786 - val_accuracy: 0.7719\n",
            "Epoch 388/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4864 - accuracy: 0.7759 - val_loss: 0.4788 - val_accuracy: 0.7719\n",
            "Epoch 389/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4906 - accuracy: 0.7723 - val_loss: 0.4786 - val_accuracy: 0.7724\n",
            "Epoch 390/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4885 - accuracy: 0.7743 - val_loss: 0.4790 - val_accuracy: 0.7728\n",
            "Epoch 391/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4814 - accuracy: 0.7795 - val_loss: 0.4789 - val_accuracy: 0.7733\n",
            "Epoch 392/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4990 - accuracy: 0.7688 - val_loss: 0.4797 - val_accuracy: 0.7719\n",
            "Epoch 393/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4739 - accuracy: 0.7859 - val_loss: 0.4790 - val_accuracy: 0.7751\n",
            "Epoch 394/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4926 - accuracy: 0.7704 - val_loss: 0.4788 - val_accuracy: 0.7733\n",
            "Epoch 395/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4922 - accuracy: 0.7696 - val_loss: 0.4790 - val_accuracy: 0.7724\n",
            "Epoch 396/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4781 - accuracy: 0.7784 - val_loss: 0.4793 - val_accuracy: 0.7746\n",
            "Epoch 397/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4876 - accuracy: 0.7746 - val_loss: 0.4795 - val_accuracy: 0.7710\n",
            "Epoch 398/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4988 - accuracy: 0.7672 - val_loss: 0.4794 - val_accuracy: 0.7737\n",
            "Epoch 399/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4883 - accuracy: 0.7765 - val_loss: 0.4800 - val_accuracy: 0.7710\n",
            "Epoch 400/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4895 - accuracy: 0.7734 - val_loss: 0.4790 - val_accuracy: 0.7751\n",
            "Epoch 401/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4873 - accuracy: 0.7777 - val_loss: 0.4798 - val_accuracy: 0.7710\n",
            "Epoch 402/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4805 - accuracy: 0.7800 - val_loss: 0.4797 - val_accuracy: 0.7755\n",
            "Epoch 403/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4901 - accuracy: 0.7708 - val_loss: 0.4788 - val_accuracy: 0.7728\n",
            "Epoch 404/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4876 - accuracy: 0.7755 - val_loss: 0.4793 - val_accuracy: 0.7737\n",
            "Epoch 405/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4823 - accuracy: 0.7803 - val_loss: 0.4806 - val_accuracy: 0.7751\n",
            "Epoch 406/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4795 - accuracy: 0.7786 - val_loss: 0.4797 - val_accuracy: 0.7728\n",
            "Epoch 407/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4928 - accuracy: 0.7679 - val_loss: 0.4791 - val_accuracy: 0.7759\n",
            "Epoch 408/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4868 - accuracy: 0.7739 - val_loss: 0.4807 - val_accuracy: 0.7715\n",
            "Epoch 409/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4897 - accuracy: 0.7796 - val_loss: 0.4790 - val_accuracy: 0.7755\n",
            "Epoch 410/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4897 - accuracy: 0.7694 - val_loss: 0.4787 - val_accuracy: 0.7768\n",
            "Epoch 411/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4802 - accuracy: 0.7806 - val_loss: 0.4802 - val_accuracy: 0.7728\n",
            "Epoch 412/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4901 - accuracy: 0.7679 - val_loss: 0.4789 - val_accuracy: 0.7715\n",
            "Epoch 413/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4888 - accuracy: 0.7746 - val_loss: 0.4796 - val_accuracy: 0.7742\n",
            "Epoch 414/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4857 - accuracy: 0.7755 - val_loss: 0.4787 - val_accuracy: 0.7733\n",
            "Epoch 415/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4848 - accuracy: 0.7753 - val_loss: 0.4789 - val_accuracy: 0.7706\n",
            "Epoch 416/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4913 - accuracy: 0.7724 - val_loss: 0.4788 - val_accuracy: 0.7724\n",
            "Epoch 417/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4883 - accuracy: 0.7790 - val_loss: 0.4799 - val_accuracy: 0.7728\n",
            "Epoch 418/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4828 - accuracy: 0.7802 - val_loss: 0.4790 - val_accuracy: 0.7719\n",
            "Epoch 419/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5003 - accuracy: 0.7615 - val_loss: 0.4787 - val_accuracy: 0.7710\n",
            "Epoch 420/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4896 - accuracy: 0.7788 - val_loss: 0.4789 - val_accuracy: 0.7724\n",
            "Epoch 421/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4974 - accuracy: 0.7680 - val_loss: 0.4788 - val_accuracy: 0.7737\n",
            "Epoch 422/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4811 - accuracy: 0.7791 - val_loss: 0.4788 - val_accuracy: 0.7751\n",
            "Epoch 423/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4931 - accuracy: 0.7692 - val_loss: 0.4787 - val_accuracy: 0.7737\n",
            "Epoch 424/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4910 - accuracy: 0.7728 - val_loss: 0.4794 - val_accuracy: 0.7728\n",
            "Epoch 425/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4930 - accuracy: 0.7722 - val_loss: 0.4787 - val_accuracy: 0.7751\n",
            "Epoch 426/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4883 - accuracy: 0.7752 - val_loss: 0.4785 - val_accuracy: 0.7759\n",
            "Epoch 427/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4785 - accuracy: 0.7810 - val_loss: 0.4801 - val_accuracy: 0.7764\n",
            "Epoch 428/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4861 - accuracy: 0.7757 - val_loss: 0.4786 - val_accuracy: 0.7728\n",
            "Epoch 429/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4978 - accuracy: 0.7683 - val_loss: 0.4787 - val_accuracy: 0.7724\n",
            "Epoch 430/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4827 - accuracy: 0.7755 - val_loss: 0.4801 - val_accuracy: 0.7693\n",
            "Epoch 431/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4861 - accuracy: 0.7803 - val_loss: 0.4799 - val_accuracy: 0.7724\n",
            "Epoch 432/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4886 - accuracy: 0.7746 - val_loss: 0.4784 - val_accuracy: 0.7764\n",
            "Epoch 433/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4838 - accuracy: 0.7766 - val_loss: 0.4795 - val_accuracy: 0.7733\n",
            "Epoch 434/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4906 - accuracy: 0.7738 - val_loss: 0.4784 - val_accuracy: 0.7742\n",
            "Epoch 435/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4744 - accuracy: 0.7860 - val_loss: 0.4783 - val_accuracy: 0.7751\n",
            "Epoch 436/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5054 - accuracy: 0.7639 - val_loss: 0.4785 - val_accuracy: 0.7742\n",
            "Epoch 437/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4989 - accuracy: 0.7649 - val_loss: 0.4792 - val_accuracy: 0.7715\n",
            "Epoch 438/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4922 - accuracy: 0.7712 - val_loss: 0.4785 - val_accuracy: 0.7764\n",
            "Epoch 439/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4931 - accuracy: 0.7740 - val_loss: 0.4788 - val_accuracy: 0.7724\n",
            "Epoch 440/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4881 - accuracy: 0.7762 - val_loss: 0.4789 - val_accuracy: 0.7737\n",
            "Epoch 441/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4931 - accuracy: 0.7731 - val_loss: 0.4781 - val_accuracy: 0.7768\n",
            "Epoch 442/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4913 - accuracy: 0.7728 - val_loss: 0.4782 - val_accuracy: 0.7733\n",
            "Epoch 443/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4907 - accuracy: 0.7719 - val_loss: 0.4785 - val_accuracy: 0.7737\n",
            "Epoch 444/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4934 - accuracy: 0.7715 - val_loss: 0.4789 - val_accuracy: 0.7737\n",
            "Epoch 445/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4911 - accuracy: 0.7726 - val_loss: 0.4803 - val_accuracy: 0.7724\n",
            "Epoch 446/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4871 - accuracy: 0.7767 - val_loss: 0.4793 - val_accuracy: 0.7751\n",
            "Epoch 447/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4965 - accuracy: 0.7660 - val_loss: 0.4790 - val_accuracy: 0.7746\n",
            "Epoch 448/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4849 - accuracy: 0.7765 - val_loss: 0.4813 - val_accuracy: 0.7710\n",
            "Epoch 449/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4980 - accuracy: 0.7691 - val_loss: 0.4792 - val_accuracy: 0.7737\n",
            "Epoch 450/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4989 - accuracy: 0.7623 - val_loss: 0.4794 - val_accuracy: 0.7751\n",
            "Epoch 451/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4932 - accuracy: 0.7684 - val_loss: 0.4816 - val_accuracy: 0.7751\n",
            "Epoch 452/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4851 - accuracy: 0.7781 - val_loss: 0.4800 - val_accuracy: 0.7733\n",
            "Epoch 453/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4905 - accuracy: 0.7721 - val_loss: 0.4791 - val_accuracy: 0.7724\n",
            "Epoch 454/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4885 - accuracy: 0.7699 - val_loss: 0.4799 - val_accuracy: 0.7737\n",
            "Epoch 455/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4959 - accuracy: 0.7663 - val_loss: 0.4792 - val_accuracy: 0.7746\n",
            "Epoch 456/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4834 - accuracy: 0.7800 - val_loss: 0.4798 - val_accuracy: 0.7728\n",
            "Epoch 457/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4916 - accuracy: 0.7770 - val_loss: 0.4791 - val_accuracy: 0.7733\n",
            "Epoch 458/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4830 - accuracy: 0.7741 - val_loss: 0.4788 - val_accuracy: 0.7733\n",
            "Epoch 459/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4895 - accuracy: 0.7750 - val_loss: 0.4790 - val_accuracy: 0.7742\n",
            "Epoch 460/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4917 - accuracy: 0.7710 - val_loss: 0.4785 - val_accuracy: 0.7746\n",
            "Epoch 461/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4867 - accuracy: 0.7738 - val_loss: 0.4787 - val_accuracy: 0.7768\n",
            "Epoch 462/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4961 - accuracy: 0.7718 - val_loss: 0.4786 - val_accuracy: 0.7746\n",
            "Epoch 463/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4927 - accuracy: 0.7708 - val_loss: 0.4784 - val_accuracy: 0.7755\n",
            "Epoch 464/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4757 - accuracy: 0.7817 - val_loss: 0.4784 - val_accuracy: 0.7737\n",
            "Epoch 465/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4910 - accuracy: 0.7714 - val_loss: 0.4781 - val_accuracy: 0.7733\n",
            "Epoch 466/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4872 - accuracy: 0.7784 - val_loss: 0.4806 - val_accuracy: 0.7755\n",
            "Epoch 467/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4996 - accuracy: 0.7652 - val_loss: 0.4788 - val_accuracy: 0.7733\n",
            "Epoch 468/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4804 - accuracy: 0.7802 - val_loss: 0.4783 - val_accuracy: 0.7728\n",
            "Epoch 469/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5054 - accuracy: 0.7670 - val_loss: 0.4785 - val_accuracy: 0.7742\n",
            "Epoch 470/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4943 - accuracy: 0.7734 - val_loss: 0.4784 - val_accuracy: 0.7737\n",
            "Epoch 471/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4919 - accuracy: 0.7727 - val_loss: 0.4785 - val_accuracy: 0.7746\n",
            "Epoch 472/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4933 - accuracy: 0.7734 - val_loss: 0.4794 - val_accuracy: 0.7728\n",
            "Epoch 473/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4845 - accuracy: 0.7704 - val_loss: 0.4782 - val_accuracy: 0.7742\n",
            "Epoch 474/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4890 - accuracy: 0.7779 - val_loss: 0.4792 - val_accuracy: 0.7737\n",
            "Epoch 475/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4915 - accuracy: 0.7772 - val_loss: 0.4782 - val_accuracy: 0.7751\n",
            "Epoch 476/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4918 - accuracy: 0.7750 - val_loss: 0.4786 - val_accuracy: 0.7733\n",
            "Epoch 477/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4901 - accuracy: 0.7707 - val_loss: 0.4803 - val_accuracy: 0.7737\n",
            "Epoch 478/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4901 - accuracy: 0.7714 - val_loss: 0.4796 - val_accuracy: 0.7751\n",
            "Epoch 479/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4883 - accuracy: 0.7714 - val_loss: 0.4788 - val_accuracy: 0.7746\n",
            "Epoch 480/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4969 - accuracy: 0.7669 - val_loss: 0.4782 - val_accuracy: 0.7759\n",
            "Epoch 481/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4888 - accuracy: 0.7731 - val_loss: 0.4788 - val_accuracy: 0.7751\n",
            "Epoch 482/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4824 - accuracy: 0.7755 - val_loss: 0.4783 - val_accuracy: 0.7755\n",
            "Epoch 483/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4910 - accuracy: 0.7745 - val_loss: 0.4794 - val_accuracy: 0.7751\n",
            "Epoch 484/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4945 - accuracy: 0.7717 - val_loss: 0.4784 - val_accuracy: 0.7764\n",
            "Epoch 485/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4945 - accuracy: 0.7748 - val_loss: 0.4789 - val_accuracy: 0.7742\n",
            "Epoch 486/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4872 - accuracy: 0.7759 - val_loss: 0.4790 - val_accuracy: 0.7759\n",
            "Epoch 487/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4858 - accuracy: 0.7755 - val_loss: 0.4788 - val_accuracy: 0.7768\n",
            "Epoch 488/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4836 - accuracy: 0.7721 - val_loss: 0.4782 - val_accuracy: 0.7768\n",
            "Epoch 489/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4930 - accuracy: 0.7707 - val_loss: 0.4788 - val_accuracy: 0.7737\n",
            "Epoch 490/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4923 - accuracy: 0.7727 - val_loss: 0.4790 - val_accuracy: 0.7768\n",
            "Epoch 491/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4987 - accuracy: 0.7621 - val_loss: 0.4783 - val_accuracy: 0.7764\n",
            "Epoch 492/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4874 - accuracy: 0.7764 - val_loss: 0.4786 - val_accuracy: 0.7724\n",
            "Epoch 493/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4825 - accuracy: 0.7735 - val_loss: 0.4784 - val_accuracy: 0.7755\n",
            "Epoch 494/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4833 - accuracy: 0.7771 - val_loss: 0.4782 - val_accuracy: 0.7764\n",
            "Epoch 495/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4837 - accuracy: 0.7762 - val_loss: 0.4794 - val_accuracy: 0.7728\n",
            "Epoch 496/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4959 - accuracy: 0.7665 - val_loss: 0.4788 - val_accuracy: 0.7728\n",
            "Epoch 497/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4968 - accuracy: 0.7696 - val_loss: 0.4787 - val_accuracy: 0.7755\n",
            "Epoch 498/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4843 - accuracy: 0.7792 - val_loss: 0.4796 - val_accuracy: 0.7742\n",
            "Epoch 499/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4906 - accuracy: 0.7711 - val_loss: 0.4787 - val_accuracy: 0.7737\n",
            "Epoch 500/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4786 - accuracy: 0.7751 - val_loss: 0.4796 - val_accuracy: 0.7746\n",
            "Epoch 501/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4904 - accuracy: 0.7722 - val_loss: 0.4785 - val_accuracy: 0.7751\n",
            "Epoch 502/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4962 - accuracy: 0.7682 - val_loss: 0.4783 - val_accuracy: 0.7724\n",
            "Epoch 503/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4899 - accuracy: 0.7722 - val_loss: 0.4788 - val_accuracy: 0.7768\n",
            "Epoch 504/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4979 - accuracy: 0.7672 - val_loss: 0.4783 - val_accuracy: 0.7733\n",
            "Epoch 505/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4878 - accuracy: 0.7720 - val_loss: 0.4792 - val_accuracy: 0.7759\n",
            "Epoch 506/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4990 - accuracy: 0.7662 - val_loss: 0.4797 - val_accuracy: 0.7737\n",
            "Epoch 507/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4877 - accuracy: 0.7784 - val_loss: 0.4794 - val_accuracy: 0.7728\n",
            "Epoch 508/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4863 - accuracy: 0.7758 - val_loss: 0.4781 - val_accuracy: 0.7759\n",
            "Epoch 509/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4830 - accuracy: 0.7789 - val_loss: 0.4782 - val_accuracy: 0.7759\n",
            "Epoch 510/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4931 - accuracy: 0.7688 - val_loss: 0.4781 - val_accuracy: 0.7764\n",
            "Epoch 511/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4913 - accuracy: 0.7716 - val_loss: 0.4779 - val_accuracy: 0.7733\n",
            "Epoch 512/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4876 - accuracy: 0.7751 - val_loss: 0.4782 - val_accuracy: 0.7733\n",
            "Epoch 513/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4888 - accuracy: 0.7691 - val_loss: 0.4788 - val_accuracy: 0.7719\n",
            "Epoch 514/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4850 - accuracy: 0.7765 - val_loss: 0.4785 - val_accuracy: 0.7710\n",
            "Epoch 515/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4869 - accuracy: 0.7773 - val_loss: 0.4789 - val_accuracy: 0.7742\n",
            "Epoch 516/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4889 - accuracy: 0.7768 - val_loss: 0.4786 - val_accuracy: 0.7742\n",
            "Epoch 517/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4896 - accuracy: 0.7724 - val_loss: 0.4785 - val_accuracy: 0.7746\n",
            "Epoch 518/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4820 - accuracy: 0.7787 - val_loss: 0.4784 - val_accuracy: 0.7759\n",
            "Epoch 519/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4837 - accuracy: 0.7737 - val_loss: 0.4782 - val_accuracy: 0.7764\n",
            "Epoch 520/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4850 - accuracy: 0.7765 - val_loss: 0.4795 - val_accuracy: 0.7755\n",
            "Epoch 521/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4885 - accuracy: 0.7709 - val_loss: 0.4791 - val_accuracy: 0.7759\n",
            "Epoch 522/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4938 - accuracy: 0.7717 - val_loss: 0.4787 - val_accuracy: 0.7742\n",
            "Epoch 523/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4808 - accuracy: 0.7773 - val_loss: 0.4785 - val_accuracy: 0.7746\n",
            "Epoch 524/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4898 - accuracy: 0.7719 - val_loss: 0.4779 - val_accuracy: 0.7751\n",
            "Epoch 525/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4859 - accuracy: 0.7712 - val_loss: 0.4779 - val_accuracy: 0.7764\n",
            "Epoch 526/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4870 - accuracy: 0.7779 - val_loss: 0.4788 - val_accuracy: 0.7733\n",
            "Epoch 527/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4886 - accuracy: 0.7764 - val_loss: 0.4786 - val_accuracy: 0.7751\n",
            "Epoch 528/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4936 - accuracy: 0.7697 - val_loss: 0.4776 - val_accuracy: 0.7768\n",
            "Epoch 529/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4855 - accuracy: 0.7780 - val_loss: 0.4797 - val_accuracy: 0.7715\n",
            "Epoch 530/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4893 - accuracy: 0.7686 - val_loss: 0.4796 - val_accuracy: 0.7724\n",
            "Epoch 531/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4854 - accuracy: 0.7734 - val_loss: 0.4781 - val_accuracy: 0.7764\n",
            "Epoch 532/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4947 - accuracy: 0.7705 - val_loss: 0.4773 - val_accuracy: 0.7755\n",
            "Epoch 533/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4812 - accuracy: 0.7767 - val_loss: 0.4783 - val_accuracy: 0.7764\n",
            "Epoch 534/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4852 - accuracy: 0.7780 - val_loss: 0.4794 - val_accuracy: 0.7751\n",
            "Epoch 535/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4793 - accuracy: 0.7789 - val_loss: 0.4786 - val_accuracy: 0.7764\n",
            "Epoch 536/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4988 - accuracy: 0.7723 - val_loss: 0.4776 - val_accuracy: 0.7755\n",
            "Epoch 537/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4914 - accuracy: 0.7708 - val_loss: 0.4796 - val_accuracy: 0.7728\n",
            "Epoch 538/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4912 - accuracy: 0.7700 - val_loss: 0.4774 - val_accuracy: 0.7755\n",
            "Epoch 539/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4790 - accuracy: 0.7777 - val_loss: 0.4786 - val_accuracy: 0.7768\n",
            "Epoch 540/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4852 - accuracy: 0.7789 - val_loss: 0.4791 - val_accuracy: 0.7737\n",
            "Epoch 541/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4902 - accuracy: 0.7755 - val_loss: 0.4796 - val_accuracy: 0.7715\n",
            "Epoch 542/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4817 - accuracy: 0.7732 - val_loss: 0.4780 - val_accuracy: 0.7728\n",
            "Epoch 543/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4871 - accuracy: 0.7732 - val_loss: 0.4778 - val_accuracy: 0.7737\n",
            "Epoch 544/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4868 - accuracy: 0.7802 - val_loss: 0.4785 - val_accuracy: 0.7719\n",
            "Epoch 545/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4925 - accuracy: 0.7709 - val_loss: 0.4790 - val_accuracy: 0.7733\n",
            "Epoch 546/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4915 - accuracy: 0.7675 - val_loss: 0.4785 - val_accuracy: 0.7764\n",
            "Epoch 547/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4926 - accuracy: 0.7687 - val_loss: 0.4781 - val_accuracy: 0.7728\n",
            "Epoch 548/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4903 - accuracy: 0.7701 - val_loss: 0.4784 - val_accuracy: 0.7764\n",
            "Epoch 549/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4842 - accuracy: 0.7801 - val_loss: 0.4782 - val_accuracy: 0.7755\n",
            "Epoch 550/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4930 - accuracy: 0.7750 - val_loss: 0.4788 - val_accuracy: 0.7733\n",
            "Epoch 551/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4893 - accuracy: 0.7749 - val_loss: 0.4779 - val_accuracy: 0.7755\n",
            "Epoch 552/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4891 - accuracy: 0.7689 - val_loss: 0.4780 - val_accuracy: 0.7751\n",
            "Epoch 553/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4903 - accuracy: 0.7684 - val_loss: 0.4779 - val_accuracy: 0.7742\n",
            "Epoch 554/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4917 - accuracy: 0.7724 - val_loss: 0.4791 - val_accuracy: 0.7751\n",
            "Epoch 555/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4815 - accuracy: 0.7743 - val_loss: 0.4779 - val_accuracy: 0.7728\n",
            "Epoch 556/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4860 - accuracy: 0.7770 - val_loss: 0.4792 - val_accuracy: 0.7737\n",
            "Epoch 557/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4976 - accuracy: 0.7783 - val_loss: 0.4781 - val_accuracy: 0.7733\n",
            "Epoch 558/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4927 - accuracy: 0.7718 - val_loss: 0.4785 - val_accuracy: 0.7742\n",
            "Epoch 559/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4929 - accuracy: 0.7704 - val_loss: 0.4781 - val_accuracy: 0.7751\n",
            "Epoch 560/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4877 - accuracy: 0.7706 - val_loss: 0.4791 - val_accuracy: 0.7733\n",
            "Epoch 561/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4941 - accuracy: 0.7664 - val_loss: 0.4780 - val_accuracy: 0.7768\n",
            "Epoch 562/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4999 - accuracy: 0.7655 - val_loss: 0.4786 - val_accuracy: 0.7746\n",
            "Epoch 563/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4901 - accuracy: 0.7763 - val_loss: 0.4784 - val_accuracy: 0.7768\n",
            "Epoch 564/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4919 - accuracy: 0.7707 - val_loss: 0.4774 - val_accuracy: 0.7742\n",
            "Epoch 565/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4849 - accuracy: 0.7746 - val_loss: 0.4775 - val_accuracy: 0.7742\n",
            "Epoch 566/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4972 - accuracy: 0.7645 - val_loss: 0.4791 - val_accuracy: 0.7746\n",
            "Epoch 567/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4952 - accuracy: 0.7698 - val_loss: 0.4780 - val_accuracy: 0.7759\n",
            "Epoch 568/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4822 - accuracy: 0.7793 - val_loss: 0.4782 - val_accuracy: 0.7755\n",
            "Epoch 569/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4881 - accuracy: 0.7757 - val_loss: 0.4776 - val_accuracy: 0.7737\n",
            "Epoch 570/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4926 - accuracy: 0.7731 - val_loss: 0.4776 - val_accuracy: 0.7759\n",
            "Epoch 571/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4801 - accuracy: 0.7748 - val_loss: 0.4781 - val_accuracy: 0.7764\n",
            "Epoch 572/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4855 - accuracy: 0.7749 - val_loss: 0.4779 - val_accuracy: 0.7755\n",
            "Epoch 573/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4847 - accuracy: 0.7779 - val_loss: 0.4781 - val_accuracy: 0.7742\n",
            "Epoch 574/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4918 - accuracy: 0.7652 - val_loss: 0.4782 - val_accuracy: 0.7751\n",
            "Epoch 575/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4858 - accuracy: 0.7794 - val_loss: 0.4785 - val_accuracy: 0.7733\n",
            "Epoch 576/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4907 - accuracy: 0.7725 - val_loss: 0.4782 - val_accuracy: 0.7764\n",
            "Epoch 577/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4878 - accuracy: 0.7713 - val_loss: 0.4781 - val_accuracy: 0.7746\n",
            "Epoch 578/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4856 - accuracy: 0.7742 - val_loss: 0.4780 - val_accuracy: 0.7746\n",
            "Epoch 579/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4938 - accuracy: 0.7691 - val_loss: 0.4779 - val_accuracy: 0.7751\n",
            "Epoch 580/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4830 - accuracy: 0.7799 - val_loss: 0.4783 - val_accuracy: 0.7768\n",
            "Epoch 581/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4884 - accuracy: 0.7771 - val_loss: 0.4784 - val_accuracy: 0.7737\n",
            "Epoch 582/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4826 - accuracy: 0.7743 - val_loss: 0.4780 - val_accuracy: 0.7742\n",
            "Epoch 583/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4875 - accuracy: 0.7795 - val_loss: 0.4782 - val_accuracy: 0.7755\n",
            "Epoch 584/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4869 - accuracy: 0.7778 - val_loss: 0.4784 - val_accuracy: 0.7746\n",
            "Epoch 585/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4955 - accuracy: 0.7655 - val_loss: 0.4786 - val_accuracy: 0.7755\n",
            "Epoch 586/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5035 - accuracy: 0.7617 - val_loss: 0.4783 - val_accuracy: 0.7719\n",
            "Epoch 587/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4883 - accuracy: 0.7760 - val_loss: 0.4790 - val_accuracy: 0.7742\n",
            "Epoch 588/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4893 - accuracy: 0.7769 - val_loss: 0.4799 - val_accuracy: 0.7733\n",
            "Epoch 589/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4907 - accuracy: 0.7699 - val_loss: 0.4780 - val_accuracy: 0.7755\n",
            "Epoch 590/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4876 - accuracy: 0.7795 - val_loss: 0.4782 - val_accuracy: 0.7751\n",
            "Epoch 591/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4830 - accuracy: 0.7796 - val_loss: 0.4778 - val_accuracy: 0.7755\n",
            "Epoch 592/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4850 - accuracy: 0.7755 - val_loss: 0.4778 - val_accuracy: 0.7768\n",
            "Epoch 593/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4870 - accuracy: 0.7738 - val_loss: 0.4775 - val_accuracy: 0.7764\n",
            "Epoch 594/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4901 - accuracy: 0.7751 - val_loss: 0.4783 - val_accuracy: 0.7733\n",
            "Epoch 595/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4741 - accuracy: 0.7878 - val_loss: 0.4787 - val_accuracy: 0.7755\n",
            "Epoch 596/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4869 - accuracy: 0.7725 - val_loss: 0.4782 - val_accuracy: 0.7759\n",
            "Epoch 597/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4893 - accuracy: 0.7691 - val_loss: 0.4785 - val_accuracy: 0.7742\n",
            "Epoch 598/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4866 - accuracy: 0.7741 - val_loss: 0.4783 - val_accuracy: 0.7737\n",
            "Epoch 599/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4897 - accuracy: 0.7791 - val_loss: 0.4775 - val_accuracy: 0.7764\n",
            "Epoch 600/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4873 - accuracy: 0.7779 - val_loss: 0.4782 - val_accuracy: 0.7746\n",
            "Epoch 601/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4908 - accuracy: 0.7707 - val_loss: 0.4777 - val_accuracy: 0.7742\n",
            "Epoch 602/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4865 - accuracy: 0.7771 - val_loss: 0.4778 - val_accuracy: 0.7768\n",
            "Epoch 603/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4950 - accuracy: 0.7654 - val_loss: 0.4785 - val_accuracy: 0.7751\n",
            "Epoch 604/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4857 - accuracy: 0.7729 - val_loss: 0.4773 - val_accuracy: 0.7746\n",
            "Epoch 605/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4730 - accuracy: 0.7830 - val_loss: 0.4779 - val_accuracy: 0.7751\n",
            "Epoch 606/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4863 - accuracy: 0.7765 - val_loss: 0.4776 - val_accuracy: 0.7746\n",
            "Epoch 607/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4958 - accuracy: 0.7745 - val_loss: 0.4774 - val_accuracy: 0.7746\n",
            "Epoch 608/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4852 - accuracy: 0.7782 - val_loss: 0.4779 - val_accuracy: 0.7724\n",
            "Epoch 609/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4865 - accuracy: 0.7747 - val_loss: 0.4776 - val_accuracy: 0.7768\n",
            "Epoch 610/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4947 - accuracy: 0.7712 - val_loss: 0.4779 - val_accuracy: 0.7759\n",
            "Epoch 611/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4881 - accuracy: 0.7734 - val_loss: 0.4786 - val_accuracy: 0.7751\n",
            "Epoch 612/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4886 - accuracy: 0.7762 - val_loss: 0.4773 - val_accuracy: 0.7751\n",
            "Epoch 613/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4871 - accuracy: 0.7797 - val_loss: 0.4776 - val_accuracy: 0.7751\n",
            "Epoch 614/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4832 - accuracy: 0.7811 - val_loss: 0.4773 - val_accuracy: 0.7751\n",
            "Epoch 615/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4852 - accuracy: 0.7768 - val_loss: 0.4785 - val_accuracy: 0.7751\n",
            "Epoch 616/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4743 - accuracy: 0.7834 - val_loss: 0.4788 - val_accuracy: 0.7755\n",
            "Epoch 617/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4886 - accuracy: 0.7686 - val_loss: 0.4781 - val_accuracy: 0.7728\n",
            "Epoch 618/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4862 - accuracy: 0.7723 - val_loss: 0.4780 - val_accuracy: 0.7737\n",
            "Epoch 619/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4878 - accuracy: 0.7718 - val_loss: 0.4783 - val_accuracy: 0.7733\n",
            "Epoch 620/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4847 - accuracy: 0.7811 - val_loss: 0.4782 - val_accuracy: 0.7724\n",
            "Epoch 621/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4926 - accuracy: 0.7730 - val_loss: 0.4781 - val_accuracy: 0.7715\n",
            "Epoch 622/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4841 - accuracy: 0.7739 - val_loss: 0.4786 - val_accuracy: 0.7768\n",
            "Epoch 623/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4867 - accuracy: 0.7755 - val_loss: 0.4775 - val_accuracy: 0.7768\n",
            "Epoch 624/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4840 - accuracy: 0.7768 - val_loss: 0.4773 - val_accuracy: 0.7759\n",
            "Epoch 625/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4897 - accuracy: 0.7752 - val_loss: 0.4771 - val_accuracy: 0.7773\n",
            "Epoch 626/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4829 - accuracy: 0.7771 - val_loss: 0.4775 - val_accuracy: 0.7759\n",
            "Epoch 627/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4771 - accuracy: 0.7805 - val_loss: 0.4792 - val_accuracy: 0.7742\n",
            "Epoch 628/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4887 - accuracy: 0.7762 - val_loss: 0.4782 - val_accuracy: 0.7737\n",
            "Epoch 629/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4876 - accuracy: 0.7743 - val_loss: 0.4783 - val_accuracy: 0.7737\n",
            "Epoch 630/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4861 - accuracy: 0.7734 - val_loss: 0.4789 - val_accuracy: 0.7755\n",
            "Epoch 631/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4922 - accuracy: 0.7724 - val_loss: 0.4780 - val_accuracy: 0.7719\n",
            "Epoch 632/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4827 - accuracy: 0.7768 - val_loss: 0.4796 - val_accuracy: 0.7719\n",
            "Epoch 633/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4875 - accuracy: 0.7752 - val_loss: 0.4793 - val_accuracy: 0.7746\n",
            "Epoch 634/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4942 - accuracy: 0.7695 - val_loss: 0.4779 - val_accuracy: 0.7773\n",
            "Epoch 635/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4930 - accuracy: 0.7682 - val_loss: 0.4775 - val_accuracy: 0.7764\n",
            "Epoch 636/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4880 - accuracy: 0.7711 - val_loss: 0.4776 - val_accuracy: 0.7755\n",
            "Epoch 637/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4847 - accuracy: 0.7810 - val_loss: 0.4779 - val_accuracy: 0.7768\n",
            "Epoch 638/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4959 - accuracy: 0.7678 - val_loss: 0.4776 - val_accuracy: 0.7782\n",
            "Epoch 639/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4847 - accuracy: 0.7758 - val_loss: 0.4777 - val_accuracy: 0.7759\n",
            "Epoch 640/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4816 - accuracy: 0.7796 - val_loss: 0.4776 - val_accuracy: 0.7764\n",
            "Epoch 641/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4808 - accuracy: 0.7764 - val_loss: 0.4779 - val_accuracy: 0.7755\n",
            "Epoch 642/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4928 - accuracy: 0.7702 - val_loss: 0.4782 - val_accuracy: 0.7773\n",
            "Epoch 643/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4743 - accuracy: 0.7841 - val_loss: 0.4777 - val_accuracy: 0.7742\n",
            "Epoch 644/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4771 - accuracy: 0.7828 - val_loss: 0.4777 - val_accuracy: 0.7755\n",
            "Epoch 645/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4951 - accuracy: 0.7692 - val_loss: 0.4779 - val_accuracy: 0.7742\n",
            "Epoch 646/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4834 - accuracy: 0.7785 - val_loss: 0.4774 - val_accuracy: 0.7773\n",
            "Epoch 647/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4903 - accuracy: 0.7729 - val_loss: 0.4773 - val_accuracy: 0.7755\n",
            "Epoch 648/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4946 - accuracy: 0.7687 - val_loss: 0.4779 - val_accuracy: 0.7759\n",
            "Epoch 649/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4945 - accuracy: 0.7701 - val_loss: 0.4773 - val_accuracy: 0.7733\n",
            "Epoch 650/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4820 - accuracy: 0.7765 - val_loss: 0.4780 - val_accuracy: 0.7746\n",
            "Epoch 651/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4899 - accuracy: 0.7709 - val_loss: 0.4781 - val_accuracy: 0.7746\n",
            "Epoch 652/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4808 - accuracy: 0.7790 - val_loss: 0.4788 - val_accuracy: 0.7706\n",
            "Epoch 653/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5001 - accuracy: 0.7658 - val_loss: 0.4776 - val_accuracy: 0.7759\n",
            "Epoch 654/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4786 - accuracy: 0.7848 - val_loss: 0.4810 - val_accuracy: 0.7715\n",
            "Epoch 655/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4827 - accuracy: 0.7763 - val_loss: 0.4784 - val_accuracy: 0.7755\n",
            "Epoch 656/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4908 - accuracy: 0.7690 - val_loss: 0.4783 - val_accuracy: 0.7751\n",
            "Epoch 657/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4792 - accuracy: 0.7768 - val_loss: 0.4783 - val_accuracy: 0.7759\n",
            "Epoch 658/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4867 - accuracy: 0.7776 - val_loss: 0.4785 - val_accuracy: 0.7768\n",
            "Epoch 659/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4871 - accuracy: 0.7753 - val_loss: 0.4782 - val_accuracy: 0.7733\n",
            "Epoch 660/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4840 - accuracy: 0.7821 - val_loss: 0.4786 - val_accuracy: 0.7737\n",
            "Epoch 661/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4849 - accuracy: 0.7758 - val_loss: 0.4782 - val_accuracy: 0.7759\n",
            "Epoch 662/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4888 - accuracy: 0.7731 - val_loss: 0.4779 - val_accuracy: 0.7764\n",
            "Epoch 663/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4920 - accuracy: 0.7679 - val_loss: 0.4776 - val_accuracy: 0.7751\n",
            "Epoch 664/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4935 - accuracy: 0.7763 - val_loss: 0.4776 - val_accuracy: 0.7742\n",
            "Epoch 665/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4724 - accuracy: 0.7845 - val_loss: 0.4780 - val_accuracy: 0.7759\n",
            "Epoch 666/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4887 - accuracy: 0.7712 - val_loss: 0.4781 - val_accuracy: 0.7759\n",
            "Epoch 667/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4977 - accuracy: 0.7721 - val_loss: 0.4779 - val_accuracy: 0.7759\n",
            "Epoch 668/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4871 - accuracy: 0.7762 - val_loss: 0.4786 - val_accuracy: 0.7746\n",
            "Epoch 669/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4876 - accuracy: 0.7736 - val_loss: 0.4782 - val_accuracy: 0.7782\n",
            "Epoch 670/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4955 - accuracy: 0.7733 - val_loss: 0.4781 - val_accuracy: 0.7755\n",
            "Epoch 671/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4890 - accuracy: 0.7766 - val_loss: 0.4777 - val_accuracy: 0.7755\n",
            "Epoch 672/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4839 - accuracy: 0.7769 - val_loss: 0.4779 - val_accuracy: 0.7746\n",
            "Epoch 673/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4866 - accuracy: 0.7741 - val_loss: 0.4779 - val_accuracy: 0.7751\n",
            "Epoch 674/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4876 - accuracy: 0.7714 - val_loss: 0.4779 - val_accuracy: 0.7737\n",
            "Epoch 675/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4919 - accuracy: 0.7725 - val_loss: 0.4787 - val_accuracy: 0.7733\n",
            "Epoch 676/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4862 - accuracy: 0.7811 - val_loss: 0.4779 - val_accuracy: 0.7768\n",
            "Epoch 677/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4773 - accuracy: 0.7807 - val_loss: 0.4783 - val_accuracy: 0.7755\n",
            "Epoch 678/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4900 - accuracy: 0.7693 - val_loss: 0.4787 - val_accuracy: 0.7755\n",
            "Epoch 679/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4895 - accuracy: 0.7720 - val_loss: 0.4777 - val_accuracy: 0.7759\n",
            "Epoch 680/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4882 - accuracy: 0.7697 - val_loss: 0.4778 - val_accuracy: 0.7737\n",
            "Epoch 681/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4797 - accuracy: 0.7781 - val_loss: 0.4778 - val_accuracy: 0.7737\n",
            "Epoch 682/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4929 - accuracy: 0.7694 - val_loss: 0.4785 - val_accuracy: 0.7742\n",
            "Epoch 683/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4932 - accuracy: 0.7671 - val_loss: 0.4807 - val_accuracy: 0.7710\n",
            "Epoch 684/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4892 - accuracy: 0.7731 - val_loss: 0.4803 - val_accuracy: 0.7710\n",
            "Epoch 685/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4858 - accuracy: 0.7762 - val_loss: 0.4788 - val_accuracy: 0.7755\n",
            "Epoch 686/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4774 - accuracy: 0.7774 - val_loss: 0.4783 - val_accuracy: 0.7768\n",
            "Epoch 687/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4858 - accuracy: 0.7729 - val_loss: 0.4774 - val_accuracy: 0.7755\n",
            "Epoch 688/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4928 - accuracy: 0.7727 - val_loss: 0.4779 - val_accuracy: 0.7755\n",
            "Epoch 689/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4826 - accuracy: 0.7743 - val_loss: 0.4780 - val_accuracy: 0.7724\n",
            "Epoch 690/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4874 - accuracy: 0.7741 - val_loss: 0.4787 - val_accuracy: 0.7733\n",
            "Epoch 691/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4881 - accuracy: 0.7752 - val_loss: 0.4773 - val_accuracy: 0.7755\n",
            "Epoch 692/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4813 - accuracy: 0.7766 - val_loss: 0.4791 - val_accuracy: 0.7724\n",
            "Epoch 693/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4923 - accuracy: 0.7724 - val_loss: 0.4785 - val_accuracy: 0.7742\n",
            "Epoch 694/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4859 - accuracy: 0.7767 - val_loss: 0.4778 - val_accuracy: 0.7773\n",
            "Epoch 695/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4814 - accuracy: 0.7771 - val_loss: 0.4783 - val_accuracy: 0.7764\n",
            "Epoch 696/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4845 - accuracy: 0.7694 - val_loss: 0.4777 - val_accuracy: 0.7759\n",
            "Epoch 697/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4849 - accuracy: 0.7750 - val_loss: 0.4787 - val_accuracy: 0.7724\n",
            "Epoch 698/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4843 - accuracy: 0.7721 - val_loss: 0.4774 - val_accuracy: 0.7764\n",
            "Epoch 699/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4858 - accuracy: 0.7783 - val_loss: 0.4775 - val_accuracy: 0.7764\n",
            "Epoch 700/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4863 - accuracy: 0.7727 - val_loss: 0.4783 - val_accuracy: 0.7751\n",
            "Epoch 701/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4864 - accuracy: 0.7729 - val_loss: 0.4781 - val_accuracy: 0.7759\n",
            "Epoch 702/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4897 - accuracy: 0.7723 - val_loss: 0.4790 - val_accuracy: 0.7733\n",
            "Epoch 703/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4820 - accuracy: 0.7738 - val_loss: 0.4795 - val_accuracy: 0.7719\n",
            "Epoch 704/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4864 - accuracy: 0.7758 - val_loss: 0.4786 - val_accuracy: 0.7746\n",
            "Epoch 705/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4850 - accuracy: 0.7744 - val_loss: 0.4781 - val_accuracy: 0.7764\n",
            "Epoch 706/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4901 - accuracy: 0.7720 - val_loss: 0.4778 - val_accuracy: 0.7742\n",
            "Epoch 707/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4911 - accuracy: 0.7735 - val_loss: 0.4778 - val_accuracy: 0.7755\n",
            "Epoch 708/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4869 - accuracy: 0.7730 - val_loss: 0.4779 - val_accuracy: 0.7768\n",
            "Epoch 709/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4842 - accuracy: 0.7794 - val_loss: 0.4784 - val_accuracy: 0.7737\n",
            "Epoch 710/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4916 - accuracy: 0.7739 - val_loss: 0.4782 - val_accuracy: 0.7742\n",
            "Epoch 711/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4904 - accuracy: 0.7707 - val_loss: 0.4782 - val_accuracy: 0.7742\n",
            "Epoch 712/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4905 - accuracy: 0.7702 - val_loss: 0.4772 - val_accuracy: 0.7759\n",
            "Epoch 713/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4902 - accuracy: 0.7665 - val_loss: 0.4785 - val_accuracy: 0.7755\n",
            "Epoch 714/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4811 - accuracy: 0.7778 - val_loss: 0.4778 - val_accuracy: 0.7737\n",
            "Epoch 715/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4938 - accuracy: 0.7706 - val_loss: 0.4774 - val_accuracy: 0.7751\n",
            "Epoch 716/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4840 - accuracy: 0.7765 - val_loss: 0.4781 - val_accuracy: 0.7773\n",
            "Epoch 717/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4835 - accuracy: 0.7786 - val_loss: 0.4776 - val_accuracy: 0.7746\n",
            "Epoch 718/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4879 - accuracy: 0.7761 - val_loss: 0.4781 - val_accuracy: 0.7742\n",
            "Epoch 719/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4844 - accuracy: 0.7763 - val_loss: 0.4776 - val_accuracy: 0.7751\n",
            "Epoch 720/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4922 - accuracy: 0.7686 - val_loss: 0.4776 - val_accuracy: 0.7764\n",
            "Epoch 721/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5001 - accuracy: 0.7641 - val_loss: 0.4772 - val_accuracy: 0.7737\n",
            "Epoch 722/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4893 - accuracy: 0.7697 - val_loss: 0.4782 - val_accuracy: 0.7737\n",
            "Epoch 723/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4803 - accuracy: 0.7757 - val_loss: 0.4774 - val_accuracy: 0.7724\n",
            "Epoch 724/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4948 - accuracy: 0.7711 - val_loss: 0.4777 - val_accuracy: 0.7759\n",
            "Epoch 725/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4864 - accuracy: 0.7732 - val_loss: 0.4780 - val_accuracy: 0.7733\n",
            "Epoch 726/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4820 - accuracy: 0.7772 - val_loss: 0.4780 - val_accuracy: 0.7724\n",
            "Epoch 727/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4863 - accuracy: 0.7750 - val_loss: 0.4778 - val_accuracy: 0.7751\n",
            "Epoch 728/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4912 - accuracy: 0.7698 - val_loss: 0.4783 - val_accuracy: 0.7746\n",
            "Epoch 729/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4882 - accuracy: 0.7750 - val_loss: 0.4783 - val_accuracy: 0.7715\n",
            "Epoch 730/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4866 - accuracy: 0.7736 - val_loss: 0.4784 - val_accuracy: 0.7764\n",
            "Epoch 731/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4877 - accuracy: 0.7695 - val_loss: 0.4775 - val_accuracy: 0.7777\n",
            "Epoch 732/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4853 - accuracy: 0.7779 - val_loss: 0.4787 - val_accuracy: 0.7764\n",
            "Epoch 733/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4897 - accuracy: 0.7733 - val_loss: 0.4775 - val_accuracy: 0.7751\n",
            "Epoch 734/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4814 - accuracy: 0.7786 - val_loss: 0.4776 - val_accuracy: 0.7764\n",
            "Epoch 735/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4884 - accuracy: 0.7775 - val_loss: 0.4781 - val_accuracy: 0.7773\n",
            "Epoch 736/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4851 - accuracy: 0.7744 - val_loss: 0.4778 - val_accuracy: 0.7764\n",
            "Epoch 737/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4933 - accuracy: 0.7670 - val_loss: 0.4777 - val_accuracy: 0.7777\n",
            "Epoch 738/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4791 - accuracy: 0.7773 - val_loss: 0.4776 - val_accuracy: 0.7764\n",
            "Epoch 739/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4811 - accuracy: 0.7763 - val_loss: 0.4783 - val_accuracy: 0.7737\n",
            "Epoch 740/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4882 - accuracy: 0.7744 - val_loss: 0.4799 - val_accuracy: 0.7724\n",
            "Epoch 741/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4864 - accuracy: 0.7746 - val_loss: 0.4798 - val_accuracy: 0.7715\n",
            "Epoch 742/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4826 - accuracy: 0.7790 - val_loss: 0.4778 - val_accuracy: 0.7755\n",
            "Epoch 743/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4878 - accuracy: 0.7739 - val_loss: 0.4782 - val_accuracy: 0.7751\n",
            "Epoch 744/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4868 - accuracy: 0.7737 - val_loss: 0.4778 - val_accuracy: 0.7724\n",
            "Epoch 745/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4813 - accuracy: 0.7778 - val_loss: 0.4777 - val_accuracy: 0.7742\n",
            "Epoch 746/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4855 - accuracy: 0.7775 - val_loss: 0.4781 - val_accuracy: 0.7724\n",
            "Epoch 747/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4894 - accuracy: 0.7733 - val_loss: 0.4777 - val_accuracy: 0.7733\n",
            "Epoch 748/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4839 - accuracy: 0.7745 - val_loss: 0.4783 - val_accuracy: 0.7724\n",
            "Epoch 749/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4914 - accuracy: 0.7721 - val_loss: 0.4783 - val_accuracy: 0.7733\n",
            "Epoch 750/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4876 - accuracy: 0.7709 - val_loss: 0.4775 - val_accuracy: 0.7742\n",
            "Epoch 751/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4833 - accuracy: 0.7736 - val_loss: 0.4779 - val_accuracy: 0.7759\n",
            "Epoch 752/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4854 - accuracy: 0.7803 - val_loss: 0.4799 - val_accuracy: 0.7724\n",
            "Epoch 753/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4870 - accuracy: 0.7721 - val_loss: 0.4771 - val_accuracy: 0.7751\n",
            "Epoch 754/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.5015 - accuracy: 0.7684 - val_loss: 0.4779 - val_accuracy: 0.7746\n",
            "Epoch 755/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4881 - accuracy: 0.7787 - val_loss: 0.4777 - val_accuracy: 0.7759\n",
            "Epoch 756/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4890 - accuracy: 0.7707 - val_loss: 0.4776 - val_accuracy: 0.7764\n",
            "Epoch 757/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4787 - accuracy: 0.7810 - val_loss: 0.4791 - val_accuracy: 0.7755\n",
            "Epoch 758/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4780 - accuracy: 0.7766 - val_loss: 0.4778 - val_accuracy: 0.7759\n",
            "Epoch 759/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4793 - accuracy: 0.7796 - val_loss: 0.4779 - val_accuracy: 0.7764\n",
            "Epoch 760/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4853 - accuracy: 0.7815 - val_loss: 0.4775 - val_accuracy: 0.7755\n",
            "Epoch 761/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4829 - accuracy: 0.7728 - val_loss: 0.4784 - val_accuracy: 0.7724\n",
            "Epoch 762/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4880 - accuracy: 0.7800 - val_loss: 0.4786 - val_accuracy: 0.7751\n",
            "Epoch 763/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4896 - accuracy: 0.7711 - val_loss: 0.4782 - val_accuracy: 0.7755\n",
            "Epoch 764/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4887 - accuracy: 0.7704 - val_loss: 0.4785 - val_accuracy: 0.7733\n",
            "Epoch 765/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4843 - accuracy: 0.7794 - val_loss: 0.4779 - val_accuracy: 0.7742\n",
            "Epoch 766/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4881 - accuracy: 0.7754 - val_loss: 0.4778 - val_accuracy: 0.7759\n",
            "Epoch 767/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4790 - accuracy: 0.7816 - val_loss: 0.4776 - val_accuracy: 0.7751\n",
            "Epoch 768/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4834 - accuracy: 0.7689 - val_loss: 0.4778 - val_accuracy: 0.7759\n",
            "Epoch 769/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4901 - accuracy: 0.7801 - val_loss: 0.4781 - val_accuracy: 0.7728\n",
            "Epoch 770/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4876 - accuracy: 0.7714 - val_loss: 0.4775 - val_accuracy: 0.7751\n",
            "Epoch 771/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4857 - accuracy: 0.7732 - val_loss: 0.4779 - val_accuracy: 0.7751\n",
            "Epoch 772/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4883 - accuracy: 0.7768 - val_loss: 0.4784 - val_accuracy: 0.7746\n",
            "Epoch 773/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4877 - accuracy: 0.7722 - val_loss: 0.4783 - val_accuracy: 0.7768\n",
            "Epoch 774/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4893 - accuracy: 0.7690 - val_loss: 0.4776 - val_accuracy: 0.7751\n",
            "Epoch 775/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4811 - accuracy: 0.7779 - val_loss: 0.4775 - val_accuracy: 0.7759\n",
            "Epoch 776/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4808 - accuracy: 0.7794 - val_loss: 0.4772 - val_accuracy: 0.7759\n",
            "Epoch 777/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4857 - accuracy: 0.7751 - val_loss: 0.4775 - val_accuracy: 0.7746\n",
            "Epoch 778/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4883 - accuracy: 0.7683 - val_loss: 0.4779 - val_accuracy: 0.7773\n",
            "Epoch 779/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4808 - accuracy: 0.7801 - val_loss: 0.4778 - val_accuracy: 0.7733\n",
            "Epoch 780/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4956 - accuracy: 0.7694 - val_loss: 0.4773 - val_accuracy: 0.7755\n",
            "Epoch 781/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4890 - accuracy: 0.7750 - val_loss: 0.4776 - val_accuracy: 0.7764\n",
            "Epoch 782/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4871 - accuracy: 0.7745 - val_loss: 0.4779 - val_accuracy: 0.7742\n",
            "Epoch 783/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4764 - accuracy: 0.7798 - val_loss: 0.4786 - val_accuracy: 0.7742\n",
            "Epoch 784/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4810 - accuracy: 0.7777 - val_loss: 0.4776 - val_accuracy: 0.7759\n",
            "Epoch 785/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4888 - accuracy: 0.7715 - val_loss: 0.4774 - val_accuracy: 0.7777\n",
            "Epoch 786/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4866 - accuracy: 0.7745 - val_loss: 0.4779 - val_accuracy: 0.7759\n",
            "Epoch 787/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4836 - accuracy: 0.7759 - val_loss: 0.4781 - val_accuracy: 0.7777\n",
            "Epoch 788/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4888 - accuracy: 0.7765 - val_loss: 0.4792 - val_accuracy: 0.7751\n",
            "Epoch 789/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4802 - accuracy: 0.7834 - val_loss: 0.4775 - val_accuracy: 0.7737\n",
            "Epoch 790/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4837 - accuracy: 0.7762 - val_loss: 0.4775 - val_accuracy: 0.7733\n",
            "Epoch 791/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4817 - accuracy: 0.7770 - val_loss: 0.4778 - val_accuracy: 0.7759\n",
            "Epoch 792/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4930 - accuracy: 0.7710 - val_loss: 0.4780 - val_accuracy: 0.7742\n",
            "Epoch 793/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4950 - accuracy: 0.7691 - val_loss: 0.4775 - val_accuracy: 0.7768\n",
            "Epoch 794/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4944 - accuracy: 0.7723 - val_loss: 0.4781 - val_accuracy: 0.7759\n",
            "Epoch 795/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4887 - accuracy: 0.7741 - val_loss: 0.4786 - val_accuracy: 0.7746\n",
            "Epoch 796/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4848 - accuracy: 0.7729 - val_loss: 0.4781 - val_accuracy: 0.7755\n",
            "Epoch 797/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4965 - accuracy: 0.7634 - val_loss: 0.4787 - val_accuracy: 0.7719\n",
            "Epoch 798/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4891 - accuracy: 0.7710 - val_loss: 0.4767 - val_accuracy: 0.7764\n",
            "Epoch 799/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4891 - accuracy: 0.7718 - val_loss: 0.4763 - val_accuracy: 0.7782\n",
            "Epoch 800/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4819 - accuracy: 0.7781 - val_loss: 0.4771 - val_accuracy: 0.7773\n",
            "Epoch 801/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4924 - accuracy: 0.7674 - val_loss: 0.4781 - val_accuracy: 0.7768\n",
            "Epoch 802/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4850 - accuracy: 0.7780 - val_loss: 0.4788 - val_accuracy: 0.7702\n",
            "Epoch 803/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4923 - accuracy: 0.7675 - val_loss: 0.4775 - val_accuracy: 0.7737\n",
            "Epoch 804/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4868 - accuracy: 0.7728 - val_loss: 0.4774 - val_accuracy: 0.7773\n",
            "Epoch 805/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4880 - accuracy: 0.7719 - val_loss: 0.4772 - val_accuracy: 0.7773\n",
            "Epoch 806/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4882 - accuracy: 0.7737 - val_loss: 0.4778 - val_accuracy: 0.7759\n",
            "Epoch 807/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4857 - accuracy: 0.7746 - val_loss: 0.4787 - val_accuracy: 0.7733\n",
            "Epoch 808/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4964 - accuracy: 0.7693 - val_loss: 0.4773 - val_accuracy: 0.7768\n",
            "Epoch 809/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4867 - accuracy: 0.7781 - val_loss: 0.4772 - val_accuracy: 0.7755\n",
            "Epoch 810/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4920 - accuracy: 0.7699 - val_loss: 0.4775 - val_accuracy: 0.7777\n",
            "Epoch 811/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4826 - accuracy: 0.7736 - val_loss: 0.4770 - val_accuracy: 0.7773\n",
            "Epoch 812/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4850 - accuracy: 0.7779 - val_loss: 0.4792 - val_accuracy: 0.7737\n",
            "Epoch 813/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4820 - accuracy: 0.7760 - val_loss: 0.4807 - val_accuracy: 0.7679\n",
            "Epoch 814/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4870 - accuracy: 0.7749 - val_loss: 0.4796 - val_accuracy: 0.7728\n",
            "Epoch 815/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4821 - accuracy: 0.7744 - val_loss: 0.4776 - val_accuracy: 0.7768\n",
            "Epoch 816/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4912 - accuracy: 0.7690 - val_loss: 0.4784 - val_accuracy: 0.7751\n",
            "Epoch 817/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4859 - accuracy: 0.7765 - val_loss: 0.4795 - val_accuracy: 0.7751\n",
            "Epoch 818/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4905 - accuracy: 0.7720 - val_loss: 0.4792 - val_accuracy: 0.7755\n",
            "Epoch 819/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4813 - accuracy: 0.7786 - val_loss: 0.4779 - val_accuracy: 0.7773\n",
            "Epoch 820/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4881 - accuracy: 0.7734 - val_loss: 0.4776 - val_accuracy: 0.7737\n",
            "Epoch 821/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4885 - accuracy: 0.7762 - val_loss: 0.4783 - val_accuracy: 0.7768\n",
            "Epoch 822/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4879 - accuracy: 0.7730 - val_loss: 0.4788 - val_accuracy: 0.7751\n",
            "Epoch 823/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4874 - accuracy: 0.7738 - val_loss: 0.4779 - val_accuracy: 0.7773\n",
            "Epoch 824/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4811 - accuracy: 0.7784 - val_loss: 0.4777 - val_accuracy: 0.7759\n",
            "Epoch 825/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4815 - accuracy: 0.7770 - val_loss: 0.4778 - val_accuracy: 0.7751\n",
            "Epoch 826/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4907 - accuracy: 0.7715 - val_loss: 0.4776 - val_accuracy: 0.7751\n",
            "Epoch 827/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4899 - accuracy: 0.7704 - val_loss: 0.4774 - val_accuracy: 0.7742\n",
            "Epoch 828/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4877 - accuracy: 0.7665 - val_loss: 0.4770 - val_accuracy: 0.7768\n",
            "Epoch 829/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4847 - accuracy: 0.7751 - val_loss: 0.4790 - val_accuracy: 0.7751\n",
            "Epoch 830/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4913 - accuracy: 0.7719 - val_loss: 0.4783 - val_accuracy: 0.7737\n",
            "Epoch 831/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4873 - accuracy: 0.7745 - val_loss: 0.4777 - val_accuracy: 0.7751\n",
            "Epoch 832/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4954 - accuracy: 0.7708 - val_loss: 0.4774 - val_accuracy: 0.7733\n",
            "Epoch 833/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4842 - accuracy: 0.7757 - val_loss: 0.4785 - val_accuracy: 0.7755\n",
            "Epoch 834/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4928 - accuracy: 0.7680 - val_loss: 0.4769 - val_accuracy: 0.7737\n",
            "Epoch 835/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4824 - accuracy: 0.7749 - val_loss: 0.4773 - val_accuracy: 0.7759\n",
            "Epoch 836/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4879 - accuracy: 0.7749 - val_loss: 0.4788 - val_accuracy: 0.7742\n",
            "Epoch 837/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4953 - accuracy: 0.7664 - val_loss: 0.4771 - val_accuracy: 0.7777\n",
            "Epoch 838/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4855 - accuracy: 0.7765 - val_loss: 0.4778 - val_accuracy: 0.7737\n",
            "Epoch 839/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4905 - accuracy: 0.7750 - val_loss: 0.4776 - val_accuracy: 0.7773\n",
            "Epoch 840/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4875 - accuracy: 0.7740 - val_loss: 0.4800 - val_accuracy: 0.7719\n",
            "Epoch 841/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4918 - accuracy: 0.7710 - val_loss: 0.4781 - val_accuracy: 0.7742\n",
            "Epoch 842/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4806 - accuracy: 0.7724 - val_loss: 0.4777 - val_accuracy: 0.7755\n",
            "Epoch 843/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4894 - accuracy: 0.7709 - val_loss: 0.4780 - val_accuracy: 0.7746\n",
            "Epoch 844/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4818 - accuracy: 0.7798 - val_loss: 0.4776 - val_accuracy: 0.7768\n",
            "Epoch 845/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4869 - accuracy: 0.7697 - val_loss: 0.4775 - val_accuracy: 0.7759\n",
            "Epoch 846/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4874 - accuracy: 0.7766 - val_loss: 0.4787 - val_accuracy: 0.7702\n",
            "Epoch 847/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4843 - accuracy: 0.7767 - val_loss: 0.4782 - val_accuracy: 0.7755\n",
            "Epoch 848/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4826 - accuracy: 0.7790 - val_loss: 0.4781 - val_accuracy: 0.7751\n",
            "Epoch 849/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4849 - accuracy: 0.7748 - val_loss: 0.4769 - val_accuracy: 0.7746\n",
            "Epoch 850/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4911 - accuracy: 0.7708 - val_loss: 0.4778 - val_accuracy: 0.7777\n",
            "Epoch 851/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4777 - accuracy: 0.7780 - val_loss: 0.4783 - val_accuracy: 0.7764\n",
            "Epoch 852/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4825 - accuracy: 0.7753 - val_loss: 0.4792 - val_accuracy: 0.7777\n",
            "Epoch 853/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4921 - accuracy: 0.7738 - val_loss: 0.4773 - val_accuracy: 0.7746\n",
            "Epoch 854/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4883 - accuracy: 0.7743 - val_loss: 0.4779 - val_accuracy: 0.7733\n",
            "Epoch 855/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4832 - accuracy: 0.7796 - val_loss: 0.4791 - val_accuracy: 0.7719\n",
            "Epoch 856/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4874 - accuracy: 0.7712 - val_loss: 0.4773 - val_accuracy: 0.7773\n",
            "Epoch 857/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4875 - accuracy: 0.7768 - val_loss: 0.4778 - val_accuracy: 0.7719\n",
            "Epoch 858/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4734 - accuracy: 0.7791 - val_loss: 0.4768 - val_accuracy: 0.7773\n",
            "Epoch 859/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4787 - accuracy: 0.7845 - val_loss: 0.4796 - val_accuracy: 0.7724\n",
            "Epoch 860/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4839 - accuracy: 0.7735 - val_loss: 0.4783 - val_accuracy: 0.7728\n",
            "Epoch 861/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4848 - accuracy: 0.7747 - val_loss: 0.4772 - val_accuracy: 0.7737\n",
            "Epoch 862/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4938 - accuracy: 0.7730 - val_loss: 0.4773 - val_accuracy: 0.7755\n",
            "Epoch 863/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4886 - accuracy: 0.7765 - val_loss: 0.4775 - val_accuracy: 0.7733\n",
            "Epoch 864/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4889 - accuracy: 0.7706 - val_loss: 0.4775 - val_accuracy: 0.7742\n",
            "Epoch 865/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4756 - accuracy: 0.7844 - val_loss: 0.4779 - val_accuracy: 0.7719\n",
            "Epoch 866/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4948 - accuracy: 0.7709 - val_loss: 0.4798 - val_accuracy: 0.7768\n",
            "Epoch 867/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4811 - accuracy: 0.7767 - val_loss: 0.4792 - val_accuracy: 0.7715\n",
            "Epoch 868/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4932 - accuracy: 0.7704 - val_loss: 0.4785 - val_accuracy: 0.7719\n",
            "Epoch 869/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4834 - accuracy: 0.7824 - val_loss: 0.4771 - val_accuracy: 0.7742\n",
            "Epoch 870/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4852 - accuracy: 0.7722 - val_loss: 0.4774 - val_accuracy: 0.7737\n",
            "Epoch 871/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4935 - accuracy: 0.7696 - val_loss: 0.4768 - val_accuracy: 0.7764\n",
            "Epoch 872/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4883 - accuracy: 0.7696 - val_loss: 0.4772 - val_accuracy: 0.7751\n",
            "Epoch 873/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4877 - accuracy: 0.7750 - val_loss: 0.4787 - val_accuracy: 0.7737\n",
            "Epoch 874/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4834 - accuracy: 0.7761 - val_loss: 0.4786 - val_accuracy: 0.7724\n",
            "Epoch 875/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4794 - accuracy: 0.7764 - val_loss: 0.4787 - val_accuracy: 0.7768\n",
            "Epoch 876/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4794 - accuracy: 0.7799 - val_loss: 0.4790 - val_accuracy: 0.7755\n",
            "Epoch 877/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4860 - accuracy: 0.7729 - val_loss: 0.4781 - val_accuracy: 0.7742\n",
            "Epoch 878/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4925 - accuracy: 0.7678 - val_loss: 0.4796 - val_accuracy: 0.7715\n",
            "Epoch 879/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4934 - accuracy: 0.7651 - val_loss: 0.4777 - val_accuracy: 0.7764\n",
            "Epoch 880/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4784 - accuracy: 0.7743 - val_loss: 0.4773 - val_accuracy: 0.7755\n",
            "Epoch 881/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4758 - accuracy: 0.7814 - val_loss: 0.4781 - val_accuracy: 0.7751\n",
            "Epoch 882/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4909 - accuracy: 0.7685 - val_loss: 0.4789 - val_accuracy: 0.7733\n",
            "Epoch 883/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4868 - accuracy: 0.7744 - val_loss: 0.4773 - val_accuracy: 0.7746\n",
            "Epoch 884/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4817 - accuracy: 0.7803 - val_loss: 0.4777 - val_accuracy: 0.7742\n",
            "Epoch 885/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4887 - accuracy: 0.7713 - val_loss: 0.4772 - val_accuracy: 0.7755\n",
            "Epoch 886/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4891 - accuracy: 0.7723 - val_loss: 0.4783 - val_accuracy: 0.7702\n",
            "Epoch 887/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4911 - accuracy: 0.7729 - val_loss: 0.4771 - val_accuracy: 0.7737\n",
            "Epoch 888/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4967 - accuracy: 0.7632 - val_loss: 0.4777 - val_accuracy: 0.7733\n",
            "Epoch 889/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4748 - accuracy: 0.7843 - val_loss: 0.4785 - val_accuracy: 0.7715\n",
            "Epoch 890/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4889 - accuracy: 0.7798 - val_loss: 0.4778 - val_accuracy: 0.7755\n",
            "Epoch 891/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4958 - accuracy: 0.7697 - val_loss: 0.4774 - val_accuracy: 0.7733\n",
            "Epoch 892/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4907 - accuracy: 0.7722 - val_loss: 0.4776 - val_accuracy: 0.7777\n",
            "Epoch 893/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4822 - accuracy: 0.7774 - val_loss: 0.4785 - val_accuracy: 0.7719\n",
            "Epoch 894/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4836 - accuracy: 0.7789 - val_loss: 0.4782 - val_accuracy: 0.7728\n",
            "Epoch 895/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4901 - accuracy: 0.7751 - val_loss: 0.4776 - val_accuracy: 0.7737\n",
            "Epoch 896/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4772 - accuracy: 0.7825 - val_loss: 0.4774 - val_accuracy: 0.7742\n",
            "Epoch 897/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4864 - accuracy: 0.7752 - val_loss: 0.4772 - val_accuracy: 0.7755\n",
            "Epoch 898/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4830 - accuracy: 0.7786 - val_loss: 0.4773 - val_accuracy: 0.7728\n",
            "Epoch 899/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4854 - accuracy: 0.7724 - val_loss: 0.4778 - val_accuracy: 0.7764\n",
            "Epoch 900/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4936 - accuracy: 0.7693 - val_loss: 0.4784 - val_accuracy: 0.7737\n",
            "Epoch 901/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4849 - accuracy: 0.7762 - val_loss: 0.4782 - val_accuracy: 0.7751\n",
            "Epoch 902/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4964 - accuracy: 0.7708 - val_loss: 0.4782 - val_accuracy: 0.7728\n",
            "Epoch 903/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4838 - accuracy: 0.7715 - val_loss: 0.4777 - val_accuracy: 0.7715\n",
            "Epoch 904/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4813 - accuracy: 0.7831 - val_loss: 0.4783 - val_accuracy: 0.7737\n",
            "Epoch 905/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4818 - accuracy: 0.7787 - val_loss: 0.4778 - val_accuracy: 0.7746\n",
            "Epoch 906/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4810 - accuracy: 0.7788 - val_loss: 0.4780 - val_accuracy: 0.7751\n",
            "Epoch 907/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4880 - accuracy: 0.7701 - val_loss: 0.4774 - val_accuracy: 0.7764\n",
            "Epoch 908/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4867 - accuracy: 0.7744 - val_loss: 0.4774 - val_accuracy: 0.7733\n",
            "Epoch 909/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4781 - accuracy: 0.7836 - val_loss: 0.4784 - val_accuracy: 0.7719\n",
            "Epoch 910/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4828 - accuracy: 0.7813 - val_loss: 0.4786 - val_accuracy: 0.7715\n",
            "Epoch 911/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4876 - accuracy: 0.7763 - val_loss: 0.4777 - val_accuracy: 0.7737\n",
            "Epoch 912/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4861 - accuracy: 0.7744 - val_loss: 0.4779 - val_accuracy: 0.7777\n",
            "Epoch 913/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4918 - accuracy: 0.7728 - val_loss: 0.4827 - val_accuracy: 0.7693\n",
            "Epoch 914/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4955 - accuracy: 0.7700 - val_loss: 0.4784 - val_accuracy: 0.7777\n",
            "Epoch 915/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4807 - accuracy: 0.7815 - val_loss: 0.4782 - val_accuracy: 0.7724\n",
            "Epoch 916/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4932 - accuracy: 0.7711 - val_loss: 0.4773 - val_accuracy: 0.7764\n",
            "Epoch 917/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4860 - accuracy: 0.7748 - val_loss: 0.4782 - val_accuracy: 0.7742\n",
            "Epoch 918/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4906 - accuracy: 0.7769 - val_loss: 0.4775 - val_accuracy: 0.7773\n",
            "Epoch 919/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4885 - accuracy: 0.7718 - val_loss: 0.4772 - val_accuracy: 0.7764\n",
            "Epoch 920/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4856 - accuracy: 0.7722 - val_loss: 0.4781 - val_accuracy: 0.7702\n",
            "Epoch 921/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4798 - accuracy: 0.7820 - val_loss: 0.4772 - val_accuracy: 0.7742\n",
            "Epoch 922/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4886 - accuracy: 0.7725 - val_loss: 0.4781 - val_accuracy: 0.7724\n",
            "Epoch 923/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4892 - accuracy: 0.7715 - val_loss: 0.4771 - val_accuracy: 0.7742\n",
            "Epoch 924/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4842 - accuracy: 0.7753 - val_loss: 0.4782 - val_accuracy: 0.7706\n",
            "Epoch 925/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4778 - accuracy: 0.7790 - val_loss: 0.4779 - val_accuracy: 0.7755\n",
            "Epoch 926/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4848 - accuracy: 0.7765 - val_loss: 0.4780 - val_accuracy: 0.7751\n",
            "Epoch 927/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4832 - accuracy: 0.7766 - val_loss: 0.4784 - val_accuracy: 0.7759\n",
            "Epoch 928/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4880 - accuracy: 0.7732 - val_loss: 0.4782 - val_accuracy: 0.7751\n",
            "Epoch 929/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4840 - accuracy: 0.7779 - val_loss: 0.4782 - val_accuracy: 0.7764\n",
            "Epoch 930/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4839 - accuracy: 0.7751 - val_loss: 0.4774 - val_accuracy: 0.7782\n",
            "Epoch 931/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4896 - accuracy: 0.7710 - val_loss: 0.4786 - val_accuracy: 0.7706\n",
            "Epoch 932/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4830 - accuracy: 0.7772 - val_loss: 0.4773 - val_accuracy: 0.7746\n",
            "Epoch 933/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4852 - accuracy: 0.7749 - val_loss: 0.4773 - val_accuracy: 0.7759\n",
            "Epoch 934/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4839 - accuracy: 0.7724 - val_loss: 0.4771 - val_accuracy: 0.7782\n",
            "Epoch 935/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4827 - accuracy: 0.7730 - val_loss: 0.4772 - val_accuracy: 0.7759\n",
            "Epoch 936/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4857 - accuracy: 0.7736 - val_loss: 0.4776 - val_accuracy: 0.7751\n",
            "Epoch 937/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4898 - accuracy: 0.7718 - val_loss: 0.4771 - val_accuracy: 0.7746\n",
            "Epoch 938/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4862 - accuracy: 0.7729 - val_loss: 0.4778 - val_accuracy: 0.7773\n",
            "Epoch 939/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4794 - accuracy: 0.7830 - val_loss: 0.4776 - val_accuracy: 0.7782\n",
            "Epoch 940/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4896 - accuracy: 0.7732 - val_loss: 0.4780 - val_accuracy: 0.7773\n",
            "Epoch 941/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4775 - accuracy: 0.7786 - val_loss: 0.4776 - val_accuracy: 0.7751\n",
            "Epoch 942/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4871 - accuracy: 0.7710 - val_loss: 0.4778 - val_accuracy: 0.7751\n",
            "Epoch 943/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4901 - accuracy: 0.7716 - val_loss: 0.4781 - val_accuracy: 0.7710\n",
            "Epoch 944/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4811 - accuracy: 0.7783 - val_loss: 0.4777 - val_accuracy: 0.7746\n",
            "Epoch 945/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4871 - accuracy: 0.7770 - val_loss: 0.4776 - val_accuracy: 0.7742\n",
            "Epoch 946/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4819 - accuracy: 0.7720 - val_loss: 0.4779 - val_accuracy: 0.7755\n",
            "Epoch 947/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4909 - accuracy: 0.7725 - val_loss: 0.4777 - val_accuracy: 0.7768\n",
            "Epoch 948/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4855 - accuracy: 0.7743 - val_loss: 0.4779 - val_accuracy: 0.7768\n",
            "Epoch 949/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4775 - accuracy: 0.7798 - val_loss: 0.4767 - val_accuracy: 0.7755\n",
            "Epoch 950/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4887 - accuracy: 0.7725 - val_loss: 0.4790 - val_accuracy: 0.7715\n",
            "Epoch 951/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4891 - accuracy: 0.7735 - val_loss: 0.4773 - val_accuracy: 0.7759\n",
            "Epoch 952/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4790 - accuracy: 0.7763 - val_loss: 0.4780 - val_accuracy: 0.7737\n",
            "Epoch 953/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4934 - accuracy: 0.7647 - val_loss: 0.4767 - val_accuracy: 0.7728\n",
            "Epoch 954/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4856 - accuracy: 0.7755 - val_loss: 0.4780 - val_accuracy: 0.7715\n",
            "Epoch 955/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4800 - accuracy: 0.7793 - val_loss: 0.4773 - val_accuracy: 0.7746\n",
            "Epoch 956/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4836 - accuracy: 0.7769 - val_loss: 0.4772 - val_accuracy: 0.7746\n",
            "Epoch 957/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4850 - accuracy: 0.7762 - val_loss: 0.4785 - val_accuracy: 0.7724\n",
            "Epoch 958/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4846 - accuracy: 0.7728 - val_loss: 0.4780 - val_accuracy: 0.7751\n",
            "Epoch 959/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4841 - accuracy: 0.7774 - val_loss: 0.4774 - val_accuracy: 0.7759\n",
            "Epoch 960/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4898 - accuracy: 0.7711 - val_loss: 0.4786 - val_accuracy: 0.7706\n",
            "Epoch 961/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4751 - accuracy: 0.7777 - val_loss: 0.4784 - val_accuracy: 0.7755\n",
            "Epoch 962/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4896 - accuracy: 0.7776 - val_loss: 0.4798 - val_accuracy: 0.7751\n",
            "Epoch 963/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4811 - accuracy: 0.7809 - val_loss: 0.4781 - val_accuracy: 0.7742\n",
            "Epoch 964/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4923 - accuracy: 0.7704 - val_loss: 0.4784 - val_accuracy: 0.7742\n",
            "Epoch 965/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4773 - accuracy: 0.7805 - val_loss: 0.4794 - val_accuracy: 0.7702\n",
            "Epoch 966/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4834 - accuracy: 0.7731 - val_loss: 0.4776 - val_accuracy: 0.7773\n",
            "Epoch 967/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4885 - accuracy: 0.7745 - val_loss: 0.4778 - val_accuracy: 0.7742\n",
            "Epoch 968/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4810 - accuracy: 0.7726 - val_loss: 0.4809 - val_accuracy: 0.7706\n",
            "Epoch 969/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4739 - accuracy: 0.7814 - val_loss: 0.4777 - val_accuracy: 0.7737\n",
            "Epoch 970/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4848 - accuracy: 0.7728 - val_loss: 0.4775 - val_accuracy: 0.7733\n",
            "Epoch 971/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4802 - accuracy: 0.7748 - val_loss: 0.4791 - val_accuracy: 0.7764\n",
            "Epoch 972/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4898 - accuracy: 0.7674 - val_loss: 0.4775 - val_accuracy: 0.7759\n",
            "Epoch 973/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4875 - accuracy: 0.7673 - val_loss: 0.4784 - val_accuracy: 0.7777\n",
            "Epoch 974/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4699 - accuracy: 0.7884 - val_loss: 0.4779 - val_accuracy: 0.7728\n",
            "Epoch 975/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4871 - accuracy: 0.7746 - val_loss: 0.4776 - val_accuracy: 0.7759\n",
            "Epoch 976/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4826 - accuracy: 0.7731 - val_loss: 0.4776 - val_accuracy: 0.7755\n",
            "Epoch 977/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4788 - accuracy: 0.7787 - val_loss: 0.4795 - val_accuracy: 0.7742\n",
            "Epoch 978/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4896 - accuracy: 0.7735 - val_loss: 0.4793 - val_accuracy: 0.7737\n",
            "Epoch 979/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4783 - accuracy: 0.7778 - val_loss: 0.4800 - val_accuracy: 0.7728\n",
            "Epoch 980/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4880 - accuracy: 0.7727 - val_loss: 0.4779 - val_accuracy: 0.7768\n",
            "Epoch 981/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4935 - accuracy: 0.7686 - val_loss: 0.4786 - val_accuracy: 0.7715\n",
            "Epoch 982/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4864 - accuracy: 0.7702 - val_loss: 0.4783 - val_accuracy: 0.7702\n",
            "Epoch 983/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4756 - accuracy: 0.7803 - val_loss: 0.4782 - val_accuracy: 0.7719\n",
            "Epoch 984/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4842 - accuracy: 0.7749 - val_loss: 0.4797 - val_accuracy: 0.7693\n",
            "Epoch 985/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4970 - accuracy: 0.7628 - val_loss: 0.4773 - val_accuracy: 0.7746\n",
            "Epoch 986/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4847 - accuracy: 0.7769 - val_loss: 0.4781 - val_accuracy: 0.7764\n",
            "Epoch 987/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4717 - accuracy: 0.7843 - val_loss: 0.4782 - val_accuracy: 0.7715\n",
            "Epoch 988/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4841 - accuracy: 0.7786 - val_loss: 0.4776 - val_accuracy: 0.7751\n",
            "Epoch 989/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4895 - accuracy: 0.7689 - val_loss: 0.4771 - val_accuracy: 0.7782\n",
            "Epoch 990/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4803 - accuracy: 0.7739 - val_loss: 0.4786 - val_accuracy: 0.7751\n",
            "Epoch 991/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4875 - accuracy: 0.7736 - val_loss: 0.4778 - val_accuracy: 0.7759\n",
            "Epoch 992/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4786 - accuracy: 0.7801 - val_loss: 0.4793 - val_accuracy: 0.7706\n",
            "Epoch 993/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4894 - accuracy: 0.7805 - val_loss: 0.4776 - val_accuracy: 0.7768\n",
            "Epoch 994/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4850 - accuracy: 0.7768 - val_loss: 0.4774 - val_accuracy: 0.7746\n",
            "Epoch 995/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4860 - accuracy: 0.7778 - val_loss: 0.4779 - val_accuracy: 0.7715\n",
            "Epoch 996/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4884 - accuracy: 0.7709 - val_loss: 0.4805 - val_accuracy: 0.7733\n",
            "Epoch 997/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4802 - accuracy: 0.7751 - val_loss: 0.4773 - val_accuracy: 0.7742\n",
            "Epoch 998/1500\n",
            "328/328 [==============================] - 1s 3ms/step - loss: 0.4815 - accuracy: 0.7769 - val_loss: 0.4782 - val_accuracy: 0.7751\n",
            "Epoch 999/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4918 - accuracy: 0.7623 - val_loss: 0.4783 - val_accuracy: 0.7759\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CN4trzHhcCf",
        "outputId": "9ee1036a-c07e-4a43-8463-ac1444cd685f"
      },
      "source": [
        "def eval_model(model, x, true_label, ds_name=\"Training\"):\r\n",
        "  loss, acc = model.evaluate(x, true_label, verbose=0)\r\n",
        "  print(\"{} Dataset: loss = {} and acccuracy = {}\".format(ds_name, np.round(loss, 4), np.round(acc, 4)))\r\n",
        "\r\n",
        "eval_model(model, xtrain_vec, ytrain, \"Training\")\r\n",
        "eval_model(model, xval_vec, yval,\"Validation\")\r\n",
        "eval_model(model, xtest_vec, ytest,\"Test\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Dataset: loss = 0.4768 and acccuracy = 0.7778\n",
            "Validation Dataset: loss = 0.4763 and acccuracy = 0.7782\n",
            "Test Dataset: loss = 0.4748 and acccuracy = 0.7826\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18ulk79tRC6f"
      },
      "source": [
        "# saving current model\r\n",
        "model.save(MODEL_DIR+SUFFIX+'_nn'+DATE+\".h5\")\r\n",
        "save_hist(model_hist, '_prediction_history.csv')\r\n",
        "\r\n",
        "ytrain_pred = model.predict(xtrain_vec)\r\n",
        "yval_pred = model.predict(xval_vec)\r\n",
        "ytest_pred = model.predict(xtest_vec)\r\n",
        "save_prediction()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "gkvjFutWfpMW",
        "outputId": "e5211352-766f-4c55-dc35-5c418cb4e4da"
      },
      "source": [
        "plot_ROC(ytrain,ytrain_pred, title='ROC on histone training')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "qeqR6tkchyaE",
        "outputId": "66382c38-3a91-4f8b-fc44-7c3a0ac07c7c"
      },
      "source": [
        "plot_recall_precision(ytrain, ytrain_pred, title='precision/recall on histone training')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "xYs8UFpbSM1N",
        "outputId": "a1cbcb79-7fb4-4726-bf42-01bb53a027a9"
      },
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\r\n",
        "for i in range(1):\r\n",
        "  ax1 = axes[0]\r\n",
        "  ax2 = axes[1]\r\n",
        "\r\n",
        "  ax1.plot(model_hist.history['loss'], label='training')\r\n",
        "  ax1.plot(model_hist.history['val_loss'], label='validation')\r\n",
        "  ax1.set_title('model loss')\r\n",
        "  ax1.set_xlabel('epoch')\r\n",
        "  ax1.set_ylabel('loss')\r\n",
        "  ax1.legend(['train', 'validation'], loc='upper left')\r\n",
        "  \r\n",
        "  ax2.plot(model_hist.history['accuracy'], label='training')\r\n",
        "  ax2.plot(model_hist.history['val_accuracy'], label='validation')\r\n",
        "  ax2.set_title('model accuracy')\r\n",
        "  ax2.set_xlabel('epoch')\r\n",
        "  ax2.set_ylabel('accuracy')\r\n",
        "  ax2.legend(['train', 'validation'], loc='upper left')\r\n",
        "fig.tight_layout()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJ1FMrCoSOZ4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}

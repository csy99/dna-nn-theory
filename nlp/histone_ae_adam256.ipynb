{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "histone_ae_adam256.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPPCnn6r/4UDUcZelxCWwCT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/csy99/dna-nn-theory/blob/master/histone_ae_adam256.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sX2CBzgbb0Mr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3ee28b2-57bc-4262-c67d-9bf351a37055"
      },
      "source": [
        "!pip install -q biopython"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.3MB 5.7MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ju-L3fnb9Z_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03c67751-86a9-4039-bb20-72159ecfdf76"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "\r\n",
        "# module auto reload\r\n",
        "%load_ext autoreload\r\n",
        "%autoreload 2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfD_sMuadGg-",
        "outputId": "b7549dc6-2e2e-4b0e-eaa4-172630a26b58"
      },
      "source": [
        "# copy modules\r\n",
        "!cp -r '/content/drive/My Drive/dna_NN_theory/reading_dna_scripts' .\r\n",
        "!ls reading_dna_scripts"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "download.py  load.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72WFD4aSdBIO"
      },
      "source": [
        "import re\r\n",
        "import time\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from itertools import product\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import sklearn.metrics as metrics\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.data import Dataset\r\n",
        "\r\n",
        "from reading_dna_scripts.load import read_fasta"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8zhPdvZb9cP"
      },
      "source": [
        "DIR = '/content/drive/My Drive/'\r\n",
        "DATA_DIR = DIR + 'dna_NN_theory/histone/'\r\n",
        "MODEL_DIR = DIR + 'dna_NN_theory/models/'\r\n",
        "DATE = '_20210313'\r\n",
        "SUFFIX = \"ae_histone_adam256\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7vvQ89Gb9eK",
        "outputId": "d5906dfd-34de-40e0-ce43-821564ae0d26"
      },
      "source": [
        "file = DIR + 'H3.fasta'\r\n",
        "sequences, labels = read_fasta(file)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14963 samples loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ealq1NGb9gY",
        "outputId": "e1ce70cf-24bd-4533-f581-177dfc5da28c"
      },
      "source": [
        "# split\r\n",
        "SEED = 3264\r\n",
        "test_size = 0.15\r\n",
        "val_size = 0.15\r\n",
        "\r\n",
        "split_options = dict(test_size=test_size, stratify=labels, random_state=SEED)\r\n",
        "x_train_val, xtest, y_train_val, ytest = train_test_split(sequences, labels, **split_options)\r\n",
        "# normalize val_size and update options\r\n",
        "split_options.update(dict(test_size=val_size/(1-test_size), stratify=y_train_val))\r\n",
        "xtrain, xval, ytrain, yval = train_test_split(x_train_val, y_train_val, **split_options)\r\n",
        "del x_train_val, y_train_val\r\n",
        "seq_len = len(xtrain[0])\r\n",
        "print('train size:', len(xtrain))\r\n",
        "print('val size: ', len(xval))\r\n",
        "print('test size: ', len(xtest))\r\n",
        "print(\"The length of the sequence is\", seq_len)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train size: 10473\n",
            "val size:  2245\n",
            "test size:  2245\n",
            "The length of the sequence is 500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Wu5WD98b9kp",
        "outputId": "001954e6-b60e-4b3b-e45b-2532b61da9d7"
      },
      "source": [
        "word_size = 1\r\n",
        "neucleotides = 'ACGT'\r\n",
        "vocab = [''.join(p) for p in product(neucleotides, repeat=word_size)]\r\n",
        "# word_to_idx = {word: i for i, word in enumerate(vocab)}\r\n",
        "vocab_size = len(neucleotides)\r\n",
        "print('vocab_size:', vocab_size)\r\n",
        "# print(\"word_to_idx\", word_to_idx)\r\n",
        "create1gram = keras.layers.experimental.preprocessing.TextVectorization(\r\n",
        "  standardize=lambda x: tf.strings.regex_replace(x, '(.)', '\\\\1 '), ngrams=1\r\n",
        ")\r\n",
        "create1gram.adapt(vocab)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab_size: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZHkrTPmRCwb"
      },
      "source": [
        "# the first two index of TextVectorization has been reserved to EOS and OOV\r\n",
        "def index_preprocess(x):\r\n",
        "  x_index = tf.subtract(create1gram(x), 2)\r\n",
        "  return x_index, x_index\r\n",
        "\r\n",
        "def ds_preprocess(x, y):\r\n",
        "  x_index = tf.subtract(create1gram(x), 2)\r\n",
        "  return x_index, y\r\n",
        "\r\n",
        "def save_hist(hist, suf=\"_history.csv\"):\r\n",
        "  filename = DIR + 'dna_NN_theory/histone/' + SUFFIX + suf\r\n",
        "  hist_df = pd.DataFrame(hist.history) \r\n",
        "  with open(filename, mode='w') as f:\r\n",
        "    hist_df.to_csv(f)\r\n",
        "\r\n",
        "def save_prediction():\r\n",
        "  res = [ytrain, ytrain_pred, yval, yval_pred, ytest, ytest_pred]\r\n",
        "  i = 0\r\n",
        "  for ds in ['train', 'val', 'test']:\r\n",
        "    filename = DIR + 'dna_NN_theory/histone/' + SUFFIX + \"_\" + ds + \"_prediction.csv\"\r\n",
        "    df = pd.DataFrame()\r\n",
        "    df[ds] = res[i]\r\n",
        "    i += 1\r\n",
        "    df[ds+'_pred'] = res[i]\r\n",
        "    i += 1\r\n",
        "    with open(filename, mode='w') as f:\r\n",
        "      df.to_csv(f)\r\n",
        "  \r\n",
        "### ref: https://stackoverflow.com/questions/25009284/how-to-plot-roc-curve-in-python\r\n",
        "def plot_ROC(label, pred, title=\"ROC\"):\r\n",
        "  fpr, tpr, threshold = metrics.roc_curve(label, pred)\r\n",
        "  roc_auc = metrics.auc(fpr, tpr)\r\n",
        "\r\n",
        "  plt.title(title)\r\n",
        "  plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\r\n",
        "  plt.legend(loc='lower right')\r\n",
        "  plt.plot([0, 1], [0, 1],'r--')\r\n",
        "  plt.xlim([0, 1])\r\n",
        "  plt.ylim([0, 1])\r\n",
        "  plt.ylabel('True Positive Rate')\r\n",
        "  plt.xlabel('False Positive Rate')\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "### ref: https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/\r\n",
        "def plot_recall_precision(label, pred, title=\"RP\"):\r\n",
        "  precision, recall, thresholds = metrics.precision_recall_curve(label, pred)\r\n",
        "  no_skill = np.sum(label) / len(label)\r\n",
        "  plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='random')\r\n",
        "  plt.plot(recall, precision, marker='.', label='model')\r\n",
        "  plt.xlabel('Recall')\r\n",
        "  plt.ylabel('Precision')\r\n",
        "  plt.legend()\r\n",
        "  plt.show()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kySE9izuRCy-"
      },
      "source": [
        "BATCH_SIZE = 256\r\n",
        "xtrain_seq = tf.data.Dataset.from_tensor_slices(xtrain).map(index_preprocess).batch(BATCH_SIZE)\r\n",
        "xval_seq = tf.data.Dataset.from_tensor_slices(xval).map(index_preprocess).batch(BATCH_SIZE)\r\n",
        "xtest_seq = tf.data.Dataset.from_tensor_slices(xtest).map(index_preprocess).batch(BATCH_SIZE)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5s8_vFbFfZ2f"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLpl_zASRC1H",
        "outputId": "56f4ce66-d898-400c-b0d9-8fb4e5550820"
      },
      "source": [
        "latent_size = 100\r\n",
        "\r\n",
        "encoder = keras.Sequential([\r\n",
        "    keras.Input(shape=(seq_len,)),\r\n",
        "    keras.layers.Embedding(seq_len, latent_size),\r\n",
        "    keras.layers.LSTM(latent_size, return_sequences=False),\r\n",
        "])\r\n",
        "\r\n",
        "decoder = keras.Sequential([\r\n",
        "    keras.layers.RepeatVector(seq_len, input_shape=[latent_size]),\r\n",
        "    keras.layers.LSTM(latent_size, return_sequences=True),\r\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(4, activation='softmax'))  # ACTG\r\n",
        "])\r\n",
        "\r\n",
        "recurrent_ae = keras.Sequential([encoder, decoder])\r\n",
        "recurrent_ae.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential (Sequential)      (None, 100)               130400    \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    (None, 500, 4)            80804     \n",
            "=================================================================\n",
            "Total params: 211,204\n",
            "Trainable params: 211,204\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaYGGPu9RC3G",
        "outputId": "1825147c-ecd3-4721-db58-d25a13f03168"
      },
      "source": [
        "recurrent_ae.compile(optimizer=tf.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics='accuracy')\r\n",
        "es_cb = keras.callbacks.EarlyStopping(patience=200, restore_best_weights=True)\r\n",
        "ae_hist = recurrent_ae.fit(xtrain_seq, validation_data=xval_seq, epochs=4000, callbacks=[es_cb])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4000\n",
            "41/41 [==============================] - 46s 354ms/step - loss: 1.3659 - accuracy: 0.3087 - val_loss: 1.3585 - val_accuracy: 0.3165\n",
            "Epoch 2/4000\n",
            "41/41 [==============================] - 13s 327ms/step - loss: 1.3586 - accuracy: 0.3161 - val_loss: 1.3589 - val_accuracy: 0.3049\n",
            "Epoch 3/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3586 - accuracy: 0.3118 - val_loss: 1.3589 - val_accuracy: 0.3152\n",
            "Epoch 4/4000\n",
            "41/41 [==============================] - 14s 328ms/step - loss: 1.3586 - accuracy: 0.3150 - val_loss: 1.3581 - val_accuracy: 0.3168\n",
            "Epoch 5/4000\n",
            "41/41 [==============================] - 14s 332ms/step - loss: 1.3583 - accuracy: 0.3158 - val_loss: 1.3583 - val_accuracy: 0.3174\n",
            "Epoch 6/4000\n",
            "41/41 [==============================] - 14s 331ms/step - loss: 1.3580 - accuracy: 0.3172 - val_loss: 1.3555 - val_accuracy: 0.3272\n",
            "Epoch 7/4000\n",
            "41/41 [==============================] - 14s 328ms/step - loss: 1.3552 - accuracy: 0.3266 - val_loss: 1.3548 - val_accuracy: 0.3296\n",
            "Epoch 8/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3538 - accuracy: 0.3298 - val_loss: 1.3521 - val_accuracy: 0.3339\n",
            "Epoch 9/4000\n",
            "41/41 [==============================] - 13s 327ms/step - loss: 1.3522 - accuracy: 0.3332 - val_loss: 1.3527 - val_accuracy: 0.3338\n",
            "Epoch 10/4000\n",
            "41/41 [==============================] - 14s 328ms/step - loss: 1.3525 - accuracy: 0.3321 - val_loss: 1.3509 - val_accuracy: 0.3337\n",
            "Epoch 11/4000\n",
            "41/41 [==============================] - 14s 328ms/step - loss: 1.3536 - accuracy: 0.3292 - val_loss: 1.3541 - val_accuracy: 0.3247\n",
            "Epoch 12/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3535 - accuracy: 0.3268 - val_loss: 1.3515 - val_accuracy: 0.3352\n",
            "Epoch 13/4000\n",
            "41/41 [==============================] - 13s 327ms/step - loss: 1.3516 - accuracy: 0.3337 - val_loss: 1.3536 - val_accuracy: 0.3341\n",
            "Epoch 14/4000\n",
            "41/41 [==============================] - 14s 328ms/step - loss: 1.3530 - accuracy: 0.3296 - val_loss: 1.3554 - val_accuracy: 0.3329\n",
            "Epoch 15/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3544 - accuracy: 0.3339 - val_loss: 1.3516 - val_accuracy: 0.3344\n",
            "Epoch 16/4000\n",
            "41/41 [==============================] - 13s 326ms/step - loss: 1.3518 - accuracy: 0.3331 - val_loss: 1.3513 - val_accuracy: 0.3327\n",
            "Epoch 17/4000\n",
            "41/41 [==============================] - 13s 327ms/step - loss: 1.3512 - accuracy: 0.3339 - val_loss: 1.3503 - val_accuracy: 0.3360\n",
            "Epoch 18/4000\n",
            "41/41 [==============================] - 14s 328ms/step - loss: 1.3540 - accuracy: 0.3268 - val_loss: 1.3567 - val_accuracy: 0.3198\n",
            "Epoch 19/4000\n",
            "41/41 [==============================] - 13s 328ms/step - loss: 1.3554 - accuracy: 0.3206 - val_loss: 1.3528 - val_accuracy: 0.3274\n",
            "Epoch 20/4000\n",
            "41/41 [==============================] - 14s 328ms/step - loss: 1.3526 - accuracy: 0.3286 - val_loss: 1.3546 - val_accuracy: 0.3158\n",
            "Epoch 21/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3545 - accuracy: 0.3131 - val_loss: 1.3531 - val_accuracy: 0.3218\n",
            "Epoch 22/4000\n",
            "41/41 [==============================] - 14s 331ms/step - loss: 1.3550 - accuracy: 0.3199 - val_loss: 1.3534 - val_accuracy: 0.3214\n",
            "Epoch 23/4000\n",
            "41/41 [==============================] - 14s 328ms/step - loss: 1.3522 - accuracy: 0.3257 - val_loss: 1.3505 - val_accuracy: 0.3333\n",
            "Epoch 24/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3514 - accuracy: 0.3309 - val_loss: 1.3512 - val_accuracy: 0.3297\n",
            "Epoch 25/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3507 - accuracy: 0.3327 - val_loss: 1.3519 - val_accuracy: 0.3312\n",
            "Epoch 26/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3525 - accuracy: 0.3286 - val_loss: 1.3498 - val_accuracy: 0.3352\n",
            "Epoch 27/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3500 - accuracy: 0.3351 - val_loss: 1.3529 - val_accuracy: 0.3315\n",
            "Epoch 28/4000\n",
            "41/41 [==============================] - 13s 327ms/step - loss: 1.3521 - accuracy: 0.3325 - val_loss: 1.3512 - val_accuracy: 0.3349\n",
            "Epoch 29/4000\n",
            "41/41 [==============================] - 13s 328ms/step - loss: 1.3506 - accuracy: 0.3347 - val_loss: 1.3491 - val_accuracy: 0.3369\n",
            "Epoch 30/4000\n",
            "41/41 [==============================] - 13s 327ms/step - loss: 1.3509 - accuracy: 0.3344 - val_loss: 1.3517 - val_accuracy: 0.3318\n",
            "Epoch 31/4000\n",
            "41/41 [==============================] - 14s 328ms/step - loss: 1.3512 - accuracy: 0.3331 - val_loss: 1.3490 - val_accuracy: 0.3369\n",
            "Epoch 32/4000\n",
            "41/41 [==============================] - 14s 328ms/step - loss: 1.3498 - accuracy: 0.3350 - val_loss: 1.3514 - val_accuracy: 0.3337\n",
            "Epoch 33/4000\n",
            "41/41 [==============================] - 13s 326ms/step - loss: 1.3507 - accuracy: 0.3342 - val_loss: 1.3495 - val_accuracy: 0.3370\n",
            "Epoch 34/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3500 - accuracy: 0.3352 - val_loss: 1.3488 - val_accuracy: 0.3362\n",
            "Epoch 35/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3486 - accuracy: 0.3361 - val_loss: 1.3514 - val_accuracy: 0.3299\n",
            "Epoch 36/4000\n",
            "41/41 [==============================] - 14s 328ms/step - loss: 1.3517 - accuracy: 0.3324 - val_loss: 1.3493 - val_accuracy: 0.3363\n",
            "Epoch 37/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3491 - accuracy: 0.3361 - val_loss: 1.3495 - val_accuracy: 0.3364\n",
            "Epoch 38/4000\n",
            "41/41 [==============================] - 13s 327ms/step - loss: 1.3492 - accuracy: 0.3355 - val_loss: 1.3487 - val_accuracy: 0.3362\n",
            "Epoch 39/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3482 - accuracy: 0.3363 - val_loss: 1.3493 - val_accuracy: 0.3343\n",
            "Epoch 40/4000\n",
            "41/41 [==============================] - 14s 328ms/step - loss: 1.3498 - accuracy: 0.3340 - val_loss: 1.3475 - val_accuracy: 0.3376\n",
            "Epoch 41/4000\n",
            "41/41 [==============================] - 13s 327ms/step - loss: 1.3477 - accuracy: 0.3367 - val_loss: 1.3481 - val_accuracy: 0.3376\n",
            "Epoch 42/4000\n",
            "41/41 [==============================] - 14s 328ms/step - loss: 1.3484 - accuracy: 0.3357 - val_loss: 1.3474 - val_accuracy: 0.3378\n",
            "Epoch 43/4000\n",
            "41/41 [==============================] - 14s 331ms/step - loss: 1.3475 - accuracy: 0.3369 - val_loss: 1.3472 - val_accuracy: 0.3378\n",
            "Epoch 44/4000\n",
            "41/41 [==============================] - 14s 328ms/step - loss: 1.3509 - accuracy: 0.3328 - val_loss: 1.3568 - val_accuracy: 0.3234\n",
            "Epoch 45/4000\n",
            "41/41 [==============================] - 13s 328ms/step - loss: 1.3552 - accuracy: 0.3266 - val_loss: 1.3503 - val_accuracy: 0.3357\n",
            "Epoch 46/4000\n",
            "41/41 [==============================] - 13s 327ms/step - loss: 1.3504 - accuracy: 0.3352 - val_loss: 1.3512 - val_accuracy: 0.3334\n",
            "Epoch 47/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3526 - accuracy: 0.3326 - val_loss: 1.3503 - val_accuracy: 0.3353\n",
            "Epoch 48/4000\n",
            "41/41 [==============================] - 14s 328ms/step - loss: 1.3501 - accuracy: 0.3351 - val_loss: 1.3501 - val_accuracy: 0.3350\n",
            "Epoch 49/4000\n",
            "41/41 [==============================] - 13s 327ms/step - loss: 1.3534 - accuracy: 0.3326 - val_loss: 1.3526 - val_accuracy: 0.3321\n",
            "Epoch 50/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3519 - accuracy: 0.3338 - val_loss: 1.3492 - val_accuracy: 0.3370\n",
            "Epoch 51/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3494 - accuracy: 0.3363 - val_loss: 1.3497 - val_accuracy: 0.3345\n",
            "Epoch 52/4000\n",
            "41/41 [==============================] - 14s 332ms/step - loss: 1.3500 - accuracy: 0.3348 - val_loss: 1.3495 - val_accuracy: 0.3361\n",
            "Epoch 53/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3494 - accuracy: 0.3360 - val_loss: 1.3490 - val_accuracy: 0.3369\n",
            "Epoch 54/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3493 - accuracy: 0.3362 - val_loss: 1.3496 - val_accuracy: 0.3351\n",
            "Epoch 55/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3499 - accuracy: 0.3352 - val_loss: 1.3479 - val_accuracy: 0.3364\n",
            "Epoch 56/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3493 - accuracy: 0.3357 - val_loss: 1.3486 - val_accuracy: 0.3367\n",
            "Epoch 57/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3483 - accuracy: 0.3365 - val_loss: 1.3478 - val_accuracy: 0.3369\n",
            "Epoch 58/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3486 - accuracy: 0.3356 - val_loss: 1.3540 - val_accuracy: 0.3365\n",
            "Epoch 59/4000\n",
            "41/41 [==============================] - 14s 331ms/step - loss: 1.3541 - accuracy: 0.3354 - val_loss: 1.3528 - val_accuracy: 0.3362\n",
            "Epoch 60/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3528 - accuracy: 0.3332 - val_loss: 1.3541 - val_accuracy: 0.3149\n",
            "Epoch 61/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3540 - accuracy: 0.3172 - val_loss: 1.3528 - val_accuracy: 0.3240\n",
            "Epoch 62/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3554 - accuracy: 0.3232 - val_loss: 1.3518 - val_accuracy: 0.3319\n",
            "Epoch 63/4000\n",
            "41/41 [==============================] - 14s 328ms/step - loss: 1.3510 - accuracy: 0.3322 - val_loss: 1.3493 - val_accuracy: 0.3361\n",
            "Epoch 64/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3496 - accuracy: 0.3350 - val_loss: 1.3503 - val_accuracy: 0.3349\n",
            "Epoch 65/4000\n",
            "41/41 [==============================] - 14s 331ms/step - loss: 1.3500 - accuracy: 0.3347 - val_loss: 1.3491 - val_accuracy: 0.3355\n",
            "Epoch 66/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3494 - accuracy: 0.3353 - val_loss: 1.3488 - val_accuracy: 0.3361\n",
            "Epoch 67/4000\n",
            "41/41 [==============================] - 14s 328ms/step - loss: 1.3490 - accuracy: 0.3359 - val_loss: 1.3487 - val_accuracy: 0.3357\n",
            "Epoch 68/4000\n",
            "41/41 [==============================] - 14s 331ms/step - loss: 1.3492 - accuracy: 0.3354 - val_loss: 1.3475 - val_accuracy: 0.3375\n",
            "Epoch 69/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3480 - accuracy: 0.3364 - val_loss: 1.3492 - val_accuracy: 0.3355\n",
            "Epoch 70/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3493 - accuracy: 0.3357 - val_loss: 1.3480 - val_accuracy: 0.3371\n",
            "Epoch 71/4000\n",
            "41/41 [==============================] - 14s 331ms/step - loss: 1.3479 - accuracy: 0.3366 - val_loss: 1.3475 - val_accuracy: 0.3374\n",
            "Epoch 72/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3476 - accuracy: 0.3368 - val_loss: 1.3472 - val_accuracy: 0.3379\n",
            "Epoch 73/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3477 - accuracy: 0.3366 - val_loss: 1.3475 - val_accuracy: 0.3378\n",
            "Epoch 74/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3475 - accuracy: 0.3369 - val_loss: 1.3469 - val_accuracy: 0.3375\n",
            "Epoch 75/4000\n",
            "41/41 [==============================] - 14s 332ms/step - loss: 1.3472 - accuracy: 0.3372 - val_loss: 1.3467 - val_accuracy: 0.3381\n",
            "Epoch 76/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3472 - accuracy: 0.3371 - val_loss: 1.3487 - val_accuracy: 0.3368\n",
            "Epoch 77/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3486 - accuracy: 0.3352 - val_loss: 1.3468 - val_accuracy: 0.3379\n",
            "Epoch 78/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3471 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3381\n",
            "Epoch 79/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3471 - accuracy: 0.3373 - val_loss: 1.3468 - val_accuracy: 0.3382\n",
            "Epoch 80/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3472 - accuracy: 0.3372 - val_loss: 1.3468 - val_accuracy: 0.3381\n",
            "Epoch 81/4000\n",
            "41/41 [==============================] - 14s 332ms/step - loss: 1.3471 - accuracy: 0.3372 - val_loss: 1.3468 - val_accuracy: 0.3381\n",
            "Epoch 82/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3475 - accuracy: 0.3368 - val_loss: 1.3468 - val_accuracy: 0.3378\n",
            "Epoch 83/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3473 - accuracy: 0.3371 - val_loss: 1.3467 - val_accuracy: 0.3380\n",
            "Epoch 84/4000\n",
            "41/41 [==============================] - 14s 331ms/step - loss: 1.3471 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 85/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3471 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3381\n",
            "Epoch 86/4000\n",
            "41/41 [==============================] - 14s 328ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3467 - val_accuracy: 0.3380\n",
            "Epoch 87/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3471 - accuracy: 0.3373 - val_loss: 1.3469 - val_accuracy: 0.3374\n",
            "Epoch 88/4000\n",
            "41/41 [==============================] - 14s 331ms/step - loss: 1.3472 - accuracy: 0.3371 - val_loss: 1.3489 - val_accuracy: 0.3364\n",
            "Epoch 89/4000\n",
            "41/41 [==============================] - 13s 328ms/step - loss: 1.3501 - accuracy: 0.3360 - val_loss: 1.3498 - val_accuracy: 0.3356\n",
            "Epoch 90/4000\n",
            "41/41 [==============================] - 14s 328ms/step - loss: 1.3498 - accuracy: 0.3351 - val_loss: 1.3496 - val_accuracy: 0.3369\n",
            "Epoch 91/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3507 - accuracy: 0.3332 - val_loss: 1.3488 - val_accuracy: 0.3365\n",
            "Epoch 92/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3489 - accuracy: 0.3360 - val_loss: 1.3488 - val_accuracy: 0.3343\n",
            "Epoch 93/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3508 - accuracy: 0.3344 - val_loss: 1.3489 - val_accuracy: 0.3366\n",
            "Epoch 94/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3483 - accuracy: 0.3365 - val_loss: 1.3478 - val_accuracy: 0.3376\n",
            "Epoch 95/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3478 - accuracy: 0.3367 - val_loss: 1.3468 - val_accuracy: 0.3378\n",
            "Epoch 96/4000\n",
            "41/41 [==============================] - 13s 327ms/step - loss: 1.3475 - accuracy: 0.3370 - val_loss: 1.3470 - val_accuracy: 0.3376\n",
            "Epoch 97/4000\n",
            "41/41 [==============================] - 14s 328ms/step - loss: 1.3473 - accuracy: 0.3372 - val_loss: 1.3470 - val_accuracy: 0.3380\n",
            "Epoch 98/4000\n",
            "41/41 [==============================] - 13s 327ms/step - loss: 1.3477 - accuracy: 0.3368 - val_loss: 1.3483 - val_accuracy: 0.3353\n",
            "Epoch 99/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3481 - accuracy: 0.3362 - val_loss: 1.3469 - val_accuracy: 0.3378\n",
            "Epoch 100/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3472 - accuracy: 0.3372 - val_loss: 1.3467 - val_accuracy: 0.3381\n",
            "Epoch 101/4000\n",
            "41/41 [==============================] - 14s 331ms/step - loss: 1.3471 - accuracy: 0.3373 - val_loss: 1.3477 - val_accuracy: 0.3381\n",
            "Epoch 102/4000\n",
            "41/41 [==============================] - 14s 331ms/step - loss: 1.3503 - accuracy: 0.3331 - val_loss: 1.3488 - val_accuracy: 0.3358\n",
            "Epoch 103/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3482 - accuracy: 0.3362 - val_loss: 1.3469 - val_accuracy: 0.3380\n",
            "Epoch 104/4000\n",
            "41/41 [==============================] - 14s 328ms/step - loss: 1.3473 - accuracy: 0.3371 - val_loss: 1.3467 - val_accuracy: 0.3381\n",
            "Epoch 105/4000\n",
            "41/41 [==============================] - 14s 331ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 106/4000\n",
            "41/41 [==============================] - 14s 332ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 107/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3476 - accuracy: 0.3370 - val_loss: 1.3473 - val_accuracy: 0.3374\n",
            "Epoch 108/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3476 - accuracy: 0.3368 - val_loss: 1.3468 - val_accuracy: 0.3380\n",
            "Epoch 109/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3471 - accuracy: 0.3373 - val_loss: 1.3469 - val_accuracy: 0.3378\n",
            "Epoch 110/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3471 - accuracy: 0.3372 - val_loss: 1.3467 - val_accuracy: 0.3380\n",
            "Epoch 111/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 112/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 113/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3471 - accuracy: 0.3373 - val_loss: 1.3468 - val_accuracy: 0.3381\n",
            "Epoch 114/4000\n",
            "41/41 [==============================] - 14s 331ms/step - loss: 1.3471 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 115/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3472 - accuracy: 0.3372 - val_loss: 1.3471 - val_accuracy: 0.3378\n",
            "Epoch 116/4000\n",
            "41/41 [==============================] - 13s 327ms/step - loss: 1.3474 - accuracy: 0.3371 - val_loss: 1.3467 - val_accuracy: 0.3382\n",
            "Epoch 117/4000\n",
            "41/41 [==============================] - 14s 328ms/step - loss: 1.3471 - accuracy: 0.3373 - val_loss: 1.3469 - val_accuracy: 0.3381\n",
            "Epoch 118/4000\n",
            "41/41 [==============================] - 13s 327ms/step - loss: 1.3474 - accuracy: 0.3369 - val_loss: 1.3467 - val_accuracy: 0.3379\n",
            "Epoch 119/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3471 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3381\n",
            "Epoch 120/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3467 - val_accuracy: 0.3380\n",
            "Epoch 121/4000\n",
            "41/41 [==============================] - 14s 328ms/step - loss: 1.3471 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3381\n",
            "Epoch 122/4000\n",
            "41/41 [==============================] - 14s 331ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 123/4000\n",
            "41/41 [==============================] - 13s 327ms/step - loss: 1.3474 - accuracy: 0.3367 - val_loss: 1.3509 - val_accuracy: 0.3279\n",
            "Epoch 124/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3500 - accuracy: 0.3321 - val_loss: 1.3483 - val_accuracy: 0.3367\n",
            "Epoch 125/4000\n",
            "41/41 [==============================] - 13s 327ms/step - loss: 1.3484 - accuracy: 0.3363 - val_loss: 1.3470 - val_accuracy: 0.3375\n",
            "Epoch 126/4000\n",
            "41/41 [==============================] - 13s 327ms/step - loss: 1.3472 - accuracy: 0.3371 - val_loss: 1.3467 - val_accuracy: 0.3381\n",
            "Epoch 127/4000\n",
            "41/41 [==============================] - 13s 327ms/step - loss: 1.3472 - accuracy: 0.3371 - val_loss: 1.3472 - val_accuracy: 0.3375\n",
            "Epoch 128/4000\n",
            "41/41 [==============================] - 14s 328ms/step - loss: 1.3475 - accuracy: 0.3367 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 129/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3466 - val_accuracy: 0.3381\n",
            "Epoch 130/4000\n",
            "41/41 [==============================] - 14s 328ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3470 - val_accuracy: 0.3378\n",
            "Epoch 131/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3474 - accuracy: 0.3369 - val_loss: 1.3473 - val_accuracy: 0.3381\n",
            "Epoch 132/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3473 - accuracy: 0.3372 - val_loss: 1.3465 - val_accuracy: 0.3382\n",
            "Epoch 133/4000\n",
            "41/41 [==============================] - 14s 328ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3468 - val_accuracy: 0.3381\n",
            "Epoch 134/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3473 - accuracy: 0.3371 - val_loss: 1.3476 - val_accuracy: 0.3367\n",
            "Epoch 135/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3492 - accuracy: 0.3346 - val_loss: 1.3508 - val_accuracy: 0.3314\n",
            "Epoch 136/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3497 - accuracy: 0.3333 - val_loss: 1.3473 - val_accuracy: 0.3378\n",
            "Epoch 137/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3474 - accuracy: 0.3370 - val_loss: 1.3498 - val_accuracy: 0.3330\n",
            "Epoch 138/4000\n",
            "41/41 [==============================] - 14s 328ms/step - loss: 1.3513 - accuracy: 0.3334 - val_loss: 1.3482 - val_accuracy: 0.3372\n",
            "Epoch 139/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3479 - accuracy: 0.3368 - val_loss: 1.3469 - val_accuracy: 0.3380\n",
            "Epoch 140/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3472 - accuracy: 0.3371 - val_loss: 1.3467 - val_accuracy: 0.3381\n",
            "Epoch 141/4000\n",
            "41/41 [==============================] - 14s 331ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 142/4000\n",
            "41/41 [==============================] - 14s 328ms/step - loss: 1.3469 - accuracy: 0.3374 - val_loss: 1.3465 - val_accuracy: 0.3382\n",
            "Epoch 143/4000\n",
            "41/41 [==============================] - 14s 328ms/step - loss: 1.3469 - accuracy: 0.3374 - val_loss: 1.3465 - val_accuracy: 0.3382\n",
            "Epoch 144/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3467 - val_accuracy: 0.3381\n",
            "Epoch 145/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3477 - accuracy: 0.3366 - val_loss: 1.3471 - val_accuracy: 0.3370\n",
            "Epoch 146/4000\n",
            "41/41 [==============================] - 14s 331ms/step - loss: 1.3472 - accuracy: 0.3371 - val_loss: 1.3470 - val_accuracy: 0.3381\n",
            "Epoch 147/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3489 - accuracy: 0.3363 - val_loss: 1.3509 - val_accuracy: 0.3345\n",
            "Epoch 148/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3502 - accuracy: 0.3345 - val_loss: 1.3489 - val_accuracy: 0.3367\n",
            "Epoch 149/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3492 - accuracy: 0.3358 - val_loss: 1.3488 - val_accuracy: 0.3367\n",
            "Epoch 150/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3491 - accuracy: 0.3362 - val_loss: 1.3486 - val_accuracy: 0.3370\n",
            "Epoch 151/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3489 - accuracy: 0.3362 - val_loss: 1.3507 - val_accuracy: 0.3350\n",
            "Epoch 152/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3543 - accuracy: 0.3213 - val_loss: 1.3533 - val_accuracy: 0.3199\n",
            "Epoch 153/4000\n",
            "41/41 [==============================] - 14s 331ms/step - loss: 1.3531 - accuracy: 0.3203 - val_loss: 1.3542 - val_accuracy: 0.3207\n",
            "Epoch 154/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3533 - accuracy: 0.3228 - val_loss: 1.3501 - val_accuracy: 0.3328\n",
            "Epoch 155/4000\n",
            "41/41 [==============================] - 14s 331ms/step - loss: 1.3502 - accuracy: 0.3328 - val_loss: 1.3499 - val_accuracy: 0.3346\n",
            "Epoch 156/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3497 - accuracy: 0.3344 - val_loss: 1.3495 - val_accuracy: 0.3343\n",
            "Epoch 157/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3499 - accuracy: 0.3336 - val_loss: 1.3476 - val_accuracy: 0.3373\n",
            "Epoch 158/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3478 - accuracy: 0.3366 - val_loss: 1.3476 - val_accuracy: 0.3377\n",
            "Epoch 159/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3485 - accuracy: 0.3361 - val_loss: 1.3497 - val_accuracy: 0.3358\n",
            "Epoch 160/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3496 - accuracy: 0.3358 - val_loss: 1.3486 - val_accuracy: 0.3371\n",
            "Epoch 161/4000\n",
            "41/41 [==============================] - 14s 328ms/step - loss: 1.3488 - accuracy: 0.3365 - val_loss: 1.3475 - val_accuracy: 0.3376\n",
            "Epoch 162/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3479 - accuracy: 0.3366 - val_loss: 1.3470 - val_accuracy: 0.3379\n",
            "Epoch 163/4000\n",
            "41/41 [==============================] - 14s 331ms/step - loss: 1.3473 - accuracy: 0.3371 - val_loss: 1.3467 - val_accuracy: 0.3382\n",
            "Epoch 164/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3467 - val_accuracy: 0.3378\n",
            "Epoch 165/4000\n",
            "41/41 [==============================] - 14s 331ms/step - loss: 1.3477 - accuracy: 0.3368 - val_loss: 1.3475 - val_accuracy: 0.3371\n",
            "Epoch 166/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3477 - accuracy: 0.3368 - val_loss: 1.3467 - val_accuracy: 0.3381\n",
            "Epoch 167/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3471 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3381\n",
            "Epoch 168/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3466 - val_accuracy: 0.3381\n",
            "Epoch 169/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 170/4000\n",
            "41/41 [==============================] - 14s 332ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3466 - val_accuracy: 0.3383\n",
            "Epoch 171/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3477 - accuracy: 0.3364 - val_loss: 1.3491 - val_accuracy: 0.3362\n",
            "Epoch 172/4000\n",
            "41/41 [==============================] - 14s 336ms/step - loss: 1.3485 - accuracy: 0.3363 - val_loss: 1.3472 - val_accuracy: 0.3379\n",
            "Epoch 173/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3473 - accuracy: 0.3371 - val_loss: 1.3467 - val_accuracy: 0.3380\n",
            "Epoch 174/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3471 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3381\n",
            "Epoch 175/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3467 - val_accuracy: 0.3381\n",
            "Epoch 176/4000\n",
            "41/41 [==============================] - 14s 332ms/step - loss: 1.3475 - accuracy: 0.3370 - val_loss: 1.3492 - val_accuracy: 0.3366\n",
            "Epoch 177/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3495 - accuracy: 0.3353 - val_loss: 1.3487 - val_accuracy: 0.3367\n",
            "Epoch 178/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3490 - accuracy: 0.3360 - val_loss: 1.3483 - val_accuracy: 0.3368\n",
            "Epoch 179/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3490 - accuracy: 0.3356 - val_loss: 1.3539 - val_accuracy: 0.3284\n",
            "Epoch 180/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3528 - accuracy: 0.3283 - val_loss: 1.3494 - val_accuracy: 0.3358\n",
            "Epoch 181/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3490 - accuracy: 0.3361 - val_loss: 1.3471 - val_accuracy: 0.3377\n",
            "Epoch 182/4000\n",
            "41/41 [==============================] - 14s 331ms/step - loss: 1.3474 - accuracy: 0.3370 - val_loss: 1.3488 - val_accuracy: 0.3364\n",
            "Epoch 183/4000\n",
            "41/41 [==============================] - 14s 332ms/step - loss: 1.3499 - accuracy: 0.3350 - val_loss: 1.3482 - val_accuracy: 0.3371\n",
            "Epoch 184/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3480 - accuracy: 0.3367 - val_loss: 1.3470 - val_accuracy: 0.3379\n",
            "Epoch 185/4000\n",
            "41/41 [==============================] - 14s 331ms/step - loss: 1.3473 - accuracy: 0.3371 - val_loss: 1.3467 - val_accuracy: 0.3380\n",
            "Epoch 186/4000\n",
            "41/41 [==============================] - 13s 327ms/step - loss: 1.3471 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 187/4000\n",
            "41/41 [==============================] - 14s 328ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 188/4000\n",
            "41/41 [==============================] - 14s 332ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3470 - val_accuracy: 0.3381\n",
            "Epoch 189/4000\n",
            "41/41 [==============================] - 14s 331ms/step - loss: 1.3475 - accuracy: 0.3370 - val_loss: 1.3477 - val_accuracy: 0.3364\n",
            "Epoch 190/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3477 - accuracy: 0.3365 - val_loss: 1.3467 - val_accuracy: 0.3380\n",
            "Epoch 191/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3471 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 192/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3466 - val_accuracy: 0.3380\n",
            "Epoch 193/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3465 - val_accuracy: 0.3381\n",
            "Epoch 194/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3469 - accuracy: 0.3374 - val_loss: 1.3465 - val_accuracy: 0.3382\n",
            "Epoch 195/4000\n",
            "41/41 [==============================] - 14s 332ms/step - loss: 1.3469 - accuracy: 0.3374 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 196/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3479 - accuracy: 0.3351 - val_loss: 1.3496 - val_accuracy: 0.3295\n",
            "Epoch 197/4000\n",
            "41/41 [==============================] - 14s 332ms/step - loss: 1.3492 - accuracy: 0.3322 - val_loss: 1.3479 - val_accuracy: 0.3376\n",
            "Epoch 198/4000\n",
            "41/41 [==============================] - 13s 328ms/step - loss: 1.3479 - accuracy: 0.3366 - val_loss: 1.3487 - val_accuracy: 0.3372\n",
            "Epoch 199/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3484 - accuracy: 0.3363 - val_loss: 1.3469 - val_accuracy: 0.3377\n",
            "Epoch 200/4000\n",
            "41/41 [==============================] - 14s 332ms/step - loss: 1.3472 - accuracy: 0.3371 - val_loss: 1.3467 - val_accuracy: 0.3381\n",
            "Epoch 201/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3471 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 202/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 203/4000\n",
            "41/41 [==============================] - 14s 328ms/step - loss: 1.3469 - accuracy: 0.3374 - val_loss: 1.3465 - val_accuracy: 0.3382\n",
            "Epoch 204/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3465 - val_accuracy: 0.3382\n",
            "Epoch 205/4000\n",
            "41/41 [==============================] - 14s 332ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3465 - val_accuracy: 0.3382\n",
            "Epoch 206/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3469 - accuracy: 0.3374 - val_loss: 1.3465 - val_accuracy: 0.3382\n",
            "Epoch 207/4000\n",
            "41/41 [==============================] - 14s 331ms/step - loss: 1.3469 - accuracy: 0.3374 - val_loss: 1.3465 - val_accuracy: 0.3382\n",
            "Epoch 208/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3471 - accuracy: 0.3372 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 209/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3468 - val_accuracy: 0.3379\n",
            "Epoch 210/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3473 - accuracy: 0.3371 - val_loss: 1.3469 - val_accuracy: 0.3372\n",
            "Epoch 211/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3472 - accuracy: 0.3369 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 212/4000\n",
            "41/41 [==============================] - 14s 328ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3465 - val_accuracy: 0.3381\n",
            "Epoch 213/4000\n",
            "41/41 [==============================] - 14s 328ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3467 - val_accuracy: 0.3379\n",
            "Epoch 214/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3467 - val_accuracy: 0.3381\n",
            "Epoch 215/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 216/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3471 - accuracy: 0.3373 - val_loss: 1.3470 - val_accuracy: 0.3380\n",
            "Epoch 217/4000\n",
            "41/41 [==============================] - 14s 331ms/step - loss: 1.3474 - accuracy: 0.3371 - val_loss: 1.3472 - val_accuracy: 0.3377\n",
            "Epoch 218/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3476 - accuracy: 0.3368 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 219/4000\n",
            "41/41 [==============================] - 14s 331ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3465 - val_accuracy: 0.3382\n",
            "Epoch 220/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3469 - accuracy: 0.3374 - val_loss: 1.3466 - val_accuracy: 0.3380\n",
            "Epoch 221/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3465 - val_accuracy: 0.3382\n",
            "Epoch 222/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3469 - accuracy: 0.3375 - val_loss: 1.3465 - val_accuracy: 0.3382\n",
            "Epoch 223/4000\n",
            "41/41 [==============================] - 14s 331ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3476 - val_accuracy: 0.3375\n",
            "Epoch 224/4000\n",
            "41/41 [==============================] - 14s 328ms/step - loss: 1.3479 - accuracy: 0.3366 - val_loss: 1.3483 - val_accuracy: 0.3356\n",
            "Epoch 225/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3481 - accuracy: 0.3355 - val_loss: 1.3468 - val_accuracy: 0.3379\n",
            "Epoch 226/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3473 - accuracy: 0.3370 - val_loss: 1.3467 - val_accuracy: 0.3382\n",
            "Epoch 227/4000\n",
            "41/41 [==============================] - 14s 329ms/step - loss: 1.3471 - accuracy: 0.3373 - val_loss: 1.3465 - val_accuracy: 0.3382\n",
            "Epoch 228/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3469 - accuracy: 0.3374 - val_loss: 1.3465 - val_accuracy: 0.3383\n",
            "Epoch 229/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3469 - accuracy: 0.3374 - val_loss: 1.3466 - val_accuracy: 0.3380\n",
            "Epoch 230/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3465 - val_accuracy: 0.3382\n",
            "Epoch 231/4000\n",
            "41/41 [==============================] - 14s 330ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3467 - val_accuracy: 0.3380\n",
            "Epoch 232/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3471 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 233/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3468 - val_accuracy: 0.3382\n",
            "Epoch 234/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3471 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3380\n",
            "Epoch 235/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3469 - accuracy: 0.3375 - val_loss: 1.3466 - val_accuracy: 0.3381\n",
            "Epoch 236/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3471 - accuracy: 0.3373 - val_loss: 1.3479 - val_accuracy: 0.3370\n",
            "Epoch 237/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3483 - accuracy: 0.3360 - val_loss: 1.3474 - val_accuracy: 0.3377\n",
            "Epoch 238/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3474 - accuracy: 0.3369 - val_loss: 1.3467 - val_accuracy: 0.3382\n",
            "Epoch 239/4000\n",
            "41/41 [==============================] - 14s 332ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3465 - val_accuracy: 0.3382\n",
            "Epoch 240/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3469 - accuracy: 0.3374 - val_loss: 1.3465 - val_accuracy: 0.3382\n",
            "Epoch 241/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3466 - val_accuracy: 0.3380\n",
            "Epoch 242/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 243/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 244/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 245/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3470 - accuracy: 0.3375 - val_loss: 1.3465 - val_accuracy: 0.3383\n",
            "Epoch 246/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3469 - accuracy: 0.3375 - val_loss: 1.3466 - val_accuracy: 0.3383\n",
            "Epoch 247/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3469 - val_accuracy: 0.3376\n",
            "Epoch 248/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3472 - accuracy: 0.3370 - val_loss: 1.3473 - val_accuracy: 0.3377\n",
            "Epoch 249/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3500 - accuracy: 0.3330 - val_loss: 1.3585 - val_accuracy: 0.3175\n",
            "Epoch 250/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3582 - accuracy: 0.3172 - val_loss: 1.3584 - val_accuracy: 0.3188\n",
            "Epoch 251/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3582 - accuracy: 0.3182 - val_loss: 1.3581 - val_accuracy: 0.3181\n",
            "Epoch 252/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3578 - accuracy: 0.3168 - val_loss: 1.3582 - val_accuracy: 0.3193\n",
            "Epoch 253/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3579 - accuracy: 0.3198 - val_loss: 1.3550 - val_accuracy: 0.3293\n",
            "Epoch 254/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3572 - accuracy: 0.3226 - val_loss: 1.3547 - val_accuracy: 0.3289\n",
            "Epoch 255/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3547 - accuracy: 0.3274 - val_loss: 1.3539 - val_accuracy: 0.3272\n",
            "Epoch 256/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3547 - accuracy: 0.3254 - val_loss: 1.3527 - val_accuracy: 0.3294\n",
            "Epoch 257/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3524 - accuracy: 0.3315 - val_loss: 1.3560 - val_accuracy: 0.3260\n",
            "Epoch 258/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3551 - accuracy: 0.3270 - val_loss: 1.3536 - val_accuracy: 0.3267\n",
            "Epoch 259/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3534 - accuracy: 0.3269 - val_loss: 1.3524 - val_accuracy: 0.3283\n",
            "Epoch 260/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3521 - accuracy: 0.3279 - val_loss: 1.3507 - val_accuracy: 0.3330\n",
            "Epoch 261/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3510 - accuracy: 0.3328 - val_loss: 1.3503 - val_accuracy: 0.3353\n",
            "Epoch 262/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3510 - accuracy: 0.3333 - val_loss: 1.3498 - val_accuracy: 0.3358\n",
            "Epoch 263/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3498 - accuracy: 0.3350 - val_loss: 1.3559 - val_accuracy: 0.3270\n",
            "Epoch 264/4000\n",
            "41/41 [==============================] - 14s 332ms/step - loss: 1.3562 - accuracy: 0.3230 - val_loss: 1.3530 - val_accuracy: 0.3314\n",
            "Epoch 265/4000\n",
            "41/41 [==============================] - 14s 332ms/step - loss: 1.3522 - accuracy: 0.3337 - val_loss: 1.3505 - val_accuracy: 0.3363\n",
            "Epoch 266/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3508 - accuracy: 0.3354 - val_loss: 1.3515 - val_accuracy: 0.3350\n",
            "Epoch 267/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3510 - accuracy: 0.3341 - val_loss: 1.3494 - val_accuracy: 0.3365\n",
            "Epoch 268/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3520 - accuracy: 0.3316 - val_loss: 1.3544 - val_accuracy: 0.3247\n",
            "Epoch 269/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3542 - accuracy: 0.3242 - val_loss: 1.3538 - val_accuracy: 0.3224\n",
            "Epoch 270/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3539 - accuracy: 0.3208 - val_loss: 1.3539 - val_accuracy: 0.3191\n",
            "Epoch 271/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3540 - accuracy: 0.3196 - val_loss: 1.3537 - val_accuracy: 0.3190\n",
            "Epoch 272/4000\n",
            "41/41 [==============================] - 14s 332ms/step - loss: 1.3537 - accuracy: 0.3199 - val_loss: 1.3535 - val_accuracy: 0.3219\n",
            "Epoch 273/4000\n",
            "41/41 [==============================] - 14s 332ms/step - loss: 1.3536 - accuracy: 0.3206 - val_loss: 1.3542 - val_accuracy: 0.3191\n",
            "Epoch 274/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3540 - accuracy: 0.3205 - val_loss: 1.3533 - val_accuracy: 0.3242\n",
            "Epoch 275/4000\n",
            "41/41 [==============================] - 14s 332ms/step - loss: 1.3534 - accuracy: 0.3226 - val_loss: 1.3540 - val_accuracy: 0.3252\n",
            "Epoch 276/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3537 - accuracy: 0.3241 - val_loss: 1.3531 - val_accuracy: 0.3260\n",
            "Epoch 277/4000\n",
            "41/41 [==============================] - 14s 332ms/step - loss: 1.3533 - accuracy: 0.3247 - val_loss: 1.3530 - val_accuracy: 0.3276\n",
            "Epoch 278/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3532 - accuracy: 0.3267 - val_loss: 1.3530 - val_accuracy: 0.3283\n",
            "Epoch 279/4000\n",
            "41/41 [==============================] - 14s 332ms/step - loss: 1.3531 - accuracy: 0.3263 - val_loss: 1.3520 - val_accuracy: 0.3320\n",
            "Epoch 280/4000\n",
            "41/41 [==============================] - 14s 332ms/step - loss: 1.3526 - accuracy: 0.3305 - val_loss: 1.3505 - val_accuracy: 0.3358\n",
            "Epoch 281/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3513 - accuracy: 0.3332 - val_loss: 1.3575 - val_accuracy: 0.3194\n",
            "Epoch 282/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3562 - accuracy: 0.3226 - val_loss: 1.3526 - val_accuracy: 0.3306\n",
            "Epoch 283/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3523 - accuracy: 0.3303 - val_loss: 1.3505 - val_accuracy: 0.3349\n",
            "Epoch 284/4000\n",
            "41/41 [==============================] - 14s 332ms/step - loss: 1.3506 - accuracy: 0.3349 - val_loss: 1.3500 - val_accuracy: 0.3353\n",
            "Epoch 285/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3500 - accuracy: 0.3354 - val_loss: 1.3511 - val_accuracy: 0.3284\n",
            "Epoch 286/4000\n",
            "41/41 [==============================] - 14s 332ms/step - loss: 1.3533 - accuracy: 0.3314 - val_loss: 1.3533 - val_accuracy: 0.3352\n",
            "Epoch 287/4000\n",
            "41/41 [==============================] - 14s 332ms/step - loss: 1.3527 - accuracy: 0.3341 - val_loss: 1.3535 - val_accuracy: 0.3227\n",
            "Epoch 288/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3532 - accuracy: 0.3221 - val_loss: 1.3506 - val_accuracy: 0.3333\n",
            "Epoch 289/4000\n",
            "41/41 [==============================] - 14s 332ms/step - loss: 1.3503 - accuracy: 0.3350 - val_loss: 1.3493 - val_accuracy: 0.3368\n",
            "Epoch 290/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3501 - accuracy: 0.3349 - val_loss: 1.3504 - val_accuracy: 0.3364\n",
            "Epoch 291/4000\n",
            "41/41 [==============================] - 14s 332ms/step - loss: 1.3503 - accuracy: 0.3348 - val_loss: 1.3490 - val_accuracy: 0.3367\n",
            "Epoch 292/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3494 - accuracy: 0.3358 - val_loss: 1.3496 - val_accuracy: 0.3365\n",
            "Epoch 293/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3496 - accuracy: 0.3357 - val_loss: 1.3490 - val_accuracy: 0.3361\n",
            "Epoch 294/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3491 - accuracy: 0.3359 - val_loss: 1.3487 - val_accuracy: 0.3363\n",
            "Epoch 295/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3490 - accuracy: 0.3360 - val_loss: 1.3485 - val_accuracy: 0.3345\n",
            "Epoch 296/4000\n",
            "41/41 [==============================] - 14s 332ms/step - loss: 1.3489 - accuracy: 0.3354 - val_loss: 1.3487 - val_accuracy: 0.3364\n",
            "Epoch 297/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3487 - accuracy: 0.3358 - val_loss: 1.3480 - val_accuracy: 0.3374\n",
            "Epoch 298/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3484 - accuracy: 0.3357 - val_loss: 1.3474 - val_accuracy: 0.3377\n",
            "Epoch 299/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3478 - accuracy: 0.3367 - val_loss: 1.3472 - val_accuracy: 0.3376\n",
            "Epoch 300/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3477 - accuracy: 0.3368 - val_loss: 1.3471 - val_accuracy: 0.3377\n",
            "Epoch 301/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3485 - accuracy: 0.3363 - val_loss: 1.3473 - val_accuracy: 0.3379\n",
            "Epoch 302/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3476 - accuracy: 0.3369 - val_loss: 1.3474 - val_accuracy: 0.3371\n",
            "Epoch 303/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3477 - accuracy: 0.3368 - val_loss: 1.3471 - val_accuracy: 0.3377\n",
            "Epoch 304/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3474 - accuracy: 0.3372 - val_loss: 1.3479 - val_accuracy: 0.3378\n",
            "Epoch 305/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3487 - accuracy: 0.3357 - val_loss: 1.3477 - val_accuracy: 0.3367\n",
            "Epoch 306/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3484 - accuracy: 0.3356 - val_loss: 1.3469 - val_accuracy: 0.3380\n",
            "Epoch 307/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3472 - accuracy: 0.3372 - val_loss: 1.3471 - val_accuracy: 0.3375\n",
            "Epoch 308/4000\n",
            "41/41 [==============================] - 14s 332ms/step - loss: 1.3479 - accuracy: 0.3365 - val_loss: 1.3484 - val_accuracy: 0.3338\n",
            "Epoch 309/4000\n",
            "41/41 [==============================] - 14s 332ms/step - loss: 1.3482 - accuracy: 0.3362 - val_loss: 1.3468 - val_accuracy: 0.3381\n",
            "Epoch 310/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3473 - accuracy: 0.3372 - val_loss: 1.3482 - val_accuracy: 0.3374\n",
            "Epoch 311/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3483 - accuracy: 0.3368 - val_loss: 1.3470 - val_accuracy: 0.3379\n",
            "Epoch 312/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3472 - accuracy: 0.3372 - val_loss: 1.3469 - val_accuracy: 0.3376\n",
            "Epoch 313/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3475 - accuracy: 0.3368 - val_loss: 1.3468 - val_accuracy: 0.3381\n",
            "Epoch 314/4000\n",
            "41/41 [==============================] - 14s 332ms/step - loss: 1.3471 - accuracy: 0.3373 - val_loss: 1.3482 - val_accuracy: 0.3364\n",
            "Epoch 315/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3490 - accuracy: 0.3347 - val_loss: 1.3473 - val_accuracy: 0.3376\n",
            "Epoch 316/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3476 - accuracy: 0.3368 - val_loss: 1.3468 - val_accuracy: 0.3380\n",
            "Epoch 317/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3472 - accuracy: 0.3372 - val_loss: 1.3467 - val_accuracy: 0.3381\n",
            "Epoch 318/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3472 - accuracy: 0.3373 - val_loss: 1.3467 - val_accuracy: 0.3381\n",
            "Epoch 319/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3471 - accuracy: 0.3373 - val_loss: 1.3471 - val_accuracy: 0.3381\n",
            "Epoch 320/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3493 - accuracy: 0.3358 - val_loss: 1.3495 - val_accuracy: 0.3362\n",
            "Epoch 321/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3494 - accuracy: 0.3359 - val_loss: 1.3487 - val_accuracy: 0.3368\n",
            "Epoch 322/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3490 - accuracy: 0.3363 - val_loss: 1.3489 - val_accuracy: 0.3369\n",
            "Epoch 323/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3493 - accuracy: 0.3359 - val_loss: 1.3568 - val_accuracy: 0.3153\n",
            "Epoch 324/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3558 - accuracy: 0.3170 - val_loss: 1.3535 - val_accuracy: 0.3202\n",
            "Epoch 325/4000\n",
            "41/41 [==============================] - 14s 332ms/step - loss: 1.3534 - accuracy: 0.3208 - val_loss: 1.3525 - val_accuracy: 0.3242\n",
            "Epoch 326/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3522 - accuracy: 0.3256 - val_loss: 1.3497 - val_accuracy: 0.3362\n",
            "Epoch 327/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3497 - accuracy: 0.3353 - val_loss: 1.3494 - val_accuracy: 0.3357\n",
            "Epoch 328/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3502 - accuracy: 0.3330 - val_loss: 1.3494 - val_accuracy: 0.3350\n",
            "Epoch 329/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3490 - accuracy: 0.3356 - val_loss: 1.3473 - val_accuracy: 0.3378\n",
            "Epoch 330/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3482 - accuracy: 0.3362 - val_loss: 1.3477 - val_accuracy: 0.3375\n",
            "Epoch 331/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3477 - accuracy: 0.3369 - val_loss: 1.3469 - val_accuracy: 0.3382\n",
            "Epoch 332/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3474 - accuracy: 0.3370 - val_loss: 1.3469 - val_accuracy: 0.3381\n",
            "Epoch 333/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3472 - accuracy: 0.3373 - val_loss: 1.3470 - val_accuracy: 0.3380\n",
            "Epoch 334/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3473 - accuracy: 0.3372 - val_loss: 1.3468 - val_accuracy: 0.3380\n",
            "Epoch 335/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3471 - accuracy: 0.3372 - val_loss: 1.3466 - val_accuracy: 0.3381\n",
            "Epoch 336/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3466 - val_accuracy: 0.3381\n",
            "Epoch 337/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3471 - val_accuracy: 0.3381\n",
            "Epoch 338/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3489 - accuracy: 0.3353 - val_loss: 1.3497 - val_accuracy: 0.3354\n",
            "Epoch 339/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3496 - accuracy: 0.3355 - val_loss: 1.3488 - val_accuracy: 0.3372\n",
            "Epoch 340/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3491 - accuracy: 0.3365 - val_loss: 1.3487 - val_accuracy: 0.3360\n",
            "Epoch 341/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3488 - accuracy: 0.3364 - val_loss: 1.3476 - val_accuracy: 0.3375\n",
            "Epoch 342/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3476 - accuracy: 0.3369 - val_loss: 1.3467 - val_accuracy: 0.3381\n",
            "Epoch 343/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3471 - accuracy: 0.3373 - val_loss: 1.3468 - val_accuracy: 0.3381\n",
            "Epoch 344/4000\n",
            "41/41 [==============================] - 14s 332ms/step - loss: 1.3471 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3381\n",
            "Epoch 345/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3473 - accuracy: 0.3368 - val_loss: 1.3474 - val_accuracy: 0.3373\n",
            "Epoch 346/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3481 - accuracy: 0.3363 - val_loss: 1.3476 - val_accuracy: 0.3374\n",
            "Epoch 347/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3477 - accuracy: 0.3365 - val_loss: 1.3471 - val_accuracy: 0.3380\n",
            "Epoch 348/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3472 - accuracy: 0.3372 - val_loss: 1.3466 - val_accuracy: 0.3381\n",
            "Epoch 349/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3465 - val_accuracy: 0.3382\n",
            "Epoch 350/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3469 - accuracy: 0.3374 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 351/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3471 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 352/4000\n",
            "41/41 [==============================] - 14s 336ms/step - loss: 1.3471 - accuracy: 0.3372 - val_loss: 1.3496 - val_accuracy: 0.3337\n",
            "Epoch 353/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3510 - accuracy: 0.3319 - val_loss: 1.3510 - val_accuracy: 0.3317\n",
            "Epoch 354/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3505 - accuracy: 0.3341 - val_loss: 1.3490 - val_accuracy: 0.3363\n",
            "Epoch 355/4000\n",
            "41/41 [==============================] - 14s 336ms/step - loss: 1.3494 - accuracy: 0.3356 - val_loss: 1.3498 - val_accuracy: 0.3362\n",
            "Epoch 356/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3497 - accuracy: 0.3352 - val_loss: 1.3490 - val_accuracy: 0.3365\n",
            "Epoch 357/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3488 - accuracy: 0.3361 - val_loss: 1.3479 - val_accuracy: 0.3371\n",
            "Epoch 358/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3480 - accuracy: 0.3363 - val_loss: 1.3468 - val_accuracy: 0.3381\n",
            "Epoch 359/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3471 - accuracy: 0.3373 - val_loss: 1.3477 - val_accuracy: 0.3379\n",
            "Epoch 360/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3482 - accuracy: 0.3364 - val_loss: 1.3469 - val_accuracy: 0.3376\n",
            "Epoch 361/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3471 - accuracy: 0.3372 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 362/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 363/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3466 - val_accuracy: 0.3381\n",
            "Epoch 364/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3476 - val_accuracy: 0.3382\n",
            "Epoch 365/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3480 - accuracy: 0.3369 - val_loss: 1.3473 - val_accuracy: 0.3375\n",
            "Epoch 366/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3472 - accuracy: 0.3372 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 367/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 368/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3465 - val_accuracy: 0.3382\n",
            "Epoch 369/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3469 - accuracy: 0.3374 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 370/4000\n",
            "41/41 [==============================] - 14s 338ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3466 - val_accuracy: 0.3380\n",
            "Epoch 371/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3466 - val_accuracy: 0.3381\n",
            "Epoch 372/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3472 - accuracy: 0.3372 - val_loss: 1.3466 - val_accuracy: 0.3381\n",
            "Epoch 373/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3471 - accuracy: 0.3372 - val_loss: 1.3482 - val_accuracy: 0.3353\n",
            "Epoch 374/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3483 - accuracy: 0.3357 - val_loss: 1.3474 - val_accuracy: 0.3376\n",
            "Epoch 375/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3474 - accuracy: 0.3370 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 376/4000\n",
            "41/41 [==============================] - 14s 332ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3467 - val_accuracy: 0.3382\n",
            "Epoch 377/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 378/4000\n",
            "41/41 [==============================] - 14s 332ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 379/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3469 - accuracy: 0.3374 - val_loss: 1.3465 - val_accuracy: 0.3382\n",
            "Epoch 380/4000\n",
            "41/41 [==============================] - 14s 332ms/step - loss: 1.3469 - accuracy: 0.3374 - val_loss: 1.3469 - val_accuracy: 0.3382\n",
            "Epoch 381/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3484 - accuracy: 0.3367 - val_loss: 1.3481 - val_accuracy: 0.3375\n",
            "Epoch 382/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3490 - accuracy: 0.3349 - val_loss: 1.3477 - val_accuracy: 0.3375\n",
            "Epoch 383/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3477 - accuracy: 0.3368 - val_loss: 1.3467 - val_accuracy: 0.3382\n",
            "Epoch 384/4000\n",
            "41/41 [==============================] - 14s 332ms/step - loss: 1.3471 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 385/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3467 - val_accuracy: 0.3381\n",
            "Epoch 386/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3465 - val_accuracy: 0.3382\n",
            "Epoch 387/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3469 - accuracy: 0.3374 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 388/4000\n",
            "41/41 [==============================] - 14s 332ms/step - loss: 1.3471 - accuracy: 0.3373 - val_loss: 1.3468 - val_accuracy: 0.3381\n",
            "Epoch 389/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3474 - accuracy: 0.3368 - val_loss: 1.3488 - val_accuracy: 0.3346\n",
            "Epoch 390/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3484 - accuracy: 0.3360 - val_loss: 1.3470 - val_accuracy: 0.3379\n",
            "Epoch 391/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3473 - accuracy: 0.3370 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 392/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3383\n",
            "Epoch 393/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3471 - accuracy: 0.3373 - val_loss: 1.3473 - val_accuracy: 0.3377\n",
            "Epoch 394/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3474 - accuracy: 0.3370 - val_loss: 1.3467 - val_accuracy: 0.3380\n",
            "Epoch 395/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3470 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3381\n",
            "Epoch 396/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3469 - accuracy: 0.3374 - val_loss: 1.3465 - val_accuracy: 0.3382\n",
            "Epoch 397/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 398/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3469 - accuracy: 0.3374 - val_loss: 1.3465 - val_accuracy: 0.3383\n",
            "Epoch 399/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3469 - accuracy: 0.3374 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 400/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 401/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3471 - accuracy: 0.3372 - val_loss: 1.3474 - val_accuracy: 0.3381\n",
            "Epoch 402/4000\n",
            "41/41 [==============================] - 14s 336ms/step - loss: 1.3474 - accuracy: 0.3370 - val_loss: 1.3469 - val_accuracy: 0.3380\n",
            "Epoch 403/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3472 - accuracy: 0.3372 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 404/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3471 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 405/4000\n",
            "41/41 [==============================] - 14s 333ms/step - loss: 1.3469 - accuracy: 0.3374 - val_loss: 1.3465 - val_accuracy: 0.3382\n",
            "Epoch 406/4000\n",
            "41/41 [==============================] - 14s 337ms/step - loss: 1.3469 - accuracy: 0.3375 - val_loss: 1.3465 - val_accuracy: 0.3383\n",
            "Epoch 407/4000\n",
            "41/41 [==============================] - 14s 337ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3466 - val_accuracy: 0.3383\n",
            "Epoch 408/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3471 - accuracy: 0.3372 - val_loss: 1.3466 - val_accuracy: 0.3381\n",
            "Epoch 409/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3466 - val_accuracy: 0.3381\n",
            "Epoch 410/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3472 - accuracy: 0.3371 - val_loss: 1.3500 - val_accuracy: 0.3329\n",
            "Epoch 411/4000\n",
            "41/41 [==============================] - 14s 337ms/step - loss: 1.3490 - accuracy: 0.3354 - val_loss: 1.3469 - val_accuracy: 0.3380\n",
            "Epoch 412/4000\n",
            "41/41 [==============================] - 14s 336ms/step - loss: 1.3473 - accuracy: 0.3371 - val_loss: 1.3468 - val_accuracy: 0.3379\n",
            "Epoch 413/4000\n",
            "41/41 [==============================] - 14s 334ms/step - loss: 1.3472 - accuracy: 0.3373 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 414/4000\n",
            "41/41 [==============================] - 14s 336ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3465 - val_accuracy: 0.3382\n",
            "Epoch 415/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3469 - accuracy: 0.3374 - val_loss: 1.3465 - val_accuracy: 0.3383\n",
            "Epoch 416/4000\n",
            "41/41 [==============================] - 14s 336ms/step - loss: 1.3469 - accuracy: 0.3374 - val_loss: 1.3465 - val_accuracy: 0.3382\n",
            "Epoch 417/4000\n",
            "41/41 [==============================] - 14s 337ms/step - loss: 1.3471 - accuracy: 0.3372 - val_loss: 1.3474 - val_accuracy: 0.3377\n",
            "Epoch 418/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3475 - accuracy: 0.3368 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 419/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3470 - accuracy: 0.3374 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 420/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3470 - accuracy: 0.3375 - val_loss: 1.3465 - val_accuracy: 0.3382\n",
            "Epoch 421/4000\n",
            "41/41 [==============================] - 14s 335ms/step - loss: 1.3469 - accuracy: 0.3375 - val_loss: 1.3466 - val_accuracy: 0.3382\n",
            "Epoch 422/4000\n",
            "41/41 [==============================] - 14s 337ms/step - loss: 1.3470 - accuracy: 0.3375 - val_loss: 1.3466 - val_accuracy: 0.3382\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1NviSfffwTI"
      },
      "source": [
        "recurrent_ae.save(MODEL_DIR+SUFFIX+'_ae'+DATE+\".h5\")\r\n",
        "save_hist(ae_hist, '_reconstruction_history.csv')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjpwA4BRhMuJ",
        "outputId": "1a4114c1-53dc-4b12-b3db-e0b66bd72c7e"
      },
      "source": [
        "xtrain_vec = encoder.predict(xtrain_seq)\r\n",
        "xval_vec = encoder.predict(xval_seq)\r\n",
        "xtest_vec = encoder.predict(xtest_seq)\r\n",
        "print('The shape of xtrain/xval/xtest_seq is', xtrain_vec.shape, xval_vec.shape, xtest_vec.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of xtrain/xval/xtest_seq is (10473, 100) (2245, 100) (2245, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uf3ED6f9hQpW"
      },
      "source": [
        "model = keras.models.Sequential([\r\n",
        "  keras.layers.Dense(128, activation=\"relu\", input_shape=[latent_size]),\r\n",
        "  keras.layers.Dropout(0.2),\r\n",
        "  keras.layers.Dense(64, activation=\"relu\"),    \r\n",
        "  keras.layers.Dropout(0.2),\r\n",
        "  keras.layers.Dense(32, activation=\"relu\"),  \r\n",
        "  keras.layers.Dropout(0.2), \r\n",
        "  keras.layers.Dense(16, activation=\"relu\"), \r\n",
        "  keras.layers.Dropout(0.2),   \r\n",
        "  keras.layers.Dense(1, activation=\"sigmoid\")                               \r\n",
        "])\r\n",
        "model.compile(keras.optimizers.SGD(learning_rate=0.001, momentum=0.9), loss=keras.losses.BinaryCrossentropy(), metrics=['accuracy'])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iySJD_bsHw4i"
      },
      "source": [
        "ytrain = np.array(ytrain)\r\n",
        "yval = np.array(yval)\r\n",
        "ytest = np.array(ytest)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzwDfPnwhSx2",
        "outputId": "2b588cae-b5f0-4046-c8b1-13e1f9c075e1"
      },
      "source": [
        "model_hist = model.fit(xtrain_vec, ytrain, validation_data=(xval_vec, yval), epochs=1500, callbacks=[es_cb])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1500\n",
            "328/328 [==============================] - 2s 4ms/step - loss: 0.6907 - accuracy: 0.5240 - val_loss: 0.6691 - val_accuracy: 0.6971\n",
            "Epoch 2/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.6684 - accuracy: 0.6540 - val_loss: 0.6353 - val_accuracy: 0.7523\n",
            "Epoch 3/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.6358 - accuracy: 0.7159 - val_loss: 0.5925 - val_accuracy: 0.7693\n",
            "Epoch 4/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.6026 - accuracy: 0.7307 - val_loss: 0.5537 - val_accuracy: 0.7724\n",
            "Epoch 5/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5695 - accuracy: 0.7476 - val_loss: 0.5305 - val_accuracy: 0.7751\n",
            "Epoch 6/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5619 - accuracy: 0.7467 - val_loss: 0.5184 - val_accuracy: 0.7688\n",
            "Epoch 7/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5419 - accuracy: 0.7563 - val_loss: 0.5089 - val_accuracy: 0.7719\n",
            "Epoch 8/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5389 - accuracy: 0.7550 - val_loss: 0.5052 - val_accuracy: 0.7702\n",
            "Epoch 9/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5397 - accuracy: 0.7464 - val_loss: 0.5020 - val_accuracy: 0.7670\n",
            "Epoch 10/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5247 - accuracy: 0.7584 - val_loss: 0.4982 - val_accuracy: 0.7724\n",
            "Epoch 11/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5246 - accuracy: 0.7573 - val_loss: 0.4985 - val_accuracy: 0.7661\n",
            "Epoch 12/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5317 - accuracy: 0.7550 - val_loss: 0.4963 - val_accuracy: 0.7693\n",
            "Epoch 13/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5243 - accuracy: 0.7608 - val_loss: 0.4954 - val_accuracy: 0.7679\n",
            "Epoch 14/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5271 - accuracy: 0.7581 - val_loss: 0.4944 - val_accuracy: 0.7688\n",
            "Epoch 15/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5291 - accuracy: 0.7550 - val_loss: 0.4938 - val_accuracy: 0.7679\n",
            "Epoch 16/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5297 - accuracy: 0.7578 - val_loss: 0.4934 - val_accuracy: 0.7697\n",
            "Epoch 17/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5176 - accuracy: 0.7662 - val_loss: 0.4941 - val_accuracy: 0.7648\n",
            "Epoch 18/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5122 - accuracy: 0.7679 - val_loss: 0.4946 - val_accuracy: 0.7644\n",
            "Epoch 19/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5171 - accuracy: 0.7644 - val_loss: 0.4949 - val_accuracy: 0.7635\n",
            "Epoch 20/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5207 - accuracy: 0.7603 - val_loss: 0.4924 - val_accuracy: 0.7670\n",
            "Epoch 21/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5195 - accuracy: 0.7603 - val_loss: 0.4924 - val_accuracy: 0.7688\n",
            "Epoch 22/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5106 - accuracy: 0.7710 - val_loss: 0.4926 - val_accuracy: 0.7653\n",
            "Epoch 23/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5158 - accuracy: 0.7649 - val_loss: 0.4912 - val_accuracy: 0.7697\n",
            "Epoch 24/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5088 - accuracy: 0.7718 - val_loss: 0.4914 - val_accuracy: 0.7644\n",
            "Epoch 25/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5124 - accuracy: 0.7652 - val_loss: 0.4907 - val_accuracy: 0.7702\n",
            "Epoch 26/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5136 - accuracy: 0.7669 - val_loss: 0.4901 - val_accuracy: 0.7670\n",
            "Epoch 27/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5175 - accuracy: 0.7589 - val_loss: 0.4906 - val_accuracy: 0.7670\n",
            "Epoch 28/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5128 - accuracy: 0.7636 - val_loss: 0.4902 - val_accuracy: 0.7670\n",
            "Epoch 29/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5176 - accuracy: 0.7589 - val_loss: 0.4916 - val_accuracy: 0.7648\n",
            "Epoch 30/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5094 - accuracy: 0.7649 - val_loss: 0.4905 - val_accuracy: 0.7675\n",
            "Epoch 31/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5139 - accuracy: 0.7627 - val_loss: 0.4896 - val_accuracy: 0.7653\n",
            "Epoch 32/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5036 - accuracy: 0.7669 - val_loss: 0.4901 - val_accuracy: 0.7661\n",
            "Epoch 33/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5093 - accuracy: 0.7653 - val_loss: 0.4917 - val_accuracy: 0.7639\n",
            "Epoch 34/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5040 - accuracy: 0.7743 - val_loss: 0.4895 - val_accuracy: 0.7653\n",
            "Epoch 35/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5141 - accuracy: 0.7564 - val_loss: 0.4890 - val_accuracy: 0.7697\n",
            "Epoch 36/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5003 - accuracy: 0.7708 - val_loss: 0.4892 - val_accuracy: 0.7693\n",
            "Epoch 37/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5057 - accuracy: 0.7739 - val_loss: 0.4893 - val_accuracy: 0.7661\n",
            "Epoch 38/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5049 - accuracy: 0.7671 - val_loss: 0.4908 - val_accuracy: 0.7635\n",
            "Epoch 39/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5116 - accuracy: 0.7670 - val_loss: 0.4885 - val_accuracy: 0.7648\n",
            "Epoch 40/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5005 - accuracy: 0.7723 - val_loss: 0.4888 - val_accuracy: 0.7644\n",
            "Epoch 41/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5124 - accuracy: 0.7658 - val_loss: 0.4883 - val_accuracy: 0.7679\n",
            "Epoch 42/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4978 - accuracy: 0.7715 - val_loss: 0.4879 - val_accuracy: 0.7670\n",
            "Epoch 43/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5055 - accuracy: 0.7710 - val_loss: 0.4877 - val_accuracy: 0.7697\n",
            "Epoch 44/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5094 - accuracy: 0.7621 - val_loss: 0.4875 - val_accuracy: 0.7702\n",
            "Epoch 45/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5089 - accuracy: 0.7652 - val_loss: 0.4881 - val_accuracy: 0.7653\n",
            "Epoch 46/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5031 - accuracy: 0.7642 - val_loss: 0.4880 - val_accuracy: 0.7661\n",
            "Epoch 47/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5116 - accuracy: 0.7630 - val_loss: 0.4872 - val_accuracy: 0.7693\n",
            "Epoch 48/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5029 - accuracy: 0.7683 - val_loss: 0.4871 - val_accuracy: 0.7688\n",
            "Epoch 49/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5061 - accuracy: 0.7664 - val_loss: 0.4871 - val_accuracy: 0.7661\n",
            "Epoch 50/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5015 - accuracy: 0.7709 - val_loss: 0.4869 - val_accuracy: 0.7693\n",
            "Epoch 51/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5002 - accuracy: 0.7703 - val_loss: 0.4877 - val_accuracy: 0.7648\n",
            "Epoch 52/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4978 - accuracy: 0.7722 - val_loss: 0.4871 - val_accuracy: 0.7697\n",
            "Epoch 53/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5059 - accuracy: 0.7694 - val_loss: 0.4873 - val_accuracy: 0.7666\n",
            "Epoch 54/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5099 - accuracy: 0.7635 - val_loss: 0.4870 - val_accuracy: 0.7679\n",
            "Epoch 55/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5000 - accuracy: 0.7712 - val_loss: 0.4871 - val_accuracy: 0.7684\n",
            "Epoch 56/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4990 - accuracy: 0.7710 - val_loss: 0.4866 - val_accuracy: 0.7679\n",
            "Epoch 57/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5066 - accuracy: 0.7642 - val_loss: 0.4864 - val_accuracy: 0.7670\n",
            "Epoch 58/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5014 - accuracy: 0.7681 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
            "Epoch 59/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4945 - accuracy: 0.7670 - val_loss: 0.4862 - val_accuracy: 0.7688\n",
            "Epoch 60/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4998 - accuracy: 0.7734 - val_loss: 0.4859 - val_accuracy: 0.7702\n",
            "Epoch 61/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5080 - accuracy: 0.7692 - val_loss: 0.4856 - val_accuracy: 0.7684\n",
            "Epoch 62/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5061 - accuracy: 0.7701 - val_loss: 0.4855 - val_accuracy: 0.7688\n",
            "Epoch 63/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5032 - accuracy: 0.7678 - val_loss: 0.4856 - val_accuracy: 0.7697\n",
            "Epoch 64/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5048 - accuracy: 0.7683 - val_loss: 0.4851 - val_accuracy: 0.7693\n",
            "Epoch 65/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5010 - accuracy: 0.7663 - val_loss: 0.4849 - val_accuracy: 0.7684\n",
            "Epoch 66/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5029 - accuracy: 0.7669 - val_loss: 0.4861 - val_accuracy: 0.7661\n",
            "Epoch 67/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5050 - accuracy: 0.7659 - val_loss: 0.4866 - val_accuracy: 0.7644\n",
            "Epoch 68/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5016 - accuracy: 0.7696 - val_loss: 0.4852 - val_accuracy: 0.7675\n",
            "Epoch 69/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5042 - accuracy: 0.7658 - val_loss: 0.4850 - val_accuracy: 0.7670\n",
            "Epoch 70/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5064 - accuracy: 0.7671 - val_loss: 0.4869 - val_accuracy: 0.7621\n",
            "Epoch 71/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4996 - accuracy: 0.7702 - val_loss: 0.4853 - val_accuracy: 0.7706\n",
            "Epoch 72/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5055 - accuracy: 0.7699 - val_loss: 0.4853 - val_accuracy: 0.7702\n",
            "Epoch 73/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5092 - accuracy: 0.7643 - val_loss: 0.4859 - val_accuracy: 0.7648\n",
            "Epoch 74/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5114 - accuracy: 0.7652 - val_loss: 0.4848 - val_accuracy: 0.7697\n",
            "Epoch 75/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4927 - accuracy: 0.7730 - val_loss: 0.4849 - val_accuracy: 0.7702\n",
            "Epoch 76/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5072 - accuracy: 0.7617 - val_loss: 0.4866 - val_accuracy: 0.7702\n",
            "Epoch 77/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5040 - accuracy: 0.7633 - val_loss: 0.4855 - val_accuracy: 0.7675\n",
            "Epoch 78/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4995 - accuracy: 0.7686 - val_loss: 0.4846 - val_accuracy: 0.7702\n",
            "Epoch 79/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4986 - accuracy: 0.7740 - val_loss: 0.4842 - val_accuracy: 0.7670\n",
            "Epoch 80/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4978 - accuracy: 0.7728 - val_loss: 0.4849 - val_accuracy: 0.7684\n",
            "Epoch 81/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5010 - accuracy: 0.7724 - val_loss: 0.4853 - val_accuracy: 0.7657\n",
            "Epoch 82/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5168 - accuracy: 0.7575 - val_loss: 0.4840 - val_accuracy: 0.7679\n",
            "Epoch 83/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4993 - accuracy: 0.7717 - val_loss: 0.4839 - val_accuracy: 0.7688\n",
            "Epoch 84/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5047 - accuracy: 0.7679 - val_loss: 0.4841 - val_accuracy: 0.7684\n",
            "Epoch 85/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5004 - accuracy: 0.7702 - val_loss: 0.4847 - val_accuracy: 0.7684\n",
            "Epoch 86/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4972 - accuracy: 0.7709 - val_loss: 0.4851 - val_accuracy: 0.7693\n",
            "Epoch 87/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5015 - accuracy: 0.7712 - val_loss: 0.4845 - val_accuracy: 0.7693\n",
            "Epoch 88/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5017 - accuracy: 0.7674 - val_loss: 0.4840 - val_accuracy: 0.7679\n",
            "Epoch 89/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4911 - accuracy: 0.7748 - val_loss: 0.4842 - val_accuracy: 0.7702\n",
            "Epoch 90/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5002 - accuracy: 0.7661 - val_loss: 0.4832 - val_accuracy: 0.7684\n",
            "Epoch 91/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4943 - accuracy: 0.7775 - val_loss: 0.4843 - val_accuracy: 0.7688\n",
            "Epoch 92/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5105 - accuracy: 0.7630 - val_loss: 0.4837 - val_accuracy: 0.7702\n",
            "Epoch 93/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5008 - accuracy: 0.7665 - val_loss: 0.4830 - val_accuracy: 0.7693\n",
            "Epoch 94/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5064 - accuracy: 0.7616 - val_loss: 0.4833 - val_accuracy: 0.7693\n",
            "Epoch 95/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5040 - accuracy: 0.7692 - val_loss: 0.4835 - val_accuracy: 0.7666\n",
            "Epoch 96/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4977 - accuracy: 0.7702 - val_loss: 0.4843 - val_accuracy: 0.7697\n",
            "Epoch 97/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4984 - accuracy: 0.7687 - val_loss: 0.4837 - val_accuracy: 0.7684\n",
            "Epoch 98/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5044 - accuracy: 0.7657 - val_loss: 0.4841 - val_accuracy: 0.7697\n",
            "Epoch 99/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5039 - accuracy: 0.7701 - val_loss: 0.4834 - val_accuracy: 0.7661\n",
            "Epoch 100/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5007 - accuracy: 0.7669 - val_loss: 0.4830 - val_accuracy: 0.7684\n",
            "Epoch 101/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5108 - accuracy: 0.7608 - val_loss: 0.4831 - val_accuracy: 0.7697\n",
            "Epoch 102/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5034 - accuracy: 0.7655 - val_loss: 0.4839 - val_accuracy: 0.7684\n",
            "Epoch 103/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5004 - accuracy: 0.7681 - val_loss: 0.4846 - val_accuracy: 0.7675\n",
            "Epoch 104/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5008 - accuracy: 0.7693 - val_loss: 0.4830 - val_accuracy: 0.7688\n",
            "Epoch 105/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4984 - accuracy: 0.7702 - val_loss: 0.4830 - val_accuracy: 0.7679\n",
            "Epoch 106/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5012 - accuracy: 0.7672 - val_loss: 0.4828 - val_accuracy: 0.7670\n",
            "Epoch 107/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4937 - accuracy: 0.7702 - val_loss: 0.4830 - val_accuracy: 0.7702\n",
            "Epoch 108/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4958 - accuracy: 0.7693 - val_loss: 0.4828 - val_accuracy: 0.7693\n",
            "Epoch 109/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5015 - accuracy: 0.7694 - val_loss: 0.4830 - val_accuracy: 0.7693\n",
            "Epoch 110/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4953 - accuracy: 0.7660 - val_loss: 0.4824 - val_accuracy: 0.7679\n",
            "Epoch 111/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4997 - accuracy: 0.7678 - val_loss: 0.4823 - val_accuracy: 0.7710\n",
            "Epoch 112/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4977 - accuracy: 0.7684 - val_loss: 0.4825 - val_accuracy: 0.7679\n",
            "Epoch 113/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4950 - accuracy: 0.7728 - val_loss: 0.4833 - val_accuracy: 0.7706\n",
            "Epoch 114/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5041 - accuracy: 0.7610 - val_loss: 0.4827 - val_accuracy: 0.7679\n",
            "Epoch 115/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4962 - accuracy: 0.7733 - val_loss: 0.4832 - val_accuracy: 0.7693\n",
            "Epoch 116/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5018 - accuracy: 0.7677 - val_loss: 0.4825 - val_accuracy: 0.7688\n",
            "Epoch 117/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4966 - accuracy: 0.7689 - val_loss: 0.4834 - val_accuracy: 0.7679\n",
            "Epoch 118/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5021 - accuracy: 0.7737 - val_loss: 0.4833 - val_accuracy: 0.7688\n",
            "Epoch 119/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5001 - accuracy: 0.7673 - val_loss: 0.4832 - val_accuracy: 0.7697\n",
            "Epoch 120/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4952 - accuracy: 0.7719 - val_loss: 0.4831 - val_accuracy: 0.7710\n",
            "Epoch 121/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4944 - accuracy: 0.7701 - val_loss: 0.4819 - val_accuracy: 0.7702\n",
            "Epoch 122/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4982 - accuracy: 0.7673 - val_loss: 0.4823 - val_accuracy: 0.7706\n",
            "Epoch 123/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5052 - accuracy: 0.7626 - val_loss: 0.4823 - val_accuracy: 0.7702\n",
            "Epoch 124/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4914 - accuracy: 0.7700 - val_loss: 0.4837 - val_accuracy: 0.7639\n",
            "Epoch 125/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4874 - accuracy: 0.7752 - val_loss: 0.4823 - val_accuracy: 0.7666\n",
            "Epoch 126/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5035 - accuracy: 0.7697 - val_loss: 0.4832 - val_accuracy: 0.7653\n",
            "Epoch 127/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5092 - accuracy: 0.7643 - val_loss: 0.4823 - val_accuracy: 0.7675\n",
            "Epoch 128/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5105 - accuracy: 0.7664 - val_loss: 0.4824 - val_accuracy: 0.7697\n",
            "Epoch 129/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4998 - accuracy: 0.7675 - val_loss: 0.4823 - val_accuracy: 0.7693\n",
            "Epoch 130/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4979 - accuracy: 0.7676 - val_loss: 0.4819 - val_accuracy: 0.7697\n",
            "Epoch 131/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5074 - accuracy: 0.7623 - val_loss: 0.4825 - val_accuracy: 0.7679\n",
            "Epoch 132/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4965 - accuracy: 0.7685 - val_loss: 0.4823 - val_accuracy: 0.7702\n",
            "Epoch 133/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4962 - accuracy: 0.7678 - val_loss: 0.4821 - val_accuracy: 0.7684\n",
            "Epoch 134/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4971 - accuracy: 0.7701 - val_loss: 0.4819 - val_accuracy: 0.7697\n",
            "Epoch 135/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4999 - accuracy: 0.7689 - val_loss: 0.4822 - val_accuracy: 0.7706\n",
            "Epoch 136/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5051 - accuracy: 0.7690 - val_loss: 0.4815 - val_accuracy: 0.7706\n",
            "Epoch 137/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4947 - accuracy: 0.7768 - val_loss: 0.4821 - val_accuracy: 0.7679\n",
            "Epoch 138/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5029 - accuracy: 0.7655 - val_loss: 0.4817 - val_accuracy: 0.7697\n",
            "Epoch 139/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5012 - accuracy: 0.7671 - val_loss: 0.4821 - val_accuracy: 0.7710\n",
            "Epoch 140/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4981 - accuracy: 0.7672 - val_loss: 0.4825 - val_accuracy: 0.7702\n",
            "Epoch 141/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5049 - accuracy: 0.7665 - val_loss: 0.4824 - val_accuracy: 0.7679\n",
            "Epoch 142/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5000 - accuracy: 0.7666 - val_loss: 0.4825 - val_accuracy: 0.7693\n",
            "Epoch 143/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5012 - accuracy: 0.7707 - val_loss: 0.4821 - val_accuracy: 0.7697\n",
            "Epoch 144/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5045 - accuracy: 0.7674 - val_loss: 0.4833 - val_accuracy: 0.7715\n",
            "Epoch 145/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4942 - accuracy: 0.7706 - val_loss: 0.4817 - val_accuracy: 0.7719\n",
            "Epoch 146/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5104 - accuracy: 0.7617 - val_loss: 0.4834 - val_accuracy: 0.7666\n",
            "Epoch 147/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4972 - accuracy: 0.7670 - val_loss: 0.4814 - val_accuracy: 0.7697\n",
            "Epoch 148/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4905 - accuracy: 0.7731 - val_loss: 0.4819 - val_accuracy: 0.7702\n",
            "Epoch 149/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4992 - accuracy: 0.7684 - val_loss: 0.4821 - val_accuracy: 0.7715\n",
            "Epoch 150/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5081 - accuracy: 0.7650 - val_loss: 0.4820 - val_accuracy: 0.7733\n",
            "Epoch 151/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4965 - accuracy: 0.7675 - val_loss: 0.4848 - val_accuracy: 0.7644\n",
            "Epoch 152/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5035 - accuracy: 0.7651 - val_loss: 0.4819 - val_accuracy: 0.7697\n",
            "Epoch 153/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4921 - accuracy: 0.7753 - val_loss: 0.4822 - val_accuracy: 0.7710\n",
            "Epoch 154/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5050 - accuracy: 0.7691 - val_loss: 0.4822 - val_accuracy: 0.7684\n",
            "Epoch 155/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4853 - accuracy: 0.7746 - val_loss: 0.4831 - val_accuracy: 0.7697\n",
            "Epoch 156/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4977 - accuracy: 0.7696 - val_loss: 0.4824 - val_accuracy: 0.7693\n",
            "Epoch 157/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5045 - accuracy: 0.7682 - val_loss: 0.4837 - val_accuracy: 0.7648\n",
            "Epoch 158/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4912 - accuracy: 0.7741 - val_loss: 0.4820 - val_accuracy: 0.7702\n",
            "Epoch 159/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4987 - accuracy: 0.7698 - val_loss: 0.4817 - val_accuracy: 0.7697\n",
            "Epoch 160/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4915 - accuracy: 0.7778 - val_loss: 0.4822 - val_accuracy: 0.7688\n",
            "Epoch 161/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4988 - accuracy: 0.7685 - val_loss: 0.4816 - val_accuracy: 0.7719\n",
            "Epoch 162/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4947 - accuracy: 0.7785 - val_loss: 0.4820 - val_accuracy: 0.7684\n",
            "Epoch 163/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4971 - accuracy: 0.7676 - val_loss: 0.4816 - val_accuracy: 0.7697\n",
            "Epoch 164/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5060 - accuracy: 0.7647 - val_loss: 0.4820 - val_accuracy: 0.7702\n",
            "Epoch 165/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4941 - accuracy: 0.7723 - val_loss: 0.4822 - val_accuracy: 0.7688\n",
            "Epoch 166/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4996 - accuracy: 0.7701 - val_loss: 0.4824 - val_accuracy: 0.7693\n",
            "Epoch 167/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4927 - accuracy: 0.7729 - val_loss: 0.4826 - val_accuracy: 0.7684\n",
            "Epoch 168/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4922 - accuracy: 0.7728 - val_loss: 0.4816 - val_accuracy: 0.7706\n",
            "Epoch 169/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5040 - accuracy: 0.7655 - val_loss: 0.4816 - val_accuracy: 0.7693\n",
            "Epoch 170/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5011 - accuracy: 0.7679 - val_loss: 0.4839 - val_accuracy: 0.7661\n",
            "Epoch 171/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4878 - accuracy: 0.7749 - val_loss: 0.4814 - val_accuracy: 0.7697\n",
            "Epoch 172/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4975 - accuracy: 0.7705 - val_loss: 0.4816 - val_accuracy: 0.7688\n",
            "Epoch 173/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4950 - accuracy: 0.7682 - val_loss: 0.4811 - val_accuracy: 0.7693\n",
            "Epoch 174/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4904 - accuracy: 0.7730 - val_loss: 0.4816 - val_accuracy: 0.7679\n",
            "Epoch 175/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4986 - accuracy: 0.7706 - val_loss: 0.4817 - val_accuracy: 0.7670\n",
            "Epoch 176/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4959 - accuracy: 0.7695 - val_loss: 0.4823 - val_accuracy: 0.7675\n",
            "Epoch 177/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4943 - accuracy: 0.7743 - val_loss: 0.4820 - val_accuracy: 0.7693\n",
            "Epoch 178/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5003 - accuracy: 0.7686 - val_loss: 0.4815 - val_accuracy: 0.7706\n",
            "Epoch 179/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5000 - accuracy: 0.7683 - val_loss: 0.4814 - val_accuracy: 0.7697\n",
            "Epoch 180/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5022 - accuracy: 0.7666 - val_loss: 0.4816 - val_accuracy: 0.7679\n",
            "Epoch 181/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4985 - accuracy: 0.7654 - val_loss: 0.4817 - val_accuracy: 0.7688\n",
            "Epoch 182/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4961 - accuracy: 0.7712 - val_loss: 0.4821 - val_accuracy: 0.7675\n",
            "Epoch 183/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4983 - accuracy: 0.7675 - val_loss: 0.4821 - val_accuracy: 0.7688\n",
            "Epoch 184/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4967 - accuracy: 0.7668 - val_loss: 0.4822 - val_accuracy: 0.7688\n",
            "Epoch 185/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4947 - accuracy: 0.7753 - val_loss: 0.4825 - val_accuracy: 0.7710\n",
            "Epoch 186/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4988 - accuracy: 0.7676 - val_loss: 0.4818 - val_accuracy: 0.7693\n",
            "Epoch 187/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4908 - accuracy: 0.7750 - val_loss: 0.4813 - val_accuracy: 0.7675\n",
            "Epoch 188/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4900 - accuracy: 0.7750 - val_loss: 0.4816 - val_accuracy: 0.7679\n",
            "Epoch 189/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5014 - accuracy: 0.7639 - val_loss: 0.4806 - val_accuracy: 0.7684\n",
            "Epoch 190/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4901 - accuracy: 0.7771 - val_loss: 0.4832 - val_accuracy: 0.7661\n",
            "Epoch 191/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4956 - accuracy: 0.7733 - val_loss: 0.4815 - val_accuracy: 0.7675\n",
            "Epoch 192/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4956 - accuracy: 0.7750 - val_loss: 0.4822 - val_accuracy: 0.7706\n",
            "Epoch 193/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4992 - accuracy: 0.7694 - val_loss: 0.4813 - val_accuracy: 0.7684\n",
            "Epoch 194/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4983 - accuracy: 0.7718 - val_loss: 0.4820 - val_accuracy: 0.7688\n",
            "Epoch 195/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4997 - accuracy: 0.7710 - val_loss: 0.4826 - val_accuracy: 0.7688\n",
            "Epoch 196/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4905 - accuracy: 0.7751 - val_loss: 0.4817 - val_accuracy: 0.7706\n",
            "Epoch 197/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4939 - accuracy: 0.7692 - val_loss: 0.4818 - val_accuracy: 0.7684\n",
            "Epoch 198/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4920 - accuracy: 0.7708 - val_loss: 0.4816 - val_accuracy: 0.7670\n",
            "Epoch 199/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4938 - accuracy: 0.7711 - val_loss: 0.4816 - val_accuracy: 0.7666\n",
            "Epoch 200/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4873 - accuracy: 0.7757 - val_loss: 0.4813 - val_accuracy: 0.7710\n",
            "Epoch 201/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4956 - accuracy: 0.7739 - val_loss: 0.4809 - val_accuracy: 0.7697\n",
            "Epoch 202/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4989 - accuracy: 0.7678 - val_loss: 0.4814 - val_accuracy: 0.7675\n",
            "Epoch 203/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4990 - accuracy: 0.7662 - val_loss: 0.4814 - val_accuracy: 0.7724\n",
            "Epoch 204/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5048 - accuracy: 0.7645 - val_loss: 0.4836 - val_accuracy: 0.7724\n",
            "Epoch 205/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5018 - accuracy: 0.7679 - val_loss: 0.4815 - val_accuracy: 0.7715\n",
            "Epoch 206/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5032 - accuracy: 0.7713 - val_loss: 0.4814 - val_accuracy: 0.7710\n",
            "Epoch 207/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5014 - accuracy: 0.7667 - val_loss: 0.4818 - val_accuracy: 0.7715\n",
            "Epoch 208/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4954 - accuracy: 0.7738 - val_loss: 0.4808 - val_accuracy: 0.7724\n",
            "Epoch 209/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4980 - accuracy: 0.7690 - val_loss: 0.4819 - val_accuracy: 0.7706\n",
            "Epoch 210/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4999 - accuracy: 0.7653 - val_loss: 0.4812 - val_accuracy: 0.7706\n",
            "Epoch 211/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4953 - accuracy: 0.7731 - val_loss: 0.4817 - val_accuracy: 0.7702\n",
            "Epoch 212/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4981 - accuracy: 0.7671 - val_loss: 0.4812 - val_accuracy: 0.7670\n",
            "Epoch 213/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4985 - accuracy: 0.7717 - val_loss: 0.4821 - val_accuracy: 0.7657\n",
            "Epoch 214/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4927 - accuracy: 0.7744 - val_loss: 0.4817 - val_accuracy: 0.7670\n",
            "Epoch 215/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4950 - accuracy: 0.7719 - val_loss: 0.4811 - val_accuracy: 0.7693\n",
            "Epoch 216/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4975 - accuracy: 0.7706 - val_loss: 0.4821 - val_accuracy: 0.7675\n",
            "Epoch 217/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4989 - accuracy: 0.7691 - val_loss: 0.4816 - val_accuracy: 0.7697\n",
            "Epoch 218/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4932 - accuracy: 0.7710 - val_loss: 0.4812 - val_accuracy: 0.7688\n",
            "Epoch 219/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4965 - accuracy: 0.7699 - val_loss: 0.4812 - val_accuracy: 0.7710\n",
            "Epoch 220/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4960 - accuracy: 0.7720 - val_loss: 0.4814 - val_accuracy: 0.7688\n",
            "Epoch 221/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4996 - accuracy: 0.7711 - val_loss: 0.4826 - val_accuracy: 0.7697\n",
            "Epoch 222/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5059 - accuracy: 0.7644 - val_loss: 0.4816 - val_accuracy: 0.7679\n",
            "Epoch 223/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4857 - accuracy: 0.7773 - val_loss: 0.4824 - val_accuracy: 0.7719\n",
            "Epoch 224/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4990 - accuracy: 0.7667 - val_loss: 0.4822 - val_accuracy: 0.7733\n",
            "Epoch 225/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4954 - accuracy: 0.7655 - val_loss: 0.4822 - val_accuracy: 0.7679\n",
            "Epoch 226/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4955 - accuracy: 0.7735 - val_loss: 0.4813 - val_accuracy: 0.7706\n",
            "Epoch 227/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4968 - accuracy: 0.7699 - val_loss: 0.4817 - val_accuracy: 0.7684\n",
            "Epoch 228/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4921 - accuracy: 0.7752 - val_loss: 0.4825 - val_accuracy: 0.7706\n",
            "Epoch 229/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4968 - accuracy: 0.7716 - val_loss: 0.4811 - val_accuracy: 0.7688\n",
            "Epoch 230/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4896 - accuracy: 0.7699 - val_loss: 0.4808 - val_accuracy: 0.7706\n",
            "Epoch 231/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4878 - accuracy: 0.7751 - val_loss: 0.4824 - val_accuracy: 0.7679\n",
            "Epoch 232/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4885 - accuracy: 0.7788 - val_loss: 0.4814 - val_accuracy: 0.7688\n",
            "Epoch 233/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4904 - accuracy: 0.7767 - val_loss: 0.4812 - val_accuracy: 0.7697\n",
            "Epoch 234/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4898 - accuracy: 0.7754 - val_loss: 0.4802 - val_accuracy: 0.7733\n",
            "Epoch 235/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4900 - accuracy: 0.7751 - val_loss: 0.4826 - val_accuracy: 0.7661\n",
            "Epoch 236/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4949 - accuracy: 0.7696 - val_loss: 0.4809 - val_accuracy: 0.7693\n",
            "Epoch 237/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5002 - accuracy: 0.7690 - val_loss: 0.4806 - val_accuracy: 0.7688\n",
            "Epoch 238/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4973 - accuracy: 0.7662 - val_loss: 0.4808 - val_accuracy: 0.7697\n",
            "Epoch 239/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4929 - accuracy: 0.7701 - val_loss: 0.4818 - val_accuracy: 0.7693\n",
            "Epoch 240/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5027 - accuracy: 0.7611 - val_loss: 0.4821 - val_accuracy: 0.7742\n",
            "Epoch 241/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5000 - accuracy: 0.7704 - val_loss: 0.4807 - val_accuracy: 0.7706\n",
            "Epoch 242/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4895 - accuracy: 0.7761 - val_loss: 0.4812 - val_accuracy: 0.7684\n",
            "Epoch 243/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4954 - accuracy: 0.7730 - val_loss: 0.4810 - val_accuracy: 0.7702\n",
            "Epoch 244/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4921 - accuracy: 0.7687 - val_loss: 0.4815 - val_accuracy: 0.7702\n",
            "Epoch 245/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4912 - accuracy: 0.7739 - val_loss: 0.4814 - val_accuracy: 0.7724\n",
            "Epoch 246/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4970 - accuracy: 0.7680 - val_loss: 0.4820 - val_accuracy: 0.7710\n",
            "Epoch 247/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4973 - accuracy: 0.7692 - val_loss: 0.4816 - val_accuracy: 0.7702\n",
            "Epoch 248/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4996 - accuracy: 0.7655 - val_loss: 0.4809 - val_accuracy: 0.7710\n",
            "Epoch 249/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5019 - accuracy: 0.7673 - val_loss: 0.4820 - val_accuracy: 0.7679\n",
            "Epoch 250/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4909 - accuracy: 0.7714 - val_loss: 0.4808 - val_accuracy: 0.7702\n",
            "Epoch 251/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4954 - accuracy: 0.7697 - val_loss: 0.4836 - val_accuracy: 0.7715\n",
            "Epoch 252/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4979 - accuracy: 0.7735 - val_loss: 0.4813 - val_accuracy: 0.7693\n",
            "Epoch 253/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4923 - accuracy: 0.7735 - val_loss: 0.4808 - val_accuracy: 0.7688\n",
            "Epoch 254/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5038 - accuracy: 0.7631 - val_loss: 0.4805 - val_accuracy: 0.7715\n",
            "Epoch 255/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4899 - accuracy: 0.7793 - val_loss: 0.4805 - val_accuracy: 0.7706\n",
            "Epoch 256/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4941 - accuracy: 0.7727 - val_loss: 0.4811 - val_accuracy: 0.7675\n",
            "Epoch 257/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4982 - accuracy: 0.7659 - val_loss: 0.4804 - val_accuracy: 0.7719\n",
            "Epoch 258/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4933 - accuracy: 0.7695 - val_loss: 0.4802 - val_accuracy: 0.7733\n",
            "Epoch 259/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4902 - accuracy: 0.7699 - val_loss: 0.4801 - val_accuracy: 0.7706\n",
            "Epoch 260/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5033 - accuracy: 0.7670 - val_loss: 0.4804 - val_accuracy: 0.7715\n",
            "Epoch 261/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4909 - accuracy: 0.7676 - val_loss: 0.4807 - val_accuracy: 0.7684\n",
            "Epoch 262/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4821 - accuracy: 0.7826 - val_loss: 0.4818 - val_accuracy: 0.7697\n",
            "Epoch 263/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4859 - accuracy: 0.7798 - val_loss: 0.4806 - val_accuracy: 0.7697\n",
            "Epoch 264/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4890 - accuracy: 0.7765 - val_loss: 0.4827 - val_accuracy: 0.7653\n",
            "Epoch 265/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4933 - accuracy: 0.7752 - val_loss: 0.4804 - val_accuracy: 0.7728\n",
            "Epoch 266/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4983 - accuracy: 0.7728 - val_loss: 0.4810 - val_accuracy: 0.7733\n",
            "Epoch 267/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4878 - accuracy: 0.7684 - val_loss: 0.4811 - val_accuracy: 0.7693\n",
            "Epoch 268/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4954 - accuracy: 0.7709 - val_loss: 0.4809 - val_accuracy: 0.7710\n",
            "Epoch 269/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4894 - accuracy: 0.7755 - val_loss: 0.4809 - val_accuracy: 0.7710\n",
            "Epoch 270/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4921 - accuracy: 0.7701 - val_loss: 0.4807 - val_accuracy: 0.7710\n",
            "Epoch 271/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4916 - accuracy: 0.7724 - val_loss: 0.4807 - val_accuracy: 0.7684\n",
            "Epoch 272/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4960 - accuracy: 0.7640 - val_loss: 0.4807 - val_accuracy: 0.7710\n",
            "Epoch 273/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4969 - accuracy: 0.7738 - val_loss: 0.4806 - val_accuracy: 0.7693\n",
            "Epoch 274/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4939 - accuracy: 0.7735 - val_loss: 0.4812 - val_accuracy: 0.7688\n",
            "Epoch 275/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4861 - accuracy: 0.7784 - val_loss: 0.4807 - val_accuracy: 0.7697\n",
            "Epoch 276/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4907 - accuracy: 0.7709 - val_loss: 0.4845 - val_accuracy: 0.7644\n",
            "Epoch 277/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4949 - accuracy: 0.7726 - val_loss: 0.4807 - val_accuracy: 0.7693\n",
            "Epoch 278/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4995 - accuracy: 0.7683 - val_loss: 0.4805 - val_accuracy: 0.7706\n",
            "Epoch 279/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4978 - accuracy: 0.7706 - val_loss: 0.4802 - val_accuracy: 0.7706\n",
            "Epoch 280/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4983 - accuracy: 0.7725 - val_loss: 0.4812 - val_accuracy: 0.7666\n",
            "Epoch 281/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4906 - accuracy: 0.7722 - val_loss: 0.4808 - val_accuracy: 0.7693\n",
            "Epoch 282/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5009 - accuracy: 0.7677 - val_loss: 0.4804 - val_accuracy: 0.7715\n",
            "Epoch 283/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4873 - accuracy: 0.7824 - val_loss: 0.4810 - val_accuracy: 0.7710\n",
            "Epoch 284/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4915 - accuracy: 0.7762 - val_loss: 0.4818 - val_accuracy: 0.7710\n",
            "Epoch 285/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4945 - accuracy: 0.7746 - val_loss: 0.4829 - val_accuracy: 0.7724\n",
            "Epoch 286/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4969 - accuracy: 0.7695 - val_loss: 0.4804 - val_accuracy: 0.7719\n",
            "Epoch 287/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4889 - accuracy: 0.7776 - val_loss: 0.4804 - val_accuracy: 0.7719\n",
            "Epoch 288/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4991 - accuracy: 0.7712 - val_loss: 0.4811 - val_accuracy: 0.7679\n",
            "Epoch 289/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4869 - accuracy: 0.7807 - val_loss: 0.4822 - val_accuracy: 0.7702\n",
            "Epoch 290/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4959 - accuracy: 0.7712 - val_loss: 0.4809 - val_accuracy: 0.7702\n",
            "Epoch 291/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4959 - accuracy: 0.7724 - val_loss: 0.4829 - val_accuracy: 0.7751\n",
            "Epoch 292/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4886 - accuracy: 0.7711 - val_loss: 0.4808 - val_accuracy: 0.7719\n",
            "Epoch 293/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4894 - accuracy: 0.7742 - val_loss: 0.4808 - val_accuracy: 0.7706\n",
            "Epoch 294/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4992 - accuracy: 0.7712 - val_loss: 0.4810 - val_accuracy: 0.7670\n",
            "Epoch 295/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4903 - accuracy: 0.7759 - val_loss: 0.4809 - val_accuracy: 0.7715\n",
            "Epoch 296/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4973 - accuracy: 0.7706 - val_loss: 0.4808 - val_accuracy: 0.7702\n",
            "Epoch 297/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4972 - accuracy: 0.7647 - val_loss: 0.4809 - val_accuracy: 0.7710\n",
            "Epoch 298/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4996 - accuracy: 0.7683 - val_loss: 0.4810 - val_accuracy: 0.7719\n",
            "Epoch 299/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4826 - accuracy: 0.7799 - val_loss: 0.4807 - val_accuracy: 0.7710\n",
            "Epoch 300/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4842 - accuracy: 0.7768 - val_loss: 0.4816 - val_accuracy: 0.7719\n",
            "Epoch 301/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4901 - accuracy: 0.7719 - val_loss: 0.4808 - val_accuracy: 0.7702\n",
            "Epoch 302/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4981 - accuracy: 0.7705 - val_loss: 0.4804 - val_accuracy: 0.7693\n",
            "Epoch 303/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4936 - accuracy: 0.7730 - val_loss: 0.4806 - val_accuracy: 0.7719\n",
            "Epoch 304/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4947 - accuracy: 0.7723 - val_loss: 0.4811 - val_accuracy: 0.7697\n",
            "Epoch 305/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4971 - accuracy: 0.7735 - val_loss: 0.4806 - val_accuracy: 0.7724\n",
            "Epoch 306/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4984 - accuracy: 0.7760 - val_loss: 0.4802 - val_accuracy: 0.7706\n",
            "Epoch 307/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4918 - accuracy: 0.7736 - val_loss: 0.4806 - val_accuracy: 0.7719\n",
            "Epoch 308/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4952 - accuracy: 0.7660 - val_loss: 0.4802 - val_accuracy: 0.7719\n",
            "Epoch 309/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4969 - accuracy: 0.7669 - val_loss: 0.4805 - val_accuracy: 0.7719\n",
            "Epoch 310/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4867 - accuracy: 0.7773 - val_loss: 0.4803 - val_accuracy: 0.7728\n",
            "Epoch 311/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4994 - accuracy: 0.7631 - val_loss: 0.4806 - val_accuracy: 0.7728\n",
            "Epoch 312/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4959 - accuracy: 0.7716 - val_loss: 0.4800 - val_accuracy: 0.7693\n",
            "Epoch 313/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4824 - accuracy: 0.7768 - val_loss: 0.4801 - val_accuracy: 0.7728\n",
            "Epoch 314/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4976 - accuracy: 0.7745 - val_loss: 0.4810 - val_accuracy: 0.7737\n",
            "Epoch 315/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4896 - accuracy: 0.7743 - val_loss: 0.4800 - val_accuracy: 0.7728\n",
            "Epoch 316/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4831 - accuracy: 0.7760 - val_loss: 0.4811 - val_accuracy: 0.7724\n",
            "Epoch 317/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5049 - accuracy: 0.7647 - val_loss: 0.4812 - val_accuracy: 0.7697\n",
            "Epoch 318/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4798 - accuracy: 0.7778 - val_loss: 0.4810 - val_accuracy: 0.7715\n",
            "Epoch 319/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4885 - accuracy: 0.7741 - val_loss: 0.4811 - val_accuracy: 0.7719\n",
            "Epoch 320/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4938 - accuracy: 0.7691 - val_loss: 0.4802 - val_accuracy: 0.7693\n",
            "Epoch 321/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4972 - accuracy: 0.7694 - val_loss: 0.4811 - val_accuracy: 0.7706\n",
            "Epoch 322/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4918 - accuracy: 0.7771 - val_loss: 0.4823 - val_accuracy: 0.7728\n",
            "Epoch 323/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4950 - accuracy: 0.7711 - val_loss: 0.4821 - val_accuracy: 0.7719\n",
            "Epoch 324/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4929 - accuracy: 0.7720 - val_loss: 0.4811 - val_accuracy: 0.7719\n",
            "Epoch 325/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4842 - accuracy: 0.7764 - val_loss: 0.4826 - val_accuracy: 0.7657\n",
            "Epoch 326/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4937 - accuracy: 0.7753 - val_loss: 0.4805 - val_accuracy: 0.7724\n",
            "Epoch 327/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5019 - accuracy: 0.7691 - val_loss: 0.4808 - val_accuracy: 0.7719\n",
            "Epoch 328/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4919 - accuracy: 0.7723 - val_loss: 0.4807 - val_accuracy: 0.7710\n",
            "Epoch 329/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4982 - accuracy: 0.7711 - val_loss: 0.4802 - val_accuracy: 0.7737\n",
            "Epoch 330/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4907 - accuracy: 0.7761 - val_loss: 0.4802 - val_accuracy: 0.7724\n",
            "Epoch 331/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5043 - accuracy: 0.7627 - val_loss: 0.4800 - val_accuracy: 0.7733\n",
            "Epoch 332/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4947 - accuracy: 0.7703 - val_loss: 0.4805 - val_accuracy: 0.7719\n",
            "Epoch 333/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4957 - accuracy: 0.7711 - val_loss: 0.4808 - val_accuracy: 0.7728\n",
            "Epoch 334/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4948 - accuracy: 0.7720 - val_loss: 0.4799 - val_accuracy: 0.7728\n",
            "Epoch 335/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4813 - accuracy: 0.7774 - val_loss: 0.4804 - val_accuracy: 0.7719\n",
            "Epoch 336/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4893 - accuracy: 0.7725 - val_loss: 0.4811 - val_accuracy: 0.7715\n",
            "Epoch 337/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4909 - accuracy: 0.7728 - val_loss: 0.4802 - val_accuracy: 0.7719\n",
            "Epoch 338/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4885 - accuracy: 0.7753 - val_loss: 0.4805 - val_accuracy: 0.7724\n",
            "Epoch 339/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4922 - accuracy: 0.7668 - val_loss: 0.4801 - val_accuracy: 0.7719\n",
            "Epoch 340/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4887 - accuracy: 0.7699 - val_loss: 0.4829 - val_accuracy: 0.7630\n",
            "Epoch 341/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4993 - accuracy: 0.7676 - val_loss: 0.4808 - val_accuracy: 0.7719\n",
            "Epoch 342/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4952 - accuracy: 0.7706 - val_loss: 0.4800 - val_accuracy: 0.7715\n",
            "Epoch 343/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4848 - accuracy: 0.7715 - val_loss: 0.4801 - val_accuracy: 0.7724\n",
            "Epoch 344/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4957 - accuracy: 0.7655 - val_loss: 0.4802 - val_accuracy: 0.7710\n",
            "Epoch 345/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4839 - accuracy: 0.7774 - val_loss: 0.4824 - val_accuracy: 0.7693\n",
            "Epoch 346/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4918 - accuracy: 0.7749 - val_loss: 0.4812 - val_accuracy: 0.7697\n",
            "Epoch 347/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4966 - accuracy: 0.7688 - val_loss: 0.4806 - val_accuracy: 0.7719\n",
            "Epoch 348/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4909 - accuracy: 0.7734 - val_loss: 0.4806 - val_accuracy: 0.7706\n",
            "Epoch 349/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4887 - accuracy: 0.7747 - val_loss: 0.4807 - val_accuracy: 0.7715\n",
            "Epoch 350/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5001 - accuracy: 0.7698 - val_loss: 0.4803 - val_accuracy: 0.7728\n",
            "Epoch 351/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5002 - accuracy: 0.7666 - val_loss: 0.4803 - val_accuracy: 0.7719\n",
            "Epoch 352/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4998 - accuracy: 0.7709 - val_loss: 0.4804 - val_accuracy: 0.7719\n",
            "Epoch 353/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4882 - accuracy: 0.7754 - val_loss: 0.4807 - val_accuracy: 0.7733\n",
            "Epoch 354/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5050 - accuracy: 0.7658 - val_loss: 0.4803 - val_accuracy: 0.7702\n",
            "Epoch 355/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4884 - accuracy: 0.7745 - val_loss: 0.4805 - val_accuracy: 0.7728\n",
            "Epoch 356/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4931 - accuracy: 0.7724 - val_loss: 0.4804 - val_accuracy: 0.7719\n",
            "Epoch 357/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4918 - accuracy: 0.7744 - val_loss: 0.4810 - val_accuracy: 0.7693\n",
            "Epoch 358/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4966 - accuracy: 0.7683 - val_loss: 0.4801 - val_accuracy: 0.7733\n",
            "Epoch 359/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4883 - accuracy: 0.7760 - val_loss: 0.4811 - val_accuracy: 0.7724\n",
            "Epoch 360/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4932 - accuracy: 0.7692 - val_loss: 0.4796 - val_accuracy: 0.7751\n",
            "Epoch 361/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4881 - accuracy: 0.7734 - val_loss: 0.4807 - val_accuracy: 0.7710\n",
            "Epoch 362/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4912 - accuracy: 0.7715 - val_loss: 0.4807 - val_accuracy: 0.7702\n",
            "Epoch 363/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4861 - accuracy: 0.7750 - val_loss: 0.4813 - val_accuracy: 0.7706\n",
            "Epoch 364/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4883 - accuracy: 0.7731 - val_loss: 0.4813 - val_accuracy: 0.7715\n",
            "Epoch 365/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4954 - accuracy: 0.7727 - val_loss: 0.4812 - val_accuracy: 0.7702\n",
            "Epoch 366/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4940 - accuracy: 0.7694 - val_loss: 0.4809 - val_accuracy: 0.7706\n",
            "Epoch 367/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4894 - accuracy: 0.7753 - val_loss: 0.4807 - val_accuracy: 0.7679\n",
            "Epoch 368/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4975 - accuracy: 0.7677 - val_loss: 0.4805 - val_accuracy: 0.7733\n",
            "Epoch 369/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4923 - accuracy: 0.7687 - val_loss: 0.4802 - val_accuracy: 0.7733\n",
            "Epoch 370/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4875 - accuracy: 0.7732 - val_loss: 0.4808 - val_accuracy: 0.7724\n",
            "Epoch 371/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4956 - accuracy: 0.7734 - val_loss: 0.4813 - val_accuracy: 0.7710\n",
            "Epoch 372/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4898 - accuracy: 0.7742 - val_loss: 0.4821 - val_accuracy: 0.7648\n",
            "Epoch 373/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4938 - accuracy: 0.7696 - val_loss: 0.4803 - val_accuracy: 0.7724\n",
            "Epoch 374/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4953 - accuracy: 0.7721 - val_loss: 0.4804 - val_accuracy: 0.7719\n",
            "Epoch 375/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4879 - accuracy: 0.7724 - val_loss: 0.4804 - val_accuracy: 0.7719\n",
            "Epoch 376/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4953 - accuracy: 0.7678 - val_loss: 0.4813 - val_accuracy: 0.7688\n",
            "Epoch 377/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4979 - accuracy: 0.7690 - val_loss: 0.4803 - val_accuracy: 0.7710\n",
            "Epoch 378/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4846 - accuracy: 0.7799 - val_loss: 0.4801 - val_accuracy: 0.7724\n",
            "Epoch 379/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4870 - accuracy: 0.7768 - val_loss: 0.4800 - val_accuracy: 0.7751\n",
            "Epoch 380/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4950 - accuracy: 0.7684 - val_loss: 0.4802 - val_accuracy: 0.7702\n",
            "Epoch 381/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4978 - accuracy: 0.7671 - val_loss: 0.4802 - val_accuracy: 0.7724\n",
            "Epoch 382/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4842 - accuracy: 0.7815 - val_loss: 0.4798 - val_accuracy: 0.7724\n",
            "Epoch 383/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4968 - accuracy: 0.7662 - val_loss: 0.4799 - val_accuracy: 0.7710\n",
            "Epoch 384/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4913 - accuracy: 0.7697 - val_loss: 0.4797 - val_accuracy: 0.7728\n",
            "Epoch 385/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4856 - accuracy: 0.7766 - val_loss: 0.4795 - val_accuracy: 0.7733\n",
            "Epoch 386/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4969 - accuracy: 0.7701 - val_loss: 0.4799 - val_accuracy: 0.7719\n",
            "Epoch 387/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4942 - accuracy: 0.7716 - val_loss: 0.4803 - val_accuracy: 0.7742\n",
            "Epoch 388/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4873 - accuracy: 0.7739 - val_loss: 0.4802 - val_accuracy: 0.7697\n",
            "Epoch 389/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5009 - accuracy: 0.7659 - val_loss: 0.4797 - val_accuracy: 0.7710\n",
            "Epoch 390/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4873 - accuracy: 0.7751 - val_loss: 0.4815 - val_accuracy: 0.7737\n",
            "Epoch 391/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4944 - accuracy: 0.7741 - val_loss: 0.4825 - val_accuracy: 0.7742\n",
            "Epoch 392/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4966 - accuracy: 0.7707 - val_loss: 0.4797 - val_accuracy: 0.7737\n",
            "Epoch 393/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4926 - accuracy: 0.7744 - val_loss: 0.4811 - val_accuracy: 0.7733\n",
            "Epoch 394/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4982 - accuracy: 0.7728 - val_loss: 0.4803 - val_accuracy: 0.7746\n",
            "Epoch 395/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4933 - accuracy: 0.7716 - val_loss: 0.4800 - val_accuracy: 0.7706\n",
            "Epoch 396/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4983 - accuracy: 0.7691 - val_loss: 0.4802 - val_accuracy: 0.7746\n",
            "Epoch 397/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4821 - accuracy: 0.7782 - val_loss: 0.4800 - val_accuracy: 0.7737\n",
            "Epoch 398/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4956 - accuracy: 0.7737 - val_loss: 0.4800 - val_accuracy: 0.7728\n",
            "Epoch 399/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4868 - accuracy: 0.7776 - val_loss: 0.4812 - val_accuracy: 0.7737\n",
            "Epoch 400/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4813 - accuracy: 0.7772 - val_loss: 0.4809 - val_accuracy: 0.7724\n",
            "Epoch 401/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4953 - accuracy: 0.7711 - val_loss: 0.4805 - val_accuracy: 0.7733\n",
            "Epoch 402/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4952 - accuracy: 0.7709 - val_loss: 0.4800 - val_accuracy: 0.7728\n",
            "Epoch 403/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4984 - accuracy: 0.7708 - val_loss: 0.4803 - val_accuracy: 0.7728\n",
            "Epoch 404/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4953 - accuracy: 0.7721 - val_loss: 0.4801 - val_accuracy: 0.7733\n",
            "Epoch 405/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4849 - accuracy: 0.7788 - val_loss: 0.4805 - val_accuracy: 0.7719\n",
            "Epoch 406/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4849 - accuracy: 0.7781 - val_loss: 0.4800 - val_accuracy: 0.7724\n",
            "Epoch 407/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4983 - accuracy: 0.7688 - val_loss: 0.4821 - val_accuracy: 0.7751\n",
            "Epoch 408/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4947 - accuracy: 0.7764 - val_loss: 0.4806 - val_accuracy: 0.7733\n",
            "Epoch 409/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4908 - accuracy: 0.7791 - val_loss: 0.4808 - val_accuracy: 0.7719\n",
            "Epoch 410/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4870 - accuracy: 0.7741 - val_loss: 0.4813 - val_accuracy: 0.7702\n",
            "Epoch 411/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4912 - accuracy: 0.7747 - val_loss: 0.4800 - val_accuracy: 0.7733\n",
            "Epoch 412/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4955 - accuracy: 0.7651 - val_loss: 0.4810 - val_accuracy: 0.7715\n",
            "Epoch 413/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4895 - accuracy: 0.7748 - val_loss: 0.4805 - val_accuracy: 0.7728\n",
            "Epoch 414/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4812 - accuracy: 0.7803 - val_loss: 0.4803 - val_accuracy: 0.7746\n",
            "Epoch 415/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4844 - accuracy: 0.7743 - val_loss: 0.4813 - val_accuracy: 0.7751\n",
            "Epoch 416/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4964 - accuracy: 0.7693 - val_loss: 0.4802 - val_accuracy: 0.7746\n",
            "Epoch 417/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4895 - accuracy: 0.7687 - val_loss: 0.4797 - val_accuracy: 0.7733\n",
            "Epoch 418/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4894 - accuracy: 0.7755 - val_loss: 0.4804 - val_accuracy: 0.7706\n",
            "Epoch 419/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4884 - accuracy: 0.7777 - val_loss: 0.4813 - val_accuracy: 0.7746\n",
            "Epoch 420/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4847 - accuracy: 0.7782 - val_loss: 0.4806 - val_accuracy: 0.7715\n",
            "Epoch 421/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4942 - accuracy: 0.7737 - val_loss: 0.4825 - val_accuracy: 0.7648\n",
            "Epoch 422/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4967 - accuracy: 0.7644 - val_loss: 0.4803 - val_accuracy: 0.7728\n",
            "Epoch 423/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4881 - accuracy: 0.7705 - val_loss: 0.4813 - val_accuracy: 0.7706\n",
            "Epoch 424/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4922 - accuracy: 0.7715 - val_loss: 0.4798 - val_accuracy: 0.7728\n",
            "Epoch 425/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4911 - accuracy: 0.7675 - val_loss: 0.4803 - val_accuracy: 0.7733\n",
            "Epoch 426/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5054 - accuracy: 0.7660 - val_loss: 0.4798 - val_accuracy: 0.7733\n",
            "Epoch 427/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4913 - accuracy: 0.7748 - val_loss: 0.4809 - val_accuracy: 0.7710\n",
            "Epoch 428/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4908 - accuracy: 0.7736 - val_loss: 0.4797 - val_accuracy: 0.7724\n",
            "Epoch 429/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4923 - accuracy: 0.7760 - val_loss: 0.4809 - val_accuracy: 0.7715\n",
            "Epoch 430/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4892 - accuracy: 0.7728 - val_loss: 0.4802 - val_accuracy: 0.7728\n",
            "Epoch 431/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4933 - accuracy: 0.7654 - val_loss: 0.4793 - val_accuracy: 0.7724\n",
            "Epoch 432/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4807 - accuracy: 0.7793 - val_loss: 0.4801 - val_accuracy: 0.7733\n",
            "Epoch 433/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4909 - accuracy: 0.7684 - val_loss: 0.4801 - val_accuracy: 0.7697\n",
            "Epoch 434/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4950 - accuracy: 0.7687 - val_loss: 0.4795 - val_accuracy: 0.7737\n",
            "Epoch 435/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4867 - accuracy: 0.7803 - val_loss: 0.4810 - val_accuracy: 0.7719\n",
            "Epoch 436/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4941 - accuracy: 0.7653 - val_loss: 0.4799 - val_accuracy: 0.7733\n",
            "Epoch 437/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4873 - accuracy: 0.7712 - val_loss: 0.4802 - val_accuracy: 0.7733\n",
            "Epoch 438/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4982 - accuracy: 0.7635 - val_loss: 0.4794 - val_accuracy: 0.7737\n",
            "Epoch 439/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4898 - accuracy: 0.7766 - val_loss: 0.4806 - val_accuracy: 0.7728\n",
            "Epoch 440/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4952 - accuracy: 0.7723 - val_loss: 0.4803 - val_accuracy: 0.7719\n",
            "Epoch 441/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4938 - accuracy: 0.7670 - val_loss: 0.4797 - val_accuracy: 0.7719\n",
            "Epoch 442/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4765 - accuracy: 0.7784 - val_loss: 0.4800 - val_accuracy: 0.7724\n",
            "Epoch 443/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4925 - accuracy: 0.7744 - val_loss: 0.4799 - val_accuracy: 0.7715\n",
            "Epoch 444/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4982 - accuracy: 0.7657 - val_loss: 0.4805 - val_accuracy: 0.7697\n",
            "Epoch 445/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4940 - accuracy: 0.7715 - val_loss: 0.4801 - val_accuracy: 0.7724\n",
            "Epoch 446/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4898 - accuracy: 0.7761 - val_loss: 0.4804 - val_accuracy: 0.7706\n",
            "Epoch 447/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4991 - accuracy: 0.7651 - val_loss: 0.4807 - val_accuracy: 0.7746\n",
            "Epoch 448/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4900 - accuracy: 0.7786 - val_loss: 0.4802 - val_accuracy: 0.7724\n",
            "Epoch 449/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4830 - accuracy: 0.7747 - val_loss: 0.4808 - val_accuracy: 0.7719\n",
            "Epoch 450/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4886 - accuracy: 0.7719 - val_loss: 0.4806 - val_accuracy: 0.7724\n",
            "Epoch 451/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4974 - accuracy: 0.7675 - val_loss: 0.4804 - val_accuracy: 0.7710\n",
            "Epoch 452/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4867 - accuracy: 0.7727 - val_loss: 0.4806 - val_accuracy: 0.7737\n",
            "Epoch 453/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4888 - accuracy: 0.7742 - val_loss: 0.4798 - val_accuracy: 0.7728\n",
            "Epoch 454/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4939 - accuracy: 0.7698 - val_loss: 0.4821 - val_accuracy: 0.7733\n",
            "Epoch 455/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4841 - accuracy: 0.7755 - val_loss: 0.4794 - val_accuracy: 0.7715\n",
            "Epoch 456/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4857 - accuracy: 0.7719 - val_loss: 0.4799 - val_accuracy: 0.7706\n",
            "Epoch 457/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5045 - accuracy: 0.7594 - val_loss: 0.4812 - val_accuracy: 0.7746\n",
            "Epoch 458/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4985 - accuracy: 0.7676 - val_loss: 0.4794 - val_accuracy: 0.7742\n",
            "Epoch 459/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4919 - accuracy: 0.7710 - val_loss: 0.4795 - val_accuracy: 0.7737\n",
            "Epoch 460/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4865 - accuracy: 0.7795 - val_loss: 0.4794 - val_accuracy: 0.7746\n",
            "Epoch 461/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4798 - accuracy: 0.7791 - val_loss: 0.4797 - val_accuracy: 0.7742\n",
            "Epoch 462/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4902 - accuracy: 0.7703 - val_loss: 0.4791 - val_accuracy: 0.7746\n",
            "Epoch 463/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4928 - accuracy: 0.7662 - val_loss: 0.4799 - val_accuracy: 0.7751\n",
            "Epoch 464/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4927 - accuracy: 0.7737 - val_loss: 0.4801 - val_accuracy: 0.7719\n",
            "Epoch 465/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4844 - accuracy: 0.7763 - val_loss: 0.4801 - val_accuracy: 0.7724\n",
            "Epoch 466/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4812 - accuracy: 0.7774 - val_loss: 0.4808 - val_accuracy: 0.7746\n",
            "Epoch 467/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4917 - accuracy: 0.7687 - val_loss: 0.4795 - val_accuracy: 0.7733\n",
            "Epoch 468/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4809 - accuracy: 0.7802 - val_loss: 0.4805 - val_accuracy: 0.7759\n",
            "Epoch 469/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4949 - accuracy: 0.7700 - val_loss: 0.4790 - val_accuracy: 0.7710\n",
            "Epoch 470/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4966 - accuracy: 0.7738 - val_loss: 0.4794 - val_accuracy: 0.7719\n",
            "Epoch 471/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4850 - accuracy: 0.7768 - val_loss: 0.4795 - val_accuracy: 0.7728\n",
            "Epoch 472/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4938 - accuracy: 0.7717 - val_loss: 0.4797 - val_accuracy: 0.7719\n",
            "Epoch 473/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4954 - accuracy: 0.7679 - val_loss: 0.4802 - val_accuracy: 0.7702\n",
            "Epoch 474/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4912 - accuracy: 0.7762 - val_loss: 0.4808 - val_accuracy: 0.7684\n",
            "Epoch 475/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4934 - accuracy: 0.7714 - val_loss: 0.4806 - val_accuracy: 0.7706\n",
            "Epoch 476/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4929 - accuracy: 0.7688 - val_loss: 0.4809 - val_accuracy: 0.7693\n",
            "Epoch 477/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4907 - accuracy: 0.7742 - val_loss: 0.4808 - val_accuracy: 0.7742\n",
            "Epoch 478/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4839 - accuracy: 0.7755 - val_loss: 0.4804 - val_accuracy: 0.7724\n",
            "Epoch 479/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5014 - accuracy: 0.7670 - val_loss: 0.4798 - val_accuracy: 0.7710\n",
            "Epoch 480/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4888 - accuracy: 0.7730 - val_loss: 0.4823 - val_accuracy: 0.7742\n",
            "Epoch 481/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4941 - accuracy: 0.7731 - val_loss: 0.4796 - val_accuracy: 0.7728\n",
            "Epoch 482/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4927 - accuracy: 0.7701 - val_loss: 0.4795 - val_accuracy: 0.7733\n",
            "Epoch 483/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4932 - accuracy: 0.7759 - val_loss: 0.4822 - val_accuracy: 0.7719\n",
            "Epoch 484/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4801 - accuracy: 0.7830 - val_loss: 0.4805 - val_accuracy: 0.7715\n",
            "Epoch 485/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4939 - accuracy: 0.7726 - val_loss: 0.4824 - val_accuracy: 0.7746\n",
            "Epoch 486/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4922 - accuracy: 0.7724 - val_loss: 0.4796 - val_accuracy: 0.7728\n",
            "Epoch 487/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4904 - accuracy: 0.7776 - val_loss: 0.4801 - val_accuracy: 0.7715\n",
            "Epoch 488/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4810 - accuracy: 0.7826 - val_loss: 0.4823 - val_accuracy: 0.7728\n",
            "Epoch 489/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4913 - accuracy: 0.7739 - val_loss: 0.4801 - val_accuracy: 0.7737\n",
            "Epoch 490/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4885 - accuracy: 0.7766 - val_loss: 0.4800 - val_accuracy: 0.7728\n",
            "Epoch 491/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4852 - accuracy: 0.7735 - val_loss: 0.4801 - val_accuracy: 0.7719\n",
            "Epoch 492/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4882 - accuracy: 0.7721 - val_loss: 0.4807 - val_accuracy: 0.7702\n",
            "Epoch 493/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4879 - accuracy: 0.7761 - val_loss: 0.4798 - val_accuracy: 0.7746\n",
            "Epoch 494/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4873 - accuracy: 0.7806 - val_loss: 0.4804 - val_accuracy: 0.7702\n",
            "Epoch 495/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4898 - accuracy: 0.7718 - val_loss: 0.4797 - val_accuracy: 0.7706\n",
            "Epoch 496/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4903 - accuracy: 0.7667 - val_loss: 0.4794 - val_accuracy: 0.7715\n",
            "Epoch 497/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4860 - accuracy: 0.7743 - val_loss: 0.4792 - val_accuracy: 0.7733\n",
            "Epoch 498/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.5003 - accuracy: 0.7650 - val_loss: 0.4795 - val_accuracy: 0.7733\n",
            "Epoch 499/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4875 - accuracy: 0.7747 - val_loss: 0.4788 - val_accuracy: 0.7728\n",
            "Epoch 500/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4958 - accuracy: 0.7729 - val_loss: 0.4792 - val_accuracy: 0.7728\n",
            "Epoch 501/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4931 - accuracy: 0.7712 - val_loss: 0.4807 - val_accuracy: 0.7728\n",
            "Epoch 502/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4892 - accuracy: 0.7718 - val_loss: 0.4793 - val_accuracy: 0.7710\n",
            "Epoch 503/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5006 - accuracy: 0.7673 - val_loss: 0.4794 - val_accuracy: 0.7719\n",
            "Epoch 504/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4845 - accuracy: 0.7752 - val_loss: 0.4818 - val_accuracy: 0.7746\n",
            "Epoch 505/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4960 - accuracy: 0.7700 - val_loss: 0.4795 - val_accuracy: 0.7742\n",
            "Epoch 506/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4910 - accuracy: 0.7670 - val_loss: 0.4796 - val_accuracy: 0.7715\n",
            "Epoch 507/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4896 - accuracy: 0.7726 - val_loss: 0.4797 - val_accuracy: 0.7724\n",
            "Epoch 508/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4965 - accuracy: 0.7707 - val_loss: 0.4799 - val_accuracy: 0.7728\n",
            "Epoch 509/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4955 - accuracy: 0.7709 - val_loss: 0.4798 - val_accuracy: 0.7728\n",
            "Epoch 510/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4898 - accuracy: 0.7729 - val_loss: 0.4805 - val_accuracy: 0.7706\n",
            "Epoch 511/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4887 - accuracy: 0.7757 - val_loss: 0.4796 - val_accuracy: 0.7759\n",
            "Epoch 512/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4914 - accuracy: 0.7760 - val_loss: 0.4797 - val_accuracy: 0.7724\n",
            "Epoch 513/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4932 - accuracy: 0.7733 - val_loss: 0.4802 - val_accuracy: 0.7706\n",
            "Epoch 514/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4925 - accuracy: 0.7713 - val_loss: 0.4807 - val_accuracy: 0.7702\n",
            "Epoch 515/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4868 - accuracy: 0.7820 - val_loss: 0.4798 - val_accuracy: 0.7715\n",
            "Epoch 516/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4893 - accuracy: 0.7757 - val_loss: 0.4801 - val_accuracy: 0.7755\n",
            "Epoch 517/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.5038 - accuracy: 0.7664 - val_loss: 0.4797 - val_accuracy: 0.7715\n",
            "Epoch 518/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4844 - accuracy: 0.7757 - val_loss: 0.4811 - val_accuracy: 0.7702\n",
            "Epoch 519/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4897 - accuracy: 0.7713 - val_loss: 0.4806 - val_accuracy: 0.7724\n",
            "Epoch 520/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4936 - accuracy: 0.7705 - val_loss: 0.4793 - val_accuracy: 0.7728\n",
            "Epoch 521/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4886 - accuracy: 0.7768 - val_loss: 0.4795 - val_accuracy: 0.7710\n",
            "Epoch 522/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4868 - accuracy: 0.7725 - val_loss: 0.4803 - val_accuracy: 0.7706\n",
            "Epoch 523/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4926 - accuracy: 0.7722 - val_loss: 0.4796 - val_accuracy: 0.7724\n",
            "Epoch 524/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4923 - accuracy: 0.7710 - val_loss: 0.4803 - val_accuracy: 0.7702\n",
            "Epoch 525/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4951 - accuracy: 0.7709 - val_loss: 0.4800 - val_accuracy: 0.7719\n",
            "Epoch 526/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4963 - accuracy: 0.7672 - val_loss: 0.4798 - val_accuracy: 0.7742\n",
            "Epoch 527/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4872 - accuracy: 0.7729 - val_loss: 0.4794 - val_accuracy: 0.7724\n",
            "Epoch 528/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4914 - accuracy: 0.7666 - val_loss: 0.4802 - val_accuracy: 0.7702\n",
            "Epoch 529/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4985 - accuracy: 0.7619 - val_loss: 0.4795 - val_accuracy: 0.7719\n",
            "Epoch 530/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5003 - accuracy: 0.7706 - val_loss: 0.4790 - val_accuracy: 0.7737\n",
            "Epoch 531/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4915 - accuracy: 0.7689 - val_loss: 0.4792 - val_accuracy: 0.7719\n",
            "Epoch 532/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4912 - accuracy: 0.7700 - val_loss: 0.4804 - val_accuracy: 0.7715\n",
            "Epoch 533/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4932 - accuracy: 0.7725 - val_loss: 0.4801 - val_accuracy: 0.7715\n",
            "Epoch 534/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4925 - accuracy: 0.7667 - val_loss: 0.4791 - val_accuracy: 0.7715\n",
            "Epoch 535/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4878 - accuracy: 0.7761 - val_loss: 0.4804 - val_accuracy: 0.7728\n",
            "Epoch 536/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5000 - accuracy: 0.7675 - val_loss: 0.4798 - val_accuracy: 0.7724\n",
            "Epoch 537/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4893 - accuracy: 0.7689 - val_loss: 0.4805 - val_accuracy: 0.7710\n",
            "Epoch 538/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4804 - accuracy: 0.7759 - val_loss: 0.4797 - val_accuracy: 0.7724\n",
            "Epoch 539/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4869 - accuracy: 0.7787 - val_loss: 0.4802 - val_accuracy: 0.7715\n",
            "Epoch 540/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4879 - accuracy: 0.7721 - val_loss: 0.4827 - val_accuracy: 0.7675\n",
            "Epoch 541/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4958 - accuracy: 0.7719 - val_loss: 0.4795 - val_accuracy: 0.7737\n",
            "Epoch 542/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4903 - accuracy: 0.7732 - val_loss: 0.4813 - val_accuracy: 0.7733\n",
            "Epoch 543/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4908 - accuracy: 0.7718 - val_loss: 0.4799 - val_accuracy: 0.7724\n",
            "Epoch 544/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4878 - accuracy: 0.7729 - val_loss: 0.4809 - val_accuracy: 0.7684\n",
            "Epoch 545/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4904 - accuracy: 0.7721 - val_loss: 0.4799 - val_accuracy: 0.7728\n",
            "Epoch 546/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4839 - accuracy: 0.7710 - val_loss: 0.4810 - val_accuracy: 0.7715\n",
            "Epoch 547/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4868 - accuracy: 0.7765 - val_loss: 0.4799 - val_accuracy: 0.7702\n",
            "Epoch 548/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4892 - accuracy: 0.7752 - val_loss: 0.4800 - val_accuracy: 0.7710\n",
            "Epoch 549/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4867 - accuracy: 0.7765 - val_loss: 0.4798 - val_accuracy: 0.7719\n",
            "Epoch 550/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4910 - accuracy: 0.7760 - val_loss: 0.4794 - val_accuracy: 0.7715\n",
            "Epoch 551/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4873 - accuracy: 0.7731 - val_loss: 0.4791 - val_accuracy: 0.7746\n",
            "Epoch 552/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4930 - accuracy: 0.7738 - val_loss: 0.4791 - val_accuracy: 0.7751\n",
            "Epoch 553/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4929 - accuracy: 0.7713 - val_loss: 0.4797 - val_accuracy: 0.7706\n",
            "Epoch 554/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4889 - accuracy: 0.7758 - val_loss: 0.4804 - val_accuracy: 0.7719\n",
            "Epoch 555/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4939 - accuracy: 0.7739 - val_loss: 0.4803 - val_accuracy: 0.7737\n",
            "Epoch 556/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4905 - accuracy: 0.7707 - val_loss: 0.4789 - val_accuracy: 0.7733\n",
            "Epoch 557/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4927 - accuracy: 0.7704 - val_loss: 0.4797 - val_accuracy: 0.7737\n",
            "Epoch 558/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4962 - accuracy: 0.7608 - val_loss: 0.4800 - val_accuracy: 0.7697\n",
            "Epoch 559/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4891 - accuracy: 0.7715 - val_loss: 0.4796 - val_accuracy: 0.7728\n",
            "Epoch 560/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4861 - accuracy: 0.7721 - val_loss: 0.4797 - val_accuracy: 0.7733\n",
            "Epoch 561/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4900 - accuracy: 0.7722 - val_loss: 0.4796 - val_accuracy: 0.7702\n",
            "Epoch 562/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4898 - accuracy: 0.7763 - val_loss: 0.4793 - val_accuracy: 0.7724\n",
            "Epoch 563/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4937 - accuracy: 0.7672 - val_loss: 0.4785 - val_accuracy: 0.7742\n",
            "Epoch 564/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4843 - accuracy: 0.7744 - val_loss: 0.4791 - val_accuracy: 0.7733\n",
            "Epoch 565/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4964 - accuracy: 0.7687 - val_loss: 0.4801 - val_accuracy: 0.7684\n",
            "Epoch 566/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4888 - accuracy: 0.7770 - val_loss: 0.4795 - val_accuracy: 0.7715\n",
            "Epoch 567/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4820 - accuracy: 0.7802 - val_loss: 0.4793 - val_accuracy: 0.7728\n",
            "Epoch 568/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4939 - accuracy: 0.7674 - val_loss: 0.4797 - val_accuracy: 0.7728\n",
            "Epoch 569/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4878 - accuracy: 0.7716 - val_loss: 0.4796 - val_accuracy: 0.7724\n",
            "Epoch 570/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4910 - accuracy: 0.7708 - val_loss: 0.4807 - val_accuracy: 0.7733\n",
            "Epoch 571/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4937 - accuracy: 0.7724 - val_loss: 0.4790 - val_accuracy: 0.7728\n",
            "Epoch 572/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4877 - accuracy: 0.7784 - val_loss: 0.4799 - val_accuracy: 0.7751\n",
            "Epoch 573/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4863 - accuracy: 0.7757 - val_loss: 0.4802 - val_accuracy: 0.7719\n",
            "Epoch 574/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4939 - accuracy: 0.7705 - val_loss: 0.4791 - val_accuracy: 0.7728\n",
            "Epoch 575/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4873 - accuracy: 0.7728 - val_loss: 0.4791 - val_accuracy: 0.7706\n",
            "Epoch 576/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4911 - accuracy: 0.7721 - val_loss: 0.4799 - val_accuracy: 0.7724\n",
            "Epoch 577/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4897 - accuracy: 0.7752 - val_loss: 0.4785 - val_accuracy: 0.7724\n",
            "Epoch 578/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4890 - accuracy: 0.7755 - val_loss: 0.4789 - val_accuracy: 0.7737\n",
            "Epoch 579/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4914 - accuracy: 0.7716 - val_loss: 0.4823 - val_accuracy: 0.7759\n",
            "Epoch 580/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4943 - accuracy: 0.7669 - val_loss: 0.4795 - val_accuracy: 0.7733\n",
            "Epoch 581/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4909 - accuracy: 0.7745 - val_loss: 0.4793 - val_accuracy: 0.7728\n",
            "Epoch 582/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4954 - accuracy: 0.7691 - val_loss: 0.4798 - val_accuracy: 0.7733\n",
            "Epoch 583/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4881 - accuracy: 0.7728 - val_loss: 0.4798 - val_accuracy: 0.7733\n",
            "Epoch 584/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4843 - accuracy: 0.7756 - val_loss: 0.4803 - val_accuracy: 0.7728\n",
            "Epoch 585/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4957 - accuracy: 0.7686 - val_loss: 0.4801 - val_accuracy: 0.7719\n",
            "Epoch 586/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4952 - accuracy: 0.7703 - val_loss: 0.4800 - val_accuracy: 0.7724\n",
            "Epoch 587/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4992 - accuracy: 0.7714 - val_loss: 0.4808 - val_accuracy: 0.7688\n",
            "Epoch 588/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4918 - accuracy: 0.7715 - val_loss: 0.4795 - val_accuracy: 0.7742\n",
            "Epoch 589/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4906 - accuracy: 0.7690 - val_loss: 0.4792 - val_accuracy: 0.7719\n",
            "Epoch 590/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4931 - accuracy: 0.7709 - val_loss: 0.4797 - val_accuracy: 0.7706\n",
            "Epoch 591/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4965 - accuracy: 0.7623 - val_loss: 0.4797 - val_accuracy: 0.7702\n",
            "Epoch 592/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.5049 - accuracy: 0.7666 - val_loss: 0.4790 - val_accuracy: 0.7733\n",
            "Epoch 593/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4984 - accuracy: 0.7669 - val_loss: 0.4807 - val_accuracy: 0.7706\n",
            "Epoch 594/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4871 - accuracy: 0.7756 - val_loss: 0.4801 - val_accuracy: 0.7715\n",
            "Epoch 595/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4897 - accuracy: 0.7720 - val_loss: 0.4794 - val_accuracy: 0.7728\n",
            "Epoch 596/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4829 - accuracy: 0.7772 - val_loss: 0.4806 - val_accuracy: 0.7719\n",
            "Epoch 597/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4877 - accuracy: 0.7737 - val_loss: 0.4803 - val_accuracy: 0.7675\n",
            "Epoch 598/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4854 - accuracy: 0.7807 - val_loss: 0.4792 - val_accuracy: 0.7733\n",
            "Epoch 599/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4931 - accuracy: 0.7704 - val_loss: 0.4788 - val_accuracy: 0.7742\n",
            "Epoch 600/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4991 - accuracy: 0.7692 - val_loss: 0.4803 - val_accuracy: 0.7719\n",
            "Epoch 601/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4929 - accuracy: 0.7716 - val_loss: 0.4791 - val_accuracy: 0.7715\n",
            "Epoch 602/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4861 - accuracy: 0.7728 - val_loss: 0.4795 - val_accuracy: 0.7728\n",
            "Epoch 603/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4882 - accuracy: 0.7745 - val_loss: 0.4800 - val_accuracy: 0.7706\n",
            "Epoch 604/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5015 - accuracy: 0.7634 - val_loss: 0.4793 - val_accuracy: 0.7733\n",
            "Epoch 605/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4845 - accuracy: 0.7755 - val_loss: 0.4783 - val_accuracy: 0.7737\n",
            "Epoch 606/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4917 - accuracy: 0.7719 - val_loss: 0.4803 - val_accuracy: 0.7679\n",
            "Epoch 607/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4958 - accuracy: 0.7684 - val_loss: 0.4789 - val_accuracy: 0.7733\n",
            "Epoch 608/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4852 - accuracy: 0.7768 - val_loss: 0.4808 - val_accuracy: 0.7751\n",
            "Epoch 609/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4962 - accuracy: 0.7694 - val_loss: 0.4809 - val_accuracy: 0.7679\n",
            "Epoch 610/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4868 - accuracy: 0.7723 - val_loss: 0.4797 - val_accuracy: 0.7728\n",
            "Epoch 611/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.5003 - accuracy: 0.7636 - val_loss: 0.4794 - val_accuracy: 0.7751\n",
            "Epoch 612/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4914 - accuracy: 0.7715 - val_loss: 0.4809 - val_accuracy: 0.7764\n",
            "Epoch 613/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4883 - accuracy: 0.7739 - val_loss: 0.4790 - val_accuracy: 0.7715\n",
            "Epoch 614/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4978 - accuracy: 0.7651 - val_loss: 0.4792 - val_accuracy: 0.7724\n",
            "Epoch 615/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4969 - accuracy: 0.7676 - val_loss: 0.4793 - val_accuracy: 0.7737\n",
            "Epoch 616/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4825 - accuracy: 0.7785 - val_loss: 0.4791 - val_accuracy: 0.7724\n",
            "Epoch 617/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4916 - accuracy: 0.7690 - val_loss: 0.4801 - val_accuracy: 0.7710\n",
            "Epoch 618/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4954 - accuracy: 0.7688 - val_loss: 0.4791 - val_accuracy: 0.7728\n",
            "Epoch 619/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4901 - accuracy: 0.7743 - val_loss: 0.4790 - val_accuracy: 0.7751\n",
            "Epoch 620/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4914 - accuracy: 0.7701 - val_loss: 0.4790 - val_accuracy: 0.7697\n",
            "Epoch 621/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4866 - accuracy: 0.7764 - val_loss: 0.4802 - val_accuracy: 0.7679\n",
            "Epoch 622/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4872 - accuracy: 0.7695 - val_loss: 0.4792 - val_accuracy: 0.7710\n",
            "Epoch 623/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4881 - accuracy: 0.7769 - val_loss: 0.4796 - val_accuracy: 0.7764\n",
            "Epoch 624/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.5025 - accuracy: 0.7729 - val_loss: 0.4804 - val_accuracy: 0.7706\n",
            "Epoch 625/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4963 - accuracy: 0.7713 - val_loss: 0.4791 - val_accuracy: 0.7724\n",
            "Epoch 626/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4863 - accuracy: 0.7745 - val_loss: 0.4798 - val_accuracy: 0.7719\n",
            "Epoch 627/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4980 - accuracy: 0.7713 - val_loss: 0.4791 - val_accuracy: 0.7724\n",
            "Epoch 628/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4838 - accuracy: 0.7812 - val_loss: 0.4814 - val_accuracy: 0.7719\n",
            "Epoch 629/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4937 - accuracy: 0.7703 - val_loss: 0.4793 - val_accuracy: 0.7724\n",
            "Epoch 630/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4887 - accuracy: 0.7753 - val_loss: 0.4799 - val_accuracy: 0.7742\n",
            "Epoch 631/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4896 - accuracy: 0.7722 - val_loss: 0.4794 - val_accuracy: 0.7724\n",
            "Epoch 632/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4799 - accuracy: 0.7807 - val_loss: 0.4807 - val_accuracy: 0.7715\n",
            "Epoch 633/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4923 - accuracy: 0.7754 - val_loss: 0.4795 - val_accuracy: 0.7710\n",
            "Epoch 634/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4870 - accuracy: 0.7704 - val_loss: 0.4791 - val_accuracy: 0.7728\n",
            "Epoch 635/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4898 - accuracy: 0.7692 - val_loss: 0.4792 - val_accuracy: 0.7755\n",
            "Epoch 636/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4845 - accuracy: 0.7768 - val_loss: 0.4792 - val_accuracy: 0.7715\n",
            "Epoch 637/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4874 - accuracy: 0.7711 - val_loss: 0.4803 - val_accuracy: 0.7688\n",
            "Epoch 638/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4902 - accuracy: 0.7760 - val_loss: 0.4796 - val_accuracy: 0.7710\n",
            "Epoch 639/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4939 - accuracy: 0.7716 - val_loss: 0.4789 - val_accuracy: 0.7733\n",
            "Epoch 640/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4893 - accuracy: 0.7717 - val_loss: 0.4795 - val_accuracy: 0.7724\n",
            "Epoch 641/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4933 - accuracy: 0.7659 - val_loss: 0.4799 - val_accuracy: 0.7715\n",
            "Epoch 642/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4836 - accuracy: 0.7784 - val_loss: 0.4794 - val_accuracy: 0.7733\n",
            "Epoch 643/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4875 - accuracy: 0.7714 - val_loss: 0.4792 - val_accuracy: 0.7724\n",
            "Epoch 644/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4936 - accuracy: 0.7695 - val_loss: 0.4796 - val_accuracy: 0.7737\n",
            "Epoch 645/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4872 - accuracy: 0.7761 - val_loss: 0.4797 - val_accuracy: 0.7733\n",
            "Epoch 646/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4888 - accuracy: 0.7759 - val_loss: 0.4795 - val_accuracy: 0.7733\n",
            "Epoch 647/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4854 - accuracy: 0.7743 - val_loss: 0.4802 - val_accuracy: 0.7706\n",
            "Epoch 648/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4903 - accuracy: 0.7732 - val_loss: 0.4800 - val_accuracy: 0.7719\n",
            "Epoch 649/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4877 - accuracy: 0.7737 - val_loss: 0.4792 - val_accuracy: 0.7724\n",
            "Epoch 650/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4789 - accuracy: 0.7788 - val_loss: 0.4797 - val_accuracy: 0.7733\n",
            "Epoch 651/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4880 - accuracy: 0.7695 - val_loss: 0.4789 - val_accuracy: 0.7728\n",
            "Epoch 652/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4941 - accuracy: 0.7677 - val_loss: 0.4801 - val_accuracy: 0.7759\n",
            "Epoch 653/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4917 - accuracy: 0.7735 - val_loss: 0.4795 - val_accuracy: 0.7724\n",
            "Epoch 654/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4973 - accuracy: 0.7717 - val_loss: 0.4801 - val_accuracy: 0.7719\n",
            "Epoch 655/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4880 - accuracy: 0.7736 - val_loss: 0.4795 - val_accuracy: 0.7719\n",
            "Epoch 656/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4960 - accuracy: 0.7663 - val_loss: 0.4798 - val_accuracy: 0.7715\n",
            "Epoch 657/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4879 - accuracy: 0.7728 - val_loss: 0.4795 - val_accuracy: 0.7693\n",
            "Epoch 658/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4888 - accuracy: 0.7741 - val_loss: 0.4791 - val_accuracy: 0.7706\n",
            "Epoch 659/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4834 - accuracy: 0.7785 - val_loss: 0.4801 - val_accuracy: 0.7706\n",
            "Epoch 660/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4921 - accuracy: 0.7709 - val_loss: 0.4801 - val_accuracy: 0.7724\n",
            "Epoch 661/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4934 - accuracy: 0.7675 - val_loss: 0.4807 - val_accuracy: 0.7688\n",
            "Epoch 662/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4936 - accuracy: 0.7713 - val_loss: 0.4786 - val_accuracy: 0.7724\n",
            "Epoch 663/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4932 - accuracy: 0.7673 - val_loss: 0.4793 - val_accuracy: 0.7710\n",
            "Epoch 664/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4861 - accuracy: 0.7751 - val_loss: 0.4793 - val_accuracy: 0.7715\n",
            "Epoch 665/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4847 - accuracy: 0.7796 - val_loss: 0.4803 - val_accuracy: 0.7724\n",
            "Epoch 666/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4915 - accuracy: 0.7700 - val_loss: 0.4804 - val_accuracy: 0.7693\n",
            "Epoch 667/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4911 - accuracy: 0.7698 - val_loss: 0.4804 - val_accuracy: 0.7728\n",
            "Epoch 668/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4916 - accuracy: 0.7739 - val_loss: 0.4792 - val_accuracy: 0.7737\n",
            "Epoch 669/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4932 - accuracy: 0.7695 - val_loss: 0.4794 - val_accuracy: 0.7710\n",
            "Epoch 670/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4815 - accuracy: 0.7788 - val_loss: 0.4791 - val_accuracy: 0.7737\n",
            "Epoch 671/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4931 - accuracy: 0.7690 - val_loss: 0.4790 - val_accuracy: 0.7724\n",
            "Epoch 672/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4906 - accuracy: 0.7730 - val_loss: 0.4796 - val_accuracy: 0.7702\n",
            "Epoch 673/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4896 - accuracy: 0.7741 - val_loss: 0.4813 - val_accuracy: 0.7706\n",
            "Epoch 674/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4967 - accuracy: 0.7687 - val_loss: 0.4797 - val_accuracy: 0.7724\n",
            "Epoch 675/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4896 - accuracy: 0.7710 - val_loss: 0.4797 - val_accuracy: 0.7702\n",
            "Epoch 676/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.5018 - accuracy: 0.7645 - val_loss: 0.4793 - val_accuracy: 0.7719\n",
            "Epoch 677/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4921 - accuracy: 0.7725 - val_loss: 0.4800 - val_accuracy: 0.7697\n",
            "Epoch 678/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.5038 - accuracy: 0.7634 - val_loss: 0.4797 - val_accuracy: 0.7710\n",
            "Epoch 679/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4811 - accuracy: 0.7824 - val_loss: 0.4794 - val_accuracy: 0.7728\n",
            "Epoch 680/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4955 - accuracy: 0.7665 - val_loss: 0.4790 - val_accuracy: 0.7706\n",
            "Epoch 681/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4966 - accuracy: 0.7684 - val_loss: 0.4807 - val_accuracy: 0.7733\n",
            "Epoch 682/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4931 - accuracy: 0.7705 - val_loss: 0.4794 - val_accuracy: 0.7697\n",
            "Epoch 683/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4801 - accuracy: 0.7813 - val_loss: 0.4795 - val_accuracy: 0.7724\n",
            "Epoch 684/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4907 - accuracy: 0.7730 - val_loss: 0.4789 - val_accuracy: 0.7715\n",
            "Epoch 685/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4892 - accuracy: 0.7762 - val_loss: 0.4795 - val_accuracy: 0.7706\n",
            "Epoch 686/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4915 - accuracy: 0.7741 - val_loss: 0.4795 - val_accuracy: 0.7710\n",
            "Epoch 687/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4916 - accuracy: 0.7691 - val_loss: 0.4796 - val_accuracy: 0.7733\n",
            "Epoch 688/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4910 - accuracy: 0.7722 - val_loss: 0.4790 - val_accuracy: 0.7724\n",
            "Epoch 689/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4887 - accuracy: 0.7705 - val_loss: 0.4797 - val_accuracy: 0.7728\n",
            "Epoch 690/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4934 - accuracy: 0.7718 - val_loss: 0.4790 - val_accuracy: 0.7737\n",
            "Epoch 691/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4805 - accuracy: 0.7787 - val_loss: 0.4795 - val_accuracy: 0.7742\n",
            "Epoch 692/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.5051 - accuracy: 0.7666 - val_loss: 0.4794 - val_accuracy: 0.7719\n",
            "Epoch 693/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4935 - accuracy: 0.7662 - val_loss: 0.4785 - val_accuracy: 0.7742\n",
            "Epoch 694/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4891 - accuracy: 0.7702 - val_loss: 0.4789 - val_accuracy: 0.7719\n",
            "Epoch 695/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4863 - accuracy: 0.7772 - val_loss: 0.4793 - val_accuracy: 0.7715\n",
            "Epoch 696/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4885 - accuracy: 0.7708 - val_loss: 0.4787 - val_accuracy: 0.7715\n",
            "Epoch 697/1500\n",
            "328/328 [==============================] - 1s 4ms/step - loss: 0.4904 - accuracy: 0.7745 - val_loss: 0.4792 - val_accuracy: 0.7724\n",
            "Epoch 698/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4748 - accuracy: 0.7842 - val_loss: 0.4793 - val_accuracy: 0.7706\n",
            "Epoch 699/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4895 - accuracy: 0.7691 - val_loss: 0.4802 - val_accuracy: 0.7684\n",
            "Epoch 700/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4799 - accuracy: 0.7797 - val_loss: 0.4796 - val_accuracy: 0.7719\n",
            "Epoch 701/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4790 - accuracy: 0.7806 - val_loss: 0.4790 - val_accuracy: 0.7728\n",
            "Epoch 702/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4861 - accuracy: 0.7745 - val_loss: 0.4789 - val_accuracy: 0.7728\n",
            "Epoch 703/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4904 - accuracy: 0.7674 - val_loss: 0.4788 - val_accuracy: 0.7724\n",
            "Epoch 704/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4946 - accuracy: 0.7687 - val_loss: 0.4797 - val_accuracy: 0.7759\n",
            "Epoch 705/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4824 - accuracy: 0.7800 - val_loss: 0.4795 - val_accuracy: 0.7715\n",
            "Epoch 706/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4925 - accuracy: 0.7734 - val_loss: 0.4793 - val_accuracy: 0.7706\n",
            "Epoch 707/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4902 - accuracy: 0.7714 - val_loss: 0.4804 - val_accuracy: 0.7724\n",
            "Epoch 708/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4943 - accuracy: 0.7663 - val_loss: 0.4811 - val_accuracy: 0.7679\n",
            "Epoch 709/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4949 - accuracy: 0.7722 - val_loss: 0.4789 - val_accuracy: 0.7746\n",
            "Epoch 710/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4870 - accuracy: 0.7722 - val_loss: 0.4789 - val_accuracy: 0.7742\n",
            "Epoch 711/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4975 - accuracy: 0.7710 - val_loss: 0.4792 - val_accuracy: 0.7733\n",
            "Epoch 712/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4933 - accuracy: 0.7764 - val_loss: 0.4790 - val_accuracy: 0.7728\n",
            "Epoch 713/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4903 - accuracy: 0.7768 - val_loss: 0.4801 - val_accuracy: 0.7706\n",
            "Epoch 714/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4951 - accuracy: 0.7662 - val_loss: 0.4810 - val_accuracy: 0.7755\n",
            "Epoch 715/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4853 - accuracy: 0.7730 - val_loss: 0.4794 - val_accuracy: 0.7728\n",
            "Epoch 716/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4971 - accuracy: 0.7630 - val_loss: 0.4798 - val_accuracy: 0.7719\n",
            "Epoch 717/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4789 - accuracy: 0.7816 - val_loss: 0.4796 - val_accuracy: 0.7728\n",
            "Epoch 718/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.5046 - accuracy: 0.7624 - val_loss: 0.4796 - val_accuracy: 0.7684\n",
            "Epoch 719/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4915 - accuracy: 0.7745 - val_loss: 0.4790 - val_accuracy: 0.7706\n",
            "Epoch 720/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4875 - accuracy: 0.7745 - val_loss: 0.4799 - val_accuracy: 0.7719\n",
            "Epoch 721/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4866 - accuracy: 0.7738 - val_loss: 0.4792 - val_accuracy: 0.7710\n",
            "Epoch 722/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4864 - accuracy: 0.7714 - val_loss: 0.4803 - val_accuracy: 0.7710\n",
            "Epoch 723/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4922 - accuracy: 0.7695 - val_loss: 0.4794 - val_accuracy: 0.7728\n",
            "Epoch 724/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4834 - accuracy: 0.7793 - val_loss: 0.4786 - val_accuracy: 0.7733\n",
            "Epoch 725/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4759 - accuracy: 0.7797 - val_loss: 0.4793 - val_accuracy: 0.7724\n",
            "Epoch 726/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4841 - accuracy: 0.7735 - val_loss: 0.4792 - val_accuracy: 0.7697\n",
            "Epoch 727/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4892 - accuracy: 0.7742 - val_loss: 0.4791 - val_accuracy: 0.7733\n",
            "Epoch 728/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4913 - accuracy: 0.7727 - val_loss: 0.4801 - val_accuracy: 0.7710\n",
            "Epoch 729/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4879 - accuracy: 0.7727 - val_loss: 0.4796 - val_accuracy: 0.7751\n",
            "Epoch 730/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4883 - accuracy: 0.7719 - val_loss: 0.4804 - val_accuracy: 0.7724\n",
            "Epoch 731/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4922 - accuracy: 0.7724 - val_loss: 0.4810 - val_accuracy: 0.7755\n",
            "Epoch 732/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4899 - accuracy: 0.7740 - val_loss: 0.4792 - val_accuracy: 0.7728\n",
            "Epoch 733/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4867 - accuracy: 0.7801 - val_loss: 0.4786 - val_accuracy: 0.7746\n",
            "Epoch 734/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4881 - accuracy: 0.7734 - val_loss: 0.4806 - val_accuracy: 0.7751\n",
            "Epoch 735/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4840 - accuracy: 0.7814 - val_loss: 0.4797 - val_accuracy: 0.7733\n",
            "Epoch 736/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4957 - accuracy: 0.7686 - val_loss: 0.4791 - val_accuracy: 0.7728\n",
            "Epoch 737/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4943 - accuracy: 0.7688 - val_loss: 0.4788 - val_accuracy: 0.7719\n",
            "Epoch 738/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4782 - accuracy: 0.7797 - val_loss: 0.4805 - val_accuracy: 0.7693\n",
            "Epoch 739/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4760 - accuracy: 0.7826 - val_loss: 0.4794 - val_accuracy: 0.7728\n",
            "Epoch 740/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4941 - accuracy: 0.7719 - val_loss: 0.4801 - val_accuracy: 0.7693\n",
            "Epoch 741/1500\n",
            "328/328 [==============================] - 1s 5ms/step - loss: 0.4904 - accuracy: 0.7732 - val_loss: 0.4788 - val_accuracy: 0.7719\n",
            "Epoch 742/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4918 - accuracy: 0.7733 - val_loss: 0.4786 - val_accuracy: 0.7719\n",
            "Epoch 743/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4812 - accuracy: 0.7809 - val_loss: 0.4805 - val_accuracy: 0.7719\n",
            "Epoch 744/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4938 - accuracy: 0.7745 - val_loss: 0.4801 - val_accuracy: 0.7710\n",
            "Epoch 745/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4889 - accuracy: 0.7745 - val_loss: 0.4796 - val_accuracy: 0.7715\n",
            "Epoch 746/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4838 - accuracy: 0.7759 - val_loss: 0.4797 - val_accuracy: 0.7706\n",
            "Epoch 747/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4831 - accuracy: 0.7748 - val_loss: 0.4785 - val_accuracy: 0.7733\n",
            "Epoch 748/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4853 - accuracy: 0.7738 - val_loss: 0.4797 - val_accuracy: 0.7742\n",
            "Epoch 749/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4828 - accuracy: 0.7751 - val_loss: 0.4791 - val_accuracy: 0.7746\n",
            "Epoch 750/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4904 - accuracy: 0.7715 - val_loss: 0.4789 - val_accuracy: 0.7737\n",
            "Epoch 751/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4920 - accuracy: 0.7713 - val_loss: 0.4787 - val_accuracy: 0.7728\n",
            "Epoch 752/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4930 - accuracy: 0.7718 - val_loss: 0.4801 - val_accuracy: 0.7742\n",
            "Epoch 753/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4818 - accuracy: 0.7797 - val_loss: 0.4792 - val_accuracy: 0.7733\n",
            "Epoch 754/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4905 - accuracy: 0.7707 - val_loss: 0.4788 - val_accuracy: 0.7728\n",
            "Epoch 755/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4778 - accuracy: 0.7787 - val_loss: 0.4791 - val_accuracy: 0.7710\n",
            "Epoch 756/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4842 - accuracy: 0.7789 - val_loss: 0.4798 - val_accuracy: 0.7706\n",
            "Epoch 757/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4889 - accuracy: 0.7733 - val_loss: 0.4794 - val_accuracy: 0.7724\n",
            "Epoch 758/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4915 - accuracy: 0.7659 - val_loss: 0.4797 - val_accuracy: 0.7719\n",
            "Epoch 759/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4870 - accuracy: 0.7756 - val_loss: 0.4809 - val_accuracy: 0.7728\n",
            "Epoch 760/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4849 - accuracy: 0.7744 - val_loss: 0.4797 - val_accuracy: 0.7742\n",
            "Epoch 761/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4910 - accuracy: 0.7744 - val_loss: 0.4803 - val_accuracy: 0.7679\n",
            "Epoch 762/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4917 - accuracy: 0.7669 - val_loss: 0.4789 - val_accuracy: 0.7710\n",
            "Epoch 763/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4960 - accuracy: 0.7637 - val_loss: 0.4785 - val_accuracy: 0.7746\n",
            "Epoch 764/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4787 - accuracy: 0.7815 - val_loss: 0.4801 - val_accuracy: 0.7746\n",
            "Epoch 765/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.5003 - accuracy: 0.7687 - val_loss: 0.4792 - val_accuracy: 0.7728\n",
            "Epoch 766/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4955 - accuracy: 0.7673 - val_loss: 0.4785 - val_accuracy: 0.7728\n",
            "Epoch 767/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4887 - accuracy: 0.7726 - val_loss: 0.4796 - val_accuracy: 0.7697\n",
            "Epoch 768/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4893 - accuracy: 0.7708 - val_loss: 0.4788 - val_accuracy: 0.7746\n",
            "Epoch 769/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4888 - accuracy: 0.7787 - val_loss: 0.4797 - val_accuracy: 0.7710\n",
            "Epoch 770/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4854 - accuracy: 0.7775 - val_loss: 0.4800 - val_accuracy: 0.7715\n",
            "Epoch 771/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4943 - accuracy: 0.7687 - val_loss: 0.4797 - val_accuracy: 0.7710\n",
            "Epoch 772/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4904 - accuracy: 0.7752 - val_loss: 0.4789 - val_accuracy: 0.7728\n",
            "Epoch 773/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4941 - accuracy: 0.7720 - val_loss: 0.4783 - val_accuracy: 0.7733\n",
            "Epoch 774/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4842 - accuracy: 0.7794 - val_loss: 0.4788 - val_accuracy: 0.7733\n",
            "Epoch 775/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4884 - accuracy: 0.7767 - val_loss: 0.4787 - val_accuracy: 0.7724\n",
            "Epoch 776/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4795 - accuracy: 0.7786 - val_loss: 0.4799 - val_accuracy: 0.7751\n",
            "Epoch 777/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4971 - accuracy: 0.7634 - val_loss: 0.4788 - val_accuracy: 0.7742\n",
            "Epoch 778/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4807 - accuracy: 0.7783 - val_loss: 0.4797 - val_accuracy: 0.7733\n",
            "Epoch 779/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4956 - accuracy: 0.7661 - val_loss: 0.4797 - val_accuracy: 0.7710\n",
            "Epoch 780/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4894 - accuracy: 0.7765 - val_loss: 0.4797 - val_accuracy: 0.7728\n",
            "Epoch 781/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4822 - accuracy: 0.7713 - val_loss: 0.4799 - val_accuracy: 0.7706\n",
            "Epoch 782/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4760 - accuracy: 0.7786 - val_loss: 0.4793 - val_accuracy: 0.7733\n",
            "Epoch 783/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4938 - accuracy: 0.7675 - val_loss: 0.4790 - val_accuracy: 0.7719\n",
            "Epoch 784/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4975 - accuracy: 0.7702 - val_loss: 0.4787 - val_accuracy: 0.7710\n",
            "Epoch 785/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4855 - accuracy: 0.7732 - val_loss: 0.4788 - val_accuracy: 0.7728\n",
            "Epoch 786/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4992 - accuracy: 0.7625 - val_loss: 0.4788 - val_accuracy: 0.7702\n",
            "Epoch 787/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4856 - accuracy: 0.7745 - val_loss: 0.4784 - val_accuracy: 0.7724\n",
            "Epoch 788/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4887 - accuracy: 0.7705 - val_loss: 0.4797 - val_accuracy: 0.7710\n",
            "Epoch 789/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4934 - accuracy: 0.7674 - val_loss: 0.4792 - val_accuracy: 0.7710\n",
            "Epoch 790/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4934 - accuracy: 0.7681 - val_loss: 0.4793 - val_accuracy: 0.7715\n",
            "Epoch 791/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4851 - accuracy: 0.7752 - val_loss: 0.4803 - val_accuracy: 0.7702\n",
            "Epoch 792/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4890 - accuracy: 0.7750 - val_loss: 0.4810 - val_accuracy: 0.7706\n",
            "Epoch 793/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4963 - accuracy: 0.7707 - val_loss: 0.4787 - val_accuracy: 0.7733\n",
            "Epoch 794/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4937 - accuracy: 0.7614 - val_loss: 0.4792 - val_accuracy: 0.7715\n",
            "Epoch 795/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4876 - accuracy: 0.7726 - val_loss: 0.4798 - val_accuracy: 0.7733\n",
            "Epoch 796/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4852 - accuracy: 0.7767 - val_loss: 0.4813 - val_accuracy: 0.7728\n",
            "Epoch 797/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4847 - accuracy: 0.7757 - val_loss: 0.4797 - val_accuracy: 0.7710\n",
            "Epoch 798/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4818 - accuracy: 0.7791 - val_loss: 0.4790 - val_accuracy: 0.7719\n",
            "Epoch 799/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4829 - accuracy: 0.7751 - val_loss: 0.4793 - val_accuracy: 0.7719\n",
            "Epoch 800/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4855 - accuracy: 0.7767 - val_loss: 0.4803 - val_accuracy: 0.7706\n",
            "Epoch 801/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4852 - accuracy: 0.7747 - val_loss: 0.4809 - val_accuracy: 0.7733\n",
            "Epoch 802/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4945 - accuracy: 0.7721 - val_loss: 0.4786 - val_accuracy: 0.7737\n",
            "Epoch 803/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4924 - accuracy: 0.7688 - val_loss: 0.4805 - val_accuracy: 0.7693\n",
            "Epoch 804/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4900 - accuracy: 0.7751 - val_loss: 0.4793 - val_accuracy: 0.7733\n",
            "Epoch 805/1500\n",
            "328/328 [==============================] - 2s 5ms/step - loss: 0.4826 - accuracy: 0.7801 - val_loss: 0.4795 - val_accuracy: 0.7697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CN4trzHhcCf",
        "outputId": "0d56069c-858c-45c2-8a90-94b0581c21a5"
      },
      "source": [
        "def eval_model(model, x, true_label, ds_name=\"Training\"):\r\n",
        "  loss, acc = model.evaluate(x, true_label, verbose=0)\r\n",
        "  print(\"{} Dataset: loss = {} and acccuracy = {}\".format(ds_name, np.round(loss, 4), np.round(acc, 4)))\r\n",
        "\r\n",
        "eval_model(model, xtrain_vec, ytrain, \"Training\")\r\n",
        "eval_model(model, xval_vec, yval,\"Validation\")\r\n",
        "eval_model(model, xtest_vec, ytest,\"Test\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Dataset: loss = 0.4802 and acccuracy = 0.7757\n",
            "Validation Dataset: loss = 0.4783 and acccuracy = 0.7737\n",
            "Test Dataset: loss = 0.4759 and acccuracy = 0.7817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18ulk79tRC6f"
      },
      "source": [
        "# saving current model\r\n",
        "model.save(MODEL_DIR+SUFFIX+'_nn'+DATE+\".h5\")\r\n",
        "save_hist(model_hist, '_prediction_history.csv')\r\n",
        "\r\n",
        "ytrain_pred = model.predict(xtrain_vec)\r\n",
        "yval_pred = model.predict(xval_vec)\r\n",
        "ytest_pred = model.predict(xtest_vec)\r\n",
        "save_prediction()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "gkvjFutWfpMW",
        "outputId": "0c23597e-1067-4293-9a50-175dec0c4790"
      },
      "source": [
        "plot_ROC(ytrain,ytrain_pred, title='ROC on histone training')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "qeqR6tkchyaE",
        "outputId": "87ec5371-c998-4989-9a56-12f8ae47d365"
      },
      "source": [
        "plot_recall_precision(ytrain, ytrain_pred, title='precision/recall on histone training')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "xYs8UFpbSM1N",
        "outputId": "50064b44-0dd7-47c6-88a6-fe26e6accb5b"
      },
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\r\n",
        "for i in range(1):\r\n",
        "  ax1 = axes[0]\r\n",
        "  ax2 = axes[1]\r\n",
        "\r\n",
        "  ax1.plot(model_hist.history['loss'], label='training')\r\n",
        "  ax1.plot(model_hist.history['val_loss'], label='validation')\r\n",
        "  ax1.set_title('model loss')\r\n",
        "  ax1.set_xlabel('epoch')\r\n",
        "  ax1.set_ylabel('loss')\r\n",
        "  ax1.legend(['train', 'validation'], loc='upper left')\r\n",
        "  \r\n",
        "  ax2.plot(model_hist.history['accuracy'], label='training')\r\n",
        "  ax2.plot(model_hist.history['val_accuracy'], label='validation')\r\n",
        "  ax2.set_title('model accuracy')\r\n",
        "  ax2.set_xlabel('epoch')\r\n",
        "  ax2.set_ylabel('accuracy')\r\n",
        "  ax2.legend(['train', 'validation'], loc='upper left')\r\n",
        "fig.tight_layout()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJ1FMrCoSOZ4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}

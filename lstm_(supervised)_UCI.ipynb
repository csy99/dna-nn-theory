{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm_(supervised)_UCI.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNkq/VIKOHigSnJMlwt4RlQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/csy99/dna-nn-theory/blob/master/lstm_(supervised)_UCI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiSO3GWw8FWG"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import product\n",
        "import re\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.manifold import TSNE\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuvNh5Ia8vvD"
      },
      "source": [
        "# Read Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5SYc4iv-RPC",
        "outputId": "61caf559-f868-4211-bd42-350bb85e89d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "source": [
        "!pip install PyDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyDrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.7.12)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.15.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.17.2)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.17.4)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.6)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (50.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (4.1.1)\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTavNzohPEjl"
      },
      "source": [
        "def convert_label(row):\n",
        "  if row[\"Classes\"] == 'EI':\n",
        "    return 0\n",
        "  if row[\"Classes\"] == 'IE':\n",
        "    return 1\n",
        "  if row[\"Classes\"] == 'N':\n",
        "    return 2"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAJOTdQfNGIB",
        "outputId": "daf59ad2-ea75-4f5f-8f52-08cadc85eca2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        }
      },
      "source": [
        "data_path = '/content/gdrive/My Drive/Colab Notebooks/UCI/'\n",
        "splice_df = pd.read_csv(data_path + 'splice.data', header=None)\n",
        "splice_df.columns = ['Classes', 'Name', 'Seq']\n",
        "splice_df[\"Seq\"] = splice_df[\"Seq\"].str.replace(' ', '').str.replace('N', 'A').str.replace('D', 'T').str.replace('S', 'C').str.replace('R', 'G')\n",
        "splice_df[\"Label\"] = splice_df.apply(lambda row: convert_label(row), axis=1)\n",
        "print('The shape of the datasize is', splice_df.shape)\n",
        "splice_df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of the datasize is (3190, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classes</th>\n",
              "      <th>Name</th>\n",
              "      <th>Seq</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>EI</td>\n",
              "      <td>ATRINS-DONOR-521</td>\n",
              "      <td>CCAGCTGCATCACAGGAGGCCAGCGAGCAGGTCTGTTCCAAGGGCC...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>EI</td>\n",
              "      <td>ATRINS-DONOR-905</td>\n",
              "      <td>AGACCCGCCGGGAGGCGGAGGACCTGCAGGGTGAGCCCCACCGCCC...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>EI</td>\n",
              "      <td>BABAPOE-DONOR-30</td>\n",
              "      <td>GAGGTGAAGGACGTCCTTCCCCAGGAGCCGGTGAGAAGCGCAGTCG...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>EI</td>\n",
              "      <td>BABAPOE-DONOR-867</td>\n",
              "      <td>GGGCTGCGTTGCTGGTCACATTCCTGGCAGGTATGGGGCGGGGCTT...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>EI</td>\n",
              "      <td>BABAPOE-DONOR-2817</td>\n",
              "      <td>GCTCAGCCCCCAGGTCACCCAGGAACTGACGTGAGTGTCCCCATCC...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Classes  ... Label\n",
              "0      EI  ...     0\n",
              "1      EI  ...     0\n",
              "2      EI  ...     0\n",
              "3      EI  ...     0\n",
              "4      EI  ...     0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_IFMicpqYIl"
      },
      "source": [
        "seq_num = 0\n",
        "for seq in splice_df[\"Seq\"]:\n",
        "  char_num = 0\n",
        "  for char in seq:\n",
        "    if char != 'A' and char != 'C' and char != 'T' and char != 'G':\n",
        "      print(\"seq\", seq_num, 'char', char_num, 'is', char)\n",
        "    char_num += 1\n",
        "  seq_num += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSFFjXSJP88L",
        "outputId": "3ccdfd57-e29a-4223-852b-e88c368a988d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# check if the length of the sequence is the same \n",
        "seq_len = len(splice_df.Seq[0])\n",
        "print(\"The length of the sequence is\", seq_len)\n",
        "for seq in splice_df.Seq[:200]:\n",
        "  assert len(seq) == seq_len"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The length of the sequence is 60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiHtYnLfkcrz",
        "outputId": "14620219-0242-4d7d-f3d1-b853a9549a4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "xtrain_full, xtest, ytrain_full, ytest = train_test_split(splice_df, splice_df.Label, test_size=0.2, random_state=100, stratify=splice_df.Label)\n",
        "xtrain, xval, ytrain, yval = train_test_split(xtrain_full, ytrain_full, test_size=0.2, random_state=100, stratify=ytrain_full)\n",
        "print(\"shape of training, validation, test set\\n\", xtrain.shape, xval.shape, xtest.shape, ytrain.shape, yval.shape, ytest.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of training, validation, test set\n",
            " (2041, 4) (511, 4) (638, 4) (2041,) (511,) (638,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2h9sGLCVtDn",
        "outputId": "a7754d3c-42d3-4625-ee8d-99ba52ad1eef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "word_size = 1\n",
        "vocab = [''.join(p) for p in product('ACGT', repeat=word_size)]\n",
        "word_to_idx = {word: i for i, word in enumerate(vocab)}\n",
        "vocab_size = len(word_to_idx)\n",
        "print('vocab_size:', vocab_size)\n",
        "create1gram = keras.layers.experimental.preprocessing.TextVectorization(\n",
        "  standardize=lambda x: tf.strings.regex_replace(x, '(.)', '\\\\1 '), ngrams=1\n",
        ")\n",
        "create1gram.adapt(vocab)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab_size: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHPvs2BCU_Mk"
      },
      "source": [
        "def ds_preprocess(x, y):\n",
        "  x_index = tf.subtract(create1gram(x), 2)\n",
        "  return x_index, y"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFvsJkEa0YuT",
        "outputId": "180f9496-ee22-47c1-920e-672611f9e7cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# not sure the correct way to get mapping from word to its index\n",
        "create1gram('A C G T') - 2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([3, 2, 1, 0])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzLRmqEjSitl"
      },
      "source": [
        "BATCH_SIZE = 256\n",
        "xtrain_ds = tf.data.Dataset.from_tensor_slices((splice_df['Seq'], splice_df['Label'])).map(ds_preprocess).batch(BATCH_SIZE)\n",
        "xval_ds = tf.data.Dataset.from_tensor_slices((splice_df['Seq'], splice_df['Label'])).map(ds_preprocess).batch(BATCH_SIZE)\n",
        "xtest_ds = tf.data.Dataset.from_tensor_slices((splice_df['Seq'], splice_df['Label'])).map(ds_preprocess).batch(BATCH_SIZE)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVLaIchQUWQl",
        "outputId": "17ebf21b-5b36-471d-89c3-6e3b323c8379",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        }
      },
      "source": [
        "latent_size = 30\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.Input(shape=(seq_len,)),\n",
        "    keras.layers.Embedding(seq_len, latent_size),\n",
        "    keras.layers.LSTM(latent_size, return_sequences=False),\n",
        "    keras.layers.Dense(128, activation=\"relu\", input_shape=[latent_size]),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(64, activation=\"relu\"),    \n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(32, activation=\"relu\"),  \n",
        "    keras.layers.Dropout(0.2), \n",
        "    keras.layers.Dense(16, activation=\"relu\"), \n",
        "    keras.layers.Dropout(0.2),   \n",
        "    keras.layers.Dense(3, activation=\"softmax\")                                \n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 60, 30)            1800      \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 30)                7320      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 128)               3968      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 24,003\n",
            "Trainable params: 24,003\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMlnaNStWLNK",
        "outputId": "a3f92157-b888-42c1-8fc5-eecf3255f8d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "es_cb = keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True)\n",
        "model.compile(keras.optimizers.Adam(0.0005), loss=keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
        "hist = model.fit(xtrain_ds, validation_data=xval_ds, epochs=1000, callbacks=[es_cb])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "13/13 [==============================] - 1s 114ms/step - loss: 1.1034 - accuracy: 0.1840 - val_loss: 1.0989 - val_accuracy: 0.2404\n",
            "Epoch 2/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 1.0982 - accuracy: 0.2549 - val_loss: 1.0969 - val_accuracy: 0.3577\n",
            "Epoch 3/1000\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 1.0960 - accuracy: 0.4784 - val_loss: 1.0944 - val_accuracy: 0.5188\n",
            "Epoch 4/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 1.0933 - accuracy: 0.5078 - val_loss: 1.0916 - val_accuracy: 0.5188\n",
            "Epoch 5/1000\n",
            "13/13 [==============================] - 1s 92ms/step - loss: 1.0898 - accuracy: 0.5116 - val_loss: 1.0879 - val_accuracy: 0.5188\n",
            "Epoch 6/1000\n",
            "13/13 [==============================] - 1s 88ms/step - loss: 1.0858 - accuracy: 0.5100 - val_loss: 1.0827 - val_accuracy: 0.5188\n",
            "Epoch 7/1000\n",
            "13/13 [==============================] - 1s 89ms/step - loss: 1.0783 - accuracy: 0.5141 - val_loss: 1.0748 - val_accuracy: 0.5188\n",
            "Epoch 8/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 1.0699 - accuracy: 0.5169 - val_loss: 1.0652 - val_accuracy: 0.5188\n",
            "Epoch 9/1000\n",
            "13/13 [==============================] - 1s 92ms/step - loss: 1.0655 - accuracy: 0.5172 - val_loss: 1.0565 - val_accuracy: 0.5188\n",
            "Epoch 10/1000\n",
            "13/13 [==============================] - 1s 90ms/step - loss: 1.0588 - accuracy: 0.5163 - val_loss: 1.0478 - val_accuracy: 0.5188\n",
            "Epoch 11/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 1.0552 - accuracy: 0.5188 - val_loss: 1.0411 - val_accuracy: 0.5188\n",
            "Epoch 12/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 1.0551 - accuracy: 0.5179 - val_loss: 1.0367 - val_accuracy: 0.5188\n",
            "Epoch 13/1000\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 1.0506 - accuracy: 0.5182 - val_loss: 1.0333 - val_accuracy: 0.5188\n",
            "Epoch 14/1000\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 1.0503 - accuracy: 0.5182 - val_loss: 1.0309 - val_accuracy: 0.5188\n",
            "Epoch 15/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 1.0448 - accuracy: 0.5182 - val_loss: 1.0289 - val_accuracy: 0.5188\n",
            "Epoch 16/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 1.0447 - accuracy: 0.5172 - val_loss: 1.0272 - val_accuracy: 0.5188\n",
            "Epoch 17/1000\n",
            "13/13 [==============================] - 1s 102ms/step - loss: 1.0526 - accuracy: 0.5185 - val_loss: 1.0266 - val_accuracy: 0.5188\n",
            "Epoch 18/1000\n",
            "13/13 [==============================] - 1s 94ms/step - loss: 1.0460 - accuracy: 0.5176 - val_loss: 1.0260 - val_accuracy: 0.5188\n",
            "Epoch 19/1000\n",
            "13/13 [==============================] - 1s 98ms/step - loss: 1.0446 - accuracy: 0.5188 - val_loss: 1.0252 - val_accuracy: 0.5188\n",
            "Epoch 20/1000\n",
            "13/13 [==============================] - 1s 96ms/step - loss: 1.0423 - accuracy: 0.5179 - val_loss: 1.0243 - val_accuracy: 0.5188\n",
            "Epoch 21/1000\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 1.0449 - accuracy: 0.5191 - val_loss: 1.0238 - val_accuracy: 0.5188\n",
            "Epoch 22/1000\n",
            "13/13 [==============================] - 1s 93ms/step - loss: 1.0382 - accuracy: 0.5191 - val_loss: 1.0231 - val_accuracy: 0.5188\n",
            "Epoch 23/1000\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 1.0446 - accuracy: 0.5188 - val_loss: 1.0227 - val_accuracy: 0.5188\n",
            "Epoch 24/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 1.0420 - accuracy: 0.5185 - val_loss: 1.0224 - val_accuracy: 0.5188\n",
            "Epoch 25/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 1.0389 - accuracy: 0.5191 - val_loss: 1.0219 - val_accuracy: 0.5188\n",
            "Epoch 26/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 1.0379 - accuracy: 0.5188 - val_loss: 1.0214 - val_accuracy: 0.5188\n",
            "Epoch 27/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 1.0381 - accuracy: 0.5197 - val_loss: 1.0210 - val_accuracy: 0.5188\n",
            "Epoch 28/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 1.0379 - accuracy: 0.5191 - val_loss: 1.0206 - val_accuracy: 0.5188\n",
            "Epoch 29/1000\n",
            "13/13 [==============================] - 1s 102ms/step - loss: 1.0427 - accuracy: 0.5185 - val_loss: 1.0204 - val_accuracy: 0.5188\n",
            "Epoch 30/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 1.0424 - accuracy: 0.5188 - val_loss: 1.0203 - val_accuracy: 0.5188\n",
            "Epoch 31/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 1.0383 - accuracy: 0.5185 - val_loss: 1.0200 - val_accuracy: 0.5188\n",
            "Epoch 32/1000\n",
            "13/13 [==============================] - 1s 91ms/step - loss: 1.0381 - accuracy: 0.5191 - val_loss: 1.0197 - val_accuracy: 0.5188\n",
            "Epoch 33/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 1.0388 - accuracy: 0.5182 - val_loss: 1.0195 - val_accuracy: 0.5188\n",
            "Epoch 34/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 1.0395 - accuracy: 0.5185 - val_loss: 1.0193 - val_accuracy: 0.5188\n",
            "Epoch 35/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 1.0341 - accuracy: 0.5188 - val_loss: 1.0190 - val_accuracy: 0.5188\n",
            "Epoch 36/1000\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 1.0380 - accuracy: 0.5188 - val_loss: 1.0187 - val_accuracy: 0.5188\n",
            "Epoch 37/1000\n",
            "13/13 [==============================] - 1s 94ms/step - loss: 1.0360 - accuracy: 0.5188 - val_loss: 1.0184 - val_accuracy: 0.5188\n",
            "Epoch 38/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 1.0376 - accuracy: 0.5188 - val_loss: 1.0182 - val_accuracy: 0.5188\n",
            "Epoch 39/1000\n",
            "13/13 [==============================] - 1s 86ms/step - loss: 1.0368 - accuracy: 0.5188 - val_loss: 1.0178 - val_accuracy: 0.5188\n",
            "Epoch 40/1000\n",
            "13/13 [==============================] - 1s 103ms/step - loss: 1.0340 - accuracy: 0.5188 - val_loss: 1.0175 - val_accuracy: 0.5188\n",
            "Epoch 41/1000\n",
            "13/13 [==============================] - 1s 99ms/step - loss: 1.0407 - accuracy: 0.5188 - val_loss: 1.0172 - val_accuracy: 0.5188\n",
            "Epoch 42/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 1.0398 - accuracy: 0.5191 - val_loss: 1.0166 - val_accuracy: 0.5188\n",
            "Epoch 43/1000\n",
            "13/13 [==============================] - 1s 89ms/step - loss: 1.0381 - accuracy: 0.5188 - val_loss: 1.0162 - val_accuracy: 0.5188\n",
            "Epoch 44/1000\n",
            "13/13 [==============================] - 1s 95ms/step - loss: 1.0339 - accuracy: 0.5188 - val_loss: 1.0145 - val_accuracy: 0.5188\n",
            "Epoch 45/1000\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 1.0346 - accuracy: 0.5188 - val_loss: 1.0148 - val_accuracy: 0.5188\n",
            "Epoch 46/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 1.0390 - accuracy: 0.5188 - val_loss: 1.0139 - val_accuracy: 0.5188\n",
            "Epoch 47/1000\n",
            "13/13 [==============================] - 1s 89ms/step - loss: 1.0332 - accuracy: 0.5188 - val_loss: 1.0138 - val_accuracy: 0.5188\n",
            "Epoch 48/1000\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 1.0311 - accuracy: 0.5185 - val_loss: 1.0130 - val_accuracy: 0.5188\n",
            "Epoch 49/1000\n",
            "13/13 [==============================] - 1s 94ms/step - loss: 1.0327 - accuracy: 0.5188 - val_loss: 1.0114 - val_accuracy: 0.5188\n",
            "Epoch 50/1000\n",
            "13/13 [==============================] - 1s 91ms/step - loss: 1.0277 - accuracy: 0.5185 - val_loss: 1.0090 - val_accuracy: 0.5188\n",
            "Epoch 51/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 1.0299 - accuracy: 0.5188 - val_loss: 1.0063 - val_accuracy: 0.5188\n",
            "Epoch 52/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 1.0250 - accuracy: 0.5188 - val_loss: 1.0020 - val_accuracy: 0.5188\n",
            "Epoch 53/1000\n",
            "13/13 [==============================] - 1s 95ms/step - loss: 1.0242 - accuracy: 0.5188 - val_loss: 0.9965 - val_accuracy: 0.5188\n",
            "Epoch 54/1000\n",
            "13/13 [==============================] - 1s 94ms/step - loss: 1.0229 - accuracy: 0.5188 - val_loss: 0.9922 - val_accuracy: 0.5188\n",
            "Epoch 55/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 1.0209 - accuracy: 0.5188 - val_loss: 0.9830 - val_accuracy: 0.5188\n",
            "Epoch 56/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 1.0209 - accuracy: 0.5188 - val_loss: 0.9744 - val_accuracy: 0.5188\n",
            "Epoch 57/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 1.0280 - accuracy: 0.5188 - val_loss: 0.9831 - val_accuracy: 0.5188\n",
            "Epoch 58/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 1.0573 - accuracy: 0.5188 - val_loss: 1.0039 - val_accuracy: 0.5188\n",
            "Epoch 59/1000\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 1.0125 - accuracy: 0.5188 - val_loss: 0.9921 - val_accuracy: 0.5188\n",
            "Epoch 60/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.9965 - accuracy: 0.5188 - val_loss: 0.9773 - val_accuracy: 0.5188\n",
            "Epoch 61/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 1.0204 - accuracy: 0.5188 - val_loss: 0.9745 - val_accuracy: 0.5188\n",
            "Epoch 62/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.9920 - accuracy: 0.5188 - val_loss: 0.9588 - val_accuracy: 0.5188\n",
            "Epoch 63/1000\n",
            "13/13 [==============================] - 1s 88ms/step - loss: 0.9879 - accuracy: 0.5185 - val_loss: 0.9469 - val_accuracy: 0.5188\n",
            "Epoch 64/1000\n",
            "13/13 [==============================] - 1s 92ms/step - loss: 0.9666 - accuracy: 0.5188 - val_loss: 0.9247 - val_accuracy: 0.5188\n",
            "Epoch 65/1000\n",
            "13/13 [==============================] - 1s 88ms/step - loss: 0.9746 - accuracy: 0.5166 - val_loss: 0.9118 - val_accuracy: 0.5188\n",
            "Epoch 66/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.9489 - accuracy: 0.5147 - val_loss: 0.8987 - val_accuracy: 0.5188\n",
            "Epoch 67/1000\n",
            "13/13 [==============================] - 1s 91ms/step - loss: 0.9487 - accuracy: 0.5132 - val_loss: 0.8772 - val_accuracy: 0.5188\n",
            "Epoch 68/1000\n",
            "13/13 [==============================] - 1s 97ms/step - loss: 0.9345 - accuracy: 0.5176 - val_loss: 0.8830 - val_accuracy: 0.5188\n",
            "Epoch 69/1000\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.9489 - accuracy: 0.5169 - val_loss: 0.8676 - val_accuracy: 0.5188\n",
            "Epoch 70/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.9319 - accuracy: 0.5141 - val_loss: 0.8737 - val_accuracy: 0.5188\n",
            "Epoch 71/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.9339 - accuracy: 0.5241 - val_loss: 0.8432 - val_accuracy: 0.5790\n",
            "Epoch 72/1000\n",
            "13/13 [==============================] - 1s 90ms/step - loss: 0.8993 - accuracy: 0.5436 - val_loss: 0.8362 - val_accuracy: 0.6354\n",
            "Epoch 73/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.8711 - accuracy: 0.5699 - val_loss: 0.8117 - val_accuracy: 0.6386\n",
            "Epoch 74/1000\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.8754 - accuracy: 0.5636 - val_loss: 0.8031 - val_accuracy: 0.6320\n",
            "Epoch 75/1000\n",
            "13/13 [==============================] - 1s 90ms/step - loss: 0.8543 - accuracy: 0.5840 - val_loss: 0.7856 - val_accuracy: 0.6361\n",
            "Epoch 76/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.8554 - accuracy: 0.5803 - val_loss: 0.7770 - val_accuracy: 0.6326\n",
            "Epoch 77/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.8537 - accuracy: 0.5893 - val_loss: 0.7718 - val_accuracy: 0.6354\n",
            "Epoch 78/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.8315 - accuracy: 0.5991 - val_loss: 0.7666 - val_accuracy: 0.6304\n",
            "Epoch 79/1000\n",
            "13/13 [==============================] - 1s 86ms/step - loss: 0.8612 - accuracy: 0.5887 - val_loss: 0.7659 - val_accuracy: 0.6357\n",
            "Epoch 80/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.8370 - accuracy: 0.5915 - val_loss: 0.7727 - val_accuracy: 0.6179\n",
            "Epoch 81/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.8676 - accuracy: 0.6060 - val_loss: 0.7755 - val_accuracy: 0.6376\n",
            "Epoch 82/1000\n",
            "13/13 [==============================] - 1s 90ms/step - loss: 0.8352 - accuracy: 0.5781 - val_loss: 0.7771 - val_accuracy: 0.6129\n",
            "Epoch 83/1000\n",
            "13/13 [==============================] - 1s 94ms/step - loss: 0.8538 - accuracy: 0.6003 - val_loss: 0.7632 - val_accuracy: 0.6404\n",
            "Epoch 84/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.8349 - accuracy: 0.5915 - val_loss: 0.7574 - val_accuracy: 0.6329\n",
            "Epoch 85/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.8225 - accuracy: 0.6132 - val_loss: 0.7455 - val_accuracy: 0.6451\n",
            "Epoch 86/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.8134 - accuracy: 0.6116 - val_loss: 0.7414 - val_accuracy: 0.6429\n",
            "Epoch 87/1000\n",
            "13/13 [==============================] - 1s 92ms/step - loss: 0.8092 - accuracy: 0.6207 - val_loss: 0.7356 - val_accuracy: 0.6464\n",
            "Epoch 88/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.8069 - accuracy: 0.6147 - val_loss: 0.7341 - val_accuracy: 0.6455\n",
            "Epoch 89/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.8145 - accuracy: 0.6185 - val_loss: 0.7293 - val_accuracy: 0.6495\n",
            "Epoch 90/1000\n",
            "13/13 [==============================] - 1s 86ms/step - loss: 0.7911 - accuracy: 0.6260 - val_loss: 0.7290 - val_accuracy: 0.6486\n",
            "Epoch 91/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.8070 - accuracy: 0.6150 - val_loss: 0.7253 - val_accuracy: 0.6580\n",
            "Epoch 92/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.7879 - accuracy: 0.6129 - val_loss: 0.7342 - val_accuracy: 0.6448\n",
            "Epoch 93/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.8064 - accuracy: 0.6279 - val_loss: 0.7247 - val_accuracy: 0.6586\n",
            "Epoch 94/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.7925 - accuracy: 0.6147 - val_loss: 0.7338 - val_accuracy: 0.6464\n",
            "Epoch 95/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.7949 - accuracy: 0.6288 - val_loss: 0.7235 - val_accuracy: 0.6589\n",
            "Epoch 96/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.7974 - accuracy: 0.6141 - val_loss: 0.7248 - val_accuracy: 0.6552\n",
            "Epoch 97/1000\n",
            "13/13 [==============================] - 1s 89ms/step - loss: 0.7921 - accuracy: 0.6310 - val_loss: 0.7190 - val_accuracy: 0.6618\n",
            "Epoch 98/1000\n",
            "13/13 [==============================] - 1s 94ms/step - loss: 0.7788 - accuracy: 0.6276 - val_loss: 0.7201 - val_accuracy: 0.6549\n",
            "Epoch 99/1000\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 0.7955 - accuracy: 0.6301 - val_loss: 0.7137 - val_accuracy: 0.6636\n",
            "Epoch 100/1000\n",
            "13/13 [==============================] - 1s 84ms/step - loss: 0.7778 - accuracy: 0.6176 - val_loss: 0.7188 - val_accuracy: 0.6508\n",
            "Epoch 101/1000\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.7870 - accuracy: 0.6329 - val_loss: 0.7092 - val_accuracy: 0.6633\n",
            "Epoch 102/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.7747 - accuracy: 0.6223 - val_loss: 0.7128 - val_accuracy: 0.6574\n",
            "Epoch 103/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.7792 - accuracy: 0.6364 - val_loss: 0.7070 - val_accuracy: 0.6671\n",
            "Epoch 104/1000\n",
            "13/13 [==============================] - 1s 88ms/step - loss: 0.7778 - accuracy: 0.6213 - val_loss: 0.7130 - val_accuracy: 0.6583\n",
            "Epoch 105/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.7896 - accuracy: 0.6345 - val_loss: 0.7058 - val_accuracy: 0.6677\n",
            "Epoch 106/1000\n",
            "13/13 [==============================] - 1s 93ms/step - loss: 0.7773 - accuracy: 0.6301 - val_loss: 0.7080 - val_accuracy: 0.6574\n",
            "Epoch 107/1000\n",
            "13/13 [==============================] - 1s 91ms/step - loss: 0.7764 - accuracy: 0.6273 - val_loss: 0.7008 - val_accuracy: 0.6715\n",
            "Epoch 108/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.7683 - accuracy: 0.6313 - val_loss: 0.7023 - val_accuracy: 0.6646\n",
            "Epoch 109/1000\n",
            "13/13 [==============================] - 1s 86ms/step - loss: 0.7668 - accuracy: 0.6379 - val_loss: 0.6987 - val_accuracy: 0.6699\n",
            "Epoch 110/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.7643 - accuracy: 0.6386 - val_loss: 0.6981 - val_accuracy: 0.6712\n",
            "Epoch 111/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.7715 - accuracy: 0.6373 - val_loss: 0.6959 - val_accuracy: 0.6727\n",
            "Epoch 112/1000\n",
            "13/13 [==============================] - 1s 91ms/step - loss: 0.7637 - accuracy: 0.6367 - val_loss: 0.6964 - val_accuracy: 0.6721\n",
            "Epoch 113/1000\n",
            "13/13 [==============================] - 1s 92ms/step - loss: 0.7606 - accuracy: 0.6445 - val_loss: 0.6928 - val_accuracy: 0.6749\n",
            "Epoch 114/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.7618 - accuracy: 0.6404 - val_loss: 0.6985 - val_accuracy: 0.6668\n",
            "Epoch 115/1000\n",
            "13/13 [==============================] - 1s 103ms/step - loss: 0.7707 - accuracy: 0.6476 - val_loss: 0.6928 - val_accuracy: 0.6755\n",
            "Epoch 116/1000\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.7608 - accuracy: 0.6320 - val_loss: 0.6992 - val_accuracy: 0.6661\n",
            "Epoch 117/1000\n",
            "13/13 [==============================] - 1s 89ms/step - loss: 0.7734 - accuracy: 0.6423 - val_loss: 0.6933 - val_accuracy: 0.6740\n",
            "Epoch 118/1000\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.7628 - accuracy: 0.6348 - val_loss: 0.6957 - val_accuracy: 0.6708\n",
            "Epoch 119/1000\n",
            "13/13 [==============================] - 1s 86ms/step - loss: 0.7623 - accuracy: 0.6429 - val_loss: 0.6901 - val_accuracy: 0.6724\n",
            "Epoch 120/1000\n",
            "13/13 [==============================] - 1s 91ms/step - loss: 0.7566 - accuracy: 0.6417 - val_loss: 0.6930 - val_accuracy: 0.6721\n",
            "Epoch 121/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.7619 - accuracy: 0.6498 - val_loss: 0.6879 - val_accuracy: 0.6777\n",
            "Epoch 122/1000\n",
            "13/13 [==============================] - 1s 94ms/step - loss: 0.7469 - accuracy: 0.6445 - val_loss: 0.6913 - val_accuracy: 0.6765\n",
            "Epoch 123/1000\n",
            "13/13 [==============================] - 1s 90ms/step - loss: 0.7550 - accuracy: 0.6473 - val_loss: 0.6840 - val_accuracy: 0.6812\n",
            "Epoch 124/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.7591 - accuracy: 0.6423 - val_loss: 0.6869 - val_accuracy: 0.6784\n",
            "Epoch 125/1000\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.7503 - accuracy: 0.6489 - val_loss: 0.6833 - val_accuracy: 0.6796\n",
            "Epoch 126/1000\n",
            "13/13 [==============================] - 1s 88ms/step - loss: 0.7515 - accuracy: 0.6420 - val_loss: 0.6874 - val_accuracy: 0.6762\n",
            "Epoch 127/1000\n",
            "13/13 [==============================] - 1s 92ms/step - loss: 0.7662 - accuracy: 0.6439 - val_loss: 0.6822 - val_accuracy: 0.6815\n",
            "Epoch 128/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.7515 - accuracy: 0.6392 - val_loss: 0.6866 - val_accuracy: 0.6781\n",
            "Epoch 129/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.7571 - accuracy: 0.6483 - val_loss: 0.6792 - val_accuracy: 0.6821\n",
            "Epoch 130/1000\n",
            "13/13 [==============================] - 1s 84ms/step - loss: 0.7464 - accuracy: 0.6373 - val_loss: 0.6832 - val_accuracy: 0.6781\n",
            "Epoch 131/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.7539 - accuracy: 0.6433 - val_loss: 0.6774 - val_accuracy: 0.6824\n",
            "Epoch 132/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.7514 - accuracy: 0.6439 - val_loss: 0.6800 - val_accuracy: 0.6793\n",
            "Epoch 133/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.7454 - accuracy: 0.6599 - val_loss: 0.6760 - val_accuracy: 0.6837\n",
            "Epoch 134/1000\n",
            "13/13 [==============================] - 1s 93ms/step - loss: 0.7491 - accuracy: 0.6505 - val_loss: 0.6790 - val_accuracy: 0.6803\n",
            "Epoch 135/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.7459 - accuracy: 0.6564 - val_loss: 0.6750 - val_accuracy: 0.6846\n",
            "Epoch 136/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.7417 - accuracy: 0.6505 - val_loss: 0.6783 - val_accuracy: 0.6809\n",
            "Epoch 137/1000\n",
            "13/13 [==============================] - 1s 93ms/step - loss: 0.7501 - accuracy: 0.6564 - val_loss: 0.6739 - val_accuracy: 0.6843\n",
            "Epoch 138/1000\n",
            "13/13 [==============================] - 1s 86ms/step - loss: 0.7427 - accuracy: 0.6480 - val_loss: 0.6800 - val_accuracy: 0.6806\n",
            "Epoch 139/1000\n",
            "13/13 [==============================] - 1s 88ms/step - loss: 0.7534 - accuracy: 0.6586 - val_loss: 0.6730 - val_accuracy: 0.6818\n",
            "Epoch 140/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.7445 - accuracy: 0.6508 - val_loss: 0.6783 - val_accuracy: 0.6806\n",
            "Epoch 141/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.7511 - accuracy: 0.6577 - val_loss: 0.6725 - val_accuracy: 0.6862\n",
            "Epoch 142/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.7469 - accuracy: 0.6492 - val_loss: 0.6723 - val_accuracy: 0.6840\n",
            "Epoch 143/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.7374 - accuracy: 0.6633 - val_loss: 0.6683 - val_accuracy: 0.6887\n",
            "Epoch 144/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.7419 - accuracy: 0.6614 - val_loss: 0.6694 - val_accuracy: 0.6871\n",
            "Epoch 145/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.7324 - accuracy: 0.6639 - val_loss: 0.6661 - val_accuracy: 0.6881\n",
            "Epoch 146/1000\n",
            "13/13 [==============================] - 1s 75ms/step - loss: 0.7419 - accuracy: 0.6536 - val_loss: 0.6662 - val_accuracy: 0.6903\n",
            "Epoch 147/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.7301 - accuracy: 0.6561 - val_loss: 0.6657 - val_accuracy: 0.6903\n",
            "Epoch 148/1000\n",
            "13/13 [==============================] - 1s 84ms/step - loss: 0.7373 - accuracy: 0.6555 - val_loss: 0.6645 - val_accuracy: 0.6903\n",
            "Epoch 149/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.7354 - accuracy: 0.6533 - val_loss: 0.6639 - val_accuracy: 0.6890\n",
            "Epoch 150/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.7317 - accuracy: 0.6668 - val_loss: 0.6621 - val_accuracy: 0.6903\n",
            "Epoch 151/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.7343 - accuracy: 0.6602 - val_loss: 0.6627 - val_accuracy: 0.6922\n",
            "Epoch 152/1000\n",
            "13/13 [==============================] - 1s 86ms/step - loss: 0.7275 - accuracy: 0.6589 - val_loss: 0.6600 - val_accuracy: 0.6906\n",
            "Epoch 153/1000\n",
            "13/13 [==============================] - 1s 75ms/step - loss: 0.7383 - accuracy: 0.6552 - val_loss: 0.6601 - val_accuracy: 0.6931\n",
            "Epoch 154/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.7300 - accuracy: 0.6618 - val_loss: 0.6595 - val_accuracy: 0.6972\n",
            "Epoch 155/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.7294 - accuracy: 0.6639 - val_loss: 0.6573 - val_accuracy: 0.6959\n",
            "Epoch 156/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.7337 - accuracy: 0.6571 - val_loss: 0.6565 - val_accuracy: 0.6975\n",
            "Epoch 157/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.7207 - accuracy: 0.6618 - val_loss: 0.6617 - val_accuracy: 0.6975\n",
            "Epoch 158/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.7412 - accuracy: 0.6574 - val_loss: 0.6590 - val_accuracy: 0.6956\n",
            "Epoch 159/1000\n",
            "13/13 [==============================] - 1s 90ms/step - loss: 0.7214 - accuracy: 0.6715 - val_loss: 0.6618 - val_accuracy: 0.7000\n",
            "Epoch 160/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.7465 - accuracy: 0.6602 - val_loss: 0.6609 - val_accuracy: 0.6959\n",
            "Epoch 161/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.7160 - accuracy: 0.6633 - val_loss: 0.6616 - val_accuracy: 0.7016\n",
            "Epoch 162/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.7327 - accuracy: 0.6721 - val_loss: 0.6555 - val_accuracy: 0.7022\n",
            "Epoch 163/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.7230 - accuracy: 0.6639 - val_loss: 0.6622 - val_accuracy: 0.6984\n",
            "Epoch 164/1000\n",
            "13/13 [==============================] - 1s 89ms/step - loss: 0.7316 - accuracy: 0.6740 - val_loss: 0.6540 - val_accuracy: 0.7056\n",
            "Epoch 165/1000\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 0.7211 - accuracy: 0.6636 - val_loss: 0.6542 - val_accuracy: 0.7050\n",
            "Epoch 166/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.7280 - accuracy: 0.6586 - val_loss: 0.6502 - val_accuracy: 0.7069\n",
            "Epoch 167/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.7093 - accuracy: 0.6687 - val_loss: 0.6508 - val_accuracy: 0.7088\n",
            "Epoch 168/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.7234 - accuracy: 0.6702 - val_loss: 0.6493 - val_accuracy: 0.7063\n",
            "Epoch 169/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.7140 - accuracy: 0.6690 - val_loss: 0.6506 - val_accuracy: 0.7094\n",
            "Epoch 170/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.7171 - accuracy: 0.6737 - val_loss: 0.6480 - val_accuracy: 0.7069\n",
            "Epoch 171/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.7068 - accuracy: 0.6730 - val_loss: 0.6468 - val_accuracy: 0.7103\n",
            "Epoch 172/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.7277 - accuracy: 0.6765 - val_loss: 0.6472 - val_accuracy: 0.7047\n",
            "Epoch 173/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.7134 - accuracy: 0.6677 - val_loss: 0.6462 - val_accuracy: 0.7103\n",
            "Epoch 174/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.7142 - accuracy: 0.6724 - val_loss: 0.6430 - val_accuracy: 0.7110\n",
            "Epoch 175/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.7055 - accuracy: 0.6727 - val_loss: 0.6434 - val_accuracy: 0.7129\n",
            "Epoch 176/1000\n",
            "13/13 [==============================] - 1s 90ms/step - loss: 0.7048 - accuracy: 0.6743 - val_loss: 0.6414 - val_accuracy: 0.7141\n",
            "Epoch 177/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.7027 - accuracy: 0.6793 - val_loss: 0.6410 - val_accuracy: 0.7135\n",
            "Epoch 178/1000\n",
            "13/13 [==============================] - 1s 94ms/step - loss: 0.7043 - accuracy: 0.6799 - val_loss: 0.6392 - val_accuracy: 0.7144\n",
            "Epoch 179/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.7118 - accuracy: 0.6755 - val_loss: 0.6376 - val_accuracy: 0.7150\n",
            "Epoch 180/1000\n",
            "13/13 [==============================] - 1s 75ms/step - loss: 0.7073 - accuracy: 0.6699 - val_loss: 0.6373 - val_accuracy: 0.7157\n",
            "Epoch 181/1000\n",
            "13/13 [==============================] - 1s 96ms/step - loss: 0.7142 - accuracy: 0.6668 - val_loss: 0.6353 - val_accuracy: 0.7163\n",
            "Epoch 182/1000\n",
            "13/13 [==============================] - 1s 86ms/step - loss: 0.7064 - accuracy: 0.6818 - val_loss: 0.6355 - val_accuracy: 0.7144\n",
            "Epoch 183/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.7056 - accuracy: 0.6734 - val_loss: 0.6339 - val_accuracy: 0.7172\n",
            "Epoch 184/1000\n",
            "13/13 [==============================] - 1s 86ms/step - loss: 0.6958 - accuracy: 0.6799 - val_loss: 0.6325 - val_accuracy: 0.7166\n",
            "Epoch 185/1000\n",
            "13/13 [==============================] - 1s 84ms/step - loss: 0.6989 - accuracy: 0.6818 - val_loss: 0.6321 - val_accuracy: 0.7147\n",
            "Epoch 186/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.7067 - accuracy: 0.6749 - val_loss: 0.6306 - val_accuracy: 0.7169\n",
            "Epoch 187/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.7072 - accuracy: 0.6821 - val_loss: 0.6294 - val_accuracy: 0.7182\n",
            "Epoch 188/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.7026 - accuracy: 0.6821 - val_loss: 0.6294 - val_accuracy: 0.7188\n",
            "Epoch 189/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.6981 - accuracy: 0.6875 - val_loss: 0.6277 - val_accuracy: 0.7191\n",
            "Epoch 190/1000\n",
            "13/13 [==============================] - 1s 89ms/step - loss: 0.7064 - accuracy: 0.6806 - val_loss: 0.6267 - val_accuracy: 0.7219\n",
            "Epoch 191/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.7015 - accuracy: 0.6793 - val_loss: 0.6269 - val_accuracy: 0.7235\n",
            "Epoch 192/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.7077 - accuracy: 0.6853 - val_loss: 0.6239 - val_accuracy: 0.7251\n",
            "Epoch 193/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.6898 - accuracy: 0.6831 - val_loss: 0.6250 - val_accuracy: 0.7260\n",
            "Epoch 194/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.7022 - accuracy: 0.6856 - val_loss: 0.6214 - val_accuracy: 0.7276\n",
            "Epoch 195/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.7002 - accuracy: 0.6850 - val_loss: 0.6227 - val_accuracy: 0.7257\n",
            "Epoch 196/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.7019 - accuracy: 0.6900 - val_loss: 0.6208 - val_accuracy: 0.7273\n",
            "Epoch 197/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.6857 - accuracy: 0.6862 - val_loss: 0.6203 - val_accuracy: 0.7266\n",
            "Epoch 198/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.6927 - accuracy: 0.6931 - val_loss: 0.6179 - val_accuracy: 0.7304\n",
            "Epoch 199/1000\n",
            "13/13 [==============================] - 1s 86ms/step - loss: 0.6878 - accuracy: 0.6912 - val_loss: 0.6169 - val_accuracy: 0.7285\n",
            "Epoch 200/1000\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 0.6855 - accuracy: 0.6956 - val_loss: 0.6164 - val_accuracy: 0.7288\n",
            "Epoch 201/1000\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.6838 - accuracy: 0.6878 - val_loss: 0.6150 - val_accuracy: 0.7292\n",
            "Epoch 202/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.6944 - accuracy: 0.6922 - val_loss: 0.6136 - val_accuracy: 0.7313\n",
            "Epoch 203/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.6829 - accuracy: 0.7016 - val_loss: 0.6124 - val_accuracy: 0.7332\n",
            "Epoch 204/1000\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.6821 - accuracy: 0.7041 - val_loss: 0.6112 - val_accuracy: 0.7323\n",
            "Epoch 205/1000\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 0.6832 - accuracy: 0.7025 - val_loss: 0.6102 - val_accuracy: 0.7323\n",
            "Epoch 206/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.6902 - accuracy: 0.6878 - val_loss: 0.6097 - val_accuracy: 0.7348\n",
            "Epoch 207/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.6748 - accuracy: 0.6978 - val_loss: 0.6078 - val_accuracy: 0.7361\n",
            "Epoch 208/1000\n",
            "13/13 [==============================] - 1s 96ms/step - loss: 0.6813 - accuracy: 0.6972 - val_loss: 0.6066 - val_accuracy: 0.7370\n",
            "Epoch 209/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.6811 - accuracy: 0.6922 - val_loss: 0.6050 - val_accuracy: 0.7395\n",
            "Epoch 210/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.6764 - accuracy: 0.6944 - val_loss: 0.6050 - val_accuracy: 0.7361\n",
            "Epoch 211/1000\n",
            "13/13 [==============================] - 1s 89ms/step - loss: 0.6837 - accuracy: 0.6987 - val_loss: 0.6050 - val_accuracy: 0.7354\n",
            "Epoch 212/1000\n",
            "13/13 [==============================] - 1s 93ms/step - loss: 0.6642 - accuracy: 0.6953 - val_loss: 0.6044 - val_accuracy: 0.7361\n",
            "Epoch 213/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.6890 - accuracy: 0.6950 - val_loss: 0.6032 - val_accuracy: 0.7364\n",
            "Epoch 214/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.6718 - accuracy: 0.6981 - val_loss: 0.6036 - val_accuracy: 0.7386\n",
            "Epoch 215/1000\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 0.6882 - accuracy: 0.7003 - val_loss: 0.6047 - val_accuracy: 0.7335\n",
            "Epoch 216/1000\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.6724 - accuracy: 0.7016 - val_loss: 0.6034 - val_accuracy: 0.7373\n",
            "Epoch 217/1000\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 0.6865 - accuracy: 0.6997 - val_loss: 0.6035 - val_accuracy: 0.7339\n",
            "Epoch 218/1000\n",
            "13/13 [==============================] - 1s 91ms/step - loss: 0.6613 - accuracy: 0.7103 - val_loss: 0.6033 - val_accuracy: 0.7379\n",
            "Epoch 219/1000\n",
            "13/13 [==============================] - 1s 90ms/step - loss: 0.6784 - accuracy: 0.7044 - val_loss: 0.5995 - val_accuracy: 0.7348\n",
            "Epoch 220/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.6662 - accuracy: 0.6994 - val_loss: 0.6007 - val_accuracy: 0.7382\n",
            "Epoch 221/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.6805 - accuracy: 0.7050 - val_loss: 0.5982 - val_accuracy: 0.7367\n",
            "Epoch 222/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.6640 - accuracy: 0.6969 - val_loss: 0.5964 - val_accuracy: 0.7401\n",
            "Epoch 223/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.6798 - accuracy: 0.7044 - val_loss: 0.5958 - val_accuracy: 0.7392\n",
            "Epoch 224/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.6616 - accuracy: 0.7013 - val_loss: 0.5949 - val_accuracy: 0.7404\n",
            "Epoch 225/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.6746 - accuracy: 0.6981 - val_loss: 0.5940 - val_accuracy: 0.7401\n",
            "Epoch 226/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.6707 - accuracy: 0.7069 - val_loss: 0.5930 - val_accuracy: 0.7411\n",
            "Epoch 227/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.6660 - accuracy: 0.7085 - val_loss: 0.5911 - val_accuracy: 0.7433\n",
            "Epoch 228/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.6514 - accuracy: 0.7060 - val_loss: 0.5911 - val_accuracy: 0.7411\n",
            "Epoch 229/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.6585 - accuracy: 0.7085 - val_loss: 0.5891 - val_accuracy: 0.7458\n",
            "Epoch 230/1000\n",
            "13/13 [==============================] - 1s 88ms/step - loss: 0.6580 - accuracy: 0.7009 - val_loss: 0.5898 - val_accuracy: 0.7442\n",
            "Epoch 231/1000\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 0.6621 - accuracy: 0.7016 - val_loss: 0.5878 - val_accuracy: 0.7426\n",
            "Epoch 232/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.6632 - accuracy: 0.7078 - val_loss: 0.5866 - val_accuracy: 0.7436\n",
            "Epoch 233/1000\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.6617 - accuracy: 0.7066 - val_loss: 0.5870 - val_accuracy: 0.7448\n",
            "Epoch 234/1000\n",
            "13/13 [==============================] - 1s 94ms/step - loss: 0.6561 - accuracy: 0.7110 - val_loss: 0.5862 - val_accuracy: 0.7436\n",
            "Epoch 235/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.6627 - accuracy: 0.7085 - val_loss: 0.5860 - val_accuracy: 0.7467\n",
            "Epoch 236/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.6521 - accuracy: 0.7160 - val_loss: 0.5838 - val_accuracy: 0.7426\n",
            "Epoch 237/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.6567 - accuracy: 0.7088 - val_loss: 0.5850 - val_accuracy: 0.7461\n",
            "Epoch 238/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.6468 - accuracy: 0.7056 - val_loss: 0.5820 - val_accuracy: 0.7439\n",
            "Epoch 239/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.6558 - accuracy: 0.7107 - val_loss: 0.5824 - val_accuracy: 0.7429\n",
            "Epoch 240/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.6535 - accuracy: 0.7157 - val_loss: 0.5818 - val_accuracy: 0.7442\n",
            "Epoch 241/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.6492 - accuracy: 0.7248 - val_loss: 0.5812 - val_accuracy: 0.7448\n",
            "Epoch 242/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.6520 - accuracy: 0.7069 - val_loss: 0.5803 - val_accuracy: 0.7476\n",
            "Epoch 243/1000\n",
            "13/13 [==============================] - 1s 86ms/step - loss: 0.6569 - accuracy: 0.7122 - val_loss: 0.5793 - val_accuracy: 0.7464\n",
            "Epoch 244/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.6453 - accuracy: 0.7044 - val_loss: 0.5791 - val_accuracy: 0.7451\n",
            "Epoch 245/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.6567 - accuracy: 0.7078 - val_loss: 0.5796 - val_accuracy: 0.7458\n",
            "Epoch 246/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.6447 - accuracy: 0.7160 - val_loss: 0.5766 - val_accuracy: 0.7483\n",
            "Epoch 247/1000\n",
            "13/13 [==============================] - 1s 95ms/step - loss: 0.6426 - accuracy: 0.7157 - val_loss: 0.5760 - val_accuracy: 0.7467\n",
            "Epoch 248/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.6478 - accuracy: 0.7135 - val_loss: 0.5774 - val_accuracy: 0.7467\n",
            "Epoch 249/1000\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.6494 - accuracy: 0.7125 - val_loss: 0.5747 - val_accuracy: 0.7458\n",
            "Epoch 250/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.6471 - accuracy: 0.7078 - val_loss: 0.5748 - val_accuracy: 0.7439\n",
            "Epoch 251/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.6493 - accuracy: 0.7147 - val_loss: 0.5739 - val_accuracy: 0.7458\n",
            "Epoch 252/1000\n",
            "13/13 [==============================] - 1s 89ms/step - loss: 0.6481 - accuracy: 0.7163 - val_loss: 0.5744 - val_accuracy: 0.7439\n",
            "Epoch 253/1000\n",
            "13/13 [==============================] - 1s 84ms/step - loss: 0.6428 - accuracy: 0.7125 - val_loss: 0.5730 - val_accuracy: 0.7473\n",
            "Epoch 254/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.6439 - accuracy: 0.7066 - val_loss: 0.5725 - val_accuracy: 0.7473\n",
            "Epoch 255/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.6414 - accuracy: 0.7116 - val_loss: 0.5716 - val_accuracy: 0.7492\n",
            "Epoch 256/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.6398 - accuracy: 0.7157 - val_loss: 0.5703 - val_accuracy: 0.7476\n",
            "Epoch 257/1000\n",
            "13/13 [==============================] - 1s 95ms/step - loss: 0.6409 - accuracy: 0.7210 - val_loss: 0.5699 - val_accuracy: 0.7492\n",
            "Epoch 258/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.6498 - accuracy: 0.7078 - val_loss: 0.5688 - val_accuracy: 0.7476\n",
            "Epoch 259/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.6347 - accuracy: 0.7207 - val_loss: 0.5694 - val_accuracy: 0.7489\n",
            "Epoch 260/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.6415 - accuracy: 0.7157 - val_loss: 0.5717 - val_accuracy: 0.7480\n",
            "Epoch 261/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.6312 - accuracy: 0.7235 - val_loss: 0.5704 - val_accuracy: 0.7451\n",
            "Epoch 262/1000\n",
            "13/13 [==============================] - 1s 92ms/step - loss: 0.6441 - accuracy: 0.7132 - val_loss: 0.5773 - val_accuracy: 0.7458\n",
            "Epoch 263/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.6296 - accuracy: 0.7150 - val_loss: 0.5767 - val_accuracy: 0.7464\n",
            "Epoch 264/1000\n",
            "13/13 [==============================] - 1s 88ms/step - loss: 0.6709 - accuracy: 0.7088 - val_loss: 0.5817 - val_accuracy: 0.7455\n",
            "Epoch 265/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.6357 - accuracy: 0.7154 - val_loss: 0.5739 - val_accuracy: 0.7451\n",
            "Epoch 266/1000\n",
            "13/13 [==============================] - 1s 90ms/step - loss: 0.6538 - accuracy: 0.7116 - val_loss: 0.5730 - val_accuracy: 0.7448\n",
            "Epoch 267/1000\n",
            "13/13 [==============================] - 1s 84ms/step - loss: 0.6317 - accuracy: 0.7204 - val_loss: 0.5699 - val_accuracy: 0.7470\n",
            "Epoch 268/1000\n",
            "13/13 [==============================] - 1s 97ms/step - loss: 0.6410 - accuracy: 0.7223 - val_loss: 0.5701 - val_accuracy: 0.7470\n",
            "Epoch 269/1000\n",
            "13/13 [==============================] - 1s 92ms/step - loss: 0.6274 - accuracy: 0.7210 - val_loss: 0.5670 - val_accuracy: 0.7492\n",
            "Epoch 270/1000\n",
            "13/13 [==============================] - 1s 88ms/step - loss: 0.6466 - accuracy: 0.7229 - val_loss: 0.5673 - val_accuracy: 0.7470\n",
            "Epoch 271/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.6186 - accuracy: 0.7245 - val_loss: 0.5664 - val_accuracy: 0.7495\n",
            "Epoch 272/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.6423 - accuracy: 0.7238 - val_loss: 0.5638 - val_accuracy: 0.7498\n",
            "Epoch 273/1000\n",
            "13/13 [==============================] - 1s 92ms/step - loss: 0.6307 - accuracy: 0.7213 - val_loss: 0.5622 - val_accuracy: 0.7502\n",
            "Epoch 274/1000\n",
            "13/13 [==============================] - 1s 94ms/step - loss: 0.6475 - accuracy: 0.7172 - val_loss: 0.5647 - val_accuracy: 0.7480\n",
            "Epoch 275/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.6201 - accuracy: 0.7166 - val_loss: 0.5658 - val_accuracy: 0.7502\n",
            "Epoch 276/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.6442 - accuracy: 0.7185 - val_loss: 0.5640 - val_accuracy: 0.7498\n",
            "Epoch 277/1000\n",
            "13/13 [==============================] - 1s 89ms/step - loss: 0.6280 - accuracy: 0.7204 - val_loss: 0.5653 - val_accuracy: 0.7492\n",
            "Epoch 278/1000\n",
            "13/13 [==============================] - 1s 102ms/step - loss: 0.6392 - accuracy: 0.7163 - val_loss: 0.5621 - val_accuracy: 0.7486\n",
            "Epoch 279/1000\n",
            "13/13 [==============================] - 1s 97ms/step - loss: 0.6193 - accuracy: 0.7273 - val_loss: 0.5621 - val_accuracy: 0.7502\n",
            "Epoch 280/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.6398 - accuracy: 0.7185 - val_loss: 0.5625 - val_accuracy: 0.7483\n",
            "Epoch 281/1000\n",
            "13/13 [==============================] - 1s 92ms/step - loss: 0.6209 - accuracy: 0.7201 - val_loss: 0.5578 - val_accuracy: 0.7527\n",
            "Epoch 282/1000\n",
            "13/13 [==============================] - 1s 75ms/step - loss: 0.6337 - accuracy: 0.7223 - val_loss: 0.5594 - val_accuracy: 0.7502\n",
            "Epoch 283/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.6336 - accuracy: 0.7213 - val_loss: 0.5553 - val_accuracy: 0.7552\n",
            "Epoch 284/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.6282 - accuracy: 0.7197 - val_loss: 0.5583 - val_accuracy: 0.7539\n",
            "Epoch 285/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.6218 - accuracy: 0.7251 - val_loss: 0.5566 - val_accuracy: 0.7520\n",
            "Epoch 286/1000\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 0.6356 - accuracy: 0.7144 - val_loss: 0.5543 - val_accuracy: 0.7561\n",
            "Epoch 287/1000\n",
            "13/13 [==============================] - 1s 88ms/step - loss: 0.6155 - accuracy: 0.7288 - val_loss: 0.5570 - val_accuracy: 0.7517\n",
            "Epoch 288/1000\n",
            "13/13 [==============================] - 1s 86ms/step - loss: 0.6329 - accuracy: 0.7210 - val_loss: 0.5538 - val_accuracy: 0.7561\n",
            "Epoch 289/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.6245 - accuracy: 0.7182 - val_loss: 0.5523 - val_accuracy: 0.7549\n",
            "Epoch 290/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.6297 - accuracy: 0.7204 - val_loss: 0.5526 - val_accuracy: 0.7564\n",
            "Epoch 291/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.6150 - accuracy: 0.7276 - val_loss: 0.5523 - val_accuracy: 0.7574\n",
            "Epoch 292/1000\n",
            "13/13 [==============================] - 1s 91ms/step - loss: 0.6183 - accuracy: 0.7273 - val_loss: 0.5502 - val_accuracy: 0.7577\n",
            "Epoch 293/1000\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 0.6279 - accuracy: 0.7210 - val_loss: 0.5502 - val_accuracy: 0.7605\n",
            "Epoch 294/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.6213 - accuracy: 0.7248 - val_loss: 0.5484 - val_accuracy: 0.7596\n",
            "Epoch 295/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.6133 - accuracy: 0.7288 - val_loss: 0.5486 - val_accuracy: 0.7586\n",
            "Epoch 296/1000\n",
            "13/13 [==============================] - 1s 93ms/step - loss: 0.6166 - accuracy: 0.7245 - val_loss: 0.5480 - val_accuracy: 0.7589\n",
            "Epoch 297/1000\n",
            "13/13 [==============================] - 1s 89ms/step - loss: 0.6147 - accuracy: 0.7354 - val_loss: 0.5464 - val_accuracy: 0.7621\n",
            "Epoch 298/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.6185 - accuracy: 0.7260 - val_loss: 0.5489 - val_accuracy: 0.7586\n",
            "Epoch 299/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.6149 - accuracy: 0.7317 - val_loss: 0.5456 - val_accuracy: 0.7605\n",
            "Epoch 300/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.6195 - accuracy: 0.7301 - val_loss: 0.5443 - val_accuracy: 0.7614\n",
            "Epoch 301/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.6068 - accuracy: 0.7260 - val_loss: 0.5467 - val_accuracy: 0.7611\n",
            "Epoch 302/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.6317 - accuracy: 0.7238 - val_loss: 0.5465 - val_accuracy: 0.7639\n",
            "Epoch 303/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.5959 - accuracy: 0.7339 - val_loss: 0.5469 - val_accuracy: 0.7596\n",
            "Epoch 304/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.6308 - accuracy: 0.7276 - val_loss: 0.5453 - val_accuracy: 0.7614\n",
            "Epoch 305/1000\n",
            "13/13 [==============================] - 1s 92ms/step - loss: 0.6112 - accuracy: 0.7329 - val_loss: 0.5477 - val_accuracy: 0.7586\n",
            "Epoch 306/1000\n",
            "13/13 [==============================] - 1s 90ms/step - loss: 0.6260 - accuracy: 0.7263 - val_loss: 0.5474 - val_accuracy: 0.7611\n",
            "Epoch 307/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.6098 - accuracy: 0.7279 - val_loss: 0.5502 - val_accuracy: 0.7589\n",
            "Epoch 308/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.6327 - accuracy: 0.7254 - val_loss: 0.5451 - val_accuracy: 0.7649\n",
            "Epoch 309/1000\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.6029 - accuracy: 0.7361 - val_loss: 0.5464 - val_accuracy: 0.7599\n",
            "Epoch 310/1000\n",
            "13/13 [==============================] - 1s 93ms/step - loss: 0.6225 - accuracy: 0.7226 - val_loss: 0.5463 - val_accuracy: 0.7630\n",
            "Epoch 311/1000\n",
            "13/13 [==============================] - 1s 89ms/step - loss: 0.6065 - accuracy: 0.7329 - val_loss: 0.5448 - val_accuracy: 0.7618\n",
            "Epoch 312/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.6239 - accuracy: 0.7351 - val_loss: 0.5417 - val_accuracy: 0.7655\n",
            "Epoch 313/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.5962 - accuracy: 0.7386 - val_loss: 0.5400 - val_accuracy: 0.7639\n",
            "Epoch 314/1000\n",
            "13/13 [==============================] - 1s 92ms/step - loss: 0.6274 - accuracy: 0.7304 - val_loss: 0.5405 - val_accuracy: 0.7665\n",
            "Epoch 315/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.5922 - accuracy: 0.7348 - val_loss: 0.5397 - val_accuracy: 0.7633\n",
            "Epoch 316/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.6218 - accuracy: 0.7292 - val_loss: 0.5374 - val_accuracy: 0.7661\n",
            "Epoch 317/1000\n",
            "13/13 [==============================] - 1s 86ms/step - loss: 0.5979 - accuracy: 0.7417 - val_loss: 0.5392 - val_accuracy: 0.7639\n",
            "Epoch 318/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.6254 - accuracy: 0.7317 - val_loss: 0.5387 - val_accuracy: 0.7661\n",
            "Epoch 319/1000\n",
            "13/13 [==============================] - 1s 99ms/step - loss: 0.5992 - accuracy: 0.7423 - val_loss: 0.5393 - val_accuracy: 0.7618\n",
            "Epoch 320/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.6113 - accuracy: 0.7313 - val_loss: 0.5337 - val_accuracy: 0.7680\n",
            "Epoch 321/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.5952 - accuracy: 0.7389 - val_loss: 0.5363 - val_accuracy: 0.7633\n",
            "Epoch 322/1000\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 0.6106 - accuracy: 0.7257 - val_loss: 0.5331 - val_accuracy: 0.7690\n",
            "Epoch 323/1000\n",
            "13/13 [==============================] - 1s 93ms/step - loss: 0.5899 - accuracy: 0.7367 - val_loss: 0.5344 - val_accuracy: 0.7665\n",
            "Epoch 324/1000\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 0.6136 - accuracy: 0.7317 - val_loss: 0.5313 - val_accuracy: 0.7699\n",
            "Epoch 325/1000\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 0.5874 - accuracy: 0.7439 - val_loss: 0.5316 - val_accuracy: 0.7671\n",
            "Epoch 326/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.6074 - accuracy: 0.7361 - val_loss: 0.5284 - val_accuracy: 0.7724\n",
            "Epoch 327/1000\n",
            "13/13 [==============================] - 1s 94ms/step - loss: 0.5863 - accuracy: 0.7467 - val_loss: 0.5306 - val_accuracy: 0.7671\n",
            "Epoch 328/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.6111 - accuracy: 0.7282 - val_loss: 0.5286 - val_accuracy: 0.7699\n",
            "Epoch 329/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.5824 - accuracy: 0.7442 - val_loss: 0.5281 - val_accuracy: 0.7696\n",
            "Epoch 330/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.6155 - accuracy: 0.7335 - val_loss: 0.5261 - val_accuracy: 0.7721\n",
            "Epoch 331/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.5822 - accuracy: 0.7480 - val_loss: 0.5269 - val_accuracy: 0.7687\n",
            "Epoch 332/1000\n",
            "13/13 [==============================] - 1s 89ms/step - loss: 0.6097 - accuracy: 0.7307 - val_loss: 0.5239 - val_accuracy: 0.7740\n",
            "Epoch 333/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.5798 - accuracy: 0.7536 - val_loss: 0.5245 - val_accuracy: 0.7674\n",
            "Epoch 334/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.6041 - accuracy: 0.7420 - val_loss: 0.5246 - val_accuracy: 0.7762\n",
            "Epoch 335/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.5818 - accuracy: 0.7511 - val_loss: 0.5258 - val_accuracy: 0.7718\n",
            "Epoch 336/1000\n",
            "13/13 [==============================] - 1s 86ms/step - loss: 0.5981 - accuracy: 0.7364 - val_loss: 0.5198 - val_accuracy: 0.7781\n",
            "Epoch 337/1000\n",
            "13/13 [==============================] - 1s 91ms/step - loss: 0.5882 - accuracy: 0.7354 - val_loss: 0.5261 - val_accuracy: 0.7718\n",
            "Epoch 338/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.6156 - accuracy: 0.7342 - val_loss: 0.5234 - val_accuracy: 0.7737\n",
            "Epoch 339/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.5713 - accuracy: 0.7545 - val_loss: 0.5251 - val_accuracy: 0.7687\n",
            "Epoch 340/1000\n",
            "13/13 [==============================] - 1s 96ms/step - loss: 0.6053 - accuracy: 0.7395 - val_loss: 0.5284 - val_accuracy: 0.7743\n",
            "Epoch 341/1000\n",
            "13/13 [==============================] - 1s 84ms/step - loss: 0.5923 - accuracy: 0.7351 - val_loss: 0.5228 - val_accuracy: 0.7708\n",
            "Epoch 342/1000\n",
            "13/13 [==============================] - 1s 99ms/step - loss: 0.6014 - accuracy: 0.7486 - val_loss: 0.5188 - val_accuracy: 0.7781\n",
            "Epoch 343/1000\n",
            "13/13 [==============================] - 1s 96ms/step - loss: 0.5791 - accuracy: 0.7527 - val_loss: 0.5214 - val_accuracy: 0.7715\n",
            "Epoch 344/1000\n",
            "13/13 [==============================] - 1s 93ms/step - loss: 0.6079 - accuracy: 0.7345 - val_loss: 0.5213 - val_accuracy: 0.7777\n",
            "Epoch 345/1000\n",
            "13/13 [==============================] - 1s 88ms/step - loss: 0.5830 - accuracy: 0.7436 - val_loss: 0.5200 - val_accuracy: 0.7759\n",
            "Epoch 346/1000\n",
            "13/13 [==============================] - 1s 92ms/step - loss: 0.5910 - accuracy: 0.7420 - val_loss: 0.5144 - val_accuracy: 0.7790\n",
            "Epoch 347/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.5696 - accuracy: 0.7517 - val_loss: 0.5133 - val_accuracy: 0.7777\n",
            "Epoch 348/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.5909 - accuracy: 0.7420 - val_loss: 0.5105 - val_accuracy: 0.7806\n",
            "Epoch 349/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.5754 - accuracy: 0.7517 - val_loss: 0.5135 - val_accuracy: 0.7784\n",
            "Epoch 350/1000\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 0.5952 - accuracy: 0.7505 - val_loss: 0.5127 - val_accuracy: 0.7799\n",
            "Epoch 351/1000\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.5637 - accuracy: 0.7555 - val_loss: 0.5137 - val_accuracy: 0.7737\n",
            "Epoch 352/1000\n",
            "13/13 [==============================] - 1s 84ms/step - loss: 0.6077 - accuracy: 0.7382 - val_loss: 0.5144 - val_accuracy: 0.7784\n",
            "Epoch 353/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.5627 - accuracy: 0.7517 - val_loss: 0.5133 - val_accuracy: 0.7793\n",
            "Epoch 354/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.5846 - accuracy: 0.7498 - val_loss: 0.5096 - val_accuracy: 0.7812\n",
            "Epoch 355/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.5659 - accuracy: 0.7552 - val_loss: 0.5125 - val_accuracy: 0.7796\n",
            "Epoch 356/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.5951 - accuracy: 0.7448 - val_loss: 0.5081 - val_accuracy: 0.7815\n",
            "Epoch 357/1000\n",
            "13/13 [==============================] - 1s 86ms/step - loss: 0.5611 - accuracy: 0.7624 - val_loss: 0.5105 - val_accuracy: 0.7799\n",
            "Epoch 358/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.5995 - accuracy: 0.7448 - val_loss: 0.5131 - val_accuracy: 0.7796\n",
            "Epoch 359/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.5601 - accuracy: 0.7527 - val_loss: 0.5069 - val_accuracy: 0.7834\n",
            "Epoch 360/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.5828 - accuracy: 0.7520 - val_loss: 0.5034 - val_accuracy: 0.7831\n",
            "Epoch 361/1000\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 0.5624 - accuracy: 0.7527 - val_loss: 0.5054 - val_accuracy: 0.7824\n",
            "Epoch 362/1000\n",
            "13/13 [==============================] - 1s 86ms/step - loss: 0.5925 - accuracy: 0.7458 - val_loss: 0.5056 - val_accuracy: 0.7834\n",
            "Epoch 363/1000\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 0.5611 - accuracy: 0.7511 - val_loss: 0.5056 - val_accuracy: 0.7834\n",
            "Epoch 364/1000\n",
            "13/13 [==============================] - 1s 90ms/step - loss: 0.5825 - accuracy: 0.7530 - val_loss: 0.5023 - val_accuracy: 0.7865\n",
            "Epoch 365/1000\n",
            "13/13 [==============================] - 1s 99ms/step - loss: 0.5706 - accuracy: 0.7533 - val_loss: 0.5017 - val_accuracy: 0.7840\n",
            "Epoch 366/1000\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 0.5889 - accuracy: 0.7451 - val_loss: 0.5005 - val_accuracy: 0.7834\n",
            "Epoch 367/1000\n",
            "13/13 [==============================] - 1s 90ms/step - loss: 0.5474 - accuracy: 0.7608 - val_loss: 0.5007 - val_accuracy: 0.7834\n",
            "Epoch 368/1000\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 0.5997 - accuracy: 0.7408 - val_loss: 0.5054 - val_accuracy: 0.7843\n",
            "Epoch 369/1000\n",
            "13/13 [==============================] - 1s 91ms/step - loss: 0.5567 - accuracy: 0.7611 - val_loss: 0.5019 - val_accuracy: 0.7812\n",
            "Epoch 370/1000\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 0.5787 - accuracy: 0.7502 - val_loss: 0.5011 - val_accuracy: 0.7843\n",
            "Epoch 371/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.5642 - accuracy: 0.7577 - val_loss: 0.4995 - val_accuracy: 0.7850\n",
            "Epoch 372/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.5797 - accuracy: 0.7480 - val_loss: 0.4969 - val_accuracy: 0.7846\n",
            "Epoch 373/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.5499 - accuracy: 0.7639 - val_loss: 0.4976 - val_accuracy: 0.7868\n",
            "Epoch 374/1000\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.5857 - accuracy: 0.7461 - val_loss: 0.4951 - val_accuracy: 0.7856\n",
            "Epoch 375/1000\n",
            "13/13 [==============================] - 1s 96ms/step - loss: 0.5475 - accuracy: 0.7621 - val_loss: 0.4930 - val_accuracy: 0.7859\n",
            "Epoch 376/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.5590 - accuracy: 0.7552 - val_loss: 0.4904 - val_accuracy: 0.7875\n",
            "Epoch 377/1000\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.5673 - accuracy: 0.7530 - val_loss: 0.4901 - val_accuracy: 0.7878\n",
            "Epoch 378/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.5664 - accuracy: 0.7618 - val_loss: 0.4872 - val_accuracy: 0.7887\n",
            "Epoch 379/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.5533 - accuracy: 0.7665 - val_loss: 0.4875 - val_accuracy: 0.7881\n",
            "Epoch 380/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.5703 - accuracy: 0.7545 - val_loss: 0.4873 - val_accuracy: 0.7897\n",
            "Epoch 381/1000\n",
            "13/13 [==============================] - 1s 91ms/step - loss: 0.5431 - accuracy: 0.7646 - val_loss: 0.4879 - val_accuracy: 0.7884\n",
            "Epoch 382/1000\n",
            "13/13 [==============================] - 1s 94ms/step - loss: 0.5620 - accuracy: 0.7586 - val_loss: 0.4876 - val_accuracy: 0.7931\n",
            "Epoch 383/1000\n",
            "13/13 [==============================] - 1s 91ms/step - loss: 0.5413 - accuracy: 0.7639 - val_loss: 0.4879 - val_accuracy: 0.7884\n",
            "Epoch 384/1000\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 0.5753 - accuracy: 0.7524 - val_loss: 0.4857 - val_accuracy: 0.7897\n",
            "Epoch 385/1000\n",
            "13/13 [==============================] - 1s 90ms/step - loss: 0.5419 - accuracy: 0.7699 - val_loss: 0.4849 - val_accuracy: 0.7909\n",
            "Epoch 386/1000\n",
            "13/13 [==============================] - 1s 88ms/step - loss: 0.5655 - accuracy: 0.7527 - val_loss: 0.4839 - val_accuracy: 0.7922\n",
            "Epoch 387/1000\n",
            "13/13 [==============================] - 1s 86ms/step - loss: 0.5478 - accuracy: 0.7665 - val_loss: 0.4873 - val_accuracy: 0.7944\n",
            "Epoch 388/1000\n",
            "13/13 [==============================] - 1s 94ms/step - loss: 0.5753 - accuracy: 0.7545 - val_loss: 0.4886 - val_accuracy: 0.7884\n",
            "Epoch 389/1000\n",
            "13/13 [==============================] - 1s 101ms/step - loss: 0.5309 - accuracy: 0.7712 - val_loss: 0.4917 - val_accuracy: 0.7887\n",
            "Epoch 390/1000\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.5787 - accuracy: 0.7536 - val_loss: 0.4919 - val_accuracy: 0.7881\n",
            "Epoch 391/1000\n",
            "13/13 [==============================] - 1s 86ms/step - loss: 0.5431 - accuracy: 0.7721 - val_loss: 0.4872 - val_accuracy: 0.7931\n",
            "Epoch 392/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.5794 - accuracy: 0.7567 - val_loss: 0.4869 - val_accuracy: 0.7903\n",
            "Epoch 393/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.5363 - accuracy: 0.7768 - val_loss: 0.4833 - val_accuracy: 0.7966\n",
            "Epoch 394/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.5800 - accuracy: 0.7498 - val_loss: 0.4823 - val_accuracy: 0.7934\n",
            "Epoch 395/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.5354 - accuracy: 0.7784 - val_loss: 0.4793 - val_accuracy: 0.7944\n",
            "Epoch 396/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.5752 - accuracy: 0.7558 - val_loss: 0.4827 - val_accuracy: 0.7931\n",
            "Epoch 397/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.5273 - accuracy: 0.7746 - val_loss: 0.4784 - val_accuracy: 0.7959\n",
            "Epoch 398/1000\n",
            "13/13 [==============================] - 1s 84ms/step - loss: 0.5652 - accuracy: 0.7555 - val_loss: 0.4774 - val_accuracy: 0.7987\n",
            "Epoch 399/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.5300 - accuracy: 0.7752 - val_loss: 0.4766 - val_accuracy: 0.7981\n",
            "Epoch 400/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.5495 - accuracy: 0.7636 - val_loss: 0.4728 - val_accuracy: 0.8019\n",
            "Epoch 401/1000\n",
            "13/13 [==============================] - 1s 86ms/step - loss: 0.5262 - accuracy: 0.7724 - val_loss: 0.4730 - val_accuracy: 0.7959\n",
            "Epoch 402/1000\n",
            "13/13 [==============================] - 1s 89ms/step - loss: 0.5463 - accuracy: 0.7658 - val_loss: 0.4732 - val_accuracy: 0.7991\n",
            "Epoch 403/1000\n",
            "13/13 [==============================] - 1s 86ms/step - loss: 0.5341 - accuracy: 0.7771 - val_loss: 0.4705 - val_accuracy: 0.7981\n",
            "Epoch 404/1000\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 0.5526 - accuracy: 0.7671 - val_loss: 0.4684 - val_accuracy: 0.8013\n",
            "Epoch 405/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.5189 - accuracy: 0.7806 - val_loss: 0.4722 - val_accuracy: 0.7981\n",
            "Epoch 406/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.5645 - accuracy: 0.7567 - val_loss: 0.4700 - val_accuracy: 0.8013\n",
            "Epoch 407/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.5240 - accuracy: 0.7765 - val_loss: 0.4675 - val_accuracy: 0.8031\n",
            "Epoch 408/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.5394 - accuracy: 0.7649 - val_loss: 0.4657 - val_accuracy: 0.8019\n",
            "Epoch 409/1000\n",
            "13/13 [==============================] - 1s 91ms/step - loss: 0.5283 - accuracy: 0.7790 - val_loss: 0.4632 - val_accuracy: 0.8034\n",
            "Epoch 410/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.5427 - accuracy: 0.7755 - val_loss: 0.4639 - val_accuracy: 0.8031\n",
            "Epoch 411/1000\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 0.5244 - accuracy: 0.7759 - val_loss: 0.4620 - val_accuracy: 0.8044\n",
            "Epoch 412/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.5323 - accuracy: 0.7727 - val_loss: 0.4615 - val_accuracy: 0.8031\n",
            "Epoch 413/1000\n",
            "13/13 [==============================] - 1s 95ms/step - loss: 0.5255 - accuracy: 0.7787 - val_loss: 0.4597 - val_accuracy: 0.8050\n",
            "Epoch 414/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.5489 - accuracy: 0.7712 - val_loss: 0.4616 - val_accuracy: 0.8031\n",
            "Epoch 415/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.5150 - accuracy: 0.7790 - val_loss: 0.4624 - val_accuracy: 0.8041\n",
            "Epoch 416/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.5447 - accuracy: 0.7646 - val_loss: 0.4657 - val_accuracy: 0.8003\n",
            "Epoch 417/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.5090 - accuracy: 0.7868 - val_loss: 0.4674 - val_accuracy: 0.8009\n",
            "Epoch 418/1000\n",
            "13/13 [==============================] - 1s 90ms/step - loss: 0.5455 - accuracy: 0.7652 - val_loss: 0.4692 - val_accuracy: 0.7997\n",
            "Epoch 419/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.5143 - accuracy: 0.7878 - val_loss: 0.4725 - val_accuracy: 0.7962\n",
            "Epoch 420/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.5663 - accuracy: 0.7571 - val_loss: 0.4767 - val_accuracy: 0.7972\n",
            "Epoch 421/1000\n",
            "13/13 [==============================] - 1s 84ms/step - loss: 0.5062 - accuracy: 0.7856 - val_loss: 0.4743 - val_accuracy: 0.7987\n",
            "Epoch 422/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.5817 - accuracy: 0.7549 - val_loss: 0.4892 - val_accuracy: 0.7925\n",
            "Epoch 423/1000\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.5356 - accuracy: 0.7715 - val_loss: 0.4634 - val_accuracy: 0.8003\n",
            "Epoch 424/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.5485 - accuracy: 0.7671 - val_loss: 0.4549 - val_accuracy: 0.8063\n",
            "Epoch 425/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.5194 - accuracy: 0.7824 - val_loss: 0.4541 - val_accuracy: 0.8056\n",
            "Epoch 426/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.5292 - accuracy: 0.7784 - val_loss: 0.4526 - val_accuracy: 0.8078\n",
            "Epoch 427/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.5120 - accuracy: 0.7856 - val_loss: 0.4507 - val_accuracy: 0.8103\n",
            "Epoch 428/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.5344 - accuracy: 0.7774 - val_loss: 0.4501 - val_accuracy: 0.8085\n",
            "Epoch 429/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.5082 - accuracy: 0.7871 - val_loss: 0.4520 - val_accuracy: 0.8066\n",
            "Epoch 430/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.5343 - accuracy: 0.7755 - val_loss: 0.4563 - val_accuracy: 0.8038\n",
            "Epoch 431/1000\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 0.5138 - accuracy: 0.7875 - val_loss: 0.4490 - val_accuracy: 0.8100\n",
            "Epoch 432/1000\n",
            "13/13 [==============================] - 1s 86ms/step - loss: 0.5288 - accuracy: 0.7721 - val_loss: 0.4569 - val_accuracy: 0.8072\n",
            "Epoch 433/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.5063 - accuracy: 0.7962 - val_loss: 0.4599 - val_accuracy: 0.8053\n",
            "Epoch 434/1000\n",
            "13/13 [==============================] - 1s 86ms/step - loss: 0.5610 - accuracy: 0.7596 - val_loss: 0.4648 - val_accuracy: 0.8056\n",
            "Epoch 435/1000\n",
            "13/13 [==============================] - 1s 89ms/step - loss: 0.5117 - accuracy: 0.7915 - val_loss: 0.4540 - val_accuracy: 0.8088\n",
            "Epoch 436/1000\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 0.5260 - accuracy: 0.7727 - val_loss: 0.4478 - val_accuracy: 0.8088\n",
            "Epoch 437/1000\n",
            "13/13 [==============================] - 1s 86ms/step - loss: 0.4979 - accuracy: 0.7865 - val_loss: 0.4504 - val_accuracy: 0.8103\n",
            "Epoch 438/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.5369 - accuracy: 0.7724 - val_loss: 0.4479 - val_accuracy: 0.8075\n",
            "Epoch 439/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.4801 - accuracy: 0.7984 - val_loss: 0.4551 - val_accuracy: 0.8110\n",
            "Epoch 440/1000\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 0.5540 - accuracy: 0.7652 - val_loss: 0.4575 - val_accuracy: 0.8041\n",
            "Epoch 441/1000\n",
            "13/13 [==============================] - 1s 86ms/step - loss: 0.4981 - accuracy: 0.7884 - val_loss: 0.4512 - val_accuracy: 0.8094\n",
            "Epoch 442/1000\n",
            "13/13 [==============================] - 1s 88ms/step - loss: 0.5401 - accuracy: 0.7696 - val_loss: 0.4498 - val_accuracy: 0.8094\n",
            "Epoch 443/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.4926 - accuracy: 0.7928 - val_loss: 0.4481 - val_accuracy: 0.8088\n",
            "Epoch 444/1000\n",
            "13/13 [==============================] - 1s 89ms/step - loss: 0.5343 - accuracy: 0.7730 - val_loss: 0.4490 - val_accuracy: 0.8088\n",
            "Epoch 445/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.4941 - accuracy: 0.7925 - val_loss: 0.4468 - val_accuracy: 0.8097\n",
            "Epoch 446/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.5391 - accuracy: 0.7702 - val_loss: 0.4471 - val_accuracy: 0.8078\n",
            "Epoch 447/1000\n",
            "13/13 [==============================] - 1s 91ms/step - loss: 0.4959 - accuracy: 0.7925 - val_loss: 0.4449 - val_accuracy: 0.8135\n",
            "Epoch 448/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.5416 - accuracy: 0.7702 - val_loss: 0.4491 - val_accuracy: 0.8097\n",
            "Epoch 449/1000\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 0.4952 - accuracy: 0.8019 - val_loss: 0.4416 - val_accuracy: 0.8150\n",
            "Epoch 450/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.5396 - accuracy: 0.7680 - val_loss: 0.4429 - val_accuracy: 0.8129\n",
            "Epoch 451/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.4885 - accuracy: 0.7959 - val_loss: 0.4417 - val_accuracy: 0.8147\n",
            "Epoch 452/1000\n",
            "13/13 [==============================] - 1s 90ms/step - loss: 0.5243 - accuracy: 0.7721 - val_loss: 0.4383 - val_accuracy: 0.8125\n",
            "Epoch 453/1000\n",
            "13/13 [==============================] - 1s 84ms/step - loss: 0.4896 - accuracy: 0.7959 - val_loss: 0.4358 - val_accuracy: 0.8154\n",
            "Epoch 454/1000\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.5179 - accuracy: 0.7818 - val_loss: 0.4347 - val_accuracy: 0.8132\n",
            "Epoch 455/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.4839 - accuracy: 0.7969 - val_loss: 0.4317 - val_accuracy: 0.8160\n",
            "Epoch 456/1000\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 0.5173 - accuracy: 0.7850 - val_loss: 0.4313 - val_accuracy: 0.8150\n",
            "Epoch 457/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.4901 - accuracy: 0.7997 - val_loss: 0.4305 - val_accuracy: 0.8157\n",
            "Epoch 458/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.5063 - accuracy: 0.7793 - val_loss: 0.4282 - val_accuracy: 0.8154\n",
            "Epoch 459/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.4762 - accuracy: 0.8041 - val_loss: 0.4335 - val_accuracy: 0.8182\n",
            "Epoch 460/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.5351 - accuracy: 0.7749 - val_loss: 0.4368 - val_accuracy: 0.8141\n",
            "Epoch 461/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.4752 - accuracy: 0.8041 - val_loss: 0.4317 - val_accuracy: 0.8176\n",
            "Epoch 462/1000\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.5262 - accuracy: 0.7765 - val_loss: 0.4367 - val_accuracy: 0.8135\n",
            "Epoch 463/1000\n",
            "13/13 [==============================] - 1s 93ms/step - loss: 0.4776 - accuracy: 0.8047 - val_loss: 0.4412 - val_accuracy: 0.8160\n",
            "Epoch 464/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.5567 - accuracy: 0.7687 - val_loss: 0.4533 - val_accuracy: 0.8078\n",
            "Epoch 465/1000\n",
            "13/13 [==============================] - 1s 84ms/step - loss: 0.4846 - accuracy: 0.7962 - val_loss: 0.4283 - val_accuracy: 0.8204\n",
            "Epoch 466/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.4957 - accuracy: 0.7918 - val_loss: 0.4240 - val_accuracy: 0.8179\n",
            "Epoch 467/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.4782 - accuracy: 0.8003 - val_loss: 0.4276 - val_accuracy: 0.8201\n",
            "Epoch 468/1000\n",
            "13/13 [==============================] - 1s 89ms/step - loss: 0.5165 - accuracy: 0.7890 - val_loss: 0.4234 - val_accuracy: 0.8201\n",
            "Epoch 469/1000\n",
            "13/13 [==============================] - 1s 84ms/step - loss: 0.4777 - accuracy: 0.8050 - val_loss: 0.4232 - val_accuracy: 0.8226\n",
            "Epoch 470/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.5008 - accuracy: 0.7846 - val_loss: 0.4172 - val_accuracy: 0.8210\n",
            "Epoch 471/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.4751 - accuracy: 0.8022 - val_loss: 0.4238 - val_accuracy: 0.8216\n",
            "Epoch 472/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.5109 - accuracy: 0.7931 - val_loss: 0.4226 - val_accuracy: 0.8201\n",
            "Epoch 473/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.4717 - accuracy: 0.8063 - val_loss: 0.4239 - val_accuracy: 0.8226\n",
            "Epoch 474/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.5195 - accuracy: 0.7821 - val_loss: 0.4260 - val_accuracy: 0.8166\n",
            "Epoch 475/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.4642 - accuracy: 0.8113 - val_loss: 0.4211 - val_accuracy: 0.8229\n",
            "Epoch 476/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.5285 - accuracy: 0.7824 - val_loss: 0.4286 - val_accuracy: 0.8185\n",
            "Epoch 477/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.4701 - accuracy: 0.8025 - val_loss: 0.4182 - val_accuracy: 0.8232\n",
            "Epoch 478/1000\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 0.4980 - accuracy: 0.7940 - val_loss: 0.4152 - val_accuracy: 0.8216\n",
            "Epoch 479/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.4600 - accuracy: 0.8119 - val_loss: 0.4186 - val_accuracy: 0.8260\n",
            "Epoch 480/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.5166 - accuracy: 0.7928 - val_loss: 0.4170 - val_accuracy: 0.8210\n",
            "Epoch 481/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.4535 - accuracy: 0.8110 - val_loss: 0.4176 - val_accuracy: 0.8254\n",
            "Epoch 482/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.5180 - accuracy: 0.7843 - val_loss: 0.4170 - val_accuracy: 0.8232\n",
            "Epoch 483/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.4579 - accuracy: 0.8129 - val_loss: 0.4177 - val_accuracy: 0.8270\n",
            "Epoch 484/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.5149 - accuracy: 0.7875 - val_loss: 0.4188 - val_accuracy: 0.8232\n",
            "Epoch 485/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.4698 - accuracy: 0.8038 - val_loss: 0.4119 - val_accuracy: 0.8285\n",
            "Epoch 486/1000\n",
            "13/13 [==============================] - 1s 88ms/step - loss: 0.5020 - accuracy: 0.7950 - val_loss: 0.4098 - val_accuracy: 0.8295\n",
            "Epoch 487/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.4585 - accuracy: 0.8141 - val_loss: 0.4156 - val_accuracy: 0.8279\n",
            "Epoch 488/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.5141 - accuracy: 0.7850 - val_loss: 0.4191 - val_accuracy: 0.8251\n",
            "Epoch 489/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.4588 - accuracy: 0.8122 - val_loss: 0.4121 - val_accuracy: 0.8288\n",
            "Epoch 490/1000\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 0.5021 - accuracy: 0.7925 - val_loss: 0.4101 - val_accuracy: 0.8282\n",
            "Epoch 491/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.4569 - accuracy: 0.8169 - val_loss: 0.4077 - val_accuracy: 0.8317\n",
            "Epoch 492/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.4919 - accuracy: 0.7972 - val_loss: 0.4045 - val_accuracy: 0.8323\n",
            "Epoch 493/1000\n",
            "13/13 [==============================] - 1s 97ms/step - loss: 0.4454 - accuracy: 0.8201 - val_loss: 0.4103 - val_accuracy: 0.8304\n",
            "Epoch 494/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.5054 - accuracy: 0.7937 - val_loss: 0.4113 - val_accuracy: 0.8320\n",
            "Epoch 495/1000\n",
            "13/13 [==============================] - 1s 90ms/step - loss: 0.4420 - accuracy: 0.8194 - val_loss: 0.4064 - val_accuracy: 0.8313\n",
            "Epoch 496/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.4957 - accuracy: 0.7922 - val_loss: 0.4110 - val_accuracy: 0.8307\n",
            "Epoch 497/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.4616 - accuracy: 0.8138 - val_loss: 0.4062 - val_accuracy: 0.8332\n",
            "Epoch 498/1000\n",
            "13/13 [==============================] - 1s 91ms/step - loss: 0.5105 - accuracy: 0.7900 - val_loss: 0.4066 - val_accuracy: 0.8317\n",
            "Epoch 499/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.4515 - accuracy: 0.8166 - val_loss: 0.4074 - val_accuracy: 0.8320\n",
            "Epoch 500/1000\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 0.4882 - accuracy: 0.7981 - val_loss: 0.3972 - val_accuracy: 0.8373\n",
            "Epoch 501/1000\n",
            "13/13 [==============================] - 1s 94ms/step - loss: 0.4510 - accuracy: 0.8201 - val_loss: 0.3958 - val_accuracy: 0.8361\n",
            "Epoch 502/1000\n",
            "13/13 [==============================] - 1s 84ms/step - loss: 0.4712 - accuracy: 0.8069 - val_loss: 0.3894 - val_accuracy: 0.8411\n",
            "Epoch 503/1000\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.4474 - accuracy: 0.8194 - val_loss: 0.3932 - val_accuracy: 0.8414\n",
            "Epoch 504/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.4769 - accuracy: 0.8091 - val_loss: 0.3913 - val_accuracy: 0.8382\n",
            "Epoch 505/1000\n",
            "13/13 [==============================] - 1s 92ms/step - loss: 0.4482 - accuracy: 0.8213 - val_loss: 0.3923 - val_accuracy: 0.8414\n",
            "Epoch 506/1000\n",
            "13/13 [==============================] - 1s 88ms/step - loss: 0.4855 - accuracy: 0.8053 - val_loss: 0.3930 - val_accuracy: 0.8398\n",
            "Epoch 507/1000\n",
            "13/13 [==============================] - 1s 89ms/step - loss: 0.4334 - accuracy: 0.8241 - val_loss: 0.3963 - val_accuracy: 0.8404\n",
            "Epoch 508/1000\n",
            "13/13 [==============================] - 1s 92ms/step - loss: 0.4956 - accuracy: 0.8044 - val_loss: 0.4009 - val_accuracy: 0.8332\n",
            "Epoch 509/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.4391 - accuracy: 0.8235 - val_loss: 0.3893 - val_accuracy: 0.8429\n",
            "Epoch 510/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.4848 - accuracy: 0.7975 - val_loss: 0.3901 - val_accuracy: 0.8423\n",
            "Epoch 511/1000\n",
            "13/13 [==============================] - 1s 90ms/step - loss: 0.4282 - accuracy: 0.8301 - val_loss: 0.3875 - val_accuracy: 0.8408\n",
            "Epoch 512/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.4682 - accuracy: 0.8103 - val_loss: 0.3839 - val_accuracy: 0.8423\n",
            "Epoch 513/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.4343 - accuracy: 0.8323 - val_loss: 0.3861 - val_accuracy: 0.8433\n",
            "Epoch 514/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.4853 - accuracy: 0.8075 - val_loss: 0.3886 - val_accuracy: 0.8426\n",
            "Epoch 515/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.4307 - accuracy: 0.8276 - val_loss: 0.3889 - val_accuracy: 0.8445\n",
            "Epoch 516/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.4752 - accuracy: 0.8078 - val_loss: 0.3895 - val_accuracy: 0.8436\n",
            "Epoch 517/1000\n",
            "13/13 [==============================] - 1s 88ms/step - loss: 0.4233 - accuracy: 0.8295 - val_loss: 0.3992 - val_accuracy: 0.8414\n",
            "Epoch 518/1000\n",
            "13/13 [==============================] - 1s 84ms/step - loss: 0.5009 - accuracy: 0.7991 - val_loss: 0.4074 - val_accuracy: 0.8345\n",
            "Epoch 519/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.4363 - accuracy: 0.8238 - val_loss: 0.3962 - val_accuracy: 0.8401\n",
            "Epoch 520/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.4852 - accuracy: 0.8072 - val_loss: 0.3901 - val_accuracy: 0.8414\n",
            "Epoch 521/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.4332 - accuracy: 0.8307 - val_loss: 0.3801 - val_accuracy: 0.8483\n",
            "Epoch 522/1000\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 0.4521 - accuracy: 0.8248 - val_loss: 0.3743 - val_accuracy: 0.8483\n",
            "Epoch 523/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.4250 - accuracy: 0.8317 - val_loss: 0.3762 - val_accuracy: 0.8473\n",
            "Epoch 524/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.4666 - accuracy: 0.8119 - val_loss: 0.3767 - val_accuracy: 0.8473\n",
            "Epoch 525/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.4204 - accuracy: 0.8329 - val_loss: 0.3749 - val_accuracy: 0.8476\n",
            "Epoch 526/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.4575 - accuracy: 0.8210 - val_loss: 0.3698 - val_accuracy: 0.8524\n",
            "Epoch 527/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.4235 - accuracy: 0.8313 - val_loss: 0.3765 - val_accuracy: 0.8480\n",
            "Epoch 528/1000\n",
            "13/13 [==============================] - 1s 84ms/step - loss: 0.4738 - accuracy: 0.8125 - val_loss: 0.3763 - val_accuracy: 0.8495\n",
            "Epoch 529/1000\n",
            "13/13 [==============================] - 1s 84ms/step - loss: 0.4133 - accuracy: 0.8348 - val_loss: 0.3761 - val_accuracy: 0.8495\n",
            "Epoch 530/1000\n",
            "13/13 [==============================] - 1s 97ms/step - loss: 0.4650 - accuracy: 0.8144 - val_loss: 0.3791 - val_accuracy: 0.8467\n",
            "Epoch 531/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.4146 - accuracy: 0.8332 - val_loss: 0.3790 - val_accuracy: 0.8489\n",
            "Epoch 532/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.4691 - accuracy: 0.8166 - val_loss: 0.3731 - val_accuracy: 0.8505\n",
            "Epoch 533/1000\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 0.4146 - accuracy: 0.8313 - val_loss: 0.3791 - val_accuracy: 0.8524\n",
            "Epoch 534/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.4670 - accuracy: 0.8125 - val_loss: 0.3769 - val_accuracy: 0.8467\n",
            "Epoch 535/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.4238 - accuracy: 0.8364 - val_loss: 0.3763 - val_accuracy: 0.8511\n",
            "Epoch 536/1000\n",
            "13/13 [==============================] - 1s 84ms/step - loss: 0.4688 - accuracy: 0.8135 - val_loss: 0.3797 - val_accuracy: 0.8458\n",
            "Epoch 537/1000\n",
            "13/13 [==============================] - 1s 90ms/step - loss: 0.4224 - accuracy: 0.8342 - val_loss: 0.3787 - val_accuracy: 0.8495\n",
            "Epoch 538/1000\n",
            "13/13 [==============================] - 1s 96ms/step - loss: 0.4811 - accuracy: 0.8044 - val_loss: 0.3868 - val_accuracy: 0.8408\n",
            "Epoch 539/1000\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 0.4245 - accuracy: 0.8263 - val_loss: 0.3709 - val_accuracy: 0.8498\n",
            "Epoch 540/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.4608 - accuracy: 0.8163 - val_loss: 0.3665 - val_accuracy: 0.8517\n",
            "Epoch 541/1000\n",
            "13/13 [==============================] - 1s 84ms/step - loss: 0.4040 - accuracy: 0.8420 - val_loss: 0.3653 - val_accuracy: 0.8558\n",
            "Epoch 542/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.4581 - accuracy: 0.8238 - val_loss: 0.3637 - val_accuracy: 0.8545\n",
            "Epoch 543/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.4086 - accuracy: 0.8361 - val_loss: 0.3601 - val_accuracy: 0.8567\n",
            "Epoch 544/1000\n",
            "13/13 [==============================] - 1s 88ms/step - loss: 0.4417 - accuracy: 0.8207 - val_loss: 0.3640 - val_accuracy: 0.8574\n",
            "Epoch 545/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.4026 - accuracy: 0.8392 - val_loss: 0.3648 - val_accuracy: 0.8524\n",
            "Epoch 546/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.4729 - accuracy: 0.8150 - val_loss: 0.3713 - val_accuracy: 0.8498\n",
            "Epoch 547/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.4071 - accuracy: 0.8395 - val_loss: 0.3633 - val_accuracy: 0.8571\n",
            "Epoch 548/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.4636 - accuracy: 0.8166 - val_loss: 0.3733 - val_accuracy: 0.8498\n",
            "Epoch 549/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.4166 - accuracy: 0.8307 - val_loss: 0.3531 - val_accuracy: 0.8586\n",
            "Epoch 550/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.4396 - accuracy: 0.8329 - val_loss: 0.3604 - val_accuracy: 0.8567\n",
            "Epoch 551/1000\n",
            "13/13 [==============================] - 1s 88ms/step - loss: 0.4061 - accuracy: 0.8354 - val_loss: 0.3575 - val_accuracy: 0.8517\n",
            "Epoch 552/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.4574 - accuracy: 0.8207 - val_loss: 0.3628 - val_accuracy: 0.8545\n",
            "Epoch 553/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.4025 - accuracy: 0.8442 - val_loss: 0.3607 - val_accuracy: 0.8533\n",
            "Epoch 554/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.4656 - accuracy: 0.8107 - val_loss: 0.3638 - val_accuracy: 0.8527\n",
            "Epoch 555/1000\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 0.3962 - accuracy: 0.8414 - val_loss: 0.3583 - val_accuracy: 0.8561\n",
            "Epoch 556/1000\n",
            "13/13 [==============================] - 1s 94ms/step - loss: 0.4492 - accuracy: 0.8226 - val_loss: 0.3567 - val_accuracy: 0.8564\n",
            "Epoch 557/1000\n",
            "13/13 [==============================] - 1s 88ms/step - loss: 0.4000 - accuracy: 0.8389 - val_loss: 0.3582 - val_accuracy: 0.8561\n",
            "Epoch 558/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.4430 - accuracy: 0.8223 - val_loss: 0.3537 - val_accuracy: 0.8558\n",
            "Epoch 559/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.4063 - accuracy: 0.8376 - val_loss: 0.3526 - val_accuracy: 0.8611\n",
            "Epoch 560/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.4438 - accuracy: 0.8251 - val_loss: 0.3541 - val_accuracy: 0.8583\n",
            "Epoch 561/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.3889 - accuracy: 0.8473 - val_loss: 0.3550 - val_accuracy: 0.8574\n",
            "Epoch 562/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.4557 - accuracy: 0.8191 - val_loss: 0.3578 - val_accuracy: 0.8542\n",
            "Epoch 563/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.3818 - accuracy: 0.8470 - val_loss: 0.3528 - val_accuracy: 0.8574\n",
            "Epoch 564/1000\n",
            "13/13 [==============================] - 1s 92ms/step - loss: 0.4554 - accuracy: 0.8150 - val_loss: 0.3629 - val_accuracy: 0.8527\n",
            "Epoch 565/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.4121 - accuracy: 0.8357 - val_loss: 0.3563 - val_accuracy: 0.8589\n",
            "Epoch 566/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.4472 - accuracy: 0.8257 - val_loss: 0.3673 - val_accuracy: 0.8533\n",
            "Epoch 567/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.4056 - accuracy: 0.8389 - val_loss: 0.3510 - val_accuracy: 0.8605\n",
            "Epoch 568/1000\n",
            "13/13 [==============================] - 1s 88ms/step - loss: 0.4394 - accuracy: 0.8323 - val_loss: 0.3525 - val_accuracy: 0.8552\n",
            "Epoch 569/1000\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 0.3916 - accuracy: 0.8467 - val_loss: 0.3435 - val_accuracy: 0.8636\n",
            "Epoch 570/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.4323 - accuracy: 0.8276 - val_loss: 0.3418 - val_accuracy: 0.8614\n",
            "Epoch 571/1000\n",
            "13/13 [==============================] - 1s 92ms/step - loss: 0.3825 - accuracy: 0.8442 - val_loss: 0.3394 - val_accuracy: 0.8630\n",
            "Epoch 572/1000\n",
            "13/13 [==============================] - 1s 90ms/step - loss: 0.4336 - accuracy: 0.8282 - val_loss: 0.3437 - val_accuracy: 0.8624\n",
            "Epoch 573/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.3841 - accuracy: 0.8517 - val_loss: 0.3487 - val_accuracy: 0.8605\n",
            "Epoch 574/1000\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 0.4440 - accuracy: 0.8254 - val_loss: 0.3502 - val_accuracy: 0.8586\n",
            "Epoch 575/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.3919 - accuracy: 0.8483 - val_loss: 0.3420 - val_accuracy: 0.8633\n",
            "Epoch 576/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.4310 - accuracy: 0.8323 - val_loss: 0.3491 - val_accuracy: 0.8608\n",
            "Epoch 577/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.3918 - accuracy: 0.8455 - val_loss: 0.3421 - val_accuracy: 0.8649\n",
            "Epoch 578/1000\n",
            "13/13 [==============================] - 1s 84ms/step - loss: 0.4290 - accuracy: 0.8345 - val_loss: 0.3389 - val_accuracy: 0.8630\n",
            "Epoch 579/1000\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 0.3681 - accuracy: 0.8555 - val_loss: 0.3314 - val_accuracy: 0.8674\n",
            "Epoch 580/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.4417 - accuracy: 0.8320 - val_loss: 0.3421 - val_accuracy: 0.8614\n",
            "Epoch 581/1000\n",
            "13/13 [==============================] - 1s 91ms/step - loss: 0.3797 - accuracy: 0.8492 - val_loss: 0.3254 - val_accuracy: 0.8668\n",
            "Epoch 582/1000\n",
            "13/13 [==============================] - 1s 84ms/step - loss: 0.4108 - accuracy: 0.8404 - val_loss: 0.3374 - val_accuracy: 0.8671\n",
            "Epoch 583/1000\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 0.3984 - accuracy: 0.8364 - val_loss: 0.3241 - val_accuracy: 0.8665\n",
            "Epoch 584/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.3963 - accuracy: 0.8455 - val_loss: 0.3329 - val_accuracy: 0.8687\n",
            "Epoch 585/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.3880 - accuracy: 0.8470 - val_loss: 0.3200 - val_accuracy: 0.8702\n",
            "Epoch 586/1000\n",
            "13/13 [==============================] - 1s 84ms/step - loss: 0.4002 - accuracy: 0.8461 - val_loss: 0.3306 - val_accuracy: 0.8680\n",
            "Epoch 587/1000\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 0.3992 - accuracy: 0.8436 - val_loss: 0.3190 - val_accuracy: 0.8693\n",
            "Epoch 588/1000\n",
            "13/13 [==============================] - 1s 91ms/step - loss: 0.3731 - accuracy: 0.8561 - val_loss: 0.3301 - val_accuracy: 0.8690\n",
            "Epoch 589/1000\n",
            "13/13 [==============================] - 1s 91ms/step - loss: 0.4144 - accuracy: 0.8357 - val_loss: 0.3228 - val_accuracy: 0.8696\n",
            "Epoch 590/1000\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 0.3616 - accuracy: 0.8561 - val_loss: 0.3422 - val_accuracy: 0.8643\n",
            "Epoch 591/1000\n",
            "13/13 [==============================] - 1s 98ms/step - loss: 0.4581 - accuracy: 0.8122 - val_loss: 0.3523 - val_accuracy: 0.8571\n",
            "Epoch 592/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.3818 - accuracy: 0.8505 - val_loss: 0.3354 - val_accuracy: 0.8680\n",
            "Epoch 593/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.4417 - accuracy: 0.8201 - val_loss: 0.3525 - val_accuracy: 0.8552\n",
            "Epoch 594/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.3823 - accuracy: 0.8527 - val_loss: 0.3305 - val_accuracy: 0.8683\n",
            "Epoch 595/1000\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 0.4357 - accuracy: 0.8276 - val_loss: 0.3443 - val_accuracy: 0.8589\n",
            "Epoch 596/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.3777 - accuracy: 0.8451 - val_loss: 0.3239 - val_accuracy: 0.8677\n",
            "Epoch 597/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.4170 - accuracy: 0.8348 - val_loss: 0.3301 - val_accuracy: 0.8652\n",
            "Epoch 598/1000\n",
            "13/13 [==============================] - 1s 88ms/step - loss: 0.3716 - accuracy: 0.8545 - val_loss: 0.3183 - val_accuracy: 0.8721\n",
            "Epoch 599/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.4030 - accuracy: 0.8382 - val_loss: 0.3208 - val_accuracy: 0.8718\n",
            "Epoch 600/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.3640 - accuracy: 0.8555 - val_loss: 0.3166 - val_accuracy: 0.8724\n",
            "Epoch 601/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.4256 - accuracy: 0.8357 - val_loss: 0.3272 - val_accuracy: 0.8724\n",
            "Epoch 602/1000\n",
            "13/13 [==============================] - 1s 96ms/step - loss: 0.3722 - accuracy: 0.8571 - val_loss: 0.3133 - val_accuracy: 0.8715\n",
            "Epoch 603/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.3882 - accuracy: 0.8536 - val_loss: 0.3167 - val_accuracy: 0.8765\n",
            "Epoch 604/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.3700 - accuracy: 0.8495 - val_loss: 0.3154 - val_accuracy: 0.8718\n",
            "Epoch 605/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.4042 - accuracy: 0.8495 - val_loss: 0.3239 - val_accuracy: 0.8718\n",
            "Epoch 606/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.3669 - accuracy: 0.8520 - val_loss: 0.3137 - val_accuracy: 0.8743\n",
            "Epoch 607/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.4070 - accuracy: 0.8395 - val_loss: 0.3212 - val_accuracy: 0.8696\n",
            "Epoch 608/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.3617 - accuracy: 0.8517 - val_loss: 0.3154 - val_accuracy: 0.8718\n",
            "Epoch 609/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.4128 - accuracy: 0.8395 - val_loss: 0.3291 - val_accuracy: 0.8693\n",
            "Epoch 610/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.3641 - accuracy: 0.8599 - val_loss: 0.3154 - val_accuracy: 0.8734\n",
            "Epoch 611/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.4222 - accuracy: 0.8301 - val_loss: 0.3306 - val_accuracy: 0.8668\n",
            "Epoch 612/1000\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 0.3675 - accuracy: 0.8605 - val_loss: 0.3113 - val_accuracy: 0.8746\n",
            "Epoch 613/1000\n",
            "13/13 [==============================] - 1s 86ms/step - loss: 0.4044 - accuracy: 0.8382 - val_loss: 0.3191 - val_accuracy: 0.8699\n",
            "Epoch 614/1000\n",
            "13/13 [==============================] - 1s 88ms/step - loss: 0.3621 - accuracy: 0.8571 - val_loss: 0.3135 - val_accuracy: 0.8781\n",
            "Epoch 615/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.4067 - accuracy: 0.8442 - val_loss: 0.3199 - val_accuracy: 0.8734\n",
            "Epoch 616/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.3560 - accuracy: 0.8586 - val_loss: 0.3148 - val_accuracy: 0.8755\n",
            "Epoch 617/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.4027 - accuracy: 0.8357 - val_loss: 0.3226 - val_accuracy: 0.8708\n",
            "Epoch 618/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.3610 - accuracy: 0.8580 - val_loss: 0.3045 - val_accuracy: 0.8784\n",
            "Epoch 619/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.3970 - accuracy: 0.8439 - val_loss: 0.3174 - val_accuracy: 0.8721\n",
            "Epoch 620/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.3543 - accuracy: 0.8668 - val_loss: 0.3087 - val_accuracy: 0.8759\n",
            "Epoch 621/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.4026 - accuracy: 0.8458 - val_loss: 0.3096 - val_accuracy: 0.8740\n",
            "Epoch 622/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.3457 - accuracy: 0.8639 - val_loss: 0.3108 - val_accuracy: 0.8759\n",
            "Epoch 623/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.4177 - accuracy: 0.8266 - val_loss: 0.3272 - val_accuracy: 0.8687\n",
            "Epoch 624/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.3609 - accuracy: 0.8552 - val_loss: 0.3117 - val_accuracy: 0.8743\n",
            "Epoch 625/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.3977 - accuracy: 0.8417 - val_loss: 0.3050 - val_accuracy: 0.8777\n",
            "Epoch 626/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.3620 - accuracy: 0.8564 - val_loss: 0.3050 - val_accuracy: 0.8793\n",
            "Epoch 627/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.3939 - accuracy: 0.8451 - val_loss: 0.3050 - val_accuracy: 0.8787\n",
            "Epoch 628/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.3475 - accuracy: 0.8633 - val_loss: 0.3145 - val_accuracy: 0.8784\n",
            "Epoch 629/1000\n",
            "13/13 [==============================] - 1s 91ms/step - loss: 0.4058 - accuracy: 0.8408 - val_loss: 0.3148 - val_accuracy: 0.8724\n",
            "Epoch 630/1000\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.3508 - accuracy: 0.8646 - val_loss: 0.3028 - val_accuracy: 0.8790\n",
            "Epoch 631/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.4067 - accuracy: 0.8401 - val_loss: 0.3129 - val_accuracy: 0.8762\n",
            "Epoch 632/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.3464 - accuracy: 0.8646 - val_loss: 0.3113 - val_accuracy: 0.8774\n",
            "Epoch 633/1000\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 0.4024 - accuracy: 0.8467 - val_loss: 0.3342 - val_accuracy: 0.8652\n",
            "Epoch 634/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.3706 - accuracy: 0.8527 - val_loss: 0.3022 - val_accuracy: 0.8806\n",
            "Epoch 635/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.3912 - accuracy: 0.8498 - val_loss: 0.3009 - val_accuracy: 0.8790\n",
            "Epoch 636/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.3466 - accuracy: 0.8592 - val_loss: 0.2961 - val_accuracy: 0.8815\n",
            "Epoch 637/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.3771 - accuracy: 0.8442 - val_loss: 0.2928 - val_accuracy: 0.8843\n",
            "Epoch 638/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.3363 - accuracy: 0.8690 - val_loss: 0.2924 - val_accuracy: 0.8821\n",
            "Epoch 639/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.3987 - accuracy: 0.8420 - val_loss: 0.2988 - val_accuracy: 0.8837\n",
            "Epoch 640/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.3224 - accuracy: 0.8749 - val_loss: 0.2908 - val_accuracy: 0.8856\n",
            "Epoch 641/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.3936 - accuracy: 0.8480 - val_loss: 0.3018 - val_accuracy: 0.8806\n",
            "Epoch 642/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.3363 - accuracy: 0.8708 - val_loss: 0.2874 - val_accuracy: 0.8884\n",
            "Epoch 643/1000\n",
            "13/13 [==============================] - 1s 90ms/step - loss: 0.3789 - accuracy: 0.8539 - val_loss: 0.3043 - val_accuracy: 0.8806\n",
            "Epoch 644/1000\n",
            "13/13 [==============================] - 1s 89ms/step - loss: 0.3538 - accuracy: 0.8621 - val_loss: 0.2854 - val_accuracy: 0.8868\n",
            "Epoch 645/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.3739 - accuracy: 0.8536 - val_loss: 0.2895 - val_accuracy: 0.8881\n",
            "Epoch 646/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.3323 - accuracy: 0.8784 - val_loss: 0.2840 - val_accuracy: 0.8871\n",
            "Epoch 647/1000\n",
            "13/13 [==============================] - 1s 89ms/step - loss: 0.3759 - accuracy: 0.8577 - val_loss: 0.2929 - val_accuracy: 0.8865\n",
            "Epoch 648/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.3280 - accuracy: 0.8740 - val_loss: 0.2869 - val_accuracy: 0.8840\n",
            "Epoch 649/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.3746 - accuracy: 0.8589 - val_loss: 0.2918 - val_accuracy: 0.8843\n",
            "Epoch 650/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.3371 - accuracy: 0.8727 - val_loss: 0.2822 - val_accuracy: 0.8859\n",
            "Epoch 651/1000\n",
            "13/13 [==============================] - 1s 90ms/step - loss: 0.3700 - accuracy: 0.8571 - val_loss: 0.2951 - val_accuracy: 0.8856\n",
            "Epoch 652/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.3431 - accuracy: 0.8687 - val_loss: 0.2759 - val_accuracy: 0.8903\n",
            "Epoch 653/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.3564 - accuracy: 0.8658 - val_loss: 0.2896 - val_accuracy: 0.8878\n",
            "Epoch 654/1000\n",
            "13/13 [==============================] - 1s 84ms/step - loss: 0.3411 - accuracy: 0.8743 - val_loss: 0.2739 - val_accuracy: 0.8893\n",
            "Epoch 655/1000\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 0.3581 - accuracy: 0.8646 - val_loss: 0.2824 - val_accuracy: 0.8922\n",
            "Epoch 656/1000\n",
            "13/13 [==============================] - 1s 95ms/step - loss: 0.3220 - accuracy: 0.8752 - val_loss: 0.2797 - val_accuracy: 0.8881\n",
            "Epoch 657/1000\n",
            "13/13 [==============================] - 1s 91ms/step - loss: 0.3679 - accuracy: 0.8583 - val_loss: 0.2955 - val_accuracy: 0.8846\n",
            "Epoch 658/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.3280 - accuracy: 0.8705 - val_loss: 0.2985 - val_accuracy: 0.8809\n",
            "Epoch 659/1000\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 0.3893 - accuracy: 0.8586 - val_loss: 0.3153 - val_accuracy: 0.8771\n",
            "Epoch 660/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.3552 - accuracy: 0.8643 - val_loss: 0.2847 - val_accuracy: 0.8881\n",
            "Epoch 661/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.3590 - accuracy: 0.8624 - val_loss: 0.2836 - val_accuracy: 0.8893\n",
            "Epoch 662/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.3361 - accuracy: 0.8712 - val_loss: 0.2730 - val_accuracy: 0.8956\n",
            "Epoch 663/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.3655 - accuracy: 0.8589 - val_loss: 0.2754 - val_accuracy: 0.8912\n",
            "Epoch 664/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.3142 - accuracy: 0.8796 - val_loss: 0.2678 - val_accuracy: 0.8918\n",
            "Epoch 665/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.3619 - accuracy: 0.8589 - val_loss: 0.2703 - val_accuracy: 0.8962\n",
            "Epoch 666/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.3255 - accuracy: 0.8846 - val_loss: 0.2673 - val_accuracy: 0.8944\n",
            "Epoch 667/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.3518 - accuracy: 0.8577 - val_loss: 0.2694 - val_accuracy: 0.8947\n",
            "Epoch 668/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.3083 - accuracy: 0.8846 - val_loss: 0.2629 - val_accuracy: 0.8962\n",
            "Epoch 669/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.3474 - accuracy: 0.8621 - val_loss: 0.2711 - val_accuracy: 0.8940\n",
            "Epoch 670/1000\n",
            "13/13 [==============================] - 1s 88ms/step - loss: 0.3207 - accuracy: 0.8790 - val_loss: 0.2617 - val_accuracy: 0.8950\n",
            "Epoch 671/1000\n",
            "13/13 [==============================] - 1s 88ms/step - loss: 0.3451 - accuracy: 0.8705 - val_loss: 0.2665 - val_accuracy: 0.8991\n",
            "Epoch 672/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.3162 - accuracy: 0.8846 - val_loss: 0.2586 - val_accuracy: 0.8972\n",
            "Epoch 673/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.3332 - accuracy: 0.8718 - val_loss: 0.2640 - val_accuracy: 0.8978\n",
            "Epoch 674/1000\n",
            "13/13 [==============================] - 1s 93ms/step - loss: 0.3142 - accuracy: 0.8831 - val_loss: 0.2638 - val_accuracy: 0.8959\n",
            "Epoch 675/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.3542 - accuracy: 0.8655 - val_loss: 0.2757 - val_accuracy: 0.8934\n",
            "Epoch 676/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.3075 - accuracy: 0.8878 - val_loss: 0.2677 - val_accuracy: 0.8994\n",
            "Epoch 677/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.3745 - accuracy: 0.8539 - val_loss: 0.2926 - val_accuracy: 0.8856\n",
            "Epoch 678/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.3234 - accuracy: 0.8734 - val_loss: 0.2953 - val_accuracy: 0.8868\n",
            "Epoch 679/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.4024 - accuracy: 0.8436 - val_loss: 0.3378 - val_accuracy: 0.8708\n",
            "Epoch 680/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.3649 - accuracy: 0.8561 - val_loss: 0.2683 - val_accuracy: 0.8947\n",
            "Epoch 681/1000\n",
            "13/13 [==============================] - 1s 86ms/step - loss: 0.3370 - accuracy: 0.8712 - val_loss: 0.2753 - val_accuracy: 0.8909\n",
            "Epoch 682/1000\n",
            "13/13 [==============================] - 1s 102ms/step - loss: 0.3260 - accuracy: 0.8699 - val_loss: 0.2594 - val_accuracy: 0.8975\n",
            "Epoch 683/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.3421 - accuracy: 0.8734 - val_loss: 0.2699 - val_accuracy: 0.8962\n",
            "Epoch 684/1000\n",
            "13/13 [==============================] - 1s 75ms/step - loss: 0.3052 - accuracy: 0.8818 - val_loss: 0.2612 - val_accuracy: 0.8994\n",
            "Epoch 685/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.3608 - accuracy: 0.8611 - val_loss: 0.2786 - val_accuracy: 0.8928\n",
            "Epoch 686/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.3034 - accuracy: 0.8831 - val_loss: 0.2587 - val_accuracy: 0.8972\n",
            "Epoch 687/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.3474 - accuracy: 0.8677 - val_loss: 0.2673 - val_accuracy: 0.8975\n",
            "Epoch 688/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.3106 - accuracy: 0.8856 - val_loss: 0.2683 - val_accuracy: 0.8937\n",
            "Epoch 689/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.3534 - accuracy: 0.8624 - val_loss: 0.2608 - val_accuracy: 0.8987\n",
            "Epoch 690/1000\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 0.3000 - accuracy: 0.8868 - val_loss: 0.2538 - val_accuracy: 0.8991\n",
            "Epoch 691/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.3483 - accuracy: 0.8661 - val_loss: 0.2658 - val_accuracy: 0.8972\n",
            "Epoch 692/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.3148 - accuracy: 0.8834 - val_loss: 0.2564 - val_accuracy: 0.8987\n",
            "Epoch 693/1000\n",
            "13/13 [==============================] - 1s 89ms/step - loss: 0.3565 - accuracy: 0.8643 - val_loss: 0.2675 - val_accuracy: 0.8931\n",
            "Epoch 694/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.3022 - accuracy: 0.8890 - val_loss: 0.2561 - val_accuracy: 0.9000\n",
            "Epoch 695/1000\n",
            "13/13 [==============================] - 1s 86ms/step - loss: 0.3595 - accuracy: 0.8605 - val_loss: 0.2746 - val_accuracy: 0.8944\n",
            "Epoch 696/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.3045 - accuracy: 0.8831 - val_loss: 0.2670 - val_accuracy: 0.8987\n",
            "Epoch 697/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.3770 - accuracy: 0.8564 - val_loss: 0.2938 - val_accuracy: 0.8881\n",
            "Epoch 698/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.3157 - accuracy: 0.8737 - val_loss: 0.2506 - val_accuracy: 0.9041\n",
            "Epoch 699/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.3460 - accuracy: 0.8680 - val_loss: 0.2736 - val_accuracy: 0.8944\n",
            "Epoch 700/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.3081 - accuracy: 0.8850 - val_loss: 0.2455 - val_accuracy: 0.9053\n",
            "Epoch 701/1000\n",
            "13/13 [==============================] - 1s 90ms/step - loss: 0.3141 - accuracy: 0.8793 - val_loss: 0.2542 - val_accuracy: 0.9025\n",
            "Epoch 702/1000\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 0.2975 - accuracy: 0.8887 - val_loss: 0.2445 - val_accuracy: 0.9053\n",
            "Epoch 703/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.3327 - accuracy: 0.8790 - val_loss: 0.2497 - val_accuracy: 0.9016\n",
            "Epoch 704/1000\n",
            "13/13 [==============================] - 1s 90ms/step - loss: 0.2885 - accuracy: 0.8928 - val_loss: 0.2434 - val_accuracy: 0.9038\n",
            "Epoch 705/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.3324 - accuracy: 0.8737 - val_loss: 0.2619 - val_accuracy: 0.8962\n",
            "Epoch 706/1000\n",
            "13/13 [==============================] - 1s 92ms/step - loss: 0.2923 - accuracy: 0.8969 - val_loss: 0.2530 - val_accuracy: 0.9000\n",
            "Epoch 707/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.3481 - accuracy: 0.8665 - val_loss: 0.2623 - val_accuracy: 0.8975\n",
            "Epoch 708/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.2992 - accuracy: 0.8828 - val_loss: 0.2433 - val_accuracy: 0.9056\n",
            "Epoch 709/1000\n",
            "13/13 [==============================] - 1s 91ms/step - loss: 0.3267 - accuracy: 0.8762 - val_loss: 0.2533 - val_accuracy: 0.9013\n",
            "Epoch 710/1000\n",
            "13/13 [==============================] - 1s 92ms/step - loss: 0.3024 - accuracy: 0.8875 - val_loss: 0.2412 - val_accuracy: 0.9069\n",
            "Epoch 711/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.3162 - accuracy: 0.8821 - val_loss: 0.2499 - val_accuracy: 0.8997\n",
            "Epoch 712/1000\n",
            "13/13 [==============================] - 1s 86ms/step - loss: 0.3029 - accuracy: 0.8853 - val_loss: 0.2439 - val_accuracy: 0.9075\n",
            "Epoch 713/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.3243 - accuracy: 0.8752 - val_loss: 0.2671 - val_accuracy: 0.8953\n",
            "Epoch 714/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.3067 - accuracy: 0.8815 - val_loss: 0.2431 - val_accuracy: 0.9056\n",
            "Epoch 715/1000\n",
            "13/13 [==============================] - 1s 89ms/step - loss: 0.3364 - accuracy: 0.8708 - val_loss: 0.2613 - val_accuracy: 0.8975\n",
            "Epoch 716/1000\n",
            "13/13 [==============================] - 1s 96ms/step - loss: 0.3032 - accuracy: 0.8818 - val_loss: 0.2475 - val_accuracy: 0.9019\n",
            "Epoch 717/1000\n",
            "13/13 [==============================] - 1s 96ms/step - loss: 0.3356 - accuracy: 0.8730 - val_loss: 0.2686 - val_accuracy: 0.8944\n",
            "Epoch 718/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.3062 - accuracy: 0.8856 - val_loss: 0.2401 - val_accuracy: 0.9050\n",
            "Epoch 719/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.3320 - accuracy: 0.8746 - val_loss: 0.2544 - val_accuracy: 0.9013\n",
            "Epoch 720/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.2822 - accuracy: 0.8934 - val_loss: 0.2399 - val_accuracy: 0.9066\n",
            "Epoch 721/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.3328 - accuracy: 0.8743 - val_loss: 0.2540 - val_accuracy: 0.9000\n",
            "Epoch 722/1000\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 0.2880 - accuracy: 0.8978 - val_loss: 0.2341 - val_accuracy: 0.9085\n",
            "Epoch 723/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.3228 - accuracy: 0.8803 - val_loss: 0.2464 - val_accuracy: 0.9038\n",
            "Epoch 724/1000\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.2886 - accuracy: 0.8931 - val_loss: 0.2327 - val_accuracy: 0.9069\n",
            "Epoch 725/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.3135 - accuracy: 0.8809 - val_loss: 0.2506 - val_accuracy: 0.9034\n",
            "Epoch 726/1000\n",
            "13/13 [==============================] - 1s 92ms/step - loss: 0.2994 - accuracy: 0.8843 - val_loss: 0.2291 - val_accuracy: 0.9113\n",
            "Epoch 727/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.2925 - accuracy: 0.8868 - val_loss: 0.2305 - val_accuracy: 0.9119\n",
            "Epoch 728/1000\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 0.2979 - accuracy: 0.8956 - val_loss: 0.2277 - val_accuracy: 0.9110\n",
            "Epoch 729/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.2806 - accuracy: 0.9000 - val_loss: 0.2289 - val_accuracy: 0.9116\n",
            "Epoch 730/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.3090 - accuracy: 0.8771 - val_loss: 0.2281 - val_accuracy: 0.9103\n",
            "Epoch 731/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.2737 - accuracy: 0.8972 - val_loss: 0.2308 - val_accuracy: 0.9113\n",
            "Epoch 732/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.3176 - accuracy: 0.8777 - val_loss: 0.2323 - val_accuracy: 0.9107\n",
            "Epoch 733/1000\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 0.2763 - accuracy: 0.8981 - val_loss: 0.2339 - val_accuracy: 0.9069\n",
            "Epoch 734/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.3422 - accuracy: 0.8671 - val_loss: 0.2509 - val_accuracy: 0.9038\n",
            "Epoch 735/1000\n",
            "13/13 [==============================] - 1s 92ms/step - loss: 0.2764 - accuracy: 0.8972 - val_loss: 0.2319 - val_accuracy: 0.9100\n",
            "Epoch 736/1000\n",
            "13/13 [==============================] - 1s 84ms/step - loss: 0.3125 - accuracy: 0.8790 - val_loss: 0.2376 - val_accuracy: 0.9094\n",
            "Epoch 737/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.2772 - accuracy: 0.8984 - val_loss: 0.2259 - val_accuracy: 0.9144\n",
            "Epoch 738/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.3082 - accuracy: 0.8837 - val_loss: 0.2403 - val_accuracy: 0.9066\n",
            "Epoch 739/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.2837 - accuracy: 0.8940 - val_loss: 0.2247 - val_accuracy: 0.9154\n",
            "Epoch 740/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.2844 - accuracy: 0.8969 - val_loss: 0.2364 - val_accuracy: 0.9066\n",
            "Epoch 741/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.3183 - accuracy: 0.8796 - val_loss: 0.2308 - val_accuracy: 0.9103\n",
            "Epoch 742/1000\n",
            "13/13 [==============================] - 1s 88ms/step - loss: 0.2753 - accuracy: 0.9003 - val_loss: 0.2468 - val_accuracy: 0.9053\n",
            "Epoch 743/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.3467 - accuracy: 0.8658 - val_loss: 0.2632 - val_accuracy: 0.8947\n",
            "Epoch 744/1000\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 0.2908 - accuracy: 0.8909 - val_loss: 0.2670 - val_accuracy: 0.9000\n",
            "Epoch 745/1000\n",
            "13/13 [==============================] - 1s 91ms/step - loss: 0.3932 - accuracy: 0.8489 - val_loss: 0.3079 - val_accuracy: 0.8784\n",
            "Epoch 746/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.3290 - accuracy: 0.8724 - val_loss: 0.2369 - val_accuracy: 0.9091\n",
            "Epoch 747/1000\n",
            "13/13 [==============================] - 1s 91ms/step - loss: 0.3154 - accuracy: 0.8790 - val_loss: 0.2330 - val_accuracy: 0.9078\n",
            "Epoch 748/1000\n",
            "13/13 [==============================] - 1s 86ms/step - loss: 0.2806 - accuracy: 0.8981 - val_loss: 0.2295 - val_accuracy: 0.9113\n",
            "Epoch 749/1000\n",
            "13/13 [==============================] - 1s 90ms/step - loss: 0.2937 - accuracy: 0.8893 - val_loss: 0.2256 - val_accuracy: 0.9141\n",
            "Epoch 750/1000\n",
            "13/13 [==============================] - 1s 88ms/step - loss: 0.2654 - accuracy: 0.9022 - val_loss: 0.2250 - val_accuracy: 0.9100\n",
            "Epoch 751/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.3180 - accuracy: 0.8762 - val_loss: 0.2353 - val_accuracy: 0.9122\n",
            "Epoch 752/1000\n",
            "13/13 [==============================] - 1s 88ms/step - loss: 0.2592 - accuracy: 0.9038 - val_loss: 0.2230 - val_accuracy: 0.9138\n",
            "Epoch 753/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.3138 - accuracy: 0.8803 - val_loss: 0.2366 - val_accuracy: 0.9094\n",
            "Epoch 754/1000\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 0.2666 - accuracy: 0.9028 - val_loss: 0.2158 - val_accuracy: 0.9163\n",
            "Epoch 755/1000\n",
            "13/13 [==============================] - 1s 91ms/step - loss: 0.2860 - accuracy: 0.8969 - val_loss: 0.2295 - val_accuracy: 0.9110\n",
            "Epoch 756/1000\n",
            "13/13 [==============================] - 1s 91ms/step - loss: 0.2931 - accuracy: 0.8925 - val_loss: 0.2146 - val_accuracy: 0.9176\n",
            "Epoch 757/1000\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 0.2772 - accuracy: 0.8966 - val_loss: 0.2323 - val_accuracy: 0.9094\n",
            "Epoch 758/1000\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 0.2873 - accuracy: 0.8887 - val_loss: 0.2175 - val_accuracy: 0.9172\n",
            "Epoch 759/1000\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.2866 - accuracy: 0.8906 - val_loss: 0.2348 - val_accuracy: 0.9100\n",
            "Epoch 760/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.2996 - accuracy: 0.8893 - val_loss: 0.2333 - val_accuracy: 0.9078\n",
            "Epoch 761/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.3037 - accuracy: 0.8824 - val_loss: 0.2322 - val_accuracy: 0.9088\n",
            "Epoch 762/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.2702 - accuracy: 0.9009 - val_loss: 0.2155 - val_accuracy: 0.9176\n",
            "Epoch 763/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.3077 - accuracy: 0.8856 - val_loss: 0.2286 - val_accuracy: 0.9097\n",
            "Epoch 764/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.2706 - accuracy: 0.9013 - val_loss: 0.2142 - val_accuracy: 0.9169\n",
            "Epoch 765/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.2919 - accuracy: 0.8850 - val_loss: 0.2184 - val_accuracy: 0.9144\n",
            "Epoch 766/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.2606 - accuracy: 0.9009 - val_loss: 0.2117 - val_accuracy: 0.9197\n",
            "Epoch 767/1000\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 0.2890 - accuracy: 0.8940 - val_loss: 0.2156 - val_accuracy: 0.9172\n",
            "Epoch 768/1000\n",
            "13/13 [==============================] - 1s 88ms/step - loss: 0.2578 - accuracy: 0.9041 - val_loss: 0.2095 - val_accuracy: 0.9188\n",
            "Epoch 769/1000\n",
            "13/13 [==============================] - 1s 90ms/step - loss: 0.2712 - accuracy: 0.8950 - val_loss: 0.2127 - val_accuracy: 0.9210\n",
            "Epoch 770/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.2566 - accuracy: 0.9056 - val_loss: 0.2099 - val_accuracy: 0.9194\n",
            "Epoch 771/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.2875 - accuracy: 0.8944 - val_loss: 0.2228 - val_accuracy: 0.9160\n",
            "Epoch 772/1000\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.2750 - accuracy: 0.8944 - val_loss: 0.2414 - val_accuracy: 0.9072\n",
            "Epoch 773/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.3423 - accuracy: 0.8730 - val_loss: 0.2769 - val_accuracy: 0.8950\n",
            "Epoch 774/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.2980 - accuracy: 0.8865 - val_loss: 0.2418 - val_accuracy: 0.9088\n",
            "Epoch 775/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.3405 - accuracy: 0.8712 - val_loss: 0.2851 - val_accuracy: 0.8884\n",
            "Epoch 776/1000\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.3117 - accuracy: 0.8821 - val_loss: 0.2252 - val_accuracy: 0.9113\n",
            "Epoch 777/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.3182 - accuracy: 0.8781 - val_loss: 0.2513 - val_accuracy: 0.9047\n",
            "Epoch 778/1000\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.2830 - accuracy: 0.8937 - val_loss: 0.2196 - val_accuracy: 0.9141\n",
            "Epoch 779/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.3010 - accuracy: 0.8871 - val_loss: 0.2326 - val_accuracy: 0.9107\n",
            "Epoch 780/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.2621 - accuracy: 0.9082 - val_loss: 0.2121 - val_accuracy: 0.9185\n",
            "Epoch 781/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.2972 - accuracy: 0.8878 - val_loss: 0.2287 - val_accuracy: 0.9110\n",
            "Epoch 782/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.2680 - accuracy: 0.9009 - val_loss: 0.2111 - val_accuracy: 0.9176\n",
            "Epoch 783/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.2738 - accuracy: 0.8959 - val_loss: 0.2296 - val_accuracy: 0.9113\n",
            "Epoch 784/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.2684 - accuracy: 0.8994 - val_loss: 0.2114 - val_accuracy: 0.9197\n",
            "Epoch 785/1000\n",
            "13/13 [==============================] - 1s 84ms/step - loss: 0.2682 - accuracy: 0.9006 - val_loss: 0.2244 - val_accuracy: 0.9122\n",
            "Epoch 786/1000\n",
            "13/13 [==============================] - 1s 89ms/step - loss: 0.2816 - accuracy: 0.8928 - val_loss: 0.2097 - val_accuracy: 0.9191\n",
            "Epoch 787/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.2526 - accuracy: 0.9088 - val_loss: 0.2068 - val_accuracy: 0.9219\n",
            "Epoch 788/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.2786 - accuracy: 0.8940 - val_loss: 0.2062 - val_accuracy: 0.9229\n",
            "Epoch 789/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.2486 - accuracy: 0.9116 - val_loss: 0.2008 - val_accuracy: 0.9248\n",
            "Epoch 790/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.2853 - accuracy: 0.8915 - val_loss: 0.2053 - val_accuracy: 0.9241\n",
            "Epoch 791/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.2419 - accuracy: 0.9100 - val_loss: 0.2015 - val_accuracy: 0.9232\n",
            "Epoch 792/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.2847 - accuracy: 0.8928 - val_loss: 0.2155 - val_accuracy: 0.9147\n",
            "Epoch 793/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.2399 - accuracy: 0.9103 - val_loss: 0.2052 - val_accuracy: 0.9226\n",
            "Epoch 794/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.2979 - accuracy: 0.8947 - val_loss: 0.2265 - val_accuracy: 0.9150\n",
            "Epoch 795/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.2609 - accuracy: 0.8991 - val_loss: 0.2044 - val_accuracy: 0.9197\n",
            "Epoch 796/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.2637 - accuracy: 0.9031 - val_loss: 0.2359 - val_accuracy: 0.9094\n",
            "Epoch 797/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.3075 - accuracy: 0.8856 - val_loss: 0.2113 - val_accuracy: 0.9185\n",
            "Epoch 798/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.2433 - accuracy: 0.9157 - val_loss: 0.2132 - val_accuracy: 0.9163\n",
            "Epoch 799/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.3213 - accuracy: 0.8755 - val_loss: 0.2353 - val_accuracy: 0.9097\n",
            "Epoch 800/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.2463 - accuracy: 0.9119 - val_loss: 0.2053 - val_accuracy: 0.9219\n",
            "Epoch 801/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.2953 - accuracy: 0.8821 - val_loss: 0.2290 - val_accuracy: 0.9097\n",
            "Epoch 802/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.2512 - accuracy: 0.9107 - val_loss: 0.2010 - val_accuracy: 0.9254\n",
            "Epoch 803/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.2998 - accuracy: 0.8862 - val_loss: 0.2306 - val_accuracy: 0.9129\n",
            "Epoch 804/1000\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 0.2645 - accuracy: 0.9050 - val_loss: 0.2020 - val_accuracy: 0.9229\n",
            "Epoch 805/1000\n",
            "13/13 [==============================] - 1s 83ms/step - loss: 0.2862 - accuracy: 0.8962 - val_loss: 0.2277 - val_accuracy: 0.9138\n",
            "Epoch 806/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.2849 - accuracy: 0.8925 - val_loss: 0.2057 - val_accuracy: 0.9188\n",
            "Epoch 807/1000\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 0.2887 - accuracy: 0.8900 - val_loss: 0.2374 - val_accuracy: 0.9094\n",
            "Epoch 808/1000\n",
            "13/13 [==============================] - 1s 90ms/step - loss: 0.2591 - accuracy: 0.9050 - val_loss: 0.1981 - val_accuracy: 0.9232\n",
            "Epoch 809/1000\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 0.2835 - accuracy: 0.8934 - val_loss: 0.2089 - val_accuracy: 0.9229\n",
            "Epoch 810/1000\n",
            "13/13 [==============================] - 1s 84ms/step - loss: 0.2409 - accuracy: 0.9135 - val_loss: 0.1921 - val_accuracy: 0.9298\n",
            "Epoch 811/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.2623 - accuracy: 0.9031 - val_loss: 0.2086 - val_accuracy: 0.9238\n",
            "Epoch 812/1000\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 0.2544 - accuracy: 0.9016 - val_loss: 0.1915 - val_accuracy: 0.9282\n",
            "Epoch 813/1000\n",
            "13/13 [==============================] - 1s 86ms/step - loss: 0.2509 - accuracy: 0.9069 - val_loss: 0.2025 - val_accuracy: 0.9245\n",
            "Epoch 814/1000\n",
            "13/13 [==============================] - 1s 91ms/step - loss: 0.2522 - accuracy: 0.9125 - val_loss: 0.1872 - val_accuracy: 0.9301\n",
            "Epoch 815/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.2517 - accuracy: 0.9053 - val_loss: 0.1894 - val_accuracy: 0.9301\n",
            "Epoch 816/1000\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.2493 - accuracy: 0.9129 - val_loss: 0.1865 - val_accuracy: 0.9285\n",
            "Epoch 817/1000\n",
            "13/13 [==============================] - 1s 88ms/step - loss: 0.2527 - accuracy: 0.9091 - val_loss: 0.1882 - val_accuracy: 0.9320\n",
            "Epoch 818/1000\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 0.2344 - accuracy: 0.9185 - val_loss: 0.1867 - val_accuracy: 0.9307\n",
            "Epoch 819/1000\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 0.2683 - accuracy: 0.9013 - val_loss: 0.1931 - val_accuracy: 0.9285\n",
            "Epoch 820/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.2360 - accuracy: 0.9204 - val_loss: 0.1920 - val_accuracy: 0.9285\n",
            "Epoch 821/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.2892 - accuracy: 0.8897 - val_loss: 0.2022 - val_accuracy: 0.9270\n",
            "Epoch 822/1000\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.2356 - accuracy: 0.9144 - val_loss: 0.2034 - val_accuracy: 0.9207\n",
            "Epoch 823/1000\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.3129 - accuracy: 0.8865 - val_loss: 0.2254 - val_accuracy: 0.9166\n",
            "Epoch 824/1000\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 0.2410 - accuracy: 0.9110 - val_loss: 0.1949 - val_accuracy: 0.9257\n",
            "Epoch 825/1000\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 0.2927 - accuracy: 0.8850 - val_loss: 0.2195 - val_accuracy: 0.9182\n",
            "Epoch 826/1000\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.2431 - accuracy: 0.9157 - val_loss: 0.1928 - val_accuracy: 0.9273\n",
            "Epoch 827/1000\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 0.2874 - accuracy: 0.8912 - val_loss: 0.2183 - val_accuracy: 0.9160\n",
            "Epoch 828/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.2398 - accuracy: 0.9141 - val_loss: 0.1976 - val_accuracy: 0.9260\n",
            "Epoch 829/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.2849 - accuracy: 0.8962 - val_loss: 0.2449 - val_accuracy: 0.9100\n",
            "Epoch 830/1000\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 0.2771 - accuracy: 0.9019 - val_loss: 0.2063 - val_accuracy: 0.9235\n",
            "Epoch 831/1000\n",
            "13/13 [==============================] - 1s 88ms/step - loss: 0.2576 - accuracy: 0.9069 - val_loss: 0.2447 - val_accuracy: 0.9091\n",
            "Epoch 832/1000\n",
            "13/13 [==============================] - 1s 92ms/step - loss: 0.3039 - accuracy: 0.8821 - val_loss: 0.2264 - val_accuracy: 0.9138\n",
            "Epoch 833/1000\n",
            "13/13 [==============================] - 1s 80ms/step - loss: 0.2702 - accuracy: 0.9016 - val_loss: 0.2841 - val_accuracy: 0.8966\n",
            "Epoch 834/1000\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 0.3716 - accuracy: 0.8630 - val_loss: 0.3034 - val_accuracy: 0.8853\n",
            "Epoch 835/1000\n",
            "13/13 [==============================] - 1s 92ms/step - loss: 0.3092 - accuracy: 0.8947 - val_loss: 0.3493 - val_accuracy: 0.8749\n",
            "Epoch 836/1000\n",
            "13/13 [==============================] - 1s 94ms/step - loss: 0.4323 - accuracy: 0.8279 - val_loss: 0.3436 - val_accuracy: 0.8652\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZfOZPvdTHmG",
        "outputId": "cd776f53-88a1-4a34-b99d-7f3335441ad1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 845
        }
      },
      "source": [
        "model.compile(keras.optimizers.SGD(momentum=0.9), loss=keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
        "hist2 = model.fit(xtrain_ds, validation_data=xval_ds, epochs=100, callbacks=[es_cb])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "13/13 [==============================] - 1s 99ms/step - loss: 2.7900 - accuracy: 0.4085 - val_loss: 1.7440 - val_accuracy: 0.5188\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 1s 76ms/step - loss: 1.7963 - accuracy: 0.2191 - val_loss: 1.0440 - val_accuracy: 0.5188\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 1s 89ms/step - loss: 1.0400 - accuracy: 0.5194 - val_loss: 1.0238 - val_accuracy: 0.5188\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 1.0963 - accuracy: 0.5188 - val_loss: 1.0282 - val_accuracy: 0.5188\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 1.0701 - accuracy: 0.5188 - val_loss: 1.0269 - val_accuracy: 0.5188\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 1s 100ms/step - loss: 1.0600 - accuracy: 0.5188 - val_loss: 1.0264 - val_accuracy: 0.5188\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 1.0528 - accuracy: 0.5188 - val_loss: 1.0263 - val_accuracy: 0.5188\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 1.0532 - accuracy: 0.5188 - val_loss: 1.0265 - val_accuracy: 0.5188\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 1.0526 - accuracy: 0.5188 - val_loss: 1.0266 - val_accuracy: 0.5188\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 1s 90ms/step - loss: 1.0516 - accuracy: 0.5188 - val_loss: 1.0267 - val_accuracy: 0.5188\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 1s 77ms/step - loss: 1.0516 - accuracy: 0.5188 - val_loss: 1.0267 - val_accuracy: 0.5188\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 1s 92ms/step - loss: 1.0516 - accuracy: 0.5188 - val_loss: 1.0268 - val_accuracy: 0.5188\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 1s 82ms/step - loss: 1.0510 - accuracy: 0.5188 - val_loss: 1.0269 - val_accuracy: 0.5188\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 1s 97ms/step - loss: 1.0494 - accuracy: 0.5188 - val_loss: 1.0270 - val_accuracy: 0.5188\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 1s 89ms/step - loss: 1.0493 - accuracy: 0.5188 - val_loss: 1.0270 - val_accuracy: 0.5188\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 1.0497 - accuracy: 0.5188 - val_loss: 1.0270 - val_accuracy: 0.5188\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 1.0492 - accuracy: 0.5188 - val_loss: 1.0270 - val_accuracy: 0.5188\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 1s 91ms/step - loss: 1.0482 - accuracy: 0.5188 - val_loss: 1.0271 - val_accuracy: 0.5188\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 1s 78ms/step - loss: 1.0482 - accuracy: 0.5188 - val_loss: 1.0272 - val_accuracy: 0.5188\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 1.0483 - accuracy: 0.5188 - val_loss: 1.0272 - val_accuracy: 0.5188\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 1s 84ms/step - loss: 1.0484 - accuracy: 0.5188 - val_loss: 1.0272 - val_accuracy: 0.5188\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 1.0489 - accuracy: 0.5188 - val_loss: 1.0272 - val_accuracy: 0.5188\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 1s 90ms/step - loss: 1.0485 - accuracy: 0.5188 - val_loss: 1.0273 - val_accuracy: 0.5188\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjiRiXQHwNOS",
        "outputId": "708b825e-0f58-4f79-bce7-6eb7ca70442a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "for i in range(1):\n",
        "  ax1 = axes[0]\n",
        "  ax2 = axes[1]\n",
        "\n",
        "  ax1.plot(hist.history['loss'], label='training')\n",
        "  ax1.plot(hist.history['val_loss'], label='validation')\n",
        "  ax1.set_title('lstm autoencoder loss')\n",
        "  ax1.set_xlabel('epoch')\n",
        "  ax1.set_ylabel('loss')\n",
        "  ax1.legend(['train', 'validation'], loc='upper left')\n",
        "  \n",
        "  ax2.plot(hist.history['accuracy'], label='training')\n",
        "  ax2.plot(hist.history['val_accuracy'], label='validation')\n",
        "  ax2.set_title('lstm autoencoder accuracy')\n",
        "  ax2.set_xlabel('epoch')\n",
        "  ax2.set_ylabel('accuracy')\n",
        "  ax2.legend(['train', 'validation'], loc='upper left')\n",
        "fig.tight_layout()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sgxZ6qrU9-9"
      },
      "source": [
        "def eval_model(model, ds, ds_name=\"Training\"):\n",
        "  loss, acc = model.evaluate(ds, verbose=0)\n",
        "  print(\"{} Dataset: loss = {} and acccuracy = {}%\".format(ds_name, np.round(loss, 3), np.round(acc*100, 2)))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwcedsFqDUnm",
        "outputId": "e3d7fed9-d52f-4faf-8552-e5adadd4a866",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "eval_model(model, xtrain_ds, \"Training\")\n",
        "eval_model(model, xval_ds, \"Validation\")\n",
        "eval_model(model, xtest_ds, \"Test\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Dataset: loss = 0.187 and acccuracy = 92.85%\n",
            "Validation Dataset: loss = 0.187 and acccuracy = 92.85%\n",
            "Test Dataset: loss = 0.187 and acccuracy = 92.85%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
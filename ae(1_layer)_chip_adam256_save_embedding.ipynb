{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ae(1 layer)_chip_adam256_save embedding.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP7IXcm1DcNOgA6uw+FJmNr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/csy99/dna-nn-theory/blob/master/ae(1_layer)_chip_adam256_save_embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiSO3GWw8FWG"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import product\n",
        "import re\n",
        "import time\n",
        "# from sklearn.model_selection import train_test_split\n",
        "from sklearn.manifold import TSNE\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LCWC3mMfj_i",
        "outputId": "b61da39f-d4d1-414a-fb2b-a48437192060",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "!pip install biopython\n",
        "from Bio import SeqIO"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: biopython in /usr/local/lib/python3.6/dist-packages (1.78)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from biopython) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuvNh5Ia8vvD"
      },
      "source": [
        "# Read Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5SYc4iv-RPC",
        "outputId": "c4f22fa2-6632-4cb4-870f-26db2cd9eb0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "source": [
        "!pip install PyDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyDrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.7.12)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.17.2)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.15.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.17.4)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (4.1.1)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (50.3.0)\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3Qvmz3MfcR1"
      },
      "source": [
        "def readFasta(file):\n",
        "  with open(file, 'r') as f:\n",
        "    records = np.array([record.seq._data.upper() for record in SeqIO.parse(f, 'fasta')])\n",
        "  with open(file, 'r') as f:\n",
        "    records_id = np.array([record.id for record in SeqIO.parse(f, 'fasta')])\n",
        "  print('reading', str(file), 'Number of sequences :', \n",
        "        len(records), 'Length of sequences :', len(records[0]))\n",
        "  records_df = pd.DataFrame({'id': records_id, 'seq': records})\n",
        "  return records_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ue0xl7xUfeCZ",
        "outputId": "e1544e6e-b592-4b96-ec08-f84e74ff14a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "# read fasta data\n",
        "data_path = '/content/gdrive/My Drive/Colab Notebooks/CHIP/'\n",
        "chip_train = readFasta(data_path + 'train.fasta')\n",
        "chip_val = readFasta(data_path + 'valid.fasta')\n",
        "chip_test = readFasta(data_path + 'test.fasta')\n",
        "chip_train[\"id\"] = chip_train[\"id\"].astype(int)\n",
        "chip_val[\"id\"] = chip_val[\"id\"].astype(int)\n",
        "chip_test[\"id\"] = chip_test[\"id\"].astype(int)\n",
        "print(chip_train.id.value_counts())\n",
        "print(chip_val.id.value_counts())\n",
        "print(chip_test.id.value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reading /content/gdrive/My Drive/Colab Notebooks/CHIP/train.fasta Number of sequences : 77174 Length of sequences : 101\n",
            "reading /content/gdrive/My Drive/Colab Notebooks/CHIP/valid.fasta Number of sequences : 1000 Length of sequences : 101\n",
            "reading /content/gdrive/My Drive/Colab Notebooks/CHIP/test.fasta Number of sequences : 19544 Length of sequences : 101\n",
            "1    38638\n",
            "0    38536\n",
            "Name: id, dtype: int64\n",
            "1    500\n",
            "0    500\n",
            "Name: id, dtype: int64\n",
            "0    9823\n",
            "1    9721\n",
            "Name: id, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_IFMicpqYIl"
      },
      "source": [
        "seq_num = 0\n",
        "for seq in chip_train[\"seq\"]:\n",
        "  char_num = 0\n",
        "  for char in seq:\n",
        "    if char != 'A' and char != 'C' and char != 'T' and char != 'G':\n",
        "      print(\"seq\", seq_num, 'char', char_num, 'is', char)\n",
        "    char_num += 1\n",
        "  seq_num += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSFFjXSJP88L",
        "outputId": "f519be8b-5708-45cf-ac37-f6087f7c6df9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# check if the length of the sequence is the same \n",
        "seq_len = len(chip_train.seq[0])\n",
        "print(\"The length of the sequence is\", seq_len)\n",
        "for seq in chip_train.seq[:200]:\n",
        "  assert len(seq) == seq_len"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The length of the sequence is 101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2h9sGLCVtDn",
        "outputId": "178f304b-7add-4bfc-a517-7ab2b29b275a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "word_size = 1\n",
        "vocab = [''.join(p) for p in product('ACGT', repeat=word_size)]\n",
        "vocab_size = len('ACGT')\n",
        "print('vocab_size:', vocab_size)\n",
        "# print(\"word_to_idx\", word_to_idx)\n",
        "create1gram = keras.layers.experimental.preprocessing.TextVectorization(\n",
        "  standardize=lambda x: tf.strings.regex_replace(x, '(.)', '\\\\1 '), ngrams=1\n",
        ")\n",
        "create1gram.adapt(vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab_size: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHPvs2BCU_Mk"
      },
      "source": [
        "# the first two index of TextVectorization has been reserved to EOS and OOV\n",
        "def index_preprocess(x):\n",
        "  x_index = tf.subtract(create1gram(x), 2)\n",
        "  return x_index, x_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFvsJkEa0YuT",
        "outputId": "2fee6d40-4fd9-4064-e0e5-4fbfba899f2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# not sure the correct way to get mapping from word to its index\n",
        "create1gram('A C G T') - 2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([3, 2, 1, 0])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzLRmqEjSitl"
      },
      "source": [
        "BATCH_SIZE = 256\n",
        "xtrain_seq = tf.data.Dataset.from_tensor_slices(chip_train['seq']).map(index_preprocess).batch(BATCH_SIZE)\n",
        "xval_seq = tf.data.Dataset.from_tensor_slices(chip_val['seq']).map(index_preprocess).batch(BATCH_SIZE)\n",
        "xtest_seq = tf.data.Dataset.from_tensor_slices(chip_test['seq']).map(index_preprocess).batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVLaIchQUWQl",
        "outputId": "c4b39857-2a34-46cd-f36f-5921b90a2637",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "latent_size = 30\n",
        "\n",
        "encoder = keras.Sequential([\n",
        "    keras.Input(shape=(seq_len,)),\n",
        "    keras.layers.Embedding(seq_len, latent_size),\n",
        "    keras.layers.LSTM(latent_size, return_sequences=False),\n",
        "])\n",
        "\n",
        "decoder = keras.Sequential([\n",
        "    keras.layers.RepeatVector(seq_len, input_shape=[latent_size]),\n",
        "    keras.layers.LSTM(latent_size, return_sequences=True),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(4, activation='softmax'))  # ACTG\n",
        "])\n",
        "\n",
        "recurrent_ae = keras.Sequential([encoder, decoder])\n",
        "recurrent_ae.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential (Sequential)      (None, 30)                10350     \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    (None, 101, 4)            7444      \n",
            "=================================================================\n",
            "Total params: 17,794\n",
            "Trainable params: 17,794\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMlnaNStWLNK"
      },
      "source": [
        "# save_freq=1500 means that the model will be saved around every 20 epochs (each epochs contain 76 batches)\n",
        "checkpoint_filepath = '/content/gdrive/My Drive/Colab Notebooks/models/lstm1_chip.256.{epoch:04d}.h5'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=False,\n",
        "    monitor='val_acc',\n",
        "    mode='max',\n",
        "    save_best_only=False,\n",
        "    save_freq=1500)\n",
        "es_cb = keras.callbacks.EarlyStopping(patience=100, restore_best_weights=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzGk4gMahIvw",
        "outputId": "699cf60c-1f13-4d36-aa55-798c8513ea0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "recurrent_ae.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "ae_hist = recurrent_ae.fit(xtrain_seq, validation_data=xval_seq, epochs=3000, callbacks=[es_cb])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3000\n",
            "302/302 [==============================] - 15s 50ms/step - loss: 1.3503 - accuracy: 0.3264 - val_loss: 1.3419 - val_accuracy: 0.3385\n",
            "Epoch 2/3000\n",
            "302/302 [==============================] - 14s 48ms/step - loss: 1.3420 - accuracy: 0.3387 - val_loss: 1.3414 - val_accuracy: 0.3389\n",
            "Epoch 3/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.3398 - accuracy: 0.3412 - val_loss: 1.3364 - val_accuracy: 0.3451\n",
            "Epoch 4/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.3323 - accuracy: 0.3497 - val_loss: 1.3295 - val_accuracy: 0.3530\n",
            "Epoch 5/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.3266 - accuracy: 0.3557 - val_loss: 1.3214 - val_accuracy: 0.3601\n",
            "Epoch 6/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.3164 - accuracy: 0.3646 - val_loss: 1.3110 - val_accuracy: 0.3694\n",
            "Epoch 7/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.3090 - accuracy: 0.3704 - val_loss: 1.3059 - val_accuracy: 0.3716\n",
            "Epoch 8/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.3052 - accuracy: 0.3731 - val_loss: 1.3033 - val_accuracy: 0.3738\n",
            "Epoch 9/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.3031 - accuracy: 0.3744 - val_loss: 1.3016 - val_accuracy: 0.3758\n",
            "Epoch 10/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.3013 - accuracy: 0.3758 - val_loss: 1.3012 - val_accuracy: 0.3751\n",
            "Epoch 11/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.2988 - accuracy: 0.3780 - val_loss: 1.2943 - val_accuracy: 0.3811\n",
            "Epoch 12/3000\n",
            "302/302 [==============================] - 15s 48ms/step - loss: 1.2928 - accuracy: 0.3828 - val_loss: 1.2892 - val_accuracy: 0.3849\n",
            "Epoch 13/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.2877 - accuracy: 0.3870 - val_loss: 1.2843 - val_accuracy: 0.3888\n",
            "Epoch 14/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.2834 - accuracy: 0.3903 - val_loss: 1.2809 - val_accuracy: 0.3928\n",
            "Epoch 15/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.2797 - accuracy: 0.3930 - val_loss: 1.2761 - val_accuracy: 0.3962\n",
            "Epoch 16/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.2753 - accuracy: 0.3962 - val_loss: 1.2724 - val_accuracy: 0.3981\n",
            "Epoch 17/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.2719 - accuracy: 0.3986 - val_loss: 1.2694 - val_accuracy: 0.3997\n",
            "Epoch 18/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.2687 - accuracy: 0.4006 - val_loss: 1.2659 - val_accuracy: 0.4027\n",
            "Epoch 19/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.2659 - accuracy: 0.4024 - val_loss: 1.2654 - val_accuracy: 0.4046\n",
            "Epoch 20/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.2639 - accuracy: 0.4039 - val_loss: 1.2668 - val_accuracy: 0.4014\n",
            "Epoch 21/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.2606 - accuracy: 0.4059 - val_loss: 1.2600 - val_accuracy: 0.4067\n",
            "Epoch 22/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.2581 - accuracy: 0.4073 - val_loss: 1.2557 - val_accuracy: 0.4094\n",
            "Epoch 23/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.2562 - accuracy: 0.4087 - val_loss: 1.2573 - val_accuracy: 0.4067\n",
            "Epoch 24/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.2541 - accuracy: 0.4100 - val_loss: 1.2522 - val_accuracy: 0.4112\n",
            "Epoch 25/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.2524 - accuracy: 0.4111 - val_loss: 1.2513 - val_accuracy: 0.4126\n",
            "Epoch 26/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.2511 - accuracy: 0.4121 - val_loss: 1.2494 - val_accuracy: 0.4129\n",
            "Epoch 27/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.2493 - accuracy: 0.4130 - val_loss: 1.2504 - val_accuracy: 0.4136\n",
            "Epoch 28/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.2481 - accuracy: 0.4140 - val_loss: 1.2479 - val_accuracy: 0.4156\n",
            "Epoch 29/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.2464 - accuracy: 0.4150 - val_loss: 1.2444 - val_accuracy: 0.4177\n",
            "Epoch 30/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.2452 - accuracy: 0.4160 - val_loss: 1.2440 - val_accuracy: 0.4169\n",
            "Epoch 31/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.2447 - accuracy: 0.4165 - val_loss: 1.2449 - val_accuracy: 0.4178\n",
            "Epoch 32/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.2426 - accuracy: 0.4179 - val_loss: 1.2489 - val_accuracy: 0.4157\n",
            "Epoch 33/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.2408 - accuracy: 0.4191 - val_loss: 1.2405 - val_accuracy: 0.4199\n",
            "Epoch 34/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.2395 - accuracy: 0.4201 - val_loss: 1.2393 - val_accuracy: 0.4202\n",
            "Epoch 35/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.2393 - accuracy: 0.4204 - val_loss: 1.2366 - val_accuracy: 0.4229\n",
            "Epoch 36/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.2364 - accuracy: 0.4219 - val_loss: 1.2385 - val_accuracy: 0.4230\n",
            "Epoch 37/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.2354 - accuracy: 0.4226 - val_loss: 1.2340 - val_accuracy: 0.4236\n",
            "Epoch 38/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.2340 - accuracy: 0.4233 - val_loss: 1.2330 - val_accuracy: 0.4246\n",
            "Epoch 39/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.2333 - accuracy: 0.4238 - val_loss: 1.2306 - val_accuracy: 0.4262\n",
            "Epoch 40/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.2322 - accuracy: 0.4245 - val_loss: 1.2301 - val_accuracy: 0.4254\n",
            "Epoch 41/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.2312 - accuracy: 0.4250 - val_loss: 1.2285 - val_accuracy: 0.4266\n",
            "Epoch 42/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.2308 - accuracy: 0.4252 - val_loss: 1.2298 - val_accuracy: 0.4265\n",
            "Epoch 43/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.2290 - accuracy: 0.4264 - val_loss: 1.2267 - val_accuracy: 0.4274\n",
            "Epoch 44/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.2294 - accuracy: 0.4262 - val_loss: 1.2346 - val_accuracy: 0.4240\n",
            "Epoch 45/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.2279 - accuracy: 0.4270 - val_loss: 1.2255 - val_accuracy: 0.4288\n",
            "Epoch 46/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.2266 - accuracy: 0.4278 - val_loss: 1.2252 - val_accuracy: 0.4285\n",
            "Epoch 47/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.2275 - accuracy: 0.4274 - val_loss: 1.2236 - val_accuracy: 0.4292\n",
            "Epoch 48/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.2245 - accuracy: 0.4290 - val_loss: 1.2228 - val_accuracy: 0.4299\n",
            "Epoch 49/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.2234 - accuracy: 0.4296 - val_loss: 1.2225 - val_accuracy: 0.4300\n",
            "Epoch 50/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.2238 - accuracy: 0.4295 - val_loss: 1.2251 - val_accuracy: 0.4293\n",
            "Epoch 51/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.2222 - accuracy: 0.4305 - val_loss: 1.2708 - val_accuracy: 0.4069\n",
            "Epoch 52/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.2229 - accuracy: 0.4301 - val_loss: 1.2201 - val_accuracy: 0.4314\n",
            "Epoch 53/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.2243 - accuracy: 0.4294 - val_loss: 1.2192 - val_accuracy: 0.4327\n",
            "Epoch 54/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.2203 - accuracy: 0.4315 - val_loss: 1.2183 - val_accuracy: 0.4335\n",
            "Epoch 55/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.2197 - accuracy: 0.4319 - val_loss: 1.2308 - val_accuracy: 0.4286\n",
            "Epoch 56/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.2202 - accuracy: 0.4318 - val_loss: 1.2198 - val_accuracy: 0.4318\n",
            "Epoch 57/3000\n",
            "302/302 [==============================] - 15s 49ms/step - loss: 1.2171 - accuracy: 0.4335 - val_loss: 1.2161 - val_accuracy: 0.4353\n",
            "Epoch 58/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.2198 - accuracy: 0.4320 - val_loss: 1.2170 - val_accuracy: 0.4339\n",
            "Epoch 59/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.2167 - accuracy: 0.4337 - val_loss: 1.2157 - val_accuracy: 0.4357\n",
            "Epoch 60/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.2162 - accuracy: 0.4340 - val_loss: 1.2157 - val_accuracy: 0.4349\n",
            "Epoch 61/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.2177 - accuracy: 0.4334 - val_loss: 1.2191 - val_accuracy: 0.4318\n",
            "Epoch 62/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.2143 - accuracy: 0.4353 - val_loss: 1.2142 - val_accuracy: 0.4371\n",
            "Epoch 63/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.2153 - accuracy: 0.4349 - val_loss: 1.2143 - val_accuracy: 0.4357\n",
            "Epoch 64/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.2133 - accuracy: 0.4361 - val_loss: 1.2422 - val_accuracy: 0.4210\n",
            "Epoch 65/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.2132 - accuracy: 0.4361 - val_loss: 1.2110 - val_accuracy: 0.4376\n",
            "Epoch 66/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.2124 - accuracy: 0.4367 - val_loss: 1.2118 - val_accuracy: 0.4380\n",
            "Epoch 67/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.2108 - accuracy: 0.4375 - val_loss: 1.2095 - val_accuracy: 0.4381\n",
            "Epoch 68/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.2087 - accuracy: 0.4388 - val_loss: 1.2084 - val_accuracy: 0.4393\n",
            "Epoch 69/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.2091 - accuracy: 0.4387 - val_loss: 1.2063 - val_accuracy: 0.4407\n",
            "Epoch 70/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.2079 - accuracy: 0.4394 - val_loss: 1.2057 - val_accuracy: 0.4406\n",
            "Epoch 71/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.2083 - accuracy: 0.4392 - val_loss: 1.2049 - val_accuracy: 0.4410\n",
            "Epoch 72/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.2054 - accuracy: 0.4408 - val_loss: 1.2041 - val_accuracy: 0.4425\n",
            "Epoch 73/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.2070 - accuracy: 0.4400 - val_loss: 1.2032 - val_accuracy: 0.4422\n",
            "Epoch 74/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.2054 - accuracy: 0.4410 - val_loss: 1.2032 - val_accuracy: 0.4425\n",
            "Epoch 75/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.2055 - accuracy: 0.4409 - val_loss: 1.2027 - val_accuracy: 0.4428\n",
            "Epoch 76/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.2064 - accuracy: 0.4405 - val_loss: 1.2045 - val_accuracy: 0.4426\n",
            "Epoch 77/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.2014 - accuracy: 0.4431 - val_loss: 1.2005 - val_accuracy: 0.4444\n",
            "Epoch 78/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.2019 - accuracy: 0.4429 - val_loss: 1.1991 - val_accuracy: 0.4450\n",
            "Epoch 79/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.2046 - accuracy: 0.4417 - val_loss: 1.2001 - val_accuracy: 0.4448\n",
            "Epoch 80/3000\n",
            "302/302 [==============================] - 15s 48ms/step - loss: 1.1992 - accuracy: 0.4444 - val_loss: 1.1986 - val_accuracy: 0.4449\n",
            "Epoch 81/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.2028 - accuracy: 0.4425 - val_loss: 1.1988 - val_accuracy: 0.4449\n",
            "Epoch 82/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.2012 - accuracy: 0.4434 - val_loss: 1.1963 - val_accuracy: 0.4474\n",
            "Epoch 83/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1987 - accuracy: 0.4448 - val_loss: 1.1982 - val_accuracy: 0.4459\n",
            "Epoch 84/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1981 - accuracy: 0.4452 - val_loss: 1.1969 - val_accuracy: 0.4470\n",
            "Epoch 85/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1993 - accuracy: 0.4447 - val_loss: 1.1964 - val_accuracy: 0.4465\n",
            "Epoch 86/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1995 - accuracy: 0.4447 - val_loss: 1.2058 - val_accuracy: 0.4423\n",
            "Epoch 87/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1963 - accuracy: 0.4462 - val_loss: 1.1960 - val_accuracy: 0.4472\n",
            "Epoch 88/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1989 - accuracy: 0.4451 - val_loss: 1.1942 - val_accuracy: 0.4486\n",
            "Epoch 89/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1975 - accuracy: 0.4458 - val_loss: 1.1935 - val_accuracy: 0.4488\n",
            "Epoch 90/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1970 - accuracy: 0.4461 - val_loss: 1.1931 - val_accuracy: 0.4490\n",
            "Epoch 91/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1949 - accuracy: 0.4473 - val_loss: 1.1925 - val_accuracy: 0.4499\n",
            "Epoch 92/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1938 - accuracy: 0.4478 - val_loss: 1.1921 - val_accuracy: 0.4499\n",
            "Epoch 93/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1962 - accuracy: 0.4467 - val_loss: 1.1907 - val_accuracy: 0.4506\n",
            "Epoch 94/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1941 - accuracy: 0.4477 - val_loss: 1.1906 - val_accuracy: 0.4503\n",
            "Epoch 95/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1924 - accuracy: 0.4487 - val_loss: 1.1913 - val_accuracy: 0.4506\n",
            "Epoch 96/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1953 - accuracy: 0.4471 - val_loss: 1.1900 - val_accuracy: 0.4512\n",
            "Epoch 97/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1910 - accuracy: 0.4495 - val_loss: 1.1898 - val_accuracy: 0.4518\n",
            "Epoch 98/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1966 - accuracy: 0.4466 - val_loss: 1.1986 - val_accuracy: 0.4470\n",
            "Epoch 99/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1928 - accuracy: 0.4485 - val_loss: 1.1904 - val_accuracy: 0.4496\n",
            "Epoch 100/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1938 - accuracy: 0.4480 - val_loss: 1.1899 - val_accuracy: 0.4500\n",
            "Epoch 101/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1971 - accuracy: 0.4465 - val_loss: 1.1895 - val_accuracy: 0.4502\n",
            "Epoch 102/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1923 - accuracy: 0.4487 - val_loss: 1.1937 - val_accuracy: 0.4473\n",
            "Epoch 103/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1922 - accuracy: 0.4487 - val_loss: 1.1872 - val_accuracy: 0.4532\n",
            "Epoch 104/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1887 - accuracy: 0.4507 - val_loss: 1.1870 - val_accuracy: 0.4524\n",
            "Epoch 105/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1899 - accuracy: 0.4501 - val_loss: 1.1877 - val_accuracy: 0.4512\n",
            "Epoch 106/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1916 - accuracy: 0.4493 - val_loss: 1.1863 - val_accuracy: 0.4530\n",
            "Epoch 107/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1888 - accuracy: 0.4506 - val_loss: 1.1858 - val_accuracy: 0.4528\n",
            "Epoch 108/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1920 - accuracy: 0.4490 - val_loss: 1.1954 - val_accuracy: 0.4475\n",
            "Epoch 109/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1940 - accuracy: 0.4483 - val_loss: 1.1933 - val_accuracy: 0.4496\n",
            "Epoch 110/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1950 - accuracy: 0.4476 - val_loss: 1.1944 - val_accuracy: 0.4489\n",
            "Epoch 111/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1918 - accuracy: 0.4491 - val_loss: 1.1862 - val_accuracy: 0.4532\n",
            "Epoch 112/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1875 - accuracy: 0.4513 - val_loss: 1.1851 - val_accuracy: 0.4527\n",
            "Epoch 113/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1910 - accuracy: 0.4498 - val_loss: 1.2006 - val_accuracy: 0.4453\n",
            "Epoch 114/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1921 - accuracy: 0.4493 - val_loss: 1.1871 - val_accuracy: 0.4519\n",
            "Epoch 115/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1915 - accuracy: 0.4493 - val_loss: 1.1860 - val_accuracy: 0.4533\n",
            "Epoch 116/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1908 - accuracy: 0.4499 - val_loss: 1.1870 - val_accuracy: 0.4521\n",
            "Epoch 117/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1861 - accuracy: 0.4522 - val_loss: 1.2355 - val_accuracy: 0.4288\n",
            "Epoch 118/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1919 - accuracy: 0.4495 - val_loss: 1.1863 - val_accuracy: 0.4527\n",
            "Epoch 119/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1860 - accuracy: 0.4524 - val_loss: 1.1828 - val_accuracy: 0.4546\n",
            "Epoch 120/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1905 - accuracy: 0.4503 - val_loss: 1.1827 - val_accuracy: 0.4545\n",
            "Epoch 121/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1834 - accuracy: 0.4539 - val_loss: 1.1824 - val_accuracy: 0.4548\n",
            "Epoch 122/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1848 - accuracy: 0.4533 - val_loss: 1.1808 - val_accuracy: 0.4557\n",
            "Epoch 123/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1891 - accuracy: 0.4514 - val_loss: 1.1861 - val_accuracy: 0.4539\n",
            "Epoch 124/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1861 - accuracy: 0.4529 - val_loss: 1.1802 - val_accuracy: 0.4563\n",
            "Epoch 125/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1882 - accuracy: 0.4518 - val_loss: 1.1805 - val_accuracy: 0.4570\n",
            "Epoch 126/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1862 - accuracy: 0.4528 - val_loss: 1.1813 - val_accuracy: 0.4565\n",
            "Epoch 127/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1830 - accuracy: 0.4545 - val_loss: 1.1784 - val_accuracy: 0.4585\n",
            "Epoch 128/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1836 - accuracy: 0.4544 - val_loss: 1.1833 - val_accuracy: 0.4568\n",
            "Epoch 129/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1837 - accuracy: 0.4544 - val_loss: 1.1812 - val_accuracy: 0.4564\n",
            "Epoch 130/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1825 - accuracy: 0.4551 - val_loss: 1.1805 - val_accuracy: 0.4576\n",
            "Epoch 131/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1813 - accuracy: 0.4558 - val_loss: 1.1802 - val_accuracy: 0.4571\n",
            "Epoch 132/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1808 - accuracy: 0.4559 - val_loss: 1.1792 - val_accuracy: 0.4584\n",
            "Epoch 133/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1804 - accuracy: 0.4563 - val_loss: 1.1794 - val_accuracy: 0.4575\n",
            "Epoch 134/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1828 - accuracy: 0.4551 - val_loss: 1.1891 - val_accuracy: 0.4519\n",
            "Epoch 135/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1816 - accuracy: 0.4557 - val_loss: 1.1761 - val_accuracy: 0.4598\n",
            "Epoch 136/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1797 - accuracy: 0.4568 - val_loss: 1.1757 - val_accuracy: 0.4597\n",
            "Epoch 137/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1801 - accuracy: 0.4564 - val_loss: 1.1745 - val_accuracy: 0.4606\n",
            "Epoch 138/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1805 - accuracy: 0.4567 - val_loss: 1.1765 - val_accuracy: 0.4589\n",
            "Epoch 139/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1783 - accuracy: 0.4577 - val_loss: 1.1742 - val_accuracy: 0.4603\n",
            "Epoch 140/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1790 - accuracy: 0.4571 - val_loss: 1.1739 - val_accuracy: 0.4602\n",
            "Epoch 141/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1790 - accuracy: 0.4572 - val_loss: 1.1790 - val_accuracy: 0.4578\n",
            "Epoch 142/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1781 - accuracy: 0.4578 - val_loss: 1.1798 - val_accuracy: 0.4579\n",
            "Epoch 143/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1764 - accuracy: 0.4587 - val_loss: 1.1739 - val_accuracy: 0.4601\n",
            "Epoch 144/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1784 - accuracy: 0.4577 - val_loss: 1.1725 - val_accuracy: 0.4618\n",
            "Epoch 145/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1798 - accuracy: 0.4570 - val_loss: 1.1728 - val_accuracy: 0.4612\n",
            "Epoch 146/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1776 - accuracy: 0.4582 - val_loss: 1.1717 - val_accuracy: 0.4616\n",
            "Epoch 147/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1775 - accuracy: 0.4582 - val_loss: 1.1718 - val_accuracy: 0.4616\n",
            "Epoch 148/3000\n",
            "302/302 [==============================] - 15s 48ms/step - loss: 1.1779 - accuracy: 0.4580 - val_loss: 1.1771 - val_accuracy: 0.4587\n",
            "Epoch 149/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1765 - accuracy: 0.4590 - val_loss: 1.1719 - val_accuracy: 0.4624\n",
            "Epoch 150/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1746 - accuracy: 0.4597 - val_loss: 1.1704 - val_accuracy: 0.4624\n",
            "Epoch 151/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1757 - accuracy: 0.4593 - val_loss: 1.1708 - val_accuracy: 0.4634\n",
            "Epoch 152/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1736 - accuracy: 0.4603 - val_loss: 1.1703 - val_accuracy: 0.4627\n",
            "Epoch 153/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1754 - accuracy: 0.4595 - val_loss: 1.1699 - val_accuracy: 0.4636\n",
            "Epoch 154/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1728 - accuracy: 0.4609 - val_loss: 1.1702 - val_accuracy: 0.4634\n",
            "Epoch 155/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1744 - accuracy: 0.4600 - val_loss: 1.1746 - val_accuracy: 0.4602\n",
            "Epoch 156/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1737 - accuracy: 0.4605 - val_loss: 1.2207 - val_accuracy: 0.4385\n",
            "Epoch 157/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1773 - accuracy: 0.4586 - val_loss: 1.1712 - val_accuracy: 0.4631\n",
            "Epoch 158/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1743 - accuracy: 0.4601 - val_loss: 1.1701 - val_accuracy: 0.4632\n",
            "Epoch 159/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1739 - accuracy: 0.4602 - val_loss: 1.1681 - val_accuracy: 0.4644\n",
            "Epoch 160/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1713 - accuracy: 0.4616 - val_loss: 1.1676 - val_accuracy: 0.4640\n",
            "Epoch 161/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1727 - accuracy: 0.4610 - val_loss: 1.1677 - val_accuracy: 0.4647\n",
            "Epoch 162/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1701 - accuracy: 0.4624 - val_loss: 1.1675 - val_accuracy: 0.4645\n",
            "Epoch 163/3000\n",
            "302/302 [==============================] - 13s 43ms/step - loss: 1.1721 - accuracy: 0.4614 - val_loss: 1.1667 - val_accuracy: 0.4646\n",
            "Epoch 164/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1750 - accuracy: 0.4599 - val_loss: 1.1698 - val_accuracy: 0.4636\n",
            "Epoch 165/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1704 - accuracy: 0.4621 - val_loss: 1.1667 - val_accuracy: 0.4650\n",
            "Epoch 166/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1733 - accuracy: 0.4607 - val_loss: 1.1666 - val_accuracy: 0.4648\n",
            "Epoch 167/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1709 - accuracy: 0.4619 - val_loss: 1.1660 - val_accuracy: 0.4655\n",
            "Epoch 168/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1711 - accuracy: 0.4618 - val_loss: 1.1679 - val_accuracy: 0.4637\n",
            "Epoch 169/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1725 - accuracy: 0.4611 - val_loss: 1.1662 - val_accuracy: 0.4651\n",
            "Epoch 170/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1724 - accuracy: 0.4613 - val_loss: 1.1685 - val_accuracy: 0.4640\n",
            "Epoch 171/3000\n",
            "302/302 [==============================] - 15s 49ms/step - loss: 1.1703 - accuracy: 0.4623 - val_loss: 1.1667 - val_accuracy: 0.4655\n",
            "Epoch 172/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1726 - accuracy: 0.4611 - val_loss: 1.1650 - val_accuracy: 0.4658\n",
            "Epoch 173/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1706 - accuracy: 0.4621 - val_loss: 1.1729 - val_accuracy: 0.4612\n",
            "Epoch 174/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1673 - accuracy: 0.4637 - val_loss: 1.1651 - val_accuracy: 0.4658\n",
            "Epoch 175/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1706 - accuracy: 0.4622 - val_loss: 1.1646 - val_accuracy: 0.4670\n",
            "Epoch 176/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1730 - accuracy: 0.4611 - val_loss: 1.1639 - val_accuracy: 0.4662\n",
            "Epoch 177/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1699 - accuracy: 0.4625 - val_loss: 1.1638 - val_accuracy: 0.4664\n",
            "Epoch 178/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1672 - accuracy: 0.4637 - val_loss: 1.1646 - val_accuracy: 0.4667\n",
            "Epoch 179/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1702 - accuracy: 0.4624 - val_loss: 1.1641 - val_accuracy: 0.4666\n",
            "Epoch 180/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1697 - accuracy: 0.4625 - val_loss: 1.1633 - val_accuracy: 0.4666\n",
            "Epoch 181/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1667 - accuracy: 0.4640 - val_loss: 1.1641 - val_accuracy: 0.4670\n",
            "Epoch 182/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1710 - accuracy: 0.4619 - val_loss: 1.1658 - val_accuracy: 0.4651\n",
            "Epoch 183/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1666 - accuracy: 0.4642 - val_loss: 1.1636 - val_accuracy: 0.4664\n",
            "Epoch 184/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1683 - accuracy: 0.4632 - val_loss: 1.1637 - val_accuracy: 0.4659\n",
            "Epoch 185/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1644 - accuracy: 0.4652 - val_loss: 1.1626 - val_accuracy: 0.4676\n",
            "Epoch 186/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1706 - accuracy: 0.4622 - val_loss: 1.1762 - val_accuracy: 0.4603\n",
            "Epoch 187/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1673 - accuracy: 0.4637 - val_loss: 1.1642 - val_accuracy: 0.4661\n",
            "Epoch 188/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1668 - accuracy: 0.4640 - val_loss: 1.1640 - val_accuracy: 0.4661\n",
            "Epoch 189/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1704 - accuracy: 0.4622 - val_loss: 1.1693 - val_accuracy: 0.4642\n",
            "Epoch 190/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1672 - accuracy: 0.4637 - val_loss: 1.1639 - val_accuracy: 0.4658\n",
            "Epoch 191/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1670 - accuracy: 0.4638 - val_loss: 1.1636 - val_accuracy: 0.4659\n",
            "Epoch 192/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1681 - accuracy: 0.4634 - val_loss: 1.1621 - val_accuracy: 0.4675\n",
            "Epoch 193/3000\n",
            "302/302 [==============================] - 13s 43ms/step - loss: 1.1678 - accuracy: 0.4634 - val_loss: 1.1626 - val_accuracy: 0.4670\n",
            "Epoch 194/3000\n",
            "302/302 [==============================] - 15s 49ms/step - loss: 1.1670 - accuracy: 0.4637 - val_loss: 1.1636 - val_accuracy: 0.4662\n",
            "Epoch 195/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1680 - accuracy: 0.4633 - val_loss: 1.1633 - val_accuracy: 0.4666\n",
            "Epoch 196/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1688 - accuracy: 0.4629 - val_loss: 1.1624 - val_accuracy: 0.4676\n",
            "Epoch 197/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1693 - accuracy: 0.4627 - val_loss: 1.1632 - val_accuracy: 0.4661\n",
            "Epoch 198/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1664 - accuracy: 0.4641 - val_loss: 1.1622 - val_accuracy: 0.4673\n",
            "Epoch 199/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1679 - accuracy: 0.4635 - val_loss: 1.1633 - val_accuracy: 0.4665\n",
            "Epoch 200/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1673 - accuracy: 0.4636 - val_loss: 1.1630 - val_accuracy: 0.4663\n",
            "Epoch 201/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1701 - accuracy: 0.4624 - val_loss: 1.1748 - val_accuracy: 0.4615\n",
            "Epoch 202/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1668 - accuracy: 0.4638 - val_loss: 1.2042 - val_accuracy: 0.4457\n",
            "Epoch 203/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1673 - accuracy: 0.4636 - val_loss: 1.1639 - val_accuracy: 0.4663\n",
            "Epoch 204/3000\n",
            "302/302 [==============================] - 13s 43ms/step - loss: 1.1639 - accuracy: 0.4652 - val_loss: 1.1607 - val_accuracy: 0.4676\n",
            "Epoch 205/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1623 - accuracy: 0.4661 - val_loss: 1.1647 - val_accuracy: 0.4665\n",
            "Epoch 206/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1659 - accuracy: 0.4644 - val_loss: 1.1665 - val_accuracy: 0.4654\n",
            "Epoch 207/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1637 - accuracy: 0.4654 - val_loss: 1.1608 - val_accuracy: 0.4674\n",
            "Epoch 208/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1688 - accuracy: 0.4630 - val_loss: 1.1622 - val_accuracy: 0.4678\n",
            "Epoch 209/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1679 - accuracy: 0.4634 - val_loss: 1.1685 - val_accuracy: 0.4633\n",
            "Epoch 210/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1633 - accuracy: 0.4656 - val_loss: 1.1617 - val_accuracy: 0.4674\n",
            "Epoch 211/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1660 - accuracy: 0.4643 - val_loss: 1.1611 - val_accuracy: 0.4682\n",
            "Epoch 212/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1657 - accuracy: 0.4643 - val_loss: 1.1603 - val_accuracy: 0.4682\n",
            "Epoch 213/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1686 - accuracy: 0.4629 - val_loss: 1.1612 - val_accuracy: 0.4674\n",
            "Epoch 214/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1644 - accuracy: 0.4649 - val_loss: 1.1598 - val_accuracy: 0.4683\n",
            "Epoch 215/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1661 - accuracy: 0.4641 - val_loss: 1.1611 - val_accuracy: 0.4679\n",
            "Epoch 216/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1650 - accuracy: 0.4647 - val_loss: 1.1615 - val_accuracy: 0.4677\n",
            "Epoch 217/3000\n",
            "302/302 [==============================] - 15s 48ms/step - loss: 1.1656 - accuracy: 0.4644 - val_loss: 1.1613 - val_accuracy: 0.4679\n",
            "Epoch 218/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1692 - accuracy: 0.4628 - val_loss: 1.1697 - val_accuracy: 0.4629\n",
            "Epoch 219/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1636 - accuracy: 0.4654 - val_loss: 1.1609 - val_accuracy: 0.4672\n",
            "Epoch 220/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1671 - accuracy: 0.4636 - val_loss: 1.1613 - val_accuracy: 0.4687\n",
            "Epoch 221/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1655 - accuracy: 0.4644 - val_loss: 1.1611 - val_accuracy: 0.4684\n",
            "Epoch 222/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1658 - accuracy: 0.4643 - val_loss: 1.1607 - val_accuracy: 0.4681\n",
            "Epoch 223/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1651 - accuracy: 0.4646 - val_loss: 1.1604 - val_accuracy: 0.4684\n",
            "Epoch 224/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1637 - accuracy: 0.4651 - val_loss: 1.1600 - val_accuracy: 0.4679\n",
            "Epoch 225/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1624 - accuracy: 0.4658 - val_loss: 1.1599 - val_accuracy: 0.4681\n",
            "Epoch 226/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1667 - accuracy: 0.4638 - val_loss: 1.1703 - val_accuracy: 0.4628\n",
            "Epoch 227/3000\n",
            "302/302 [==============================] - 13s 43ms/step - loss: 1.1611 - accuracy: 0.4665 - val_loss: 1.1621 - val_accuracy: 0.4675\n",
            "Epoch 228/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1670 - accuracy: 0.4636 - val_loss: 1.1601 - val_accuracy: 0.4686\n",
            "Epoch 229/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1645 - accuracy: 0.4646 - val_loss: 1.1682 - val_accuracy: 0.4641\n",
            "Epoch 230/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1653 - accuracy: 0.4643 - val_loss: 1.1649 - val_accuracy: 0.4653\n",
            "Epoch 231/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1629 - accuracy: 0.4655 - val_loss: 1.1611 - val_accuracy: 0.4680\n",
            "Epoch 232/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1655 - accuracy: 0.4642 - val_loss: 1.1611 - val_accuracy: 0.4675\n",
            "Epoch 233/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1650 - accuracy: 0.4644 - val_loss: 1.1596 - val_accuracy: 0.4671\n",
            "Epoch 234/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1661 - accuracy: 0.4640 - val_loss: 1.1622 - val_accuracy: 0.4667\n",
            "Epoch 235/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1605 - accuracy: 0.4668 - val_loss: 1.1770 - val_accuracy: 0.4591\n",
            "Epoch 236/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1617 - accuracy: 0.4662 - val_loss: 1.1586 - val_accuracy: 0.4682\n",
            "Epoch 237/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1597 - accuracy: 0.4672 - val_loss: 1.1600 - val_accuracy: 0.4677\n",
            "Epoch 238/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1646 - accuracy: 0.4648 - val_loss: 1.1592 - val_accuracy: 0.4679\n",
            "Epoch 239/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1628 - accuracy: 0.4656 - val_loss: 1.1595 - val_accuracy: 0.4680\n",
            "Epoch 240/3000\n",
            "302/302 [==============================] - 15s 48ms/step - loss: 1.1631 - accuracy: 0.4653 - val_loss: 1.1669 - val_accuracy: 0.4642\n",
            "Epoch 241/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1608 - accuracy: 0.4666 - val_loss: 1.1588 - val_accuracy: 0.4687\n",
            "Epoch 242/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1622 - accuracy: 0.4658 - val_loss: 1.1588 - val_accuracy: 0.4681\n",
            "Epoch 243/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1614 - accuracy: 0.4661 - val_loss: 1.1610 - val_accuracy: 0.4661\n",
            "Epoch 244/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1590 - accuracy: 0.4673 - val_loss: 1.1573 - val_accuracy: 0.4687\n",
            "Epoch 245/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1648 - accuracy: 0.4646 - val_loss: 1.1585 - val_accuracy: 0.4676\n",
            "Epoch 246/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1616 - accuracy: 0.4660 - val_loss: 1.1649 - val_accuracy: 0.4645\n",
            "Epoch 247/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1593 - accuracy: 0.4672 - val_loss: 1.1575 - val_accuracy: 0.4680\n",
            "Epoch 248/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1644 - accuracy: 0.4647 - val_loss: 1.1570 - val_accuracy: 0.4687\n",
            "Epoch 249/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1622 - accuracy: 0.4658 - val_loss: 1.1584 - val_accuracy: 0.4679\n",
            "Epoch 250/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1582 - accuracy: 0.4676 - val_loss: 1.1578 - val_accuracy: 0.4683\n",
            "Epoch 251/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1614 - accuracy: 0.4661 - val_loss: 1.1561 - val_accuracy: 0.4688\n",
            "Epoch 252/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1622 - accuracy: 0.4656 - val_loss: 1.1689 - val_accuracy: 0.4634\n",
            "Epoch 253/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1635 - accuracy: 0.4652 - val_loss: 1.1586 - val_accuracy: 0.4681\n",
            "Epoch 254/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1583 - accuracy: 0.4676 - val_loss: 1.1562 - val_accuracy: 0.4694\n",
            "Epoch 255/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1645 - accuracy: 0.4646 - val_loss: 1.1573 - val_accuracy: 0.4686\n",
            "Epoch 256/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1614 - accuracy: 0.4660 - val_loss: 1.1623 - val_accuracy: 0.4657\n",
            "Epoch 257/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1584 - accuracy: 0.4674 - val_loss: 1.1556 - val_accuracy: 0.4694\n",
            "Epoch 258/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1610 - accuracy: 0.4662 - val_loss: 1.1571 - val_accuracy: 0.4687\n",
            "Epoch 259/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1588 - accuracy: 0.4671 - val_loss: 1.1646 - val_accuracy: 0.4651\n",
            "Epoch 260/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1585 - accuracy: 0.4673 - val_loss: 1.1563 - val_accuracy: 0.4688\n",
            "Epoch 261/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1594 - accuracy: 0.4669 - val_loss: 1.1641 - val_accuracy: 0.4658\n",
            "Epoch 262/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1590 - accuracy: 0.4671 - val_loss: 1.1568 - val_accuracy: 0.4688\n",
            "Epoch 263/3000\n",
            "302/302 [==============================] - 15s 49ms/step - loss: 1.1603 - accuracy: 0.4664 - val_loss: 1.1649 - val_accuracy: 0.4645\n",
            "Epoch 264/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1604 - accuracy: 0.4664 - val_loss: 1.1569 - val_accuracy: 0.4682\n",
            "Epoch 265/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1568 - accuracy: 0.4680 - val_loss: 1.1535 - val_accuracy: 0.4698\n",
            "Epoch 266/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1567 - accuracy: 0.4681 - val_loss: 1.1540 - val_accuracy: 0.4699\n",
            "Epoch 267/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1592 - accuracy: 0.4669 - val_loss: 1.1583 - val_accuracy: 0.4666\n",
            "Epoch 268/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1560 - accuracy: 0.4684 - val_loss: 1.1544 - val_accuracy: 0.4694\n",
            "Epoch 269/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1564 - accuracy: 0.4681 - val_loss: 1.1558 - val_accuracy: 0.4683\n",
            "Epoch 270/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1583 - accuracy: 0.4672 - val_loss: 1.1635 - val_accuracy: 0.4651\n",
            "Epoch 271/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1587 - accuracy: 0.4672 - val_loss: 1.1562 - val_accuracy: 0.4687\n",
            "Epoch 272/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.1596 - accuracy: 0.4668 - val_loss: 1.1620 - val_accuracy: 0.4664\n",
            "Epoch 273/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1571 - accuracy: 0.4680 - val_loss: 1.1548 - val_accuracy: 0.4691\n",
            "Epoch 274/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1592 - accuracy: 0.4668 - val_loss: 1.1596 - val_accuracy: 0.4670\n",
            "Epoch 275/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1555 - accuracy: 0.4686 - val_loss: 1.1538 - val_accuracy: 0.4700\n",
            "Epoch 276/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1547 - accuracy: 0.4688 - val_loss: 1.1523 - val_accuracy: 0.4702\n",
            "Epoch 277/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1624 - accuracy: 0.4654 - val_loss: 1.1583 - val_accuracy: 0.4680\n",
            "Epoch 278/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.1563 - accuracy: 0.4682 - val_loss: 1.1538 - val_accuracy: 0.4697\n",
            "Epoch 279/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1582 - accuracy: 0.4672 - val_loss: 1.1546 - val_accuracy: 0.4696\n",
            "Epoch 280/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1577 - accuracy: 0.4675 - val_loss: 1.1587 - val_accuracy: 0.4678\n",
            "Epoch 281/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1548 - accuracy: 0.4690 - val_loss: 1.1540 - val_accuracy: 0.4699\n",
            "Epoch 282/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1546 - accuracy: 0.4688 - val_loss: 1.1533 - val_accuracy: 0.4699\n",
            "Epoch 283/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1552 - accuracy: 0.4687 - val_loss: 1.1519 - val_accuracy: 0.4704\n",
            "Epoch 284/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1530 - accuracy: 0.4696 - val_loss: 1.1518 - val_accuracy: 0.4703\n",
            "Epoch 285/3000\n",
            "302/302 [==============================] - 15s 49ms/step - loss: 1.1535 - accuracy: 0.4694 - val_loss: 1.1527 - val_accuracy: 0.4704\n",
            "Epoch 286/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1555 - accuracy: 0.4688 - val_loss: 1.1528 - val_accuracy: 0.4700\n",
            "Epoch 287/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1533 - accuracy: 0.4695 - val_loss: 1.1516 - val_accuracy: 0.4710\n",
            "Epoch 288/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1532 - accuracy: 0.4696 - val_loss: 1.1512 - val_accuracy: 0.4708\n",
            "Epoch 289/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1599 - accuracy: 0.4665 - val_loss: 1.1586 - val_accuracy: 0.4683\n",
            "Epoch 290/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1582 - accuracy: 0.4673 - val_loss: 1.1575 - val_accuracy: 0.4684\n",
            "Epoch 291/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1551 - accuracy: 0.4687 - val_loss: 1.1524 - val_accuracy: 0.4704\n",
            "Epoch 292/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1550 - accuracy: 0.4688 - val_loss: 1.1534 - val_accuracy: 0.4701\n",
            "Epoch 293/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1597 - accuracy: 0.4666 - val_loss: 1.1546 - val_accuracy: 0.4700\n",
            "Epoch 294/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1533 - accuracy: 0.4697 - val_loss: 1.1519 - val_accuracy: 0.4701\n",
            "Epoch 295/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1560 - accuracy: 0.4683 - val_loss: 1.1506 - val_accuracy: 0.4715\n",
            "Epoch 296/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1520 - accuracy: 0.4702 - val_loss: 1.1521 - val_accuracy: 0.4705\n",
            "Epoch 297/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1521 - accuracy: 0.4702 - val_loss: 1.1503 - val_accuracy: 0.4714\n",
            "Epoch 298/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1519 - accuracy: 0.4702 - val_loss: 1.1500 - val_accuracy: 0.4711\n",
            "Epoch 299/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1560 - accuracy: 0.4684 - val_loss: 1.1503 - val_accuracy: 0.4713\n",
            "Epoch 300/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.1579 - accuracy: 0.4675 - val_loss: 1.1522 - val_accuracy: 0.4708\n",
            "Epoch 301/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1523 - accuracy: 0.4702 - val_loss: 1.1519 - val_accuracy: 0.4708\n",
            "Epoch 302/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1519 - accuracy: 0.4703 - val_loss: 1.1501 - val_accuracy: 0.4719\n",
            "Epoch 303/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1513 - accuracy: 0.4705 - val_loss: 1.1499 - val_accuracy: 0.4716\n",
            "Epoch 304/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1580 - accuracy: 0.4675 - val_loss: 1.1524 - val_accuracy: 0.4710\n",
            "Epoch 305/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1520 - accuracy: 0.4704 - val_loss: 1.1501 - val_accuracy: 0.4719\n",
            "Epoch 306/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1588 - accuracy: 0.4672 - val_loss: 1.1557 - val_accuracy: 0.4695\n",
            "Epoch 307/3000\n",
            "302/302 [==============================] - 15s 49ms/step - loss: 1.1524 - accuracy: 0.4702 - val_loss: 1.1510 - val_accuracy: 0.4711\n",
            "Epoch 308/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.1515 - accuracy: 0.4706 - val_loss: 1.1503 - val_accuracy: 0.4719\n",
            "Epoch 309/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1553 - accuracy: 0.4689 - val_loss: 1.1499 - val_accuracy: 0.4721\n",
            "Epoch 310/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1511 - accuracy: 0.4708 - val_loss: 1.1491 - val_accuracy: 0.4722\n",
            "Epoch 311/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1511 - accuracy: 0.4709 - val_loss: 1.1493 - val_accuracy: 0.4722\n",
            "Epoch 312/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1510 - accuracy: 0.4709 - val_loss: 1.1488 - val_accuracy: 0.4725\n",
            "Epoch 313/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1508 - accuracy: 0.4710 - val_loss: 1.1485 - val_accuracy: 0.4727\n",
            "Epoch 314/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1507 - accuracy: 0.4711 - val_loss: 1.1488 - val_accuracy: 0.4719\n",
            "Epoch 315/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1507 - accuracy: 0.4711 - val_loss: 1.1491 - val_accuracy: 0.4726\n",
            "Epoch 316/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1583 - accuracy: 0.4674 - val_loss: 1.1569 - val_accuracy: 0.4683\n",
            "Epoch 317/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1541 - accuracy: 0.4693 - val_loss: 1.1496 - val_accuracy: 0.4724\n",
            "Epoch 318/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.1510 - accuracy: 0.4709 - val_loss: 1.1490 - val_accuracy: 0.4722\n",
            "Epoch 319/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1529 - accuracy: 0.4701 - val_loss: 1.1487 - val_accuracy: 0.4728\n",
            "Epoch 320/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1588 - accuracy: 0.4672 - val_loss: 1.1553 - val_accuracy: 0.4693\n",
            "Epoch 321/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1518 - accuracy: 0.4705 - val_loss: 1.1491 - val_accuracy: 0.4731\n",
            "Epoch 322/3000\n",
            "302/302 [==============================] - 15s 49ms/step - loss: 1.1503 - accuracy: 0.4713 - val_loss: 1.1481 - val_accuracy: 0.4733\n",
            "Epoch 323/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1518 - accuracy: 0.4706 - val_loss: 1.1481 - val_accuracy: 0.4727\n",
            "Epoch 324/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1498 - accuracy: 0.4716 - val_loss: 1.1479 - val_accuracy: 0.4727\n",
            "Epoch 325/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.1583 - accuracy: 0.4675 - val_loss: 1.1548 - val_accuracy: 0.4700\n",
            "Epoch 326/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1518 - accuracy: 0.4705 - val_loss: 1.1490 - val_accuracy: 0.4725\n",
            "Epoch 327/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1502 - accuracy: 0.4713 - val_loss: 1.1489 - val_accuracy: 0.4725\n",
            "Epoch 328/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1556 - accuracy: 0.4686 - val_loss: 1.1553 - val_accuracy: 0.4696\n",
            "Epoch 329/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.1513 - accuracy: 0.4708 - val_loss: 1.1497 - val_accuracy: 0.4720\n",
            "Epoch 330/3000\n",
            "302/302 [==============================] - 15s 49ms/step - loss: 1.1530 - accuracy: 0.4699 - val_loss: 1.1485 - val_accuracy: 0.4731\n",
            "Epoch 331/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1495 - accuracy: 0.4717 - val_loss: 1.1484 - val_accuracy: 0.4727\n",
            "Epoch 332/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1493 - accuracy: 0.4717 - val_loss: 1.1477 - val_accuracy: 0.4726\n",
            "Epoch 333/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1516 - accuracy: 0.4707 - val_loss: 1.1477 - val_accuracy: 0.4723\n",
            "Epoch 334/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1489 - accuracy: 0.4720 - val_loss: 1.1474 - val_accuracy: 0.4732\n",
            "Epoch 335/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1534 - accuracy: 0.4697 - val_loss: 1.1474 - val_accuracy: 0.4727\n",
            "Epoch 336/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.1486 - accuracy: 0.4721 - val_loss: 1.1474 - val_accuracy: 0.4727\n",
            "Epoch 337/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1578 - accuracy: 0.4676 - val_loss: 1.1544 - val_accuracy: 0.4697\n",
            "Epoch 338/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1500 - accuracy: 0.4713 - val_loss: 1.1483 - val_accuracy: 0.4726\n",
            "Epoch 339/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1495 - accuracy: 0.4715 - val_loss: 1.1474 - val_accuracy: 0.4734\n",
            "Epoch 340/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1491 - accuracy: 0.4717 - val_loss: 1.1476 - val_accuracy: 0.4728\n",
            "Epoch 341/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1490 - accuracy: 0.4717 - val_loss: 1.1469 - val_accuracy: 0.4734\n",
            "Epoch 342/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1490 - accuracy: 0.4717 - val_loss: 1.1468 - val_accuracy: 0.4733\n",
            "Epoch 343/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1489 - accuracy: 0.4718 - val_loss: 1.1472 - val_accuracy: 0.4725\n",
            "Epoch 344/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.1487 - accuracy: 0.4719 - val_loss: 1.1474 - val_accuracy: 0.4727\n",
            "Epoch 345/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1501 - accuracy: 0.4712 - val_loss: 1.1467 - val_accuracy: 0.4736\n",
            "Epoch 346/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1481 - accuracy: 0.4721 - val_loss: 1.1462 - val_accuracy: 0.4733\n",
            "Epoch 347/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.1508 - accuracy: 0.4708 - val_loss: 1.1461 - val_accuracy: 0.4735\n",
            "Epoch 348/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1477 - accuracy: 0.4723 - val_loss: 1.1468 - val_accuracy: 0.4729\n",
            "Epoch 349/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1479 - accuracy: 0.4721 - val_loss: 1.1458 - val_accuracy: 0.4731\n",
            "Epoch 350/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1479 - accuracy: 0.4722 - val_loss: 1.1459 - val_accuracy: 0.4733\n",
            "Epoch 351/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1482 - accuracy: 0.4720 - val_loss: 1.1458 - val_accuracy: 0.4738\n",
            "Epoch 352/3000\n",
            "302/302 [==============================] - 15s 50ms/step - loss: 1.1478 - accuracy: 0.4723 - val_loss: 1.1456 - val_accuracy: 0.4733\n",
            "Epoch 353/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1478 - accuracy: 0.4722 - val_loss: 1.1461 - val_accuracy: 0.4729\n",
            "Epoch 354/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1478 - accuracy: 0.4722 - val_loss: 1.1459 - val_accuracy: 0.4735\n",
            "Epoch 355/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1477 - accuracy: 0.4722 - val_loss: 1.1459 - val_accuracy: 0.4730\n",
            "Epoch 356/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1474 - accuracy: 0.4723 - val_loss: 1.1453 - val_accuracy: 0.4734\n",
            "Epoch 357/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1475 - accuracy: 0.4723 - val_loss: 1.1445 - val_accuracy: 0.4739\n",
            "Epoch 358/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1475 - accuracy: 0.4723 - val_loss: 1.1446 - val_accuracy: 0.4735\n",
            "Epoch 359/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1474 - accuracy: 0.4723 - val_loss: 1.1451 - val_accuracy: 0.4734\n",
            "Epoch 360/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1480 - accuracy: 0.4720 - val_loss: 1.1452 - val_accuracy: 0.4742\n",
            "Epoch 361/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1474 - accuracy: 0.4723 - val_loss: 1.1459 - val_accuracy: 0.4729\n",
            "Epoch 362/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1474 - accuracy: 0.4723 - val_loss: 1.1450 - val_accuracy: 0.4745\n",
            "Epoch 363/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1468 - accuracy: 0.4726 - val_loss: 1.1446 - val_accuracy: 0.4740\n",
            "Epoch 364/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1472 - accuracy: 0.4723 - val_loss: 1.1449 - val_accuracy: 0.4737\n",
            "Epoch 365/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1469 - accuracy: 0.4724 - val_loss: 1.1447 - val_accuracy: 0.4732\n",
            "Epoch 366/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1472 - accuracy: 0.4723 - val_loss: 1.1444 - val_accuracy: 0.4747\n",
            "Epoch 367/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1520 - accuracy: 0.4704 - val_loss: 1.1789 - val_accuracy: 0.4582\n",
            "Epoch 368/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1554 - accuracy: 0.4682 - val_loss: 1.1528 - val_accuracy: 0.4704\n",
            "Epoch 369/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1549 - accuracy: 0.4685 - val_loss: 1.1521 - val_accuracy: 0.4710\n",
            "Epoch 370/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1527 - accuracy: 0.4696 - val_loss: 1.1508 - val_accuracy: 0.4717\n",
            "Epoch 371/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1523 - accuracy: 0.4698 - val_loss: 1.1499 - val_accuracy: 0.4720\n",
            "Epoch 372/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1517 - accuracy: 0.4702 - val_loss: 1.1492 - val_accuracy: 0.4720\n",
            "Epoch 373/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1510 - accuracy: 0.4706 - val_loss: 1.1489 - val_accuracy: 0.4721\n",
            "Epoch 374/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1504 - accuracy: 0.4709 - val_loss: 1.1483 - val_accuracy: 0.4727\n",
            "Epoch 375/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1499 - accuracy: 0.4712 - val_loss: 1.1474 - val_accuracy: 0.4734\n",
            "Epoch 376/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1497 - accuracy: 0.4714 - val_loss: 1.1472 - val_accuracy: 0.4733\n",
            "Epoch 377/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1494 - accuracy: 0.4716 - val_loss: 1.1469 - val_accuracy: 0.4736\n",
            "Epoch 378/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1491 - accuracy: 0.4717 - val_loss: 1.1466 - val_accuracy: 0.4734\n",
            "Epoch 379/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1489 - accuracy: 0.4717 - val_loss: 1.1464 - val_accuracy: 0.4732\n",
            "Epoch 380/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1487 - accuracy: 0.4718 - val_loss: 1.1462 - val_accuracy: 0.4735\n",
            "Epoch 381/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1486 - accuracy: 0.4720 - val_loss: 1.1459 - val_accuracy: 0.4738\n",
            "Epoch 382/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1484 - accuracy: 0.4720 - val_loss: 1.1457 - val_accuracy: 0.4739\n",
            "Epoch 383/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1482 - accuracy: 0.4721 - val_loss: 1.1455 - val_accuracy: 0.4739\n",
            "Epoch 384/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1481 - accuracy: 0.4721 - val_loss: 1.1454 - val_accuracy: 0.4739\n",
            "Epoch 385/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1479 - accuracy: 0.4722 - val_loss: 1.1453 - val_accuracy: 0.4738\n",
            "Epoch 386/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1478 - accuracy: 0.4723 - val_loss: 1.1451 - val_accuracy: 0.4737\n",
            "Epoch 387/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1477 - accuracy: 0.4723 - val_loss: 1.1450 - val_accuracy: 0.4739\n",
            "Epoch 388/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1476 - accuracy: 0.4724 - val_loss: 1.1449 - val_accuracy: 0.4739\n",
            "Epoch 389/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1475 - accuracy: 0.4724 - val_loss: 1.1448 - val_accuracy: 0.4743\n",
            "Epoch 390/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1474 - accuracy: 0.4724 - val_loss: 1.1446 - val_accuracy: 0.4744\n",
            "Epoch 391/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1472 - accuracy: 0.4725 - val_loss: 1.1445 - val_accuracy: 0.4746\n",
            "Epoch 392/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1472 - accuracy: 0.4725 - val_loss: 1.1447 - val_accuracy: 0.4744\n",
            "Epoch 393/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1471 - accuracy: 0.4725 - val_loss: 1.1447 - val_accuracy: 0.4744\n",
            "Epoch 394/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1469 - accuracy: 0.4725 - val_loss: 1.1445 - val_accuracy: 0.4745\n",
            "Epoch 395/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1469 - accuracy: 0.4725 - val_loss: 1.1443 - val_accuracy: 0.4747\n",
            "Epoch 396/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1468 - accuracy: 0.4725 - val_loss: 1.1442 - val_accuracy: 0.4743\n",
            "Epoch 397/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1467 - accuracy: 0.4725 - val_loss: 1.1440 - val_accuracy: 0.4749\n",
            "Epoch 398/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.1466 - accuracy: 0.4726 - val_loss: 1.1440 - val_accuracy: 0.4750\n",
            "Epoch 399/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1479 - accuracy: 0.4720 - val_loss: 1.1437 - val_accuracy: 0.4750\n",
            "Epoch 400/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1462 - accuracy: 0.4728 - val_loss: 1.1436 - val_accuracy: 0.4743\n",
            "Epoch 401/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1462 - accuracy: 0.4727 - val_loss: 1.1438 - val_accuracy: 0.4741\n",
            "Epoch 402/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1509 - accuracy: 0.4705 - val_loss: 1.1535 - val_accuracy: 0.4710\n",
            "Epoch 403/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1498 - accuracy: 0.4711 - val_loss: 1.1437 - val_accuracy: 0.4749\n",
            "Epoch 404/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1460 - accuracy: 0.4727 - val_loss: 1.1433 - val_accuracy: 0.4744\n",
            "Epoch 405/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1460 - accuracy: 0.4727 - val_loss: 1.1434 - val_accuracy: 0.4742\n",
            "Epoch 406/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1490 - accuracy: 0.4715 - val_loss: 1.1432 - val_accuracy: 0.4743\n",
            "Epoch 407/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1458 - accuracy: 0.4728 - val_loss: 1.1432 - val_accuracy: 0.4748\n",
            "Epoch 408/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1457 - accuracy: 0.4729 - val_loss: 1.1429 - val_accuracy: 0.4749\n",
            "Epoch 409/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1457 - accuracy: 0.4728 - val_loss: 1.1430 - val_accuracy: 0.4745\n",
            "Epoch 410/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1467 - accuracy: 0.4723 - val_loss: 1.1430 - val_accuracy: 0.4751\n",
            "Epoch 411/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1454 - accuracy: 0.4730 - val_loss: 1.1428 - val_accuracy: 0.4746\n",
            "Epoch 412/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1455 - accuracy: 0.4730 - val_loss: 1.1426 - val_accuracy: 0.4747\n",
            "Epoch 413/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1455 - accuracy: 0.4729 - val_loss: 1.1428 - val_accuracy: 0.4747\n",
            "Epoch 414/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1498 - accuracy: 0.4710 - val_loss: 1.1540 - val_accuracy: 0.4699\n",
            "Epoch 415/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1491 - accuracy: 0.4713 - val_loss: 1.1426 - val_accuracy: 0.4748\n",
            "Epoch 416/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1452 - accuracy: 0.4730 - val_loss: 1.1425 - val_accuracy: 0.4752\n",
            "Epoch 417/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1451 - accuracy: 0.4731 - val_loss: 1.1422 - val_accuracy: 0.4749\n",
            "Epoch 418/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1451 - accuracy: 0.4731 - val_loss: 1.1423 - val_accuracy: 0.4754\n",
            "Epoch 419/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1494 - accuracy: 0.4711 - val_loss: 1.1423 - val_accuracy: 0.4750\n",
            "Epoch 420/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1449 - accuracy: 0.4731 - val_loss: 1.1422 - val_accuracy: 0.4753\n",
            "Epoch 421/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1448 - accuracy: 0.4732 - val_loss: 1.1420 - val_accuracy: 0.4748\n",
            "Epoch 422/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1449 - accuracy: 0.4732 - val_loss: 1.1420 - val_accuracy: 0.4752\n",
            "Epoch 423/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1535 - accuracy: 0.4692 - val_loss: 1.1424 - val_accuracy: 0.4751\n",
            "Epoch 424/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1448 - accuracy: 0.4732 - val_loss: 1.1418 - val_accuracy: 0.4750\n",
            "Epoch 425/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1447 - accuracy: 0.4732 - val_loss: 1.1418 - val_accuracy: 0.4754\n",
            "Epoch 426/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1447 - accuracy: 0.4732 - val_loss: 1.1418 - val_accuracy: 0.4755\n",
            "Epoch 427/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1493 - accuracy: 0.4711 - val_loss: 1.1448 - val_accuracy: 0.4739\n",
            "Epoch 428/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1440 - accuracy: 0.4736 - val_loss: 1.1417 - val_accuracy: 0.4751\n",
            "Epoch 429/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1443 - accuracy: 0.4733 - val_loss: 1.1418 - val_accuracy: 0.4750\n",
            "Epoch 430/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1443 - accuracy: 0.4734 - val_loss: 1.1415 - val_accuracy: 0.4751\n",
            "Epoch 431/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1443 - accuracy: 0.4734 - val_loss: 1.1414 - val_accuracy: 0.4753\n",
            "Epoch 432/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1513 - accuracy: 0.4701 - val_loss: 1.1420 - val_accuracy: 0.4743\n",
            "Epoch 433/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1441 - accuracy: 0.4735 - val_loss: 1.1417 - val_accuracy: 0.4752\n",
            "Epoch 434/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1441 - accuracy: 0.4735 - val_loss: 1.1414 - val_accuracy: 0.4753\n",
            "Epoch 435/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1440 - accuracy: 0.4735 - val_loss: 1.1412 - val_accuracy: 0.4754\n",
            "Epoch 436/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1527 - accuracy: 0.4695 - val_loss: 1.1419 - val_accuracy: 0.4747\n",
            "Epoch 437/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1439 - accuracy: 0.4736 - val_loss: 1.1416 - val_accuracy: 0.4754\n",
            "Epoch 438/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1439 - accuracy: 0.4736 - val_loss: 1.1414 - val_accuracy: 0.4752\n",
            "Epoch 439/3000\n",
            "302/302 [==============================] - 13s 43ms/step - loss: 1.1438 - accuracy: 0.4736 - val_loss: 1.1412 - val_accuracy: 0.4751\n",
            "Epoch 440/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1529 - accuracy: 0.4695 - val_loss: 1.1419 - val_accuracy: 0.4747\n",
            "Epoch 441/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1437 - accuracy: 0.4736 - val_loss: 1.1415 - val_accuracy: 0.4751\n",
            "Epoch 442/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1437 - accuracy: 0.4736 - val_loss: 1.1412 - val_accuracy: 0.4753\n",
            "Epoch 443/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1437 - accuracy: 0.4737 - val_loss: 1.1409 - val_accuracy: 0.4750\n",
            "Epoch 444/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.1438 - accuracy: 0.4736 - val_loss: 1.1414 - val_accuracy: 0.4746\n",
            "Epoch 445/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1437 - accuracy: 0.4736 - val_loss: 1.1411 - val_accuracy: 0.4750\n",
            "Epoch 446/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1434 - accuracy: 0.4738 - val_loss: 1.1413 - val_accuracy: 0.4750\n",
            "Epoch 447/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1494 - accuracy: 0.4711 - val_loss: 1.1413 - val_accuracy: 0.4749\n",
            "Epoch 448/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1432 - accuracy: 0.4739 - val_loss: 1.1406 - val_accuracy: 0.4752\n",
            "Epoch 449/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1433 - accuracy: 0.4738 - val_loss: 1.1411 - val_accuracy: 0.4747\n",
            "Epoch 450/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1487 - accuracy: 0.4715 - val_loss: 1.1554 - val_accuracy: 0.4679\n",
            "Epoch 451/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1434 - accuracy: 0.4739 - val_loss: 1.1409 - val_accuracy: 0.4749\n",
            "Epoch 452/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1429 - accuracy: 0.4740 - val_loss: 1.1410 - val_accuracy: 0.4755\n",
            "Epoch 453/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1430 - accuracy: 0.4739 - val_loss: 1.1406 - val_accuracy: 0.4749\n",
            "Epoch 454/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1430 - accuracy: 0.4739 - val_loss: 1.1409 - val_accuracy: 0.4749\n",
            "Epoch 455/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1430 - accuracy: 0.4740 - val_loss: 1.1410 - val_accuracy: 0.4750\n",
            "Epoch 456/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1430 - accuracy: 0.4740 - val_loss: 1.1408 - val_accuracy: 0.4749\n",
            "Epoch 457/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1429 - accuracy: 0.4740 - val_loss: 1.1409 - val_accuracy: 0.4744\n",
            "Epoch 458/3000\n",
            "302/302 [==============================] - 13s 43ms/step - loss: 1.1429 - accuracy: 0.4740 - val_loss: 1.1407 - val_accuracy: 0.4748\n",
            "Epoch 459/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1427 - accuracy: 0.4741 - val_loss: 1.1403 - val_accuracy: 0.4753\n",
            "Epoch 460/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1427 - accuracy: 0.4740 - val_loss: 1.1403 - val_accuracy: 0.4751\n",
            "Epoch 461/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1457 - accuracy: 0.4727 - val_loss: 1.1403 - val_accuracy: 0.4755\n",
            "Epoch 462/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1422 - accuracy: 0.4743 - val_loss: 1.1400 - val_accuracy: 0.4759\n",
            "Epoch 463/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1423 - accuracy: 0.4742 - val_loss: 1.1402 - val_accuracy: 0.4755\n",
            "Epoch 464/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1423 - accuracy: 0.4742 - val_loss: 1.1403 - val_accuracy: 0.4754\n",
            "Epoch 465/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1423 - accuracy: 0.4742 - val_loss: 1.1403 - val_accuracy: 0.4748\n",
            "Epoch 466/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1481 - accuracy: 0.4717 - val_loss: 1.1511 - val_accuracy: 0.4699\n",
            "Epoch 467/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.1475 - accuracy: 0.4718 - val_loss: 1.1408 - val_accuracy: 0.4747\n",
            "Epoch 468/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1423 - accuracy: 0.4742 - val_loss: 1.1404 - val_accuracy: 0.4759\n",
            "Epoch 469/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1421 - accuracy: 0.4743 - val_loss: 1.1405 - val_accuracy: 0.4754\n",
            "Epoch 470/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1498 - accuracy: 0.4708 - val_loss: 1.1585 - val_accuracy: 0.4662\n",
            "Epoch 471/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1460 - accuracy: 0.4726 - val_loss: 1.1403 - val_accuracy: 0.4753\n",
            "Epoch 472/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1420 - accuracy: 0.4743 - val_loss: 1.1403 - val_accuracy: 0.4760\n",
            "Epoch 473/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1432 - accuracy: 0.4739 - val_loss: 1.1399 - val_accuracy: 0.4757\n",
            "Epoch 474/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1417 - accuracy: 0.4744 - val_loss: 1.1404 - val_accuracy: 0.4759\n",
            "Epoch 475/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1418 - accuracy: 0.4744 - val_loss: 1.1403 - val_accuracy: 0.4758\n",
            "Epoch 476/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1417 - accuracy: 0.4745 - val_loss: 1.1409 - val_accuracy: 0.4756\n",
            "Epoch 477/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1417 - accuracy: 0.4745 - val_loss: 1.1405 - val_accuracy: 0.4759\n",
            "Epoch 478/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1418 - accuracy: 0.4744 - val_loss: 1.1397 - val_accuracy: 0.4764\n",
            "Epoch 479/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1480 - accuracy: 0.4716 - val_loss: 1.1682 - val_accuracy: 0.4620\n",
            "Epoch 480/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1479 - accuracy: 0.4714 - val_loss: 1.1426 - val_accuracy: 0.4750\n",
            "Epoch 481/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1419 - accuracy: 0.4743 - val_loss: 1.1398 - val_accuracy: 0.4756\n",
            "Epoch 482/3000\n",
            "302/302 [==============================] - 13s 43ms/step - loss: 1.1417 - accuracy: 0.4744 - val_loss: 1.1397 - val_accuracy: 0.4762\n",
            "Epoch 483/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1414 - accuracy: 0.4746 - val_loss: 1.1402 - val_accuracy: 0.4761\n",
            "Epoch 484/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1414 - accuracy: 0.4746 - val_loss: 1.1401 - val_accuracy: 0.4764\n",
            "Epoch 485/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1456 - accuracy: 0.4727 - val_loss: 1.1433 - val_accuracy: 0.4730\n",
            "Epoch 486/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1411 - accuracy: 0.4747 - val_loss: 1.1393 - val_accuracy: 0.4759\n",
            "Epoch 487/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1413 - accuracy: 0.4746 - val_loss: 1.1395 - val_accuracy: 0.4761\n",
            "Epoch 488/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1411 - accuracy: 0.4747 - val_loss: 1.1401 - val_accuracy: 0.4759\n",
            "Epoch 489/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1461 - accuracy: 0.4725 - val_loss: 1.1482 - val_accuracy: 0.4726\n",
            "Epoch 490/3000\n",
            "302/302 [==============================] - 15s 48ms/step - loss: 1.1457 - accuracy: 0.4725 - val_loss: 1.1394 - val_accuracy: 0.4762\n",
            "Epoch 491/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1412 - accuracy: 0.4746 - val_loss: 1.1395 - val_accuracy: 0.4761\n",
            "Epoch 492/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1410 - accuracy: 0.4748 - val_loss: 1.1400 - val_accuracy: 0.4761\n",
            "Epoch 493/3000\n",
            "302/302 [==============================] - 13s 43ms/step - loss: 1.1482 - accuracy: 0.4715 - val_loss: 1.1456 - val_accuracy: 0.4737\n",
            "Epoch 494/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1463 - accuracy: 0.4723 - val_loss: 1.1419 - val_accuracy: 0.4753\n",
            "Epoch 495/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1413 - accuracy: 0.4746 - val_loss: 1.1393 - val_accuracy: 0.4756\n",
            "Epoch 496/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1484 - accuracy: 0.4713 - val_loss: 1.1438 - val_accuracy: 0.4734\n",
            "Epoch 497/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1408 - accuracy: 0.4749 - val_loss: 1.1388 - val_accuracy: 0.4770\n",
            "Epoch 498/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1407 - accuracy: 0.4748 - val_loss: 1.1394 - val_accuracy: 0.4758\n",
            "Epoch 499/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1406 - accuracy: 0.4749 - val_loss: 1.1402 - val_accuracy: 0.4752\n",
            "Epoch 500/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1452 - accuracy: 0.4730 - val_loss: 1.1477 - val_accuracy: 0.4721\n",
            "Epoch 501/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1458 - accuracy: 0.4725 - val_loss: 1.1393 - val_accuracy: 0.4765\n",
            "Epoch 502/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1408 - accuracy: 0.4747 - val_loss: 1.1395 - val_accuracy: 0.4761\n",
            "Epoch 503/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1405 - accuracy: 0.4749 - val_loss: 1.1398 - val_accuracy: 0.4755\n",
            "Epoch 504/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1515 - accuracy: 0.4700 - val_loss: 1.1720 - val_accuracy: 0.4605\n",
            "Epoch 505/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1514 - accuracy: 0.4702 - val_loss: 1.1431 - val_accuracy: 0.4740\n",
            "Epoch 506/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1423 - accuracy: 0.4742 - val_loss: 1.1392 - val_accuracy: 0.4759\n",
            "Epoch 507/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1406 - accuracy: 0.4748 - val_loss: 1.1388 - val_accuracy: 0.4760\n",
            "Epoch 508/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1451 - accuracy: 0.4728 - val_loss: 1.1410 - val_accuracy: 0.4753\n",
            "Epoch 509/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1402 - accuracy: 0.4751 - val_loss: 1.1384 - val_accuracy: 0.4763\n",
            "Epoch 510/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1401 - accuracy: 0.4751 - val_loss: 1.1395 - val_accuracy: 0.4757\n",
            "Epoch 511/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1484 - accuracy: 0.4714 - val_loss: 1.1510 - val_accuracy: 0.4705\n",
            "Epoch 512/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1463 - accuracy: 0.4723 - val_loss: 1.1428 - val_accuracy: 0.4750\n",
            "Epoch 513/3000\n",
            "302/302 [==============================] - 15s 48ms/step - loss: 1.1453 - accuracy: 0.4728 - val_loss: 1.1843 - val_accuracy: 0.4559\n",
            "Epoch 514/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1433 - accuracy: 0.4736 - val_loss: 1.1381 - val_accuracy: 0.4773\n",
            "Epoch 515/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1401 - accuracy: 0.4751 - val_loss: 1.1388 - val_accuracy: 0.4762\n",
            "Epoch 516/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1400 - accuracy: 0.4752 - val_loss: 1.1393 - val_accuracy: 0.4762\n",
            "Epoch 517/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1468 - accuracy: 0.4721 - val_loss: 1.1422 - val_accuracy: 0.4748\n",
            "Epoch 518/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1397 - accuracy: 0.4753 - val_loss: 1.1376 - val_accuracy: 0.4777\n",
            "Epoch 519/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1397 - accuracy: 0.4753 - val_loss: 1.1387 - val_accuracy: 0.4762\n",
            "Epoch 520/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1397 - accuracy: 0.4752 - val_loss: 1.1391 - val_accuracy: 0.4764\n",
            "Epoch 521/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1462 - accuracy: 0.4723 - val_loss: 1.1411 - val_accuracy: 0.4747\n",
            "Epoch 522/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1395 - accuracy: 0.4755 - val_loss: 1.1374 - val_accuracy: 0.4780\n",
            "Epoch 523/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1395 - accuracy: 0.4754 - val_loss: 1.1379 - val_accuracy: 0.4764\n",
            "Epoch 524/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1394 - accuracy: 0.4753 - val_loss: 1.1386 - val_accuracy: 0.4762\n",
            "Epoch 525/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1498 - accuracy: 0.4707 - val_loss: 1.1726 - val_accuracy: 0.4593\n",
            "Epoch 526/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1535 - accuracy: 0.4691 - val_loss: 1.1424 - val_accuracy: 0.4755\n",
            "Epoch 527/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1423 - accuracy: 0.4743 - val_loss: 1.1409 - val_accuracy: 0.4758\n",
            "Epoch 528/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1412 - accuracy: 0.4746 - val_loss: 1.1398 - val_accuracy: 0.4759\n",
            "Epoch 529/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1404 - accuracy: 0.4749 - val_loss: 1.1384 - val_accuracy: 0.4761\n",
            "Epoch 530/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1476 - accuracy: 0.4719 - val_loss: 1.1623 - val_accuracy: 0.4648\n",
            "Epoch 531/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1457 - accuracy: 0.4727 - val_loss: 1.1380 - val_accuracy: 0.4767\n",
            "Epoch 532/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1392 - accuracy: 0.4755 - val_loss: 1.1384 - val_accuracy: 0.4771\n",
            "Epoch 533/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1422 - accuracy: 0.4740 - val_loss: 1.1396 - val_accuracy: 0.4753\n",
            "Epoch 534/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1388 - accuracy: 0.4756 - val_loss: 1.1370 - val_accuracy: 0.4776\n",
            "Epoch 535/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1389 - accuracy: 0.4755 - val_loss: 1.1373 - val_accuracy: 0.4763\n",
            "Epoch 536/3000\n",
            "302/302 [==============================] - 15s 48ms/step - loss: 1.1444 - accuracy: 0.4729 - val_loss: 1.1367 - val_accuracy: 0.4771\n",
            "Epoch 537/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1386 - accuracy: 0.4757 - val_loss: 1.1368 - val_accuracy: 0.4775\n",
            "Epoch 538/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1388 - accuracy: 0.4756 - val_loss: 1.1369 - val_accuracy: 0.4769\n",
            "Epoch 539/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1388 - accuracy: 0.4756 - val_loss: 1.1370 - val_accuracy: 0.4766\n",
            "Epoch 540/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1387 - accuracy: 0.4756 - val_loss: 1.1370 - val_accuracy: 0.4767\n",
            "Epoch 541/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1459 - accuracy: 0.4725 - val_loss: 1.1412 - val_accuracy: 0.4734\n",
            "Epoch 542/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1387 - accuracy: 0.4756 - val_loss: 1.1368 - val_accuracy: 0.4777\n",
            "Epoch 543/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1384 - accuracy: 0.4757 - val_loss: 1.1363 - val_accuracy: 0.4770\n",
            "Epoch 544/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1385 - accuracy: 0.4757 - val_loss: 1.1369 - val_accuracy: 0.4766\n",
            "Epoch 545/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1470 - accuracy: 0.4719 - val_loss: 1.1444 - val_accuracy: 0.4731\n",
            "Epoch 546/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1385 - accuracy: 0.4757 - val_loss: 1.1369 - val_accuracy: 0.4773\n",
            "Epoch 547/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1382 - accuracy: 0.4759 - val_loss: 1.1364 - val_accuracy: 0.4776\n",
            "Epoch 548/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1383 - accuracy: 0.4758 - val_loss: 1.1367 - val_accuracy: 0.4762\n",
            "Epoch 549/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1456 - accuracy: 0.4726 - val_loss: 1.1503 - val_accuracy: 0.4705\n",
            "Epoch 550/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1447 - accuracy: 0.4730 - val_loss: 1.1412 - val_accuracy: 0.4750\n",
            "Epoch 551/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1432 - accuracy: 0.4736 - val_loss: 1.1404 - val_accuracy: 0.4755\n",
            "Epoch 552/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1424 - accuracy: 0.4740 - val_loss: 1.1400 - val_accuracy: 0.4761\n",
            "Epoch 553/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1419 - accuracy: 0.4743 - val_loss: 1.1417 - val_accuracy: 0.4754\n",
            "Epoch 554/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1414 - accuracy: 0.4746 - val_loss: 1.1420 - val_accuracy: 0.4752\n",
            "Epoch 555/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1412 - accuracy: 0.4748 - val_loss: 1.1413 - val_accuracy: 0.4753\n",
            "Epoch 556/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1402 - accuracy: 0.4752 - val_loss: 1.1367 - val_accuracy: 0.4777\n",
            "Epoch 557/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1387 - accuracy: 0.4757 - val_loss: 1.1377 - val_accuracy: 0.4766\n",
            "Epoch 558/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1384 - accuracy: 0.4757 - val_loss: 1.1375 - val_accuracy: 0.4762\n",
            "Epoch 559/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.1488 - accuracy: 0.4711 - val_loss: 1.1468 - val_accuracy: 0.4721\n",
            "Epoch 560/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1417 - accuracy: 0.4744 - val_loss: 1.1409 - val_accuracy: 0.4749\n",
            "Epoch 561/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1397 - accuracy: 0.4751 - val_loss: 1.1386 - val_accuracy: 0.4757\n",
            "Epoch 562/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1388 - accuracy: 0.4755 - val_loss: 1.1364 - val_accuracy: 0.4775\n",
            "Epoch 563/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1457 - accuracy: 0.4723 - val_loss: 1.1503 - val_accuracy: 0.4706\n",
            "Epoch 564/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1433 - accuracy: 0.4734 - val_loss: 1.1399 - val_accuracy: 0.4752\n",
            "Epoch 565/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1407 - accuracy: 0.4746 - val_loss: 1.1360 - val_accuracy: 0.4779\n",
            "Epoch 566/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1380 - accuracy: 0.4759 - val_loss: 1.1359 - val_accuracy: 0.4776\n",
            "Epoch 567/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1378 - accuracy: 0.4759 - val_loss: 1.1374 - val_accuracy: 0.4765\n",
            "Epoch 568/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1377 - accuracy: 0.4759 - val_loss: 1.1381 - val_accuracy: 0.4757\n",
            "Epoch 569/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1448 - accuracy: 0.4728 - val_loss: 1.1739 - val_accuracy: 0.4586\n",
            "Epoch 570/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1524 - accuracy: 0.4696 - val_loss: 1.1418 - val_accuracy: 0.4752\n",
            "Epoch 571/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1397 - accuracy: 0.4753 - val_loss: 1.1381 - val_accuracy: 0.4762\n",
            "Epoch 572/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1390 - accuracy: 0.4754 - val_loss: 1.1364 - val_accuracy: 0.4777\n",
            "Epoch 573/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1386 - accuracy: 0.4755 - val_loss: 1.1362 - val_accuracy: 0.4776\n",
            "Epoch 574/3000\n",
            "302/302 [==============================] - 14s 48ms/step - loss: 1.1386 - accuracy: 0.4754 - val_loss: 1.1364 - val_accuracy: 0.4765\n",
            "Epoch 575/3000\n",
            "302/302 [==============================] - 14s 48ms/step - loss: 1.1373 - accuracy: 0.4761 - val_loss: 1.1357 - val_accuracy: 0.4777\n",
            "Epoch 576/3000\n",
            "302/302 [==============================] - 15s 49ms/step - loss: 1.1384 - accuracy: 0.4755 - val_loss: 1.1353 - val_accuracy: 0.4774\n",
            "Epoch 577/3000\n",
            "302/302 [==============================] - 15s 49ms/step - loss: 1.1370 - accuracy: 0.4762 - val_loss: 1.1356 - val_accuracy: 0.4772\n",
            "Epoch 578/3000\n",
            "302/302 [==============================] - 15s 49ms/step - loss: 1.1371 - accuracy: 0.4761 - val_loss: 1.1374 - val_accuracy: 0.4760\n",
            "Epoch 579/3000\n",
            "302/302 [==============================] - 15s 50ms/step - loss: 1.1414 - accuracy: 0.4742 - val_loss: 1.1398 - val_accuracy: 0.4743\n",
            "Epoch 580/3000\n",
            "302/302 [==============================] - 15s 50ms/step - loss: 1.1367 - accuracy: 0.4761 - val_loss: 1.1352 - val_accuracy: 0.4770\n",
            "Epoch 581/3000\n",
            "302/302 [==============================] - 16s 52ms/step - loss: 1.1365 - accuracy: 0.4765 - val_loss: 1.1352 - val_accuracy: 0.4771\n",
            "Epoch 582/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.1366 - accuracy: 0.4763 - val_loss: 1.1374 - val_accuracy: 0.4760\n",
            "Epoch 583/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1420 - accuracy: 0.4741 - val_loss: 1.1486 - val_accuracy: 0.4696\n",
            "Epoch 584/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.1424 - accuracy: 0.4737 - val_loss: 1.1391 - val_accuracy: 0.4759\n",
            "Epoch 585/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.1412 - accuracy: 0.4743 - val_loss: 1.1383 - val_accuracy: 0.4765\n",
            "Epoch 586/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.1405 - accuracy: 0.4746 - val_loss: 1.1393 - val_accuracy: 0.4751\n",
            "Epoch 587/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1398 - accuracy: 0.4750 - val_loss: 1.1414 - val_accuracy: 0.4748\n",
            "Epoch 588/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.1392 - accuracy: 0.4754 - val_loss: 1.1364 - val_accuracy: 0.4768\n",
            "Epoch 589/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.1376 - accuracy: 0.4758 - val_loss: 1.1381 - val_accuracy: 0.4759\n",
            "Epoch 590/3000\n",
            "302/302 [==============================] - 15s 48ms/step - loss: 1.1369 - accuracy: 0.4762 - val_loss: 1.1380 - val_accuracy: 0.4761\n",
            "Epoch 591/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1453 - accuracy: 0.4726 - val_loss: 1.1712 - val_accuracy: 0.4614\n",
            "Epoch 592/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.1608 - accuracy: 0.4655 - val_loss: 1.1588 - val_accuracy: 0.4664\n",
            "Epoch 593/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1536 - accuracy: 0.4691 - val_loss: 1.1443 - val_accuracy: 0.4722\n",
            "Epoch 594/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1438 - accuracy: 0.4729 - val_loss: 1.1467 - val_accuracy: 0.4707\n",
            "Epoch 595/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1419 - accuracy: 0.4737 - val_loss: 1.1459 - val_accuracy: 0.4716\n",
            "Epoch 596/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1412 - accuracy: 0.4741 - val_loss: 1.1452 - val_accuracy: 0.4720\n",
            "Epoch 597/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.1407 - accuracy: 0.4744 - val_loss: 1.1444 - val_accuracy: 0.4720\n",
            "Epoch 598/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1405 - accuracy: 0.4746 - val_loss: 1.1457 - val_accuracy: 0.4718\n",
            "Epoch 599/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.1402 - accuracy: 0.4747 - val_loss: 1.1470 - val_accuracy: 0.4714\n",
            "Epoch 600/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1401 - accuracy: 0.4748 - val_loss: 1.1477 - val_accuracy: 0.4705\n",
            "Epoch 601/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1400 - accuracy: 0.4748 - val_loss: 1.1468 - val_accuracy: 0.4708\n",
            "Epoch 602/3000\n",
            "302/302 [==============================] - 14s 48ms/step - loss: 1.1398 - accuracy: 0.4749 - val_loss: 1.1478 - val_accuracy: 0.4699\n",
            "Epoch 603/3000\n",
            "302/302 [==============================] - 15s 49ms/step - loss: 1.1397 - accuracy: 0.4750 - val_loss: 1.1480 - val_accuracy: 0.4702\n",
            "Epoch 604/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1395 - accuracy: 0.4750 - val_loss: 1.1478 - val_accuracy: 0.4702\n",
            "Epoch 605/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1393 - accuracy: 0.4750 - val_loss: 1.1476 - val_accuracy: 0.4702\n",
            "Epoch 606/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1393 - accuracy: 0.4751 - val_loss: 1.1478 - val_accuracy: 0.4701\n",
            "Epoch 607/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.1391 - accuracy: 0.4752 - val_loss: 1.1483 - val_accuracy: 0.4702\n",
            "Epoch 608/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1391 - accuracy: 0.4751 - val_loss: 1.1476 - val_accuracy: 0.4704\n",
            "Epoch 609/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1388 - accuracy: 0.4753 - val_loss: 1.1451 - val_accuracy: 0.4721\n",
            "Epoch 610/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.1387 - accuracy: 0.4754 - val_loss: 1.1458 - val_accuracy: 0.4714\n",
            "Epoch 611/3000\n",
            "302/302 [==============================] - 15s 50ms/step - loss: 1.1386 - accuracy: 0.4754 - val_loss: 1.1462 - val_accuracy: 0.4707\n",
            "Epoch 612/3000\n",
            "302/302 [==============================] - 16s 52ms/step - loss: 1.1385 - accuracy: 0.4754 - val_loss: 1.1450 - val_accuracy: 0.4717\n",
            "Epoch 613/3000\n",
            "302/302 [==============================] - 15s 49ms/step - loss: 1.1385 - accuracy: 0.4754 - val_loss: 1.1456 - val_accuracy: 0.4715\n",
            "Epoch 614/3000\n",
            "302/302 [==============================] - 15s 51ms/step - loss: 1.1383 - accuracy: 0.4754 - val_loss: 1.1452 - val_accuracy: 0.4719\n",
            "Epoch 615/3000\n",
            "302/302 [==============================] - 14s 48ms/step - loss: 1.1383 - accuracy: 0.4754 - val_loss: 1.1445 - val_accuracy: 0.4717\n",
            "Epoch 616/3000\n",
            "302/302 [==============================] - 15s 49ms/step - loss: 1.1381 - accuracy: 0.4755 - val_loss: 1.1450 - val_accuracy: 0.4718\n",
            "Epoch 617/3000\n",
            "302/302 [==============================] - 15s 49ms/step - loss: 1.1381 - accuracy: 0.4756 - val_loss: 1.1442 - val_accuracy: 0.4723\n",
            "Epoch 618/3000\n",
            "302/302 [==============================] - 14s 48ms/step - loss: 1.1380 - accuracy: 0.4756 - val_loss: 1.1435 - val_accuracy: 0.4729\n",
            "Epoch 619/3000\n",
            "302/302 [==============================] - 15s 49ms/step - loss: 1.1379 - accuracy: 0.4756 - val_loss: 1.1442 - val_accuracy: 0.4722\n",
            "Epoch 620/3000\n",
            "302/302 [==============================] - 14s 48ms/step - loss: 1.1378 - accuracy: 0.4756 - val_loss: 1.1442 - val_accuracy: 0.4720\n",
            "Epoch 621/3000\n",
            "302/302 [==============================] - 14s 48ms/step - loss: 1.1377 - accuracy: 0.4757 - val_loss: 1.1434 - val_accuracy: 0.4722\n",
            "Epoch 622/3000\n",
            "302/302 [==============================] - 14s 48ms/step - loss: 1.1376 - accuracy: 0.4757 - val_loss: 1.1426 - val_accuracy: 0.4730\n",
            "Epoch 623/3000\n",
            "302/302 [==============================] - 14s 48ms/step - loss: 1.1376 - accuracy: 0.4756 - val_loss: 1.1396 - val_accuracy: 0.4742\n",
            "Epoch 624/3000\n",
            "302/302 [==============================] - 16s 52ms/step - loss: 1.1426 - accuracy: 0.4731 - val_loss: 1.1346 - val_accuracy: 0.4773\n",
            "Epoch 625/3000\n",
            "302/302 [==============================] - 15s 48ms/step - loss: 1.1368 - accuracy: 0.4761 - val_loss: 1.1459 - val_accuracy: 0.4704\n",
            "Epoch 626/3000\n",
            "302/302 [==============================] - 14s 48ms/step - loss: 1.1531 - accuracy: 0.4691 - val_loss: 1.1425 - val_accuracy: 0.4729\n",
            "Epoch 627/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.1441 - accuracy: 0.4730 - val_loss: 1.1420 - val_accuracy: 0.4724\n",
            "Epoch 628/3000\n",
            "302/302 [==============================] - 14s 48ms/step - loss: 1.1429 - accuracy: 0.4735 - val_loss: 1.1418 - val_accuracy: 0.4730\n",
            "Epoch 629/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.1422 - accuracy: 0.4739 - val_loss: 1.1422 - val_accuracy: 0.4724\n",
            "Epoch 630/3000\n",
            "302/302 [==============================] - 15s 48ms/step - loss: 1.1413 - accuracy: 0.4742 - val_loss: 1.1424 - val_accuracy: 0.4728\n",
            "Epoch 631/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.1407 - accuracy: 0.4745 - val_loss: 1.1409 - val_accuracy: 0.4731\n",
            "Epoch 632/3000\n",
            "302/302 [==============================] - 15s 48ms/step - loss: 1.1402 - accuracy: 0.4748 - val_loss: 1.1402 - val_accuracy: 0.4735\n",
            "Epoch 633/3000\n",
            "302/302 [==============================] - 15s 48ms/step - loss: 1.1398 - accuracy: 0.4750 - val_loss: 1.1401 - val_accuracy: 0.4738\n",
            "Epoch 634/3000\n",
            "302/302 [==============================] - 15s 48ms/step - loss: 1.1394 - accuracy: 0.4751 - val_loss: 1.1391 - val_accuracy: 0.4745\n",
            "Epoch 635/3000\n",
            "302/302 [==============================] - 14s 48ms/step - loss: 1.1391 - accuracy: 0.4752 - val_loss: 1.1377 - val_accuracy: 0.4757\n",
            "Epoch 636/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.1388 - accuracy: 0.4753 - val_loss: 1.1377 - val_accuracy: 0.4754\n",
            "Epoch 637/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.1425 - accuracy: 0.4737 - val_loss: 1.1358 - val_accuracy: 0.4770\n",
            "Epoch 638/3000\n",
            "302/302 [==============================] - 15s 48ms/step - loss: 1.1381 - accuracy: 0.4756 - val_loss: 1.1404 - val_accuracy: 0.4743\n",
            "Epoch 639/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.1381 - accuracy: 0.4755 - val_loss: 1.1387 - val_accuracy: 0.4751\n",
            "Epoch 640/3000\n",
            "302/302 [==============================] - 14s 48ms/step - loss: 1.1380 - accuracy: 0.4756 - val_loss: 1.1383 - val_accuracy: 0.4753\n",
            "Epoch 641/3000\n",
            "302/302 [==============================] - 14s 48ms/step - loss: 1.1376 - accuracy: 0.4756 - val_loss: 1.1375 - val_accuracy: 0.4752\n",
            "Epoch 642/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.1373 - accuracy: 0.4758 - val_loss: 1.1361 - val_accuracy: 0.4757\n",
            "Epoch 643/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.1371 - accuracy: 0.4758 - val_loss: 1.1355 - val_accuracy: 0.4757\n",
            "Epoch 644/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.1370 - accuracy: 0.4759 - val_loss: 1.1353 - val_accuracy: 0.4754\n",
            "Epoch 645/3000\n",
            "302/302 [==============================] - 15s 49ms/step - loss: 1.1368 - accuracy: 0.4759 - val_loss: 1.1351 - val_accuracy: 0.4756\n",
            "Epoch 646/3000\n",
            "302/302 [==============================] - 14s 48ms/step - loss: 1.1367 - accuracy: 0.4760 - val_loss: 1.1347 - val_accuracy: 0.4759\n",
            "Epoch 647/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1403 - accuracy: 0.4744 - val_loss: 1.1335 - val_accuracy: 0.4771\n",
            "Epoch 648/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1359 - accuracy: 0.4764 - val_loss: 1.1361 - val_accuracy: 0.4755\n",
            "Epoch 649/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1364 - accuracy: 0.4761 - val_loss: 1.1348 - val_accuracy: 0.4752\n",
            "Epoch 650/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1364 - accuracy: 0.4761 - val_loss: 1.3040 - val_accuracy: 0.4353\n",
            "Epoch 651/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1427 - accuracy: 0.4736 - val_loss: 1.1331 - val_accuracy: 0.4777\n",
            "Epoch 652/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1353 - accuracy: 0.4766 - val_loss: 1.1336 - val_accuracy: 0.4766\n",
            "Epoch 653/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1356 - accuracy: 0.4765 - val_loss: 1.1341 - val_accuracy: 0.4764\n",
            "Epoch 654/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1491 - accuracy: 0.4708 - val_loss: 1.1368 - val_accuracy: 0.4760\n",
            "Epoch 655/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1385 - accuracy: 0.4753 - val_loss: 1.1366 - val_accuracy: 0.4752\n",
            "Epoch 656/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1379 - accuracy: 0.4756 - val_loss: 1.1369 - val_accuracy: 0.4750\n",
            "Epoch 657/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1440 - accuracy: 0.4729 - val_loss: 1.1345 - val_accuracy: 0.4779\n",
            "Epoch 658/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1365 - accuracy: 0.4763 - val_loss: 1.1343 - val_accuracy: 0.4763\n",
            "Epoch 659/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1367 - accuracy: 0.4762 - val_loss: 1.1350 - val_accuracy: 0.4760\n",
            "Epoch 660/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1409 - accuracy: 0.4742 - val_loss: 1.1335 - val_accuracy: 0.4776\n",
            "Epoch 661/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1360 - accuracy: 0.4765 - val_loss: 1.1342 - val_accuracy: 0.4760\n",
            "Epoch 662/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1363 - accuracy: 0.4763 - val_loss: 1.1346 - val_accuracy: 0.4763\n",
            "Epoch 663/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1679 - accuracy: 0.4621 - val_loss: 1.1526 - val_accuracy: 0.4687\n",
            "Epoch 664/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1510 - accuracy: 0.4699 - val_loss: 1.1478 - val_accuracy: 0.4710\n",
            "Epoch 665/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1488 - accuracy: 0.4708 - val_loss: 1.1437 - val_accuracy: 0.4738\n",
            "Epoch 666/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1498 - accuracy: 0.4699 - val_loss: 1.1424 - val_accuracy: 0.4732\n",
            "Epoch 667/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1398 - accuracy: 0.4745 - val_loss: 1.1351 - val_accuracy: 0.4769\n",
            "Epoch 668/3000\n",
            "302/302 [==============================] - 14s 48ms/step - loss: 1.1367 - accuracy: 0.4757 - val_loss: 1.1345 - val_accuracy: 0.4764\n",
            "Epoch 669/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1365 - accuracy: 0.4758 - val_loss: 1.1337 - val_accuracy: 0.4766\n",
            "Epoch 670/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1361 - accuracy: 0.4760 - val_loss: 1.1338 - val_accuracy: 0.4765\n",
            "Epoch 671/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1614 - accuracy: 0.4649 - val_loss: 1.1493 - val_accuracy: 0.4703\n",
            "Epoch 672/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1498 - accuracy: 0.4701 - val_loss: 1.1476 - val_accuracy: 0.4713\n",
            "Epoch 673/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1491 - accuracy: 0.4704 - val_loss: 1.1459 - val_accuracy: 0.4715\n",
            "Epoch 674/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1452 - accuracy: 0.4721 - val_loss: 1.1364 - val_accuracy: 0.4761\n",
            "Epoch 675/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1418 - accuracy: 0.4737 - val_loss: 1.1377 - val_accuracy: 0.4750\n",
            "Epoch 676/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1355 - accuracy: 0.4765 - val_loss: 1.1330 - val_accuracy: 0.4775\n",
            "Epoch 677/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1353 - accuracy: 0.4765 - val_loss: 1.1338 - val_accuracy: 0.4763\n",
            "Epoch 678/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1444 - accuracy: 0.4725 - val_loss: 1.1398 - val_accuracy: 0.4736\n",
            "Epoch 679/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1369 - accuracy: 0.4759 - val_loss: 1.1334 - val_accuracy: 0.4773\n",
            "Epoch 680/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1356 - accuracy: 0.4766 - val_loss: 1.1337 - val_accuracy: 0.4768\n",
            "Epoch 681/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1358 - accuracy: 0.4765 - val_loss: 1.1343 - val_accuracy: 0.4762\n",
            "Epoch 682/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1469 - accuracy: 0.4718 - val_loss: 1.1465 - val_accuracy: 0.4709\n",
            "Epoch 683/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1376 - accuracy: 0.4756 - val_loss: 1.1331 - val_accuracy: 0.4772\n",
            "Epoch 684/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1352 - accuracy: 0.4768 - val_loss: 1.1343 - val_accuracy: 0.4761\n",
            "Epoch 685/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1423 - accuracy: 0.4739 - val_loss: 1.1340 - val_accuracy: 0.4759\n",
            "Epoch 686/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1342 - accuracy: 0.4773 - val_loss: 1.1326 - val_accuracy: 0.4769\n",
            "Epoch 687/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1345 - accuracy: 0.4771 - val_loss: 1.1331 - val_accuracy: 0.4769\n",
            "Epoch 688/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1412 - accuracy: 0.4744 - val_loss: 1.1331 - val_accuracy: 0.4770\n",
            "Epoch 689/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1338 - accuracy: 0.4774 - val_loss: 1.1318 - val_accuracy: 0.4779\n",
            "Epoch 690/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1340 - accuracy: 0.4773 - val_loss: 1.1322 - val_accuracy: 0.4769\n",
            "Epoch 691/3000\n",
            "302/302 [==============================] - 15s 49ms/step - loss: 1.1401 - accuracy: 0.4746 - val_loss: 1.1325 - val_accuracy: 0.4771\n",
            "Epoch 692/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1334 - accuracy: 0.4777 - val_loss: 1.1317 - val_accuracy: 0.4779\n",
            "Epoch 693/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1338 - accuracy: 0.4774 - val_loss: 1.1340 - val_accuracy: 0.4766\n",
            "Epoch 694/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1341 - accuracy: 0.4772 - val_loss: 1.1320 - val_accuracy: 0.4773\n",
            "Epoch 695/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1339 - accuracy: 0.4772 - val_loss: 1.1326 - val_accuracy: 0.4772\n",
            "Epoch 696/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1338 - accuracy: 0.4772 - val_loss: 1.1319 - val_accuracy: 0.4773\n",
            "Epoch 697/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1336 - accuracy: 0.4773 - val_loss: 1.1314 - val_accuracy: 0.4775\n",
            "Epoch 698/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1338 - accuracy: 0.4772 - val_loss: 1.1312 - val_accuracy: 0.4778\n",
            "Epoch 699/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1334 - accuracy: 0.4774 - val_loss: 1.1313 - val_accuracy: 0.4776\n",
            "Epoch 700/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1334 - accuracy: 0.4775 - val_loss: 1.1319 - val_accuracy: 0.4772\n",
            "Epoch 701/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1333 - accuracy: 0.4775 - val_loss: 1.1305 - val_accuracy: 0.4784\n",
            "Epoch 702/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1332 - accuracy: 0.4775 - val_loss: 1.1312 - val_accuracy: 0.4777\n",
            "Epoch 703/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1331 - accuracy: 0.4775 - val_loss: 1.1307 - val_accuracy: 0.4778\n",
            "Epoch 704/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1399 - accuracy: 0.4745 - val_loss: 1.1851 - val_accuracy: 0.4470\n",
            "Epoch 705/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1356 - accuracy: 0.4758 - val_loss: 1.1295 - val_accuracy: 0.4789\n",
            "Epoch 706/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1320 - accuracy: 0.4781 - val_loss: 1.1307 - val_accuracy: 0.4785\n",
            "Epoch 707/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1323 - accuracy: 0.4779 - val_loss: 1.1315 - val_accuracy: 0.4773\n",
            "Epoch 708/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1419 - accuracy: 0.4739 - val_loss: 1.1328 - val_accuracy: 0.4771\n",
            "Epoch 709/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1318 - accuracy: 0.4782 - val_loss: 1.1299 - val_accuracy: 0.4795\n",
            "Epoch 710/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1326 - accuracy: 0.4777 - val_loss: 1.1302 - val_accuracy: 0.4788\n",
            "Epoch 711/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1321 - accuracy: 0.4779 - val_loss: 1.1302 - val_accuracy: 0.4785\n",
            "Epoch 712/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1323 - accuracy: 0.4778 - val_loss: 1.1302 - val_accuracy: 0.4786\n",
            "Epoch 713/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1400 - accuracy: 0.4742 - val_loss: 1.1294 - val_accuracy: 0.4798\n",
            "Epoch 714/3000\n",
            "302/302 [==============================] - 15s 49ms/step - loss: 1.1314 - accuracy: 0.4783 - val_loss: 1.1297 - val_accuracy: 0.4790\n",
            "Epoch 715/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1316 - accuracy: 0.4782 - val_loss: 1.1303 - val_accuracy: 0.4782\n",
            "Epoch 716/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1415 - accuracy: 0.4741 - val_loss: 1.1290 - val_accuracy: 0.4802\n",
            "Epoch 717/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1310 - accuracy: 0.4786 - val_loss: 1.1298 - val_accuracy: 0.4789\n",
            "Epoch 718/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1315 - accuracy: 0.4782 - val_loss: 1.1296 - val_accuracy: 0.4782\n",
            "Epoch 719/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1398 - accuracy: 0.4741 - val_loss: 1.1290 - val_accuracy: 0.4798\n",
            "Epoch 720/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1309 - accuracy: 0.4785 - val_loss: 1.1295 - val_accuracy: 0.4793\n",
            "Epoch 721/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1315 - accuracy: 0.4783 - val_loss: 1.1287 - val_accuracy: 0.4794\n",
            "Epoch 722/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1422 - accuracy: 0.4739 - val_loss: 1.1284 - val_accuracy: 0.4796\n",
            "Epoch 723/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1306 - accuracy: 0.4786 - val_loss: 1.1291 - val_accuracy: 0.4795\n",
            "Epoch 724/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1364 - accuracy: 0.4759 - val_loss: 1.1282 - val_accuracy: 0.4794\n",
            "Epoch 725/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1304 - accuracy: 0.4787 - val_loss: 1.1284 - val_accuracy: 0.4797\n",
            "Epoch 726/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1308 - accuracy: 0.4786 - val_loss: 1.1289 - val_accuracy: 0.4784\n",
            "Epoch 727/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1310 - accuracy: 0.4783 - val_loss: 1.1285 - val_accuracy: 0.4784\n",
            "Epoch 728/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1312 - accuracy: 0.4783 - val_loss: 1.1289 - val_accuracy: 0.4785\n",
            "Epoch 729/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1311 - accuracy: 0.4782 - val_loss: 1.1287 - val_accuracy: 0.4786\n",
            "Epoch 730/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1311 - accuracy: 0.4783 - val_loss: 1.1288 - val_accuracy: 0.4776\n",
            "Epoch 731/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1441 - accuracy: 0.4725 - val_loss: 1.1279 - val_accuracy: 0.4795\n",
            "Epoch 732/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1299 - accuracy: 0.4788 - val_loss: 1.1278 - val_accuracy: 0.4794\n",
            "Epoch 733/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1303 - accuracy: 0.4787 - val_loss: 1.1281 - val_accuracy: 0.4787\n",
            "Epoch 734/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1307 - accuracy: 0.4784 - val_loss: 1.1281 - val_accuracy: 0.4785\n",
            "Epoch 735/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1307 - accuracy: 0.4784 - val_loss: 1.1284 - val_accuracy: 0.4780\n",
            "Epoch 736/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1315 - accuracy: 0.4779 - val_loss: 1.1277 - val_accuracy: 0.4787\n",
            "Epoch 737/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.1300 - accuracy: 0.4788 - val_loss: 1.1280 - val_accuracy: 0.4782\n",
            "Epoch 738/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1308 - accuracy: 0.4782 - val_loss: 1.1285 - val_accuracy: 0.4776\n",
            "Epoch 739/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1305 - accuracy: 0.4784 - val_loss: 1.1285 - val_accuracy: 0.4778\n",
            "Epoch 740/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1377 - accuracy: 0.4756 - val_loss: 1.1274 - val_accuracy: 0.4793\n",
            "Epoch 741/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1294 - accuracy: 0.4791 - val_loss: 1.1273 - val_accuracy: 0.4789\n",
            "Epoch 742/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1301 - accuracy: 0.4785 - val_loss: 1.1274 - val_accuracy: 0.4785\n",
            "Epoch 743/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1300 - accuracy: 0.4786 - val_loss: 1.1280 - val_accuracy: 0.4779\n",
            "Epoch 744/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1301 - accuracy: 0.4786 - val_loss: 1.1282 - val_accuracy: 0.4775\n",
            "Epoch 745/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1299 - accuracy: 0.4786 - val_loss: 1.1285 - val_accuracy: 0.4776\n",
            "Epoch 746/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1300 - accuracy: 0.4786 - val_loss: 1.1284 - val_accuracy: 0.4774\n",
            "Epoch 747/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1387 - accuracy: 0.4746 - val_loss: 1.1274 - val_accuracy: 0.4794\n",
            "Epoch 748/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1288 - accuracy: 0.4792 - val_loss: 1.1266 - val_accuracy: 0.4793\n",
            "Epoch 749/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1290 - accuracy: 0.4792 - val_loss: 1.1275 - val_accuracy: 0.4780\n",
            "Epoch 750/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1296 - accuracy: 0.4789 - val_loss: 1.1272 - val_accuracy: 0.4777\n",
            "Epoch 751/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1395 - accuracy: 0.4735 - val_loss: 1.1262 - val_accuracy: 0.4798\n",
            "Epoch 752/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1284 - accuracy: 0.4795 - val_loss: 1.1265 - val_accuracy: 0.4792\n",
            "Epoch 753/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1287 - accuracy: 0.4794 - val_loss: 1.1272 - val_accuracy: 0.4788\n",
            "Epoch 754/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1291 - accuracy: 0.4791 - val_loss: 1.1281 - val_accuracy: 0.4779\n",
            "Epoch 755/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1363 - accuracy: 0.4760 - val_loss: 1.1257 - val_accuracy: 0.4797\n",
            "Epoch 756/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1282 - accuracy: 0.4795 - val_loss: 1.1263 - val_accuracy: 0.4790\n",
            "Epoch 757/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1286 - accuracy: 0.4793 - val_loss: 1.1263 - val_accuracy: 0.4791\n",
            "Epoch 758/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1293 - accuracy: 0.4789 - val_loss: 1.1335 - val_accuracy: 0.4750\n",
            "Epoch 759/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.1287 - accuracy: 0.4792 - val_loss: 1.1265 - val_accuracy: 0.4784\n",
            "Epoch 760/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1289 - accuracy: 0.4791 - val_loss: 1.1264 - val_accuracy: 0.4790\n",
            "Epoch 761/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1639 - accuracy: 0.4637 - val_loss: 1.1510 - val_accuracy: 0.4684\n",
            "Epoch 762/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1492 - accuracy: 0.4701 - val_loss: 1.1441 - val_accuracy: 0.4724\n",
            "Epoch 763/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1458 - accuracy: 0.4717 - val_loss: 1.1439 - val_accuracy: 0.4723\n",
            "Epoch 764/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1458 - accuracy: 0.4714 - val_loss: 1.1413 - val_accuracy: 0.4731\n",
            "Epoch 765/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1436 - accuracy: 0.4724 - val_loss: 1.1412 - val_accuracy: 0.4727\n",
            "Epoch 766/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1428 - accuracy: 0.4724 - val_loss: 1.1381 - val_accuracy: 0.4733\n",
            "Epoch 767/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1461 - accuracy: 0.4709 - val_loss: 1.1354 - val_accuracy: 0.4752\n",
            "Epoch 768/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1325 - accuracy: 0.4770 - val_loss: 1.1278 - val_accuracy: 0.4777\n",
            "Epoch 769/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1288 - accuracy: 0.4786 - val_loss: 1.1260 - val_accuracy: 0.4790\n",
            "Epoch 770/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1326 - accuracy: 0.4769 - val_loss: 1.1251 - val_accuracy: 0.4793\n",
            "Epoch 771/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1278 - accuracy: 0.4793 - val_loss: 1.1255 - val_accuracy: 0.4794\n",
            "Epoch 772/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1280 - accuracy: 0.4792 - val_loss: 1.1259 - val_accuracy: 0.4788\n",
            "Epoch 773/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1286 - accuracy: 0.4789 - val_loss: 1.1256 - val_accuracy: 0.4791\n",
            "Epoch 774/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1463 - accuracy: 0.4715 - val_loss: 1.1573 - val_accuracy: 0.4651\n",
            "Epoch 775/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1535 - accuracy: 0.4675 - val_loss: 1.1481 - val_accuracy: 0.4697\n",
            "Epoch 776/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1468 - accuracy: 0.4710 - val_loss: 1.1431 - val_accuracy: 0.4729\n",
            "Epoch 777/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1468 - accuracy: 0.4708 - val_loss: 1.1404 - val_accuracy: 0.4727\n",
            "Epoch 778/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1427 - accuracy: 0.4727 - val_loss: 1.1405 - val_accuracy: 0.4733\n",
            "Epoch 779/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1433 - accuracy: 0.4721 - val_loss: 1.1409 - val_accuracy: 0.4729\n",
            "Epoch 780/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1423 - accuracy: 0.4725 - val_loss: 1.1393 - val_accuracy: 0.4731\n",
            "Epoch 781/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1436 - accuracy: 0.4718 - val_loss: 1.1391 - val_accuracy: 0.4726\n",
            "Epoch 782/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.1517 - accuracy: 0.4680 - val_loss: 1.1441 - val_accuracy: 0.4704\n",
            "Epoch 783/3000\n",
            "302/302 [==============================] - 14s 47ms/step - loss: 1.1409 - accuracy: 0.4730 - val_loss: 1.1379 - val_accuracy: 0.4738\n",
            "Epoch 784/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1408 - accuracy: 0.4729 - val_loss: 1.1398 - val_accuracy: 0.4724\n",
            "Epoch 785/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1484 - accuracy: 0.4696 - val_loss: 1.1392 - val_accuracy: 0.4730\n",
            "Epoch 786/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1402 - accuracy: 0.4730 - val_loss: 1.1378 - val_accuracy: 0.4737\n",
            "Epoch 787/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1551 - accuracy: 0.4662 - val_loss: 1.1458 - val_accuracy: 0.4687\n",
            "Epoch 788/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1406 - accuracy: 0.4727 - val_loss: 1.1370 - val_accuracy: 0.4740\n",
            "Epoch 789/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1470 - accuracy: 0.4705 - val_loss: 1.2008 - val_accuracy: 0.4439\n",
            "Epoch 790/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1415 - accuracy: 0.4720 - val_loss: 1.1344 - val_accuracy: 0.4749\n",
            "Epoch 791/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1380 - accuracy: 0.4738 - val_loss: 1.1345 - val_accuracy: 0.4742\n",
            "Epoch 792/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1408 - accuracy: 0.4722 - val_loss: 1.1335 - val_accuracy: 0.4742\n",
            "Epoch 793/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1356 - accuracy: 0.4750 - val_loss: 1.1330 - val_accuracy: 0.4750\n",
            "Epoch 794/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1351 - accuracy: 0.4754 - val_loss: 1.1317 - val_accuracy: 0.4763\n",
            "Epoch 795/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1369 - accuracy: 0.4746 - val_loss: 1.1298 - val_accuracy: 0.4765\n",
            "Epoch 796/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1329 - accuracy: 0.4764 - val_loss: 1.1294 - val_accuracy: 0.4766\n",
            "Epoch 797/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1415 - accuracy: 0.4720 - val_loss: 1.1282 - val_accuracy: 0.4771\n",
            "Epoch 798/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1314 - accuracy: 0.4772 - val_loss: 1.1292 - val_accuracy: 0.4769\n",
            "Epoch 799/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1401 - accuracy: 0.4735 - val_loss: 1.1276 - val_accuracy: 0.4782\n",
            "Epoch 800/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1308 - accuracy: 0.4774 - val_loss: 1.1286 - val_accuracy: 0.4778\n",
            "Epoch 801/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1402 - accuracy: 0.4732 - val_loss: 1.1275 - val_accuracy: 0.4781\n",
            "Epoch 802/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1301 - accuracy: 0.4779 - val_loss: 1.1295 - val_accuracy: 0.4770\n",
            "Epoch 803/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1318 - accuracy: 0.4770 - val_loss: 1.1262 - val_accuracy: 0.4783\n",
            "Epoch 804/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1300 - accuracy: 0.4778 - val_loss: 1.1299 - val_accuracy: 0.4769\n",
            "Epoch 805/3000\n",
            "302/302 [==============================] - 14s 48ms/step - loss: 1.1381 - accuracy: 0.4737 - val_loss: 1.1264 - val_accuracy: 0.4778\n",
            "Epoch 806/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1289 - accuracy: 0.4785 - val_loss: 1.1300 - val_accuracy: 0.4777\n",
            "Epoch 807/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1296 - accuracy: 0.4781 - val_loss: 1.1275 - val_accuracy: 0.4780\n",
            "Epoch 808/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1606 - accuracy: 0.4649 - val_loss: 1.1440 - val_accuracy: 0.4714\n",
            "Epoch 809/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1400 - accuracy: 0.4734 - val_loss: 1.1395 - val_accuracy: 0.4723\n",
            "Epoch 810/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1381 - accuracy: 0.4739 - val_loss: 1.1328 - val_accuracy: 0.4758\n",
            "Epoch 811/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1415 - accuracy: 0.4733 - val_loss: 1.1286 - val_accuracy: 0.4771\n",
            "Epoch 812/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1515 - accuracy: 0.4689 - val_loss: 1.1409 - val_accuracy: 0.4727\n",
            "Epoch 813/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1377 - accuracy: 0.4741 - val_loss: 1.1341 - val_accuracy: 0.4752\n",
            "Epoch 814/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1795 - accuracy: 0.4531 - val_loss: 1.2370 - val_accuracy: 0.4223\n",
            "Epoch 815/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.2273 - accuracy: 0.4292 - val_loss: 1.2201 - val_accuracy: 0.4341\n",
            "Epoch 816/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.2148 - accuracy: 0.4363 - val_loss: 1.2106 - val_accuracy: 0.4390\n",
            "Epoch 817/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.2045 - accuracy: 0.4420 - val_loss: 1.2023 - val_accuracy: 0.4422\n",
            "Epoch 818/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1976 - accuracy: 0.4457 - val_loss: 1.1951 - val_accuracy: 0.4459\n",
            "Epoch 819/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1927 - accuracy: 0.4485 - val_loss: 1.1904 - val_accuracy: 0.4493\n",
            "Epoch 820/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1888 - accuracy: 0.4506 - val_loss: 1.1869 - val_accuracy: 0.4524\n",
            "Epoch 821/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1857 - accuracy: 0.4524 - val_loss: 1.1829 - val_accuracy: 0.4548\n",
            "Epoch 822/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1828 - accuracy: 0.4541 - val_loss: 1.1806 - val_accuracy: 0.4551\n",
            "Epoch 823/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.2089 - accuracy: 0.4408 - val_loss: 1.2042 - val_accuracy: 0.4439\n",
            "Epoch 824/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1981 - accuracy: 0.4461 - val_loss: 1.1924 - val_accuracy: 0.4485\n",
            "Epoch 825/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1902 - accuracy: 0.4501 - val_loss: 1.1868 - val_accuracy: 0.4513\n",
            "Epoch 826/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1849 - accuracy: 0.4528 - val_loss: 1.1801 - val_accuracy: 0.4553\n",
            "Epoch 827/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.2027 - accuracy: 0.4441 - val_loss: 1.1931 - val_accuracy: 0.4490\n",
            "Epoch 828/3000\n",
            "302/302 [==============================] - 15s 49ms/step - loss: 1.1866 - accuracy: 0.4518 - val_loss: 1.1772 - val_accuracy: 0.4566\n",
            "Epoch 829/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1825 - accuracy: 0.4541 - val_loss: 1.1736 - val_accuracy: 0.4589\n",
            "Epoch 830/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1732 - accuracy: 0.4587 - val_loss: 1.1742 - val_accuracy: 0.4583\n",
            "Epoch 831/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1710 - accuracy: 0.4600 - val_loss: 1.1703 - val_accuracy: 0.4588\n",
            "Epoch 832/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1679 - accuracy: 0.4616 - val_loss: 1.1701 - val_accuracy: 0.4610\n",
            "Epoch 833/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1667 - accuracy: 0.4622 - val_loss: 1.1685 - val_accuracy: 0.4615\n",
            "Epoch 834/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1651 - accuracy: 0.4631 - val_loss: 1.1647 - val_accuracy: 0.4636\n",
            "Epoch 835/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1641 - accuracy: 0.4636 - val_loss: 1.1630 - val_accuracy: 0.4641\n",
            "Epoch 836/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1629 - accuracy: 0.4642 - val_loss: 1.1611 - val_accuracy: 0.4653\n",
            "Epoch 837/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1619 - accuracy: 0.4648 - val_loss: 1.1593 - val_accuracy: 0.4667\n",
            "Epoch 838/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1618 - accuracy: 0.4650 - val_loss: 1.1576 - val_accuracy: 0.4681\n",
            "Epoch 839/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1593 - accuracy: 0.4663 - val_loss: 1.1589 - val_accuracy: 0.4673\n",
            "Epoch 840/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1613 - accuracy: 0.4652 - val_loss: 1.1558 - val_accuracy: 0.4697\n",
            "Epoch 841/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1575 - accuracy: 0.4672 - val_loss: 1.1569 - val_accuracy: 0.4683\n",
            "Epoch 842/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1573 - accuracy: 0.4673 - val_loss: 1.1581 - val_accuracy: 0.4680\n",
            "Epoch 843/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1567 - accuracy: 0.4676 - val_loss: 1.1567 - val_accuracy: 0.4681\n",
            "Epoch 844/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1564 - accuracy: 0.4677 - val_loss: 1.1564 - val_accuracy: 0.4685\n",
            "Epoch 845/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1590 - accuracy: 0.4661 - val_loss: 1.1551 - val_accuracy: 0.4691\n",
            "Epoch 846/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1549 - accuracy: 0.4683 - val_loss: 1.1563 - val_accuracy: 0.4690\n",
            "Epoch 847/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1548 - accuracy: 0.4684 - val_loss: 1.1553 - val_accuracy: 0.4692\n",
            "Epoch 848/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1589 - accuracy: 0.4667 - val_loss: 1.1510 - val_accuracy: 0.4702\n",
            "Epoch 849/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1535 - accuracy: 0.4690 - val_loss: 1.1546 - val_accuracy: 0.4695\n",
            "Epoch 850/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1535 - accuracy: 0.4690 - val_loss: 1.1555 - val_accuracy: 0.4692\n",
            "Epoch 851/3000\n",
            "302/302 [==============================] - 15s 48ms/step - loss: 1.1534 - accuracy: 0.4690 - val_loss: 1.1540 - val_accuracy: 0.4699\n",
            "Epoch 852/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1598 - accuracy: 0.4662 - val_loss: 1.1495 - val_accuracy: 0.4713\n",
            "Epoch 853/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1524 - accuracy: 0.4695 - val_loss: 1.1517 - val_accuracy: 0.4708\n",
            "Epoch 854/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1528 - accuracy: 0.4692 - val_loss: 1.1527 - val_accuracy: 0.4700\n",
            "Epoch 855/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1519 - accuracy: 0.4697 - val_loss: 1.1504 - val_accuracy: 0.4713\n",
            "Epoch 856/3000\n",
            "302/302 [==============================] - 14s 46ms/step - loss: 1.1566 - accuracy: 0.4679 - val_loss: 1.1542 - val_accuracy: 0.4683\n",
            "Epoch 857/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1513 - accuracy: 0.4699 - val_loss: 1.1506 - val_accuracy: 0.4707\n",
            "Epoch 858/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1618 - accuracy: 0.4652 - val_loss: 1.1869 - val_accuracy: 0.4525\n",
            "Epoch 859/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1734 - accuracy: 0.4595 - val_loss: 1.1581 - val_accuracy: 0.4677\n",
            "Epoch 860/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1702 - accuracy: 0.4608 - val_loss: 1.1501 - val_accuracy: 0.4707\n",
            "Epoch 861/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1507 - accuracy: 0.4703 - val_loss: 1.1482 - val_accuracy: 0.4731\n",
            "Epoch 862/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1503 - accuracy: 0.4706 - val_loss: 1.1493 - val_accuracy: 0.4712\n",
            "Epoch 863/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1500 - accuracy: 0.4707 - val_loss: 1.1467 - val_accuracy: 0.4727\n",
            "Epoch 864/3000\n",
            "302/302 [==============================] - 13s 43ms/step - loss: 1.1711 - accuracy: 0.4610 - val_loss: 1.1678 - val_accuracy: 0.4629\n",
            "Epoch 865/3000\n",
            "302/302 [==============================] - 13s 45ms/step - loss: 1.1573 - accuracy: 0.4673 - val_loss: 1.1471 - val_accuracy: 0.4729\n",
            "Epoch 866/3000\n",
            "302/302 [==============================] - 14s 45ms/step - loss: 1.1939 - accuracy: 0.4493 - val_loss: 1.1922 - val_accuracy: 0.4513\n",
            "Epoch 867/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1806 - accuracy: 0.4569 - val_loss: 1.1732 - val_accuracy: 0.4603\n",
            "Epoch 868/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1663 - accuracy: 0.4632 - val_loss: 1.1559 - val_accuracy: 0.4690\n",
            "Epoch 869/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1830 - accuracy: 0.4550 - val_loss: 1.1877 - val_accuracy: 0.4529\n",
            "Epoch 870/3000\n",
            "302/302 [==============================] - 13s 44ms/step - loss: 1.1744 - accuracy: 0.4596 - val_loss: 1.1683 - val_accuracy: 0.4624\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utCqK9OeXysf"
      },
      "source": [
        "model_path = '/content/gdrive/My Drive/Colab Notebooks/models/'\n",
        "recurrent_ae.save(model_path + 'ae(1)_chip_adam256.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5Cx01EEYGI5"
      },
      "source": [
        "def save_hist():\n",
        "  filename = data_path + \"ae_chip_adam256_reconstruction_history.csv\"\n",
        "  hist_df = pd.DataFrame(ae_hist.history) \n",
        "  with open(filename, mode='w') as f:\n",
        "    hist_df.to_csv(f)\n",
        "save_hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXRSsdEzcog7"
      },
      "source": [
        "# # can continue training\n",
        "# loaded_ae_model = keras.models.load_model('/content/gdrive/My Drive/Colab Notebooks/models/lstm1_chip.0030.h5')\n",
        "# reconstructed_encoder = keras.Model(loaded_ae_model.layers[0].input, loaded_ae_model.layers[0].output)\n",
        "# reconstructed_decoder = keras.Model(loaded_ae_model.layers[1].input, loaded_ae_model.layers[1].output)\n",
        "# reconstructed_autoencoder = keras.Sequential([reconstructed_encoder, reconstructed_decoder])\n",
        "# reconstructed_autoencoder.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "# ae_hist2 = reconstructed_autoencoder.fit(xtrain_seq, validation_data=xval_seq, epochs=200, callbacks=[es_cb,model_checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjiRiXQHwNOS",
        "outputId": "25b025ee-a63e-45fe-f80f-070e7319d51e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "for i in range(1):\n",
        "  ax1 = axes[0]\n",
        "  ax2 = axes[1]\n",
        "\n",
        "  ax1.plot(ae_hist.history['loss'], label='training')\n",
        "  ax1.plot(ae_hist.history['val_loss'], label='validation')\n",
        "  ax1.set_title('lstm autoencoder loss')\n",
        "  ax1.set_xlabel('epoch')\n",
        "  ax1.set_ylabel('loss')\n",
        "  ax1.legend(['train', 'validation'], loc='upper left')\n",
        "  \n",
        "  ax2.plot(ae_hist.history['accuracy'], label='training')\n",
        "  ax2.plot(ae_hist.history['val_accuracy'], label='validation')\n",
        "  ax2.set_title('lstm autoencoder accuracy')\n",
        "  ax2.set_xlabel('epoch')\n",
        "  ax2.set_ylabel('accuracy')\n",
        "  ax2.legend(['train', 'validation'], loc='upper left')\n",
        "fig.tight_layout()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y98IDmGbxTqx",
        "outputId": "e78f00b6-fd68-4cfe-b061-813e43d7ee9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        }
      },
      "source": [
        "# how to reconstruct the sequence\n",
        "idx_to_char = {'0':'T', '1':'G', '2':'C', '3':'A'}\n",
        "def show_reconstructions(model, x_seq=xtrain_seq, original_data=chip_train, samples=10):\n",
        "  reconstructions = model.predict(x_seq)\n",
        "  print('The shape of reconstructions', reconstructions.shape)\n",
        "  recon_softmax = np.argmax(reconstructions, axis=-1)\n",
        "  for i in range(samples):\n",
        "    seq = ''\n",
        "    for idx in recon_softmax[i]:\n",
        "      seq += idx_to_char[str(idx)]\n",
        "    print()\n",
        "    print('The {}-th original sequence vs after reconstruction'.format(i))\n",
        "    print(original_data['seq'].iloc[i])\n",
        "    print(seq)\n",
        "\n",
        "show_reconstructions(recurrent_ae, xval_seq, chip_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of reconstructions (1000, 101, 4)\n",
            "\n",
            "The 0-th original sequence vs after reconstruction\n",
            "CATTGCAGTTCGTCTTAGCGCCGCCAGGCATGGTGTCCTGCATCACGGCCTCTTCCTGCACTGCTCCCTCTGCTGGCAGACCCCCTTCCCCTGCAGGTTCA\n",
            "GGGGGGGCCCCCCCCCCCGGGGGGGGGGGGGGGGCCCCCCCCCTTGGCCCCCCCCCCCCCTTCCCCCCCCCCCCCCCCCCCCCCCCCCCCTTGCAGGTTCA\n",
            "\n",
            "The 1-th original sequence vs after reconstruction\n",
            "GGCCTGAGCTGCACAGGGGCCTGCTCAAATTTCTCCACTGGGCAGCACCATCGCCCAGAGGACCTGAAGAAAGCCTTCAGCTCCATTGACAGAGGCACTCT\n",
            "CCCCCCGGGGGGGGGGGGGGCCCCCCCCCCCCCCCCCCAGGGGGCCCCCCCCCCCAAGGGGACCCAAAGGGGACCCCCCCCCCCCCTGAAAAAGGCCCCCT\n",
            "\n",
            "The 2-th original sequence vs after reconstruction\n",
            "ACTCTTTTGCTGGTGTTTCCCCGGTATCACACGTAGCCCTGCTTCCAGCTAGCCCAGTAGCACGGCTTGACACTCTGCTGGGTCGGGCATGACTTTCACTC\n",
            "CTTTTTTTTTTTTTTTTTTTTTTGGGGGGGGGGCCCCTTCCCCCCCTTGGGCCCCCAGGGGGCCCCAGGGGCCCCCCTTTTTTTGGGGGAAACTTTCACCC\n",
            "\n",
            "The 3-th original sequence vs after reconstruction\n",
            "GTCAGGATAAACTAGTGCACAAACAGCCAAATTACCACTAGGGGGCCTGCCAGTCTCAAGAAAAATTTTGCGCGTCTGGGGAAAACTTGCTCATGGGACAG\n",
            "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACCCCCCCAAGGGGGCCCCTTTTCCCCAAGGGGACCAAGGGGGGCCAAAAGGGGGGGTTCCCTAGGGACAG\n",
            "\n",
            "The 4-th original sequence vs after reconstruction\n",
            "GATGGTGACTGGCTCCATCTGGGGGCGGGAGGGTCGGCCGTGGGTCAGGGGACCTGGACGGTAAGCGCCCCCCACAGGCCCACTGGCCTCAGCCGCCAATG\n",
            "GGGGGGGGGTTTTTTGGGGGGGGGGGGGGGGGGCCCCCGGGGGCCGGGGGGGCCCGGGGGGGGGGCCCCCCCCCCCCCCCCCCCCCCCCCGGCCGCCAATG\n",
            "\n",
            "The 5-th original sequence vs after reconstruction\n",
            "GCAGCCGAGGCCAACCTCCGGGATTGACATCCTAGTGCGGCCTCGCAACCCCCGAACTAGAGCACCTGCAGGTCAAAGGCCCGCCGCTCAGCAGGACGGGG\n",
            "GGGGGGGGGGCCCCCCCCCCCCCCCCCCCCCCCGGGGGGCCCCCCCCCCCCCCCCCGGGGGGCCCCCCAAGGGGGGCCCCCCCCCCCCCCAAAGGCAGGGG\n",
            "\n",
            "The 6-th original sequence vs after reconstruction\n",
            "GCAGCTTGTCCAGGCTTGTGGCTGAGGAGCTCCTTGGAGATCTCCCTGCTTTGCGGGGGCACTGGTGGCCAGCTGCAGAGCCCTGGCCCCAGCCCTCCTGC\n",
            "GGCCCTTCGGGGGGGGGGGGGGGGGGGGGGGCCCCCGGGGGCCCCCCCCCCCTGGGGGGCCCTGGGGGCCCCGGGGGGGGGGCCCCCCCCAACCCTCCTGC\n",
            "\n",
            "The 7-th original sequence vs after reconstruction\n",
            "ACAGAAACTTTAGCTAACCACCTAAAATCAACTGAGTCTCCTCTGCAGTGGGCACACCCTACAACTAAAGAGGATCTTGCATGGCTCCTTCAAAAGTGCAA\n",
            "AAAAAAAAAACCCCCCCCAAAAAAAAAAAAAAAAACCCCCCCCCTAAAGGGGGCCCCCCCCCCCCAAAGGGGGAAAAATTTTTTTTTTTTCAAAAGGTCAA\n",
            "\n",
            "The 8-th original sequence vs after reconstruction\n",
            "CGCCAACCAGCAGAACATAGCCCTACACAACCCCAAGCAGCAATATTCACGGCGTCCTCTAGGTGGAGCTCTGCAGTGCACAGCCTGGGCAGCTGGAGGCA\n",
            "CCCCCCCCAAAAAAAAAAAACCCCCCCCCCCCCCGGGAAACCCCCCCCCCGGGGCCCCCCTGGGGGGCCCGGGGGCCCCGGGGGGGGGCAGGCTGGAGGCA\n",
            "\n",
            "The 9-th original sequence vs after reconstruction\n",
            "CCTTCTAGTGACGGACCCTTGGGGGGCTGGTCCAGCTCCTGCCAACGATCCGACTATCCAGACTATTGGGCCTTGACGTCCATGTGAATTGGGCTGTCTGG\n",
            "CTTTTTTGGGGGGGGGGGGGGGGGGGGGGGGGCCCCCCCCCCCCCCTTGGGCCCCCTTTCCCCCAGGGGGCCCCCCCCCCCCCGGGGGGGGGGCTGTCTGG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvND3IYxU967",
        "outputId": "fabf0668-c604-4f61-b1cf-e5a65ca74607",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "xtrain_vec = encoder.predict(xtrain_seq)\n",
        "xval_vec = encoder.predict(xval_seq)\n",
        "xtest_vec = encoder.predict(xtest_seq)\n",
        "print('The shape of xtrain/xval/xtest_seq is', xtrain_vec.shape, xval_vec.shape, xtest_vec.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of xtrain/xval/xtest_seq is (77174, 30) (1000, 30) (19544, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kUn_jsA-ne1"
      },
      "source": [
        "def plotVec(ax, x, y, title=\"title\"):\n",
        "  scatter = ax.scatter(x[:, 0], x[:, 1], c=y, \n",
        "             cmap=matplotlib.colors.ListedColormap([\"red\", \"blue\", \"yellow\"]))\n",
        "  ax.set_title(title)\n",
        "  ax.legend(*scatter.legend_elements(), loc=0, title=\"Classes\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmoSauXnU-Gf"
      },
      "source": [
        "# # too many training example\n",
        "# xtrain_tsne = TSNE(n_components=2, metric=\"cosine\").fit_transform(xtrain_vec[:1000])\n",
        "# xval_tsne = TSNE(n_components=2, metric=\"cosine\").fit_transform(xval_vec)\n",
        "# xtest_tsne = TSNE(n_components=2, metric=\"cosine\").fit_transform(xtest_vec[:1000])\n",
        "\n",
        "# fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "# plotVec(axes[0], xtrain_tsne, chip_train[:1000][\"id\"], title=\"TSNE, training\")\n",
        "# plotVec(axes[1], xval_tsne, chip_val[\"id\"], title=\"TSNE, validation\")\n",
        "# plotVec(axes[2], xtest_tsne, chip_test[:1000][\"id\"], title=\"TSNE, test\")\n",
        "# fig.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kbo0bGNU-Em"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "  keras.layers.Dense(128, activation=\"relu\", input_shape=[latent_size]),\n",
        "  keras.layers.Dropout(0.2),\n",
        "  keras.layers.Dense(64, activation=\"relu\"),    \n",
        "  keras.layers.Dropout(0.2),\n",
        "  keras.layers.Dense(32, activation=\"relu\"),  \n",
        "  keras.layers.Dropout(0.2), \n",
        "  keras.layers.Dense(16, activation=\"relu\"), \n",
        "  keras.layers.Dropout(0.2),   \n",
        "  keras.layers.Dense(1, activation=\"sigmoid\")                               \n",
        "])\n",
        "model.compile(keras.optimizers.SGD(momentum=0.9), loss=keras.losses.BinaryCrossentropy(), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shzjYa-MlBuj",
        "outputId": "0c2c303d-0262-4404-8430-7e77fb0cd40f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_hist = model.fit(xtrain_vec, chip_train['id'], validation_data=(xval_vec, chip_val['id']), epochs=1000, callbacks=[es_cb])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6935 - accuracy: 0.5009 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 2/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6933 - accuracy: 0.5014 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
            "Epoch 3/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6933 - accuracy: 0.5009 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
            "Epoch 4/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6933 - accuracy: 0.5014 - val_loss: 0.6929 - val_accuracy: 0.5020\n",
            "Epoch 5/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6930 - accuracy: 0.5087 - val_loss: 0.6921 - val_accuracy: 0.5350\n",
            "Epoch 6/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6927 - accuracy: 0.5128 - val_loss: 0.6919 - val_accuracy: 0.5010\n",
            "Epoch 7/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6919 - accuracy: 0.5217 - val_loss: 0.6914 - val_accuracy: 0.5150\n",
            "Epoch 8/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6907 - accuracy: 0.5286 - val_loss: 0.6852 - val_accuracy: 0.5490\n",
            "Epoch 9/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6896 - accuracy: 0.5337 - val_loss: 0.6857 - val_accuracy: 0.5510\n",
            "Epoch 10/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6880 - accuracy: 0.5404 - val_loss: 0.6886 - val_accuracy: 0.5180\n",
            "Epoch 11/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6879 - accuracy: 0.5407 - val_loss: 0.6879 - val_accuracy: 0.5370\n",
            "Epoch 12/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6866 - accuracy: 0.5472 - val_loss: 0.6814 - val_accuracy: 0.5660\n",
            "Epoch 13/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6857 - accuracy: 0.5500 - val_loss: 0.6795 - val_accuracy: 0.5580\n",
            "Epoch 14/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6852 - accuracy: 0.5525 - val_loss: 0.6804 - val_accuracy: 0.5610\n",
            "Epoch 15/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6839 - accuracy: 0.5548 - val_loss: 0.6806 - val_accuracy: 0.5710\n",
            "Epoch 16/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6842 - accuracy: 0.5553 - val_loss: 0.6774 - val_accuracy: 0.5590\n",
            "Epoch 17/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6833 - accuracy: 0.5569 - val_loss: 0.6774 - val_accuracy: 0.5720\n",
            "Epoch 18/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6821 - accuracy: 0.5609 - val_loss: 0.6946 - val_accuracy: 0.5280\n",
            "Epoch 19/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6821 - accuracy: 0.5611 - val_loss: 0.6736 - val_accuracy: 0.5820\n",
            "Epoch 20/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6814 - accuracy: 0.5641 - val_loss: 0.6853 - val_accuracy: 0.5220\n",
            "Epoch 21/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6805 - accuracy: 0.5640 - val_loss: 0.6723 - val_accuracy: 0.5870\n",
            "Epoch 22/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6794 - accuracy: 0.5673 - val_loss: 0.6732 - val_accuracy: 0.5880\n",
            "Epoch 23/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6790 - accuracy: 0.5696 - val_loss: 0.6777 - val_accuracy: 0.5720\n",
            "Epoch 24/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6777 - accuracy: 0.5715 - val_loss: 0.6690 - val_accuracy: 0.5670\n",
            "Epoch 25/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6764 - accuracy: 0.5743 - val_loss: 0.6710 - val_accuracy: 0.5890\n",
            "Epoch 26/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6753 - accuracy: 0.5775 - val_loss: 0.6799 - val_accuracy: 0.5720\n",
            "Epoch 27/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6744 - accuracy: 0.5785 - val_loss: 0.6773 - val_accuracy: 0.5690\n",
            "Epoch 28/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6743 - accuracy: 0.5805 - val_loss: 0.6715 - val_accuracy: 0.5680\n",
            "Epoch 29/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6742 - accuracy: 0.5829 - val_loss: 0.6671 - val_accuracy: 0.5860\n",
            "Epoch 30/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6708 - accuracy: 0.5844 - val_loss: 0.6660 - val_accuracy: 0.5850\n",
            "Epoch 31/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6712 - accuracy: 0.5856 - val_loss: 0.6591 - val_accuracy: 0.6030\n",
            "Epoch 32/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6699 - accuracy: 0.5868 - val_loss: 0.6617 - val_accuracy: 0.5960\n",
            "Epoch 33/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6694 - accuracy: 0.5911 - val_loss: 0.6615 - val_accuracy: 0.6050\n",
            "Epoch 34/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6685 - accuracy: 0.5914 - val_loss: 0.6610 - val_accuracy: 0.6080\n",
            "Epoch 35/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6674 - accuracy: 0.5916 - val_loss: 0.6620 - val_accuracy: 0.6070\n",
            "Epoch 36/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6667 - accuracy: 0.5944 - val_loss: 0.6695 - val_accuracy: 0.5820\n",
            "Epoch 37/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6650 - accuracy: 0.5970 - val_loss: 0.6549 - val_accuracy: 0.6210\n",
            "Epoch 38/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6653 - accuracy: 0.5957 - val_loss: 0.6534 - val_accuracy: 0.6020\n",
            "Epoch 39/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6656 - accuracy: 0.5962 - val_loss: 0.6596 - val_accuracy: 0.6040\n",
            "Epoch 40/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6641 - accuracy: 0.5981 - val_loss: 0.6593 - val_accuracy: 0.6200\n",
            "Epoch 41/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6632 - accuracy: 0.6007 - val_loss: 0.6558 - val_accuracy: 0.6040\n",
            "Epoch 42/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6634 - accuracy: 0.6008 - val_loss: 0.6630 - val_accuracy: 0.5970\n",
            "Epoch 43/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6624 - accuracy: 0.6009 - val_loss: 0.6610 - val_accuracy: 0.5970\n",
            "Epoch 44/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6613 - accuracy: 0.6046 - val_loss: 0.6543 - val_accuracy: 0.6010\n",
            "Epoch 45/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6617 - accuracy: 0.6042 - val_loss: 0.6548 - val_accuracy: 0.6170\n",
            "Epoch 46/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6613 - accuracy: 0.6028 - val_loss: 0.6558 - val_accuracy: 0.6130\n",
            "Epoch 47/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6606 - accuracy: 0.6055 - val_loss: 0.6519 - val_accuracy: 0.6200\n",
            "Epoch 48/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6607 - accuracy: 0.6047 - val_loss: 0.6535 - val_accuracy: 0.6280\n",
            "Epoch 49/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6592 - accuracy: 0.6069 - val_loss: 0.6551 - val_accuracy: 0.5990\n",
            "Epoch 50/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6595 - accuracy: 0.6052 - val_loss: 0.6496 - val_accuracy: 0.6180\n",
            "Epoch 51/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6589 - accuracy: 0.6087 - val_loss: 0.6459 - val_accuracy: 0.6220\n",
            "Epoch 52/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6589 - accuracy: 0.6090 - val_loss: 0.6585 - val_accuracy: 0.6080\n",
            "Epoch 53/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6584 - accuracy: 0.6076 - val_loss: 0.6490 - val_accuracy: 0.6060\n",
            "Epoch 54/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6579 - accuracy: 0.6083 - val_loss: 0.6511 - val_accuracy: 0.6170\n",
            "Epoch 55/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6574 - accuracy: 0.6092 - val_loss: 0.6473 - val_accuracy: 0.6210\n",
            "Epoch 56/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6562 - accuracy: 0.6100 - val_loss: 0.6513 - val_accuracy: 0.6190\n",
            "Epoch 57/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6573 - accuracy: 0.6102 - val_loss: 0.6542 - val_accuracy: 0.6120\n",
            "Epoch 58/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6563 - accuracy: 0.6102 - val_loss: 0.6653 - val_accuracy: 0.6010\n",
            "Epoch 59/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6574 - accuracy: 0.6115 - val_loss: 0.6481 - val_accuracy: 0.6280\n",
            "Epoch 60/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6555 - accuracy: 0.6118 - val_loss: 0.6426 - val_accuracy: 0.6250\n",
            "Epoch 61/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6552 - accuracy: 0.6119 - val_loss: 0.6519 - val_accuracy: 0.6200\n",
            "Epoch 62/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6557 - accuracy: 0.6130 - val_loss: 0.6520 - val_accuracy: 0.6210\n",
            "Epoch 63/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6560 - accuracy: 0.6123 - val_loss: 0.6548 - val_accuracy: 0.6090\n",
            "Epoch 64/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6552 - accuracy: 0.6132 - val_loss: 0.6475 - val_accuracy: 0.6250\n",
            "Epoch 65/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6551 - accuracy: 0.6129 - val_loss: 0.6491 - val_accuracy: 0.6310\n",
            "Epoch 66/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6546 - accuracy: 0.6147 - val_loss: 0.6503 - val_accuracy: 0.6160\n",
            "Epoch 67/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6542 - accuracy: 0.6150 - val_loss: 0.6458 - val_accuracy: 0.6270\n",
            "Epoch 68/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6536 - accuracy: 0.6169 - val_loss: 0.6484 - val_accuracy: 0.6050\n",
            "Epoch 69/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6544 - accuracy: 0.6143 - val_loss: 0.6632 - val_accuracy: 0.5920\n",
            "Epoch 70/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6543 - accuracy: 0.6150 - val_loss: 0.6450 - val_accuracy: 0.6200\n",
            "Epoch 71/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6538 - accuracy: 0.6141 - val_loss: 0.6430 - val_accuracy: 0.6290\n",
            "Epoch 72/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6543 - accuracy: 0.6148 - val_loss: 0.6473 - val_accuracy: 0.6250\n",
            "Epoch 73/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6542 - accuracy: 0.6162 - val_loss: 0.6476 - val_accuracy: 0.6040\n",
            "Epoch 74/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6535 - accuracy: 0.6173 - val_loss: 0.6466 - val_accuracy: 0.6220\n",
            "Epoch 75/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6534 - accuracy: 0.6187 - val_loss: 0.6437 - val_accuracy: 0.6250\n",
            "Epoch 76/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6526 - accuracy: 0.6168 - val_loss: 0.6443 - val_accuracy: 0.6240\n",
            "Epoch 77/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6527 - accuracy: 0.6161 - val_loss: 0.6499 - val_accuracy: 0.6170\n",
            "Epoch 78/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6534 - accuracy: 0.6157 - val_loss: 0.6456 - val_accuracy: 0.6200\n",
            "Epoch 79/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6518 - accuracy: 0.6191 - val_loss: 0.6460 - val_accuracy: 0.6230\n",
            "Epoch 80/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6522 - accuracy: 0.6172 - val_loss: 0.6462 - val_accuracy: 0.6170\n",
            "Epoch 81/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6514 - accuracy: 0.6182 - val_loss: 0.6442 - val_accuracy: 0.6300\n",
            "Epoch 82/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6526 - accuracy: 0.6182 - val_loss: 0.6445 - val_accuracy: 0.6310\n",
            "Epoch 83/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6517 - accuracy: 0.6179 - val_loss: 0.6466 - val_accuracy: 0.6230\n",
            "Epoch 84/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6517 - accuracy: 0.6177 - val_loss: 0.6522 - val_accuracy: 0.5980\n",
            "Epoch 85/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6518 - accuracy: 0.6176 - val_loss: 0.6454 - val_accuracy: 0.6060\n",
            "Epoch 86/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6502 - accuracy: 0.6212 - val_loss: 0.6482 - val_accuracy: 0.6190\n",
            "Epoch 87/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6514 - accuracy: 0.6192 - val_loss: 0.6433 - val_accuracy: 0.6220\n",
            "Epoch 88/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6507 - accuracy: 0.6205 - val_loss: 0.6476 - val_accuracy: 0.6180\n",
            "Epoch 89/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6510 - accuracy: 0.6185 - val_loss: 0.6380 - val_accuracy: 0.6310\n",
            "Epoch 90/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6506 - accuracy: 0.6202 - val_loss: 0.6401 - val_accuracy: 0.6270\n",
            "Epoch 91/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6507 - accuracy: 0.6214 - val_loss: 0.6456 - val_accuracy: 0.6260\n",
            "Epoch 92/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6508 - accuracy: 0.6204 - val_loss: 0.6494 - val_accuracy: 0.6300\n",
            "Epoch 93/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6492 - accuracy: 0.6218 - val_loss: 0.6455 - val_accuracy: 0.6120\n",
            "Epoch 94/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6493 - accuracy: 0.6222 - val_loss: 0.6506 - val_accuracy: 0.6030\n",
            "Epoch 95/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6496 - accuracy: 0.6202 - val_loss: 0.6522 - val_accuracy: 0.6220\n",
            "Epoch 96/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6496 - accuracy: 0.6225 - val_loss: 0.6476 - val_accuracy: 0.6050\n",
            "Epoch 97/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6498 - accuracy: 0.6217 - val_loss: 0.6377 - val_accuracy: 0.6350\n",
            "Epoch 98/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6496 - accuracy: 0.6222 - val_loss: 0.6410 - val_accuracy: 0.6180\n",
            "Epoch 99/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6485 - accuracy: 0.6247 - val_loss: 0.6496 - val_accuracy: 0.6220\n",
            "Epoch 100/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6495 - accuracy: 0.6218 - val_loss: 0.6484 - val_accuracy: 0.6200\n",
            "Epoch 101/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6491 - accuracy: 0.6210 - val_loss: 0.6481 - val_accuracy: 0.6260\n",
            "Epoch 102/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6481 - accuracy: 0.6220 - val_loss: 0.6455 - val_accuracy: 0.6280\n",
            "Epoch 103/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6486 - accuracy: 0.6206 - val_loss: 0.6388 - val_accuracy: 0.6250\n",
            "Epoch 104/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6481 - accuracy: 0.6239 - val_loss: 0.6406 - val_accuracy: 0.6230\n",
            "Epoch 105/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6476 - accuracy: 0.6242 - val_loss: 0.6459 - val_accuracy: 0.6190\n",
            "Epoch 106/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6484 - accuracy: 0.6232 - val_loss: 0.6418 - val_accuracy: 0.6290\n",
            "Epoch 107/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6480 - accuracy: 0.6236 - val_loss: 0.6491 - val_accuracy: 0.6030\n",
            "Epoch 108/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6481 - accuracy: 0.6249 - val_loss: 0.6451 - val_accuracy: 0.6290\n",
            "Epoch 109/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6483 - accuracy: 0.6254 - val_loss: 0.6405 - val_accuracy: 0.6340\n",
            "Epoch 110/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6485 - accuracy: 0.6243 - val_loss: 0.6448 - val_accuracy: 0.6120\n",
            "Epoch 111/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6471 - accuracy: 0.6251 - val_loss: 0.6435 - val_accuracy: 0.6360\n",
            "Epoch 112/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6476 - accuracy: 0.6237 - val_loss: 0.6368 - val_accuracy: 0.6260\n",
            "Epoch 113/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6478 - accuracy: 0.6242 - val_loss: 0.6372 - val_accuracy: 0.6340\n",
            "Epoch 114/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6469 - accuracy: 0.6246 - val_loss: 0.6412 - val_accuracy: 0.6260\n",
            "Epoch 115/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6464 - accuracy: 0.6261 - val_loss: 0.6404 - val_accuracy: 0.6290\n",
            "Epoch 116/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6471 - accuracy: 0.6261 - val_loss: 0.6380 - val_accuracy: 0.6300\n",
            "Epoch 117/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6463 - accuracy: 0.6254 - val_loss: 0.6405 - val_accuracy: 0.6340\n",
            "Epoch 118/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6475 - accuracy: 0.6249 - val_loss: 0.6379 - val_accuracy: 0.6260\n",
            "Epoch 119/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6475 - accuracy: 0.6251 - val_loss: 0.6468 - val_accuracy: 0.6270\n",
            "Epoch 120/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6463 - accuracy: 0.6273 - val_loss: 0.6411 - val_accuracy: 0.6310\n",
            "Epoch 121/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6456 - accuracy: 0.6267 - val_loss: 0.6457 - val_accuracy: 0.6250\n",
            "Epoch 122/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6456 - accuracy: 0.6277 - val_loss: 0.6467 - val_accuracy: 0.6220\n",
            "Epoch 123/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6455 - accuracy: 0.6274 - val_loss: 0.6410 - val_accuracy: 0.6340\n",
            "Epoch 124/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6466 - accuracy: 0.6245 - val_loss: 0.6412 - val_accuracy: 0.6120\n",
            "Epoch 125/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6456 - accuracy: 0.6260 - val_loss: 0.6414 - val_accuracy: 0.6140\n",
            "Epoch 126/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6455 - accuracy: 0.6264 - val_loss: 0.6387 - val_accuracy: 0.6430\n",
            "Epoch 127/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6451 - accuracy: 0.6283 - val_loss: 0.6340 - val_accuracy: 0.6550\n",
            "Epoch 128/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6454 - accuracy: 0.6293 - val_loss: 0.6571 - val_accuracy: 0.5910\n",
            "Epoch 129/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6458 - accuracy: 0.6271 - val_loss: 0.6372 - val_accuracy: 0.6270\n",
            "Epoch 130/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6452 - accuracy: 0.6261 - val_loss: 0.6426 - val_accuracy: 0.6300\n",
            "Epoch 131/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6451 - accuracy: 0.6275 - val_loss: 0.6394 - val_accuracy: 0.6340\n",
            "Epoch 132/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6446 - accuracy: 0.6282 - val_loss: 0.6411 - val_accuracy: 0.6300\n",
            "Epoch 133/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6452 - accuracy: 0.6285 - val_loss: 0.6428 - val_accuracy: 0.6260\n",
            "Epoch 134/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6448 - accuracy: 0.6292 - val_loss: 0.6349 - val_accuracy: 0.6380\n",
            "Epoch 135/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6454 - accuracy: 0.6269 - val_loss: 0.6445 - val_accuracy: 0.6220\n",
            "Epoch 136/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6445 - accuracy: 0.6280 - val_loss: 0.6452 - val_accuracy: 0.6190\n",
            "Epoch 137/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6443 - accuracy: 0.6290 - val_loss: 0.6377 - val_accuracy: 0.6480\n",
            "Epoch 138/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6450 - accuracy: 0.6283 - val_loss: 0.6353 - val_accuracy: 0.6340\n",
            "Epoch 139/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6444 - accuracy: 0.6290 - val_loss: 0.6390 - val_accuracy: 0.6460\n",
            "Epoch 140/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6443 - accuracy: 0.6296 - val_loss: 0.6379 - val_accuracy: 0.6430\n",
            "Epoch 141/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6430 - accuracy: 0.6282 - val_loss: 0.6396 - val_accuracy: 0.6180\n",
            "Epoch 142/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6445 - accuracy: 0.6315 - val_loss: 0.6443 - val_accuracy: 0.6160\n",
            "Epoch 143/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6430 - accuracy: 0.6323 - val_loss: 0.6364 - val_accuracy: 0.6330\n",
            "Epoch 144/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6436 - accuracy: 0.6317 - val_loss: 0.6341 - val_accuracy: 0.6420\n",
            "Epoch 145/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6437 - accuracy: 0.6304 - val_loss: 0.6414 - val_accuracy: 0.6240\n",
            "Epoch 146/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6438 - accuracy: 0.6302 - val_loss: 0.6380 - val_accuracy: 0.6400\n",
            "Epoch 147/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6431 - accuracy: 0.6305 - val_loss: 0.6352 - val_accuracy: 0.6340\n",
            "Epoch 148/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6421 - accuracy: 0.6306 - val_loss: 0.6383 - val_accuracy: 0.6320\n",
            "Epoch 149/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6432 - accuracy: 0.6314 - val_loss: 0.6336 - val_accuracy: 0.6400\n",
            "Epoch 150/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6431 - accuracy: 0.6321 - val_loss: 0.6273 - val_accuracy: 0.6470\n",
            "Epoch 151/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6433 - accuracy: 0.6304 - val_loss: 0.6338 - val_accuracy: 0.6390\n",
            "Epoch 152/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6421 - accuracy: 0.6312 - val_loss: 0.6346 - val_accuracy: 0.6400\n",
            "Epoch 153/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6429 - accuracy: 0.6319 - val_loss: 0.6313 - val_accuracy: 0.6420\n",
            "Epoch 154/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6429 - accuracy: 0.6310 - val_loss: 0.6380 - val_accuracy: 0.6390\n",
            "Epoch 155/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6418 - accuracy: 0.6330 - val_loss: 0.6307 - val_accuracy: 0.6500\n",
            "Epoch 156/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6423 - accuracy: 0.6316 - val_loss: 0.6365 - val_accuracy: 0.6470\n",
            "Epoch 157/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6412 - accuracy: 0.6317 - val_loss: 0.6363 - val_accuracy: 0.6390\n",
            "Epoch 158/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6422 - accuracy: 0.6326 - val_loss: 0.6349 - val_accuracy: 0.6460\n",
            "Epoch 159/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6411 - accuracy: 0.6327 - val_loss: 0.6395 - val_accuracy: 0.6370\n",
            "Epoch 160/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6423 - accuracy: 0.6316 - val_loss: 0.6402 - val_accuracy: 0.6200\n",
            "Epoch 161/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6416 - accuracy: 0.6312 - val_loss: 0.6364 - val_accuracy: 0.6370\n",
            "Epoch 162/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6417 - accuracy: 0.6332 - val_loss: 0.6350 - val_accuracy: 0.6440\n",
            "Epoch 163/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6413 - accuracy: 0.6327 - val_loss: 0.6410 - val_accuracy: 0.6380\n",
            "Epoch 164/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6411 - accuracy: 0.6334 - val_loss: 0.6348 - val_accuracy: 0.6340\n",
            "Epoch 165/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6413 - accuracy: 0.6306 - val_loss: 0.6393 - val_accuracy: 0.6420\n",
            "Epoch 166/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6409 - accuracy: 0.6357 - val_loss: 0.6366 - val_accuracy: 0.6320\n",
            "Epoch 167/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6410 - accuracy: 0.6334 - val_loss: 0.6328 - val_accuracy: 0.6380\n",
            "Epoch 168/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6403 - accuracy: 0.6340 - val_loss: 0.6350 - val_accuracy: 0.6430\n",
            "Epoch 169/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6404 - accuracy: 0.6351 - val_loss: 0.6342 - val_accuracy: 0.6300\n",
            "Epoch 170/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6409 - accuracy: 0.6318 - val_loss: 0.6364 - val_accuracy: 0.6350\n",
            "Epoch 171/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6407 - accuracy: 0.6331 - val_loss: 0.6290 - val_accuracy: 0.6410\n",
            "Epoch 172/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6399 - accuracy: 0.6319 - val_loss: 0.6583 - val_accuracy: 0.6070\n",
            "Epoch 173/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6414 - accuracy: 0.6322 - val_loss: 0.6335 - val_accuracy: 0.6410\n",
            "Epoch 174/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6409 - accuracy: 0.6343 - val_loss: 0.6352 - val_accuracy: 0.6530\n",
            "Epoch 175/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6409 - accuracy: 0.6340 - val_loss: 0.6368 - val_accuracy: 0.6430\n",
            "Epoch 176/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6409 - accuracy: 0.6337 - val_loss: 0.6383 - val_accuracy: 0.6300\n",
            "Epoch 177/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6400 - accuracy: 0.6338 - val_loss: 0.6377 - val_accuracy: 0.6420\n",
            "Epoch 178/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6393 - accuracy: 0.6348 - val_loss: 0.6346 - val_accuracy: 0.6420\n",
            "Epoch 179/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6403 - accuracy: 0.6326 - val_loss: 0.6345 - val_accuracy: 0.6430\n",
            "Epoch 180/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6396 - accuracy: 0.6357 - val_loss: 0.6364 - val_accuracy: 0.6360\n",
            "Epoch 181/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6405 - accuracy: 0.6342 - val_loss: 0.6424 - val_accuracy: 0.6250\n",
            "Epoch 182/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6394 - accuracy: 0.6352 - val_loss: 0.6330 - val_accuracy: 0.6270\n",
            "Epoch 183/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6396 - accuracy: 0.6347 - val_loss: 0.6338 - val_accuracy: 0.6540\n",
            "Epoch 184/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6393 - accuracy: 0.6343 - val_loss: 0.6327 - val_accuracy: 0.6240\n",
            "Epoch 185/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6397 - accuracy: 0.6355 - val_loss: 0.6398 - val_accuracy: 0.6450\n",
            "Epoch 186/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6391 - accuracy: 0.6365 - val_loss: 0.6372 - val_accuracy: 0.6370\n",
            "Epoch 187/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6400 - accuracy: 0.6370 - val_loss: 0.6332 - val_accuracy: 0.6350\n",
            "Epoch 188/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6393 - accuracy: 0.6367 - val_loss: 0.6246 - val_accuracy: 0.6510\n",
            "Epoch 189/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6390 - accuracy: 0.6358 - val_loss: 0.6330 - val_accuracy: 0.6400\n",
            "Epoch 190/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6401 - accuracy: 0.6358 - val_loss: 0.6340 - val_accuracy: 0.6370\n",
            "Epoch 191/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6387 - accuracy: 0.6383 - val_loss: 0.6300 - val_accuracy: 0.6510\n",
            "Epoch 192/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6398 - accuracy: 0.6356 - val_loss: 0.6344 - val_accuracy: 0.6460\n",
            "Epoch 193/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6386 - accuracy: 0.6364 - val_loss: 0.6303 - val_accuracy: 0.6430\n",
            "Epoch 194/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6386 - accuracy: 0.6353 - val_loss: 0.6372 - val_accuracy: 0.6370\n",
            "Epoch 195/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6393 - accuracy: 0.6353 - val_loss: 0.6299 - val_accuracy: 0.6470\n",
            "Epoch 196/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6391 - accuracy: 0.6356 - val_loss: 0.6290 - val_accuracy: 0.6500\n",
            "Epoch 197/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6388 - accuracy: 0.6362 - val_loss: 0.6321 - val_accuracy: 0.6560\n",
            "Epoch 198/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6386 - accuracy: 0.6370 - val_loss: 0.6348 - val_accuracy: 0.6400\n",
            "Epoch 199/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6377 - accuracy: 0.6373 - val_loss: 0.6277 - val_accuracy: 0.6410\n",
            "Epoch 200/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6384 - accuracy: 0.6365 - val_loss: 0.6272 - val_accuracy: 0.6460\n",
            "Epoch 201/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6373 - accuracy: 0.6372 - val_loss: 0.6248 - val_accuracy: 0.6500\n",
            "Epoch 202/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6385 - accuracy: 0.6364 - val_loss: 0.6320 - val_accuracy: 0.6360\n",
            "Epoch 203/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6375 - accuracy: 0.6384 - val_loss: 0.6321 - val_accuracy: 0.6420\n",
            "Epoch 204/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6371 - accuracy: 0.6380 - val_loss: 0.6335 - val_accuracy: 0.6250\n",
            "Epoch 205/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6377 - accuracy: 0.6380 - val_loss: 0.6207 - val_accuracy: 0.6590\n",
            "Epoch 206/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6396 - accuracy: 0.6355 - val_loss: 0.6305 - val_accuracy: 0.6480\n",
            "Epoch 207/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6376 - accuracy: 0.6368 - val_loss: 0.6321 - val_accuracy: 0.6420\n",
            "Epoch 208/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6375 - accuracy: 0.6366 - val_loss: 0.6315 - val_accuracy: 0.6560\n",
            "Epoch 209/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6382 - accuracy: 0.6379 - val_loss: 0.6290 - val_accuracy: 0.6490\n",
            "Epoch 210/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6373 - accuracy: 0.6373 - val_loss: 0.6290 - val_accuracy: 0.6330\n",
            "Epoch 211/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6376 - accuracy: 0.6375 - val_loss: 0.6316 - val_accuracy: 0.6540\n",
            "Epoch 212/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6365 - accuracy: 0.6390 - val_loss: 0.6302 - val_accuracy: 0.6480\n",
            "Epoch 213/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6368 - accuracy: 0.6384 - val_loss: 0.6294 - val_accuracy: 0.6480\n",
            "Epoch 214/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6373 - accuracy: 0.6396 - val_loss: 0.6293 - val_accuracy: 0.6420\n",
            "Epoch 215/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6387 - accuracy: 0.6366 - val_loss: 0.6283 - val_accuracy: 0.6590\n",
            "Epoch 216/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6377 - accuracy: 0.6374 - val_loss: 0.6242 - val_accuracy: 0.6480\n",
            "Epoch 217/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6366 - accuracy: 0.6406 - val_loss: 0.6246 - val_accuracy: 0.6440\n",
            "Epoch 218/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6371 - accuracy: 0.6395 - val_loss: 0.6376 - val_accuracy: 0.6380\n",
            "Epoch 219/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6363 - accuracy: 0.6374 - val_loss: 0.6282 - val_accuracy: 0.6520\n",
            "Epoch 220/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6369 - accuracy: 0.6383 - val_loss: 0.6268 - val_accuracy: 0.6440\n",
            "Epoch 221/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6366 - accuracy: 0.6402 - val_loss: 0.6324 - val_accuracy: 0.6540\n",
            "Epoch 222/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6360 - accuracy: 0.6387 - val_loss: 0.6338 - val_accuracy: 0.6580\n",
            "Epoch 223/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6362 - accuracy: 0.6390 - val_loss: 0.6307 - val_accuracy: 0.6500\n",
            "Epoch 224/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6365 - accuracy: 0.6394 - val_loss: 0.6275 - val_accuracy: 0.6500\n",
            "Epoch 225/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6363 - accuracy: 0.6400 - val_loss: 0.6274 - val_accuracy: 0.6420\n",
            "Epoch 226/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6361 - accuracy: 0.6398 - val_loss: 0.6357 - val_accuracy: 0.6450\n",
            "Epoch 227/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6372 - accuracy: 0.6401 - val_loss: 0.6340 - val_accuracy: 0.6580\n",
            "Epoch 228/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6365 - accuracy: 0.6393 - val_loss: 0.6393 - val_accuracy: 0.6340\n",
            "Epoch 229/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6367 - accuracy: 0.6380 - val_loss: 0.6225 - val_accuracy: 0.6600\n",
            "Epoch 230/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6357 - accuracy: 0.6400 - val_loss: 0.6277 - val_accuracy: 0.6430\n",
            "Epoch 231/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6357 - accuracy: 0.6414 - val_loss: 0.6289 - val_accuracy: 0.6500\n",
            "Epoch 232/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6357 - accuracy: 0.6387 - val_loss: 0.6345 - val_accuracy: 0.6380\n",
            "Epoch 233/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6356 - accuracy: 0.6398 - val_loss: 0.6289 - val_accuracy: 0.6460\n",
            "Epoch 234/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6365 - accuracy: 0.6418 - val_loss: 0.6371 - val_accuracy: 0.6320\n",
            "Epoch 235/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6373 - accuracy: 0.6372 - val_loss: 0.6278 - val_accuracy: 0.6460\n",
            "Epoch 236/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6351 - accuracy: 0.6421 - val_loss: 0.6351 - val_accuracy: 0.6390\n",
            "Epoch 237/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6350 - accuracy: 0.6419 - val_loss: 0.6261 - val_accuracy: 0.6450\n",
            "Epoch 238/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6359 - accuracy: 0.6399 - val_loss: 0.6297 - val_accuracy: 0.6450\n",
            "Epoch 239/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6349 - accuracy: 0.6420 - val_loss: 0.6322 - val_accuracy: 0.6430\n",
            "Epoch 240/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6351 - accuracy: 0.6412 - val_loss: 0.6342 - val_accuracy: 0.6450\n",
            "Epoch 241/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6346 - accuracy: 0.6418 - val_loss: 0.6220 - val_accuracy: 0.6530\n",
            "Epoch 242/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6351 - accuracy: 0.6408 - val_loss: 0.6312 - val_accuracy: 0.6480\n",
            "Epoch 243/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6354 - accuracy: 0.6416 - val_loss: 0.6251 - val_accuracy: 0.6620\n",
            "Epoch 244/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6350 - accuracy: 0.6426 - val_loss: 0.6275 - val_accuracy: 0.6430\n",
            "Epoch 245/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6354 - accuracy: 0.6424 - val_loss: 0.6296 - val_accuracy: 0.6540\n",
            "Epoch 246/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6346 - accuracy: 0.6418 - val_loss: 0.6327 - val_accuracy: 0.6510\n",
            "Epoch 247/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6346 - accuracy: 0.6407 - val_loss: 0.6270 - val_accuracy: 0.6560\n",
            "Epoch 248/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6348 - accuracy: 0.6419 - val_loss: 0.6219 - val_accuracy: 0.6590\n",
            "Epoch 249/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6348 - accuracy: 0.6409 - val_loss: 0.6266 - val_accuracy: 0.6450\n",
            "Epoch 250/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6353 - accuracy: 0.6427 - val_loss: 0.6280 - val_accuracy: 0.6530\n",
            "Epoch 251/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6345 - accuracy: 0.6420 - val_loss: 0.6314 - val_accuracy: 0.6410\n",
            "Epoch 252/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6345 - accuracy: 0.6413 - val_loss: 0.6260 - val_accuracy: 0.6600\n",
            "Epoch 253/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6344 - accuracy: 0.6425 - val_loss: 0.6277 - val_accuracy: 0.6520\n",
            "Epoch 254/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6334 - accuracy: 0.6423 - val_loss: 0.6276 - val_accuracy: 0.6490\n",
            "Epoch 255/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6350 - accuracy: 0.6414 - val_loss: 0.6267 - val_accuracy: 0.6510\n",
            "Epoch 256/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6340 - accuracy: 0.6419 - val_loss: 0.6398 - val_accuracy: 0.6350\n",
            "Epoch 257/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6336 - accuracy: 0.6439 - val_loss: 0.6285 - val_accuracy: 0.6470\n",
            "Epoch 258/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6353 - accuracy: 0.6432 - val_loss: 0.6282 - val_accuracy: 0.6590\n",
            "Epoch 259/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6335 - accuracy: 0.6431 - val_loss: 0.6295 - val_accuracy: 0.6520\n",
            "Epoch 260/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6338 - accuracy: 0.6435 - val_loss: 0.6278 - val_accuracy: 0.6520\n",
            "Epoch 261/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6320 - accuracy: 0.6468 - val_loss: 0.6249 - val_accuracy: 0.6550\n",
            "Epoch 262/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6337 - accuracy: 0.6438 - val_loss: 0.6273 - val_accuracy: 0.6550\n",
            "Epoch 263/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6333 - accuracy: 0.6426 - val_loss: 0.6241 - val_accuracy: 0.6560\n",
            "Epoch 264/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6334 - accuracy: 0.6431 - val_loss: 0.6256 - val_accuracy: 0.6530\n",
            "Epoch 265/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6336 - accuracy: 0.6414 - val_loss: 0.6303 - val_accuracy: 0.6400\n",
            "Epoch 266/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6330 - accuracy: 0.6434 - val_loss: 0.6249 - val_accuracy: 0.6610\n",
            "Epoch 267/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6328 - accuracy: 0.6448 - val_loss: 0.6254 - val_accuracy: 0.6540\n",
            "Epoch 268/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6336 - accuracy: 0.6414 - val_loss: 0.6283 - val_accuracy: 0.6360\n",
            "Epoch 269/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6331 - accuracy: 0.6433 - val_loss: 0.6211 - val_accuracy: 0.6560\n",
            "Epoch 270/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6328 - accuracy: 0.6439 - val_loss: 0.6287 - val_accuracy: 0.6520\n",
            "Epoch 271/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6333 - accuracy: 0.6434 - val_loss: 0.6217 - val_accuracy: 0.6570\n",
            "Epoch 272/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6320 - accuracy: 0.6435 - val_loss: 0.6229 - val_accuracy: 0.6510\n",
            "Epoch 273/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6334 - accuracy: 0.6429 - val_loss: 0.6219 - val_accuracy: 0.6570\n",
            "Epoch 274/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6337 - accuracy: 0.6427 - val_loss: 0.6250 - val_accuracy: 0.6550\n",
            "Epoch 275/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6328 - accuracy: 0.6439 - val_loss: 0.6218 - val_accuracy: 0.6640\n",
            "Epoch 276/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6318 - accuracy: 0.6462 - val_loss: 0.6313 - val_accuracy: 0.6410\n",
            "Epoch 277/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6328 - accuracy: 0.6449 - val_loss: 0.6232 - val_accuracy: 0.6650\n",
            "Epoch 278/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6337 - accuracy: 0.6427 - val_loss: 0.6253 - val_accuracy: 0.6590\n",
            "Epoch 279/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6332 - accuracy: 0.6431 - val_loss: 0.6237 - val_accuracy: 0.6590\n",
            "Epoch 280/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6327 - accuracy: 0.6450 - val_loss: 0.6305 - val_accuracy: 0.6510\n",
            "Epoch 281/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6325 - accuracy: 0.6455 - val_loss: 0.6268 - val_accuracy: 0.6630\n",
            "Epoch 282/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6327 - accuracy: 0.6437 - val_loss: 0.6206 - val_accuracy: 0.6630\n",
            "Epoch 283/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6321 - accuracy: 0.6440 - val_loss: 0.6298 - val_accuracy: 0.6630\n",
            "Epoch 284/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6321 - accuracy: 0.6446 - val_loss: 0.6221 - val_accuracy: 0.6560\n",
            "Epoch 285/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6320 - accuracy: 0.6455 - val_loss: 0.6292 - val_accuracy: 0.6440\n",
            "Epoch 286/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6326 - accuracy: 0.6451 - val_loss: 0.6313 - val_accuracy: 0.6410\n",
            "Epoch 287/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6327 - accuracy: 0.6440 - val_loss: 0.6282 - val_accuracy: 0.6490\n",
            "Epoch 288/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6317 - accuracy: 0.6453 - val_loss: 0.6214 - val_accuracy: 0.6530\n",
            "Epoch 289/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6321 - accuracy: 0.6460 - val_loss: 0.6279 - val_accuracy: 0.6560\n",
            "Epoch 290/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6309 - accuracy: 0.6459 - val_loss: 0.6233 - val_accuracy: 0.6600\n",
            "Epoch 291/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6316 - accuracy: 0.6445 - val_loss: 0.6246 - val_accuracy: 0.6520\n",
            "Epoch 292/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6317 - accuracy: 0.6461 - val_loss: 0.6239 - val_accuracy: 0.6450\n",
            "Epoch 293/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6329 - accuracy: 0.6458 - val_loss: 0.6264 - val_accuracy: 0.6420\n",
            "Epoch 294/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6313 - accuracy: 0.6459 - val_loss: 0.6234 - val_accuracy: 0.6540\n",
            "Epoch 295/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6323 - accuracy: 0.6439 - val_loss: 0.6276 - val_accuracy: 0.6350\n",
            "Epoch 296/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6316 - accuracy: 0.6477 - val_loss: 0.6231 - val_accuracy: 0.6630\n",
            "Epoch 297/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6313 - accuracy: 0.6448 - val_loss: 0.6212 - val_accuracy: 0.6600\n",
            "Epoch 298/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6324 - accuracy: 0.6443 - val_loss: 0.6263 - val_accuracy: 0.6460\n",
            "Epoch 299/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6316 - accuracy: 0.6456 - val_loss: 0.6246 - val_accuracy: 0.6510\n",
            "Epoch 300/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6320 - accuracy: 0.6455 - val_loss: 0.6241 - val_accuracy: 0.6570\n",
            "Epoch 301/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6313 - accuracy: 0.6462 - val_loss: 0.6215 - val_accuracy: 0.6600\n",
            "Epoch 302/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6315 - accuracy: 0.6451 - val_loss: 0.6236 - val_accuracy: 0.6370\n",
            "Epoch 303/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6311 - accuracy: 0.6458 - val_loss: 0.6233 - val_accuracy: 0.6480\n",
            "Epoch 304/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6302 - accuracy: 0.6475 - val_loss: 0.6332 - val_accuracy: 0.6440\n",
            "Epoch 305/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6317 - accuracy: 0.6463 - val_loss: 0.6262 - val_accuracy: 0.6600\n",
            "Epoch 306/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6310 - accuracy: 0.6467 - val_loss: 0.6336 - val_accuracy: 0.6280\n",
            "Epoch 307/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6311 - accuracy: 0.6461 - val_loss: 0.6213 - val_accuracy: 0.6560\n",
            "Epoch 308/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6317 - accuracy: 0.6444 - val_loss: 0.6233 - val_accuracy: 0.6570\n",
            "Epoch 309/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6307 - accuracy: 0.6438 - val_loss: 0.6194 - val_accuracy: 0.6530\n",
            "Epoch 310/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6306 - accuracy: 0.6475 - val_loss: 0.6217 - val_accuracy: 0.6580\n",
            "Epoch 311/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6307 - accuracy: 0.6469 - val_loss: 0.6289 - val_accuracy: 0.6400\n",
            "Epoch 312/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6310 - accuracy: 0.6455 - val_loss: 0.6228 - val_accuracy: 0.6610\n",
            "Epoch 313/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6301 - accuracy: 0.6463 - val_loss: 0.6231 - val_accuracy: 0.6670\n",
            "Epoch 314/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6299 - accuracy: 0.6466 - val_loss: 0.6253 - val_accuracy: 0.6600\n",
            "Epoch 315/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6315 - accuracy: 0.6444 - val_loss: 0.6246 - val_accuracy: 0.6430\n",
            "Epoch 316/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6304 - accuracy: 0.6465 - val_loss: 0.6271 - val_accuracy: 0.6530\n",
            "Epoch 317/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6310 - accuracy: 0.6443 - val_loss: 0.6242 - val_accuracy: 0.6590\n",
            "Epoch 318/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6301 - accuracy: 0.6467 - val_loss: 0.6201 - val_accuracy: 0.6520\n",
            "Epoch 319/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6310 - accuracy: 0.6450 - val_loss: 0.6136 - val_accuracy: 0.6760\n",
            "Epoch 320/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6313 - accuracy: 0.6467 - val_loss: 0.6286 - val_accuracy: 0.6440\n",
            "Epoch 321/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6300 - accuracy: 0.6465 - val_loss: 0.6238 - val_accuracy: 0.6580\n",
            "Epoch 322/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6295 - accuracy: 0.6482 - val_loss: 0.6238 - val_accuracy: 0.6450\n",
            "Epoch 323/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6298 - accuracy: 0.6483 - val_loss: 0.6202 - val_accuracy: 0.6610\n",
            "Epoch 324/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6303 - accuracy: 0.6467 - val_loss: 0.6312 - val_accuracy: 0.6450\n",
            "Epoch 325/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6312 - accuracy: 0.6455 - val_loss: 0.6232 - val_accuracy: 0.6550\n",
            "Epoch 326/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6310 - accuracy: 0.6463 - val_loss: 0.6164 - val_accuracy: 0.6640\n",
            "Epoch 327/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6304 - accuracy: 0.6479 - val_loss: 0.6228 - val_accuracy: 0.6790\n",
            "Epoch 328/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6303 - accuracy: 0.6470 - val_loss: 0.6186 - val_accuracy: 0.6610\n",
            "Epoch 329/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6306 - accuracy: 0.6469 - val_loss: 0.6263 - val_accuracy: 0.6560\n",
            "Epoch 330/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6304 - accuracy: 0.6467 - val_loss: 0.6168 - val_accuracy: 0.6510\n",
            "Epoch 331/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6284 - accuracy: 0.6494 - val_loss: 0.6248 - val_accuracy: 0.6620\n",
            "Epoch 332/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6299 - accuracy: 0.6478 - val_loss: 0.6213 - val_accuracy: 0.6640\n",
            "Epoch 333/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6296 - accuracy: 0.6477 - val_loss: 0.6232 - val_accuracy: 0.6620\n",
            "Epoch 334/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6294 - accuracy: 0.6484 - val_loss: 0.6214 - val_accuracy: 0.6740\n",
            "Epoch 335/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6294 - accuracy: 0.6475 - val_loss: 0.6242 - val_accuracy: 0.6470\n",
            "Epoch 336/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6306 - accuracy: 0.6457 - val_loss: 0.6226 - val_accuracy: 0.6660\n",
            "Epoch 337/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6304 - accuracy: 0.6461 - val_loss: 0.6197 - val_accuracy: 0.6570\n",
            "Epoch 338/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6301 - accuracy: 0.6461 - val_loss: 0.6322 - val_accuracy: 0.6380\n",
            "Epoch 339/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6299 - accuracy: 0.6480 - val_loss: 0.6336 - val_accuracy: 0.6420\n",
            "Epoch 340/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6291 - accuracy: 0.6497 - val_loss: 0.6224 - val_accuracy: 0.6590\n",
            "Epoch 341/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6291 - accuracy: 0.6479 - val_loss: 0.6221 - val_accuracy: 0.6560\n",
            "Epoch 342/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6297 - accuracy: 0.6459 - val_loss: 0.6253 - val_accuracy: 0.6540\n",
            "Epoch 343/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6300 - accuracy: 0.6475 - val_loss: 0.6207 - val_accuracy: 0.6590\n",
            "Epoch 344/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6293 - accuracy: 0.6471 - val_loss: 0.6203 - val_accuracy: 0.6700\n",
            "Epoch 345/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6287 - accuracy: 0.6485 - val_loss: 0.6254 - val_accuracy: 0.6510\n",
            "Epoch 346/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6288 - accuracy: 0.6481 - val_loss: 0.6155 - val_accuracy: 0.6590\n",
            "Epoch 347/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6297 - accuracy: 0.6471 - val_loss: 0.6209 - val_accuracy: 0.6600\n",
            "Epoch 348/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6293 - accuracy: 0.6481 - val_loss: 0.6208 - val_accuracy: 0.6580\n",
            "Epoch 349/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6299 - accuracy: 0.6486 - val_loss: 0.6231 - val_accuracy: 0.6350\n",
            "Epoch 350/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6295 - accuracy: 0.6482 - val_loss: 0.6166 - val_accuracy: 0.6590\n",
            "Epoch 351/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6287 - accuracy: 0.6496 - val_loss: 0.6199 - val_accuracy: 0.6640\n",
            "Epoch 352/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6285 - accuracy: 0.6504 - val_loss: 0.6207 - val_accuracy: 0.6630\n",
            "Epoch 353/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6286 - accuracy: 0.6481 - val_loss: 0.6182 - val_accuracy: 0.6670\n",
            "Epoch 354/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6282 - accuracy: 0.6495 - val_loss: 0.6280 - val_accuracy: 0.6380\n",
            "Epoch 355/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6285 - accuracy: 0.6488 - val_loss: 0.6190 - val_accuracy: 0.6680\n",
            "Epoch 356/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6296 - accuracy: 0.6483 - val_loss: 0.6203 - val_accuracy: 0.6670\n",
            "Epoch 357/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6285 - accuracy: 0.6487 - val_loss: 0.6196 - val_accuracy: 0.6530\n",
            "Epoch 358/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6289 - accuracy: 0.6492 - val_loss: 0.6216 - val_accuracy: 0.6590\n",
            "Epoch 359/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6285 - accuracy: 0.6493 - val_loss: 0.6205 - val_accuracy: 0.6460\n",
            "Epoch 360/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6295 - accuracy: 0.6476 - val_loss: 0.6167 - val_accuracy: 0.6540\n",
            "Epoch 361/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6282 - accuracy: 0.6484 - val_loss: 0.6206 - val_accuracy: 0.6500\n",
            "Epoch 362/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6281 - accuracy: 0.6488 - val_loss: 0.6204 - val_accuracy: 0.6660\n",
            "Epoch 363/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6287 - accuracy: 0.6506 - val_loss: 0.6173 - val_accuracy: 0.6680\n",
            "Epoch 364/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6278 - accuracy: 0.6477 - val_loss: 0.6203 - val_accuracy: 0.6490\n",
            "Epoch 365/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6278 - accuracy: 0.6509 - val_loss: 0.6149 - val_accuracy: 0.6610\n",
            "Epoch 366/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6278 - accuracy: 0.6489 - val_loss: 0.6216 - val_accuracy: 0.6660\n",
            "Epoch 367/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6276 - accuracy: 0.6519 - val_loss: 0.6234 - val_accuracy: 0.6660\n",
            "Epoch 368/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6281 - accuracy: 0.6500 - val_loss: 0.6198 - val_accuracy: 0.6630\n",
            "Epoch 369/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6285 - accuracy: 0.6491 - val_loss: 0.6196 - val_accuracy: 0.6450\n",
            "Epoch 370/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6278 - accuracy: 0.6508 - val_loss: 0.6211 - val_accuracy: 0.6590\n",
            "Epoch 371/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6281 - accuracy: 0.6498 - val_loss: 0.6235 - val_accuracy: 0.6570\n",
            "Epoch 372/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6275 - accuracy: 0.6494 - val_loss: 0.6269 - val_accuracy: 0.6500\n",
            "Epoch 373/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6290 - accuracy: 0.6489 - val_loss: 0.6207 - val_accuracy: 0.6700\n",
            "Epoch 374/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6274 - accuracy: 0.6500 - val_loss: 0.6199 - val_accuracy: 0.6520\n",
            "Epoch 375/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6285 - accuracy: 0.6488 - val_loss: 0.6220 - val_accuracy: 0.6570\n",
            "Epoch 376/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6285 - accuracy: 0.6498 - val_loss: 0.6252 - val_accuracy: 0.6500\n",
            "Epoch 377/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6270 - accuracy: 0.6480 - val_loss: 0.6249 - val_accuracy: 0.6550\n",
            "Epoch 378/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6286 - accuracy: 0.6498 - val_loss: 0.6185 - val_accuracy: 0.6580\n",
            "Epoch 379/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6284 - accuracy: 0.6498 - val_loss: 0.6204 - val_accuracy: 0.6450\n",
            "Epoch 380/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6278 - accuracy: 0.6495 - val_loss: 0.6233 - val_accuracy: 0.6720\n",
            "Epoch 381/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6267 - accuracy: 0.6499 - val_loss: 0.6214 - val_accuracy: 0.6510\n",
            "Epoch 382/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6279 - accuracy: 0.6506 - val_loss: 0.6213 - val_accuracy: 0.6640\n",
            "Epoch 383/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6267 - accuracy: 0.6501 - val_loss: 0.6195 - val_accuracy: 0.6730\n",
            "Epoch 384/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6274 - accuracy: 0.6501 - val_loss: 0.6245 - val_accuracy: 0.6620\n",
            "Epoch 385/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6272 - accuracy: 0.6523 - val_loss: 0.6180 - val_accuracy: 0.6660\n",
            "Epoch 386/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6281 - accuracy: 0.6502 - val_loss: 0.6252 - val_accuracy: 0.6510\n",
            "Epoch 387/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6278 - accuracy: 0.6501 - val_loss: 0.6161 - val_accuracy: 0.6600\n",
            "Epoch 388/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6272 - accuracy: 0.6496 - val_loss: 0.6202 - val_accuracy: 0.6500\n",
            "Epoch 389/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6276 - accuracy: 0.6509 - val_loss: 0.6241 - val_accuracy: 0.6650\n",
            "Epoch 390/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6280 - accuracy: 0.6509 - val_loss: 0.6160 - val_accuracy: 0.6650\n",
            "Epoch 391/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6281 - accuracy: 0.6494 - val_loss: 0.6215 - val_accuracy: 0.6600\n",
            "Epoch 392/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6280 - accuracy: 0.6506 - val_loss: 0.6220 - val_accuracy: 0.6520\n",
            "Epoch 393/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6265 - accuracy: 0.6509 - val_loss: 0.6271 - val_accuracy: 0.6590\n",
            "Epoch 394/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6275 - accuracy: 0.6524 - val_loss: 0.6207 - val_accuracy: 0.6590\n",
            "Epoch 395/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6279 - accuracy: 0.6493 - val_loss: 0.6187 - val_accuracy: 0.6630\n",
            "Epoch 396/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6266 - accuracy: 0.6512 - val_loss: 0.6153 - val_accuracy: 0.6630\n",
            "Epoch 397/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6269 - accuracy: 0.6515 - val_loss: 0.6162 - val_accuracy: 0.6570\n",
            "Epoch 398/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6273 - accuracy: 0.6511 - val_loss: 0.6201 - val_accuracy: 0.6610\n",
            "Epoch 399/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6274 - accuracy: 0.6504 - val_loss: 0.6150 - val_accuracy: 0.6560\n",
            "Epoch 400/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6277 - accuracy: 0.6498 - val_loss: 0.6231 - val_accuracy: 0.6530\n",
            "Epoch 401/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6275 - accuracy: 0.6499 - val_loss: 0.6189 - val_accuracy: 0.6570\n",
            "Epoch 402/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6269 - accuracy: 0.6517 - val_loss: 0.6247 - val_accuracy: 0.6570\n",
            "Epoch 403/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6272 - accuracy: 0.6497 - val_loss: 0.6186 - val_accuracy: 0.6530\n",
            "Epoch 404/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6267 - accuracy: 0.6510 - val_loss: 0.6212 - val_accuracy: 0.6610\n",
            "Epoch 405/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6276 - accuracy: 0.6485 - val_loss: 0.6214 - val_accuracy: 0.6550\n",
            "Epoch 406/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6264 - accuracy: 0.6501 - val_loss: 0.6210 - val_accuracy: 0.6560\n",
            "Epoch 407/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6266 - accuracy: 0.6509 - val_loss: 0.6207 - val_accuracy: 0.6470\n",
            "Epoch 408/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6272 - accuracy: 0.6505 - val_loss: 0.6204 - val_accuracy: 0.6550\n",
            "Epoch 409/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6279 - accuracy: 0.6492 - val_loss: 0.6162 - val_accuracy: 0.6660\n",
            "Epoch 410/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6263 - accuracy: 0.6532 - val_loss: 0.6219 - val_accuracy: 0.6520\n",
            "Epoch 411/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6269 - accuracy: 0.6516 - val_loss: 0.6217 - val_accuracy: 0.6690\n",
            "Epoch 412/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6269 - accuracy: 0.6507 - val_loss: 0.6210 - val_accuracy: 0.6530\n",
            "Epoch 413/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6269 - accuracy: 0.6514 - val_loss: 0.6197 - val_accuracy: 0.6680\n",
            "Epoch 414/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6259 - accuracy: 0.6509 - val_loss: 0.6158 - val_accuracy: 0.6600\n",
            "Epoch 415/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6272 - accuracy: 0.6499 - val_loss: 0.6228 - val_accuracy: 0.6680\n",
            "Epoch 416/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6273 - accuracy: 0.6501 - val_loss: 0.6199 - val_accuracy: 0.6620\n",
            "Epoch 417/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6268 - accuracy: 0.6509 - val_loss: 0.6195 - val_accuracy: 0.6610\n",
            "Epoch 418/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6255 - accuracy: 0.6516 - val_loss: 0.6220 - val_accuracy: 0.6450\n",
            "Epoch 419/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6265 - accuracy: 0.6502 - val_loss: 0.6233 - val_accuracy: 0.6480\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sgxZ6qrU9-9"
      },
      "source": [
        "def eval_model(model, x, true_label, ds_name=\"Training\"):\n",
        "  loss, acc = model.evaluate(x, true_label, verbose=0)\n",
        "  print(\"{} Dataset: loss = {} and acccuracy = {}\".format(ds_name, np.round(loss, 3), np.round(acc, 3)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwcedsFqDUnm",
        "outputId": "658e2ba6-55b6-4318-cddf-ba1963fc448f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "eval_model(model, xtrain_vec, chip_train[\"id\"], \"Training\")\n",
        "eval_model(model, xval_vec, chip_val[\"id\"], \"Validation\")\n",
        "eval_model(model, xtest_vec, chip_test[\"id\"], \"Test\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Dataset: loss = 0.616 and acccuracy = 0.661\n",
            "Validation Dataset: loss = 0.614 and acccuracy = 0.676\n",
            "Test Dataset: loss = 0.624 and acccuracy = 0.654\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsKcAZpuD1cT",
        "outputId": "74190919-fead-46a0-9fae-9ab95c597e28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "for i in range(1):\n",
        "  ax1 = axes[0]\n",
        "  ax2 = axes[1]\n",
        "\n",
        "  ax1.plot(model_hist.history['loss'], label='training')\n",
        "  ax1.plot(model_hist.history['val_loss'], label='validation')\n",
        "  ax1.set_title('NN Multiclassification loss')\n",
        "  ax1.set_xlabel('epoch')\n",
        "  ax1.set_ylabel('loss')\n",
        "  ax1.legend(['train', 'validation'], loc='upper left')\n",
        "  \n",
        "  ax2.plot(model_hist.history['accuracy'], label='training')\n",
        "  ax2.plot(model_hist.history['val_accuracy'], label='validation')\n",
        "  ax2.set_title('NN Multiclassification accuracy')\n",
        "  ax2.set_xlabel('epoch')\n",
        "  ax2.set_ylabel('accuracy')\n",
        "  ax2.legend(['train', 'validation'], loc='upper left')\n",
        "fig.tight_layout()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGS26IKAYaBt"
      },
      "source": [
        "def save_hist():\n",
        "  filename = data_path + \"ae_chip_adam256_prediction_history.csv\"\n",
        "  hist_df = pd.DataFrame(model_hist.history) \n",
        "  with open(filename, mode='w') as f:\n",
        "    hist_df.to_csv(f)\n",
        "save_hist()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
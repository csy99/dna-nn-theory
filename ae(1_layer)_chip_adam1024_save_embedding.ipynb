{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ae(1 layer)_chip_adam1024_save embedding.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/csy99/dna-nn-theory/blob/master/ae(1_layer)_chip_adam1024_save_embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiSO3GWw8FWG"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import product\n",
        "import re\n",
        "import time\n",
        "# from sklearn.model_selection import train_test_split\n",
        "from sklearn.manifold import TSNE\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LCWC3mMfj_i",
        "outputId": "64ec9be4-f093-40a3-b6bb-710c64199782",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install biopython\n",
        "from Bio import SeqIO"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting biopython\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/02/8b606c4aa92ff61b5eda71d23b499ab1de57d5e818be33f77b01a6f435a8/biopython-1.78-cp36-cp36m-manylinux1_x86_64.whl (2.3MB)\n",
            "\r\u001b[K     |▏                               | 10kB 21.2MB/s eta 0:00:01\r\u001b[K     |▎                               | 20kB 16.2MB/s eta 0:00:01\r\u001b[K     |▍                               | 30kB 21.1MB/s eta 0:00:01\r\u001b[K     |▋                               | 40kB 18.4MB/s eta 0:00:01\r\u001b[K     |▊                               | 51kB 12.0MB/s eta 0:00:01\r\u001b[K     |▉                               | 61kB 11.2MB/s eta 0:00:01\r\u001b[K     |█                               | 71kB 10.3MB/s eta 0:00:01\r\u001b[K     |█▏                              | 81kB 11.0MB/s eta 0:00:01\r\u001b[K     |█▎                              | 92kB 10.6MB/s eta 0:00:01\r\u001b[K     |█▌                              | 102kB 10.8MB/s eta 0:00:01\r\u001b[K     |█▋                              | 112kB 10.8MB/s eta 0:00:01\r\u001b[K     |█▊                              | 122kB 10.8MB/s eta 0:00:01\r\u001b[K     |██                              | 133kB 10.8MB/s eta 0:00:01\r\u001b[K     |██                              | 143kB 10.8MB/s eta 0:00:01\r\u001b[K     |██▏                             | 153kB 10.8MB/s eta 0:00:01\r\u001b[K     |██▎                             | 163kB 10.8MB/s eta 0:00:01\r\u001b[K     |██▌                             | 174kB 10.8MB/s eta 0:00:01\r\u001b[K     |██▋                             | 184kB 10.8MB/s eta 0:00:01\r\u001b[K     |██▊                             | 194kB 10.8MB/s eta 0:00:01\r\u001b[K     |███                             | 204kB 10.8MB/s eta 0:00:01\r\u001b[K     |███                             | 215kB 10.8MB/s eta 0:00:01\r\u001b[K     |███▏                            | 225kB 10.8MB/s eta 0:00:01\r\u001b[K     |███▍                            | 235kB 10.8MB/s eta 0:00:01\r\u001b[K     |███▌                            | 245kB 10.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 256kB 10.8MB/s eta 0:00:01\r\u001b[K     |███▉                            | 266kB 10.8MB/s eta 0:00:01\r\u001b[K     |████                            | 276kB 10.8MB/s eta 0:00:01\r\u001b[K     |████                            | 286kB 10.8MB/s eta 0:00:01\r\u001b[K     |████▏                           | 296kB 10.8MB/s eta 0:00:01\r\u001b[K     |████▍                           | 307kB 10.8MB/s eta 0:00:01\r\u001b[K     |████▌                           | 317kB 10.8MB/s eta 0:00:01\r\u001b[K     |████▋                           | 327kB 10.8MB/s eta 0:00:01\r\u001b[K     |████▉                           | 337kB 10.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 348kB 10.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 358kB 10.8MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 368kB 10.8MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 378kB 10.8MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 389kB 10.8MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 399kB 10.8MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 409kB 10.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 419kB 10.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 430kB 10.8MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 440kB 10.8MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 450kB 10.8MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 460kB 10.8MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 471kB 10.8MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 481kB 10.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 491kB 10.8MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 501kB 10.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 512kB 10.8MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 522kB 10.8MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 532kB 10.8MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 542kB 10.8MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 552kB 10.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 563kB 10.8MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 573kB 10.8MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 583kB 10.8MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 593kB 10.8MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 604kB 10.8MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 614kB 10.8MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 624kB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 634kB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 645kB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 655kB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 665kB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 675kB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 686kB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 696kB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 706kB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 716kB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 727kB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 737kB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 747kB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 757kB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 768kB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 778kB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 788kB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 798kB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 808kB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 819kB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 829kB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 839kB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 849kB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 860kB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 870kB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 880kB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 890kB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 901kB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 911kB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 921kB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 931kB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 942kB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 952kB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 962kB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 972kB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 983kB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 993kB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 1.0MB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 1.0MB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 1.0MB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 1.0MB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 1.0MB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.1MB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 1.1MB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 1.1MB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 1.1MB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 1.1MB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 1.1MB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 1.1MB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.1MB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 1.1MB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 1.1MB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 1.2MB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 1.2MB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 1.2MB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 1.2MB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.2MB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 1.2MB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.2MB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 1.2MB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.2MB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.2MB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.3MB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.3MB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.3MB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.3MB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.3MB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.3MB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.3MB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.3MB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.3MB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.4MB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.4MB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.4MB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.4MB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.4MB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.4MB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.4MB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.4MB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.4MB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.4MB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.5MB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.5MB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.5MB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.5MB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.5MB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.5MB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.5MB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.5MB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.5MB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.5MB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.6MB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.6MB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.6MB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.6MB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.6MB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.6MB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.6MB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.6MB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.6MB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.6MB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.7MB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.7MB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.7MB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.7MB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.7MB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.7MB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.7MB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.7MB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.7MB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.8MB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.8MB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.8MB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.8MB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.8MB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.8MB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.8MB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.8MB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.8MB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.8MB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.9MB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.9MB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.9MB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.9MB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.9MB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.9MB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.9MB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.9MB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.9MB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.9MB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 2.0MB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.0MB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.0MB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 2.0MB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 2.0MB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 2.0MB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 2.0MB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 2.0MB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 2.0MB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 2.0MB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 2.1MB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 2.1MB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 2.1MB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 2.1MB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 2.1MB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 2.1MB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 2.1MB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 2.1MB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 2.1MB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 2.2MB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 2.2MB 10.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 2.2MB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 2.2MB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 2.2MB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 2.2MB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 2.2MB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 2.2MB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 2.2MB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 2.2MB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.3MB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.3MB 10.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from biopython) (1.18.5)\n",
            "Installing collected packages: biopython\n",
            "Successfully installed biopython-1.78\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuvNh5Ia8vvD"
      },
      "source": [
        "# Read Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5SYc4iv-RPC",
        "outputId": "c07c2ee3-0767-40bd-800d-5f72cdf1b6e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install PyDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyDrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.7.12)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.15.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.17.2)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.17.4)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.4)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (4.1.1)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (50.3.2)\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3Qvmz3MfcR1"
      },
      "source": [
        "def readFasta(file):\n",
        "  with open(file, 'r') as f:\n",
        "    records = np.array([record.seq._data.upper() for record in SeqIO.parse(f, 'fasta')])\n",
        "  with open(file, 'r') as f:\n",
        "    records_id = np.array([record.id for record in SeqIO.parse(f, 'fasta')])\n",
        "  print('reading', str(file), 'Number of sequences :', \n",
        "        len(records), 'Length of sequences :', len(records[0]))\n",
        "  records_df = pd.DataFrame({'id': records_id, 'seq': records})\n",
        "  return records_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ue0xl7xUfeCZ",
        "outputId": "177d8d39-07c2-469e-9592-a375fe06b01b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# read fasta data\n",
        "data_path = '/content/gdrive/My Drive/Colab Notebooks/CHIP/'\n",
        "chip_train = readFasta(data_path + 'train.fasta')\n",
        "chip_val = readFasta(data_path + 'valid.fasta')\n",
        "chip_test = readFasta(data_path + 'test.fasta')\n",
        "chip_train[\"id\"] = chip_train[\"id\"].astype(int)\n",
        "chip_val[\"id\"] = chip_val[\"id\"].astype(int)\n",
        "chip_test[\"id\"] = chip_test[\"id\"].astype(int)\n",
        "print(chip_train.id.value_counts())\n",
        "print(chip_val.id.value_counts())\n",
        "print(chip_test.id.value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reading /content/gdrive/My Drive/Colab Notebooks/CHIP/train.fasta Number of sequences : 77174 Length of sequences : 101\n",
            "reading /content/gdrive/My Drive/Colab Notebooks/CHIP/valid.fasta Number of sequences : 1000 Length of sequences : 101\n",
            "reading /content/gdrive/My Drive/Colab Notebooks/CHIP/test.fasta Number of sequences : 19544 Length of sequences : 101\n",
            "1    38638\n",
            "0    38536\n",
            "Name: id, dtype: int64\n",
            "1    500\n",
            "0    500\n",
            "Name: id, dtype: int64\n",
            "0    9823\n",
            "1    9721\n",
            "Name: id, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_IFMicpqYIl"
      },
      "source": [
        "seq_num = 0\n",
        "for seq in chip_train[\"seq\"]:\n",
        "  char_num = 0\n",
        "  for char in seq:\n",
        "    if char != 'A' and char != 'C' and char != 'T' and char != 'G':\n",
        "      print(\"seq\", seq_num, 'char', char_num, 'is', char)\n",
        "    char_num += 1\n",
        "  seq_num += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSFFjXSJP88L",
        "outputId": "e9ef78ad-fbeb-4008-9c2c-f2da2c0d7dc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# check if the length of the sequence is the same \n",
        "seq_len = len(chip_train.seq[0])\n",
        "print(\"The length of the sequence is\", seq_len)\n",
        "for seq in chip_train.seq[:200]:\n",
        "  assert len(seq) == seq_len"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The length of the sequence is 101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2h9sGLCVtDn",
        "outputId": "e0287da9-7604-4e21-e5c3-ca13f816e068",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "word_size = 1\n",
        "vocab = [''.join(p) for p in product('ACGT', repeat=word_size)]\n",
        "vocab_size = len('ACGT')\n",
        "print('vocab_size:', vocab_size)\n",
        "# print(\"word_to_idx\", word_to_idx)\n",
        "create1gram = keras.layers.experimental.preprocessing.TextVectorization(\n",
        "  standardize=lambda x: tf.strings.regex_replace(x, '(.)', '\\\\1 '), ngrams=1\n",
        ")\n",
        "create1gram.adapt(vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab_size: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHPvs2BCU_Mk"
      },
      "source": [
        "# the first two index of TextVectorization has been reserved to EOS and OOV\n",
        "def index_preprocess(x):\n",
        "  x_index = tf.subtract(create1gram(x), 2)\n",
        "  return x_index, x_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFvsJkEa0YuT",
        "outputId": "2fee6d40-4fd9-4064-e0e5-4fbfba899f2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# not sure the correct way to get mapping from word to its index\n",
        "create1gram('A C G T') - 2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([3, 2, 1, 0])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzLRmqEjSitl"
      },
      "source": [
        "BATCH_SIZE = 1024\n",
        "xtrain_seq = tf.data.Dataset.from_tensor_slices(chip_train['seq']).map(index_preprocess).batch(BATCH_SIZE)\n",
        "xval_seq = tf.data.Dataset.from_tensor_slices(chip_val['seq']).map(index_preprocess).batch(BATCH_SIZE)\n",
        "xtest_seq = tf.data.Dataset.from_tensor_slices(chip_test['seq']).map(index_preprocess).batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVLaIchQUWQl",
        "outputId": "44f2b8d2-1743-4c67-d9e9-3550c52cc58b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "latent_size = 30\n",
        "\n",
        "encoder = keras.Sequential([\n",
        "    keras.Input(shape=(seq_len,)),\n",
        "    keras.layers.Embedding(seq_len, latent_size),\n",
        "    keras.layers.LSTM(latent_size, return_sequences=False),\n",
        "])\n",
        "\n",
        "decoder = keras.Sequential([\n",
        "    keras.layers.RepeatVector(seq_len, input_shape=[latent_size]),\n",
        "    keras.layers.LSTM(latent_size, return_sequences=True),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(4, activation='softmax'))  # ACTG\n",
        "])\n",
        "\n",
        "recurrent_ae = keras.Sequential([encoder, decoder])\n",
        "recurrent_ae.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential (Sequential)      (None, 30)                10350     \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    (None, 101, 4)            7444      \n",
            "=================================================================\n",
            "Total params: 17,794\n",
            "Trainable params: 17,794\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMlnaNStWLNK"
      },
      "source": [
        "# save_freq=1500 means that the model will be saved around every 20 epochs (each epochs contain 76 batches)\n",
        "checkpoint_filepath = '/content/gdrive/My Drive/Colab Notebooks/models/lstm1_chip.1024.{epoch:04d}.h5'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=False,\n",
        "    monitor='val_acc',\n",
        "    mode='max',\n",
        "    save_best_only=False,\n",
        "    save_freq=1500)\n",
        "es_cb = keras.callbacks.EarlyStopping(patience=100, restore_best_weights=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzGk4gMahIvw",
        "outputId": "75cb2b16-093f-4ace-a378-26d585aa6b8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "recurrent_ae.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "ae_hist = recurrent_ae.fit(xtrain_seq, validation_data=xval_seq, epochs=3000, callbacks=[es_cb])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3000\n",
            "76/76 [==============================] - 14s 190ms/step - loss: 1.3664 - accuracy: 0.2991 - val_loss: 1.3506 - val_accuracy: 0.3247\n",
            "Epoch 2/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.3464 - accuracy: 0.3329 - val_loss: 1.3428 - val_accuracy: 0.3377\n",
            "Epoch 3/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.3428 - accuracy: 0.3381 - val_loss: 1.3422 - val_accuracy: 0.3382\n",
            "Epoch 4/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.3424 - accuracy: 0.3384 - val_loss: 1.3419 - val_accuracy: 0.3376\n",
            "Epoch 5/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.3421 - accuracy: 0.3386 - val_loss: 1.3417 - val_accuracy: 0.3381\n",
            "Epoch 6/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.3419 - accuracy: 0.3387 - val_loss: 1.3415 - val_accuracy: 0.3386\n",
            "Epoch 7/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.3418 - accuracy: 0.3388 - val_loss: 1.3413 - val_accuracy: 0.3389\n",
            "Epoch 8/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.3418 - accuracy: 0.3389 - val_loss: 1.3403 - val_accuracy: 0.3394\n",
            "Epoch 9/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.3401 - accuracy: 0.3404 - val_loss: 1.3389 - val_accuracy: 0.3418\n",
            "Epoch 10/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.3389 - accuracy: 0.3417 - val_loss: 1.3381 - val_accuracy: 0.3432\n",
            "Epoch 11/3000\n",
            "76/76 [==============================] - 13s 178ms/step - loss: 1.3380 - accuracy: 0.3429 - val_loss: 1.3369 - val_accuracy: 0.3435\n",
            "Epoch 12/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.3357 - accuracy: 0.3454 - val_loss: 1.3321 - val_accuracy: 0.3493\n",
            "Epoch 13/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.3309 - accuracy: 0.3501 - val_loss: 1.3282 - val_accuracy: 0.3528\n",
            "Epoch 14/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.3268 - accuracy: 0.3539 - val_loss: 1.3247 - val_accuracy: 0.3556\n",
            "Epoch 15/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.3251 - accuracy: 0.3554 - val_loss: 1.3252 - val_accuracy: 0.3547\n",
            "Epoch 16/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.3243 - accuracy: 0.3561 - val_loss: 1.3229 - val_accuracy: 0.3573\n",
            "Epoch 17/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.3245 - accuracy: 0.3559 - val_loss: 1.3222 - val_accuracy: 0.3581\n",
            "Epoch 18/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.3223 - accuracy: 0.3579 - val_loss: 1.3215 - val_accuracy: 0.3574\n",
            "Epoch 19/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.3205 - accuracy: 0.3595 - val_loss: 1.3189 - val_accuracy: 0.3601\n",
            "Epoch 20/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.3192 - accuracy: 0.3605 - val_loss: 1.3173 - val_accuracy: 0.3614\n",
            "Epoch 21/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.3175 - accuracy: 0.3621 - val_loss: 1.3158 - val_accuracy: 0.3631\n",
            "Epoch 22/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.3158 - accuracy: 0.3634 - val_loss: 1.3153 - val_accuracy: 0.3635\n",
            "Epoch 23/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.3141 - accuracy: 0.3647 - val_loss: 1.3139 - val_accuracy: 0.3647\n",
            "Epoch 24/3000\n",
            "76/76 [==============================] - 15s 195ms/step - loss: 1.3145 - accuracy: 0.3646 - val_loss: 1.3108 - val_accuracy: 0.3674\n",
            "Epoch 25/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.3131 - accuracy: 0.3655 - val_loss: 1.3223 - val_accuracy: 0.3538\n",
            "Epoch 26/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.3112 - accuracy: 0.3672 - val_loss: 1.3076 - val_accuracy: 0.3707\n",
            "Epoch 27/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.3073 - accuracy: 0.3705 - val_loss: 1.3067 - val_accuracy: 0.3715\n",
            "Epoch 28/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.3059 - accuracy: 0.3715 - val_loss: 1.3049 - val_accuracy: 0.3727\n",
            "Epoch 29/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.3055 - accuracy: 0.3718 - val_loss: 1.3037 - val_accuracy: 0.3738\n",
            "Epoch 30/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.3034 - accuracy: 0.3734 - val_loss: 1.3033 - val_accuracy: 0.3729\n",
            "Epoch 31/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.3031 - accuracy: 0.3737 - val_loss: 1.3013 - val_accuracy: 0.3754\n",
            "Epoch 32/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.3011 - accuracy: 0.3753 - val_loss: 1.3027 - val_accuracy: 0.3741\n",
            "Epoch 33/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.3006 - accuracy: 0.3757 - val_loss: 1.2993 - val_accuracy: 0.3770\n",
            "Epoch 34/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.3012 - accuracy: 0.3750 - val_loss: 1.3099 - val_accuracy: 0.3669\n",
            "Epoch 35/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.3016 - accuracy: 0.3741 - val_loss: 1.2977 - val_accuracy: 0.3769\n",
            "Epoch 36/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.2972 - accuracy: 0.3786 - val_loss: 1.2957 - val_accuracy: 0.3796\n",
            "Epoch 37/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.2957 - accuracy: 0.3798 - val_loss: 1.2942 - val_accuracy: 0.3802\n",
            "Epoch 38/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.2941 - accuracy: 0.3810 - val_loss: 1.2925 - val_accuracy: 0.3812\n",
            "Epoch 39/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.2927 - accuracy: 0.3821 - val_loss: 1.2915 - val_accuracy: 0.3818\n",
            "Epoch 40/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.2917 - accuracy: 0.3828 - val_loss: 1.2919 - val_accuracy: 0.3820\n",
            "Epoch 41/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.2905 - accuracy: 0.3837 - val_loss: 1.2902 - val_accuracy: 0.3830\n",
            "Epoch 42/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2902 - accuracy: 0.3839 - val_loss: 1.2891 - val_accuracy: 0.3834\n",
            "Epoch 43/3000\n",
            "76/76 [==============================] - 13s 178ms/step - loss: 1.2893 - accuracy: 0.3846 - val_loss: 1.2886 - val_accuracy: 0.3840\n",
            "Epoch 44/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.2894 - accuracy: 0.3847 - val_loss: 1.2881 - val_accuracy: 0.3835\n",
            "Epoch 45/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.2883 - accuracy: 0.3855 - val_loss: 1.2882 - val_accuracy: 0.3835\n",
            "Epoch 46/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.2885 - accuracy: 0.3854 - val_loss: 1.2874 - val_accuracy: 0.3850\n",
            "Epoch 47/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.2871 - accuracy: 0.3865 - val_loss: 1.2894 - val_accuracy: 0.3828\n",
            "Epoch 48/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.2903 - accuracy: 0.3844 - val_loss: 1.2859 - val_accuracy: 0.3872\n",
            "Epoch 49/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.2851 - accuracy: 0.3884 - val_loss: 1.2845 - val_accuracy: 0.3886\n",
            "Epoch 50/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.2848 - accuracy: 0.3886 - val_loss: 1.2844 - val_accuracy: 0.3873\n",
            "Epoch 51/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.2840 - accuracy: 0.3892 - val_loss: 1.2836 - val_accuracy: 0.3884\n",
            "Epoch 52/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.2831 - accuracy: 0.3898 - val_loss: 1.2834 - val_accuracy: 0.3881\n",
            "Epoch 53/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.2835 - accuracy: 0.3895 - val_loss: 1.2863 - val_accuracy: 0.3862\n",
            "Epoch 54/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.2822 - accuracy: 0.3903 - val_loss: 1.2819 - val_accuracy: 0.3898\n",
            "Epoch 55/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2817 - accuracy: 0.3907 - val_loss: 1.2825 - val_accuracy: 0.3900\n",
            "Epoch 56/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.2814 - accuracy: 0.3909 - val_loss: 1.2843 - val_accuracy: 0.3882\n",
            "Epoch 57/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.2810 - accuracy: 0.3912 - val_loss: 1.3023 - val_accuracy: 0.3747\n",
            "Epoch 58/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.2904 - accuracy: 0.3832 - val_loss: 1.2807 - val_accuracy: 0.3913\n",
            "Epoch 59/3000\n",
            "76/76 [==============================] - 13s 178ms/step - loss: 1.2794 - accuracy: 0.3925 - val_loss: 1.2792 - val_accuracy: 0.3925\n",
            "Epoch 60/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.2783 - accuracy: 0.3933 - val_loss: 1.2785 - val_accuracy: 0.3931\n",
            "Epoch 61/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.2782 - accuracy: 0.3934 - val_loss: 1.2946 - val_accuracy: 0.3793\n",
            "Epoch 62/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2787 - accuracy: 0.3931 - val_loss: 1.2770 - val_accuracy: 0.3941\n",
            "Epoch 63/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.2763 - accuracy: 0.3948 - val_loss: 1.2773 - val_accuracy: 0.3929\n",
            "Epoch 64/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2760 - accuracy: 0.3951 - val_loss: 1.2777 - val_accuracy: 0.3927\n",
            "Epoch 65/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.2751 - accuracy: 0.3957 - val_loss: 1.2763 - val_accuracy: 0.3936\n",
            "Epoch 66/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2748 - accuracy: 0.3959 - val_loss: 1.2789 - val_accuracy: 0.3912\n",
            "Epoch 67/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.2737 - accuracy: 0.3968 - val_loss: 1.2759 - val_accuracy: 0.3950\n",
            "Epoch 68/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2726 - accuracy: 0.3976 - val_loss: 1.2817 - val_accuracy: 0.3907\n",
            "Epoch 69/3000\n",
            "76/76 [==============================] - 15s 197ms/step - loss: 1.2720 - accuracy: 0.3980 - val_loss: 1.2736 - val_accuracy: 0.3972\n",
            "Epoch 70/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.2703 - accuracy: 0.3993 - val_loss: 1.2729 - val_accuracy: 0.3960\n",
            "Epoch 71/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.2696 - accuracy: 0.3999 - val_loss: 1.2700 - val_accuracy: 0.3986\n",
            "Epoch 72/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2685 - accuracy: 0.4007 - val_loss: 1.2685 - val_accuracy: 0.3997\n",
            "Epoch 73/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.2681 - accuracy: 0.4010 - val_loss: 1.2680 - val_accuracy: 0.4000\n",
            "Epoch 74/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.2674 - accuracy: 0.4015 - val_loss: 1.2679 - val_accuracy: 0.4005\n",
            "Epoch 75/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.2670 - accuracy: 0.4017 - val_loss: 1.2695 - val_accuracy: 0.3993\n",
            "Epoch 76/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.2665 - accuracy: 0.4022 - val_loss: 1.2675 - val_accuracy: 0.4010\n",
            "Epoch 77/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2663 - accuracy: 0.4023 - val_loss: 1.2670 - val_accuracy: 0.4009\n",
            "Epoch 78/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.2657 - accuracy: 0.4027 - val_loss: 1.2669 - val_accuracy: 0.4013\n",
            "Epoch 79/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.2658 - accuracy: 0.4026 - val_loss: 1.2657 - val_accuracy: 0.4027\n",
            "Epoch 80/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.2653 - accuracy: 0.4030 - val_loss: 1.2660 - val_accuracy: 0.4023\n",
            "Epoch 81/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.2646 - accuracy: 0.4035 - val_loss: 1.2687 - val_accuracy: 0.3999\n",
            "Epoch 82/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.2647 - accuracy: 0.4036 - val_loss: 1.2648 - val_accuracy: 0.4035\n",
            "Epoch 83/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2641 - accuracy: 0.4039 - val_loss: 1.2649 - val_accuracy: 0.4027\n",
            "Epoch 84/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.2639 - accuracy: 0.4041 - val_loss: 1.2642 - val_accuracy: 0.4031\n",
            "Epoch 85/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.2637 - accuracy: 0.4044 - val_loss: 1.2646 - val_accuracy: 0.4046\n",
            "Epoch 86/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2629 - accuracy: 0.4050 - val_loss: 1.2630 - val_accuracy: 0.4040\n",
            "Epoch 87/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.2623 - accuracy: 0.4053 - val_loss: 1.2646 - val_accuracy: 0.4030\n",
            "Epoch 88/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.2622 - accuracy: 0.4054 - val_loss: 1.2613 - val_accuracy: 0.4057\n",
            "Epoch 89/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.2610 - accuracy: 0.4063 - val_loss: 1.2609 - val_accuracy: 0.4062\n",
            "Epoch 90/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.2606 - accuracy: 0.4065 - val_loss: 1.2602 - val_accuracy: 0.4078\n",
            "Epoch 91/3000\n",
            "76/76 [==============================] - 15s 194ms/step - loss: 1.2597 - accuracy: 0.4070 - val_loss: 1.2608 - val_accuracy: 0.4063\n",
            "Epoch 92/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2596 - accuracy: 0.4072 - val_loss: 1.2637 - val_accuracy: 0.4028\n",
            "Epoch 93/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2583 - accuracy: 0.4081 - val_loss: 1.2579 - val_accuracy: 0.4079\n",
            "Epoch 94/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.2579 - accuracy: 0.4086 - val_loss: 1.2579 - val_accuracy: 0.4091\n",
            "Epoch 95/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.2573 - accuracy: 0.4089 - val_loss: 1.2575 - val_accuracy: 0.4093\n",
            "Epoch 96/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.2568 - accuracy: 0.4093 - val_loss: 1.2582 - val_accuracy: 0.4078\n",
            "Epoch 97/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.2565 - accuracy: 0.4096 - val_loss: 1.2570 - val_accuracy: 0.4089\n",
            "Epoch 98/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.2557 - accuracy: 0.4101 - val_loss: 1.2561 - val_accuracy: 0.4099\n",
            "Epoch 99/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.2554 - accuracy: 0.4104 - val_loss: 1.2562 - val_accuracy: 0.4107\n",
            "Epoch 100/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2550 - accuracy: 0.4107 - val_loss: 1.2550 - val_accuracy: 0.4094\n",
            "Epoch 101/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.2543 - accuracy: 0.4112 - val_loss: 1.2551 - val_accuracy: 0.4101\n",
            "Epoch 102/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.2572 - accuracy: 0.4094 - val_loss: 1.2539 - val_accuracy: 0.4109\n",
            "Epoch 103/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.2535 - accuracy: 0.4118 - val_loss: 1.2544 - val_accuracy: 0.4118\n",
            "Epoch 104/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.2537 - accuracy: 0.4117 - val_loss: 1.2540 - val_accuracy: 0.4118\n",
            "Epoch 105/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.2535 - accuracy: 0.4118 - val_loss: 1.2609 - val_accuracy: 0.4083\n",
            "Epoch 106/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.2554 - accuracy: 0.4106 - val_loss: 1.2523 - val_accuracy: 0.4129\n",
            "Epoch 107/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.2519 - accuracy: 0.4128 - val_loss: 1.2522 - val_accuracy: 0.4142\n",
            "Epoch 108/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.2521 - accuracy: 0.4127 - val_loss: 1.2519 - val_accuracy: 0.4132\n",
            "Epoch 109/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.2517 - accuracy: 0.4130 - val_loss: 1.2515 - val_accuracy: 0.4143\n",
            "Epoch 110/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.2517 - accuracy: 0.4130 - val_loss: 1.2526 - val_accuracy: 0.4126\n",
            "Epoch 111/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2507 - accuracy: 0.4137 - val_loss: 1.2505 - val_accuracy: 0.4147\n",
            "Epoch 112/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.2507 - accuracy: 0.4138 - val_loss: 1.2534 - val_accuracy: 0.4127\n",
            "Epoch 113/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.2499 - accuracy: 0.4143 - val_loss: 1.2500 - val_accuracy: 0.4143\n",
            "Epoch 114/3000\n",
            "76/76 [==============================] - 14s 190ms/step - loss: 1.2496 - accuracy: 0.4145 - val_loss: 1.2498 - val_accuracy: 0.4145\n",
            "Epoch 115/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2491 - accuracy: 0.4147 - val_loss: 1.2505 - val_accuracy: 0.4144\n",
            "Epoch 116/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2489 - accuracy: 0.4149 - val_loss: 1.2506 - val_accuracy: 0.4154\n",
            "Epoch 117/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2488 - accuracy: 0.4150 - val_loss: 1.2487 - val_accuracy: 0.4155\n",
            "Epoch 118/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2478 - accuracy: 0.4156 - val_loss: 1.2474 - val_accuracy: 0.4157\n",
            "Epoch 119/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.2477 - accuracy: 0.4157 - val_loss: 1.2479 - val_accuracy: 0.4156\n",
            "Epoch 120/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.2475 - accuracy: 0.4158 - val_loss: 1.2497 - val_accuracy: 0.4156\n",
            "Epoch 121/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.2471 - accuracy: 0.4161 - val_loss: 1.2465 - val_accuracy: 0.4170\n",
            "Epoch 122/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2467 - accuracy: 0.4161 - val_loss: 1.2471 - val_accuracy: 0.4163\n",
            "Epoch 123/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.2464 - accuracy: 0.4166 - val_loss: 1.2466 - val_accuracy: 0.4170\n",
            "Epoch 124/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.2459 - accuracy: 0.4168 - val_loss: 1.2451 - val_accuracy: 0.4176\n",
            "Epoch 125/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.2457 - accuracy: 0.4170 - val_loss: 1.2450 - val_accuracy: 0.4183\n",
            "Epoch 126/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.2492 - accuracy: 0.4146 - val_loss: 1.2449 - val_accuracy: 0.4169\n",
            "Epoch 127/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.2441 - accuracy: 0.4180 - val_loss: 1.2451 - val_accuracy: 0.4177\n",
            "Epoch 128/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2444 - accuracy: 0.4177 - val_loss: 1.2449 - val_accuracy: 0.4186\n",
            "Epoch 129/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.2442 - accuracy: 0.4179 - val_loss: 1.2444 - val_accuracy: 0.4191\n",
            "Epoch 130/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.2437 - accuracy: 0.4182 - val_loss: 1.2438 - val_accuracy: 0.4183\n",
            "Epoch 131/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2436 - accuracy: 0.4183 - val_loss: 1.2436 - val_accuracy: 0.4176\n",
            "Epoch 132/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.2431 - accuracy: 0.4186 - val_loss: 1.2423 - val_accuracy: 0.4184\n",
            "Epoch 133/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2423 - accuracy: 0.4192 - val_loss: 1.2417 - val_accuracy: 0.4194\n",
            "Epoch 134/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.2423 - accuracy: 0.4192 - val_loss: 1.2408 - val_accuracy: 0.4194\n",
            "Epoch 135/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2418 - accuracy: 0.4196 - val_loss: 1.2408 - val_accuracy: 0.4201\n",
            "Epoch 136/3000\n",
            "76/76 [==============================] - 15s 197ms/step - loss: 1.2410 - accuracy: 0.4200 - val_loss: 1.2413 - val_accuracy: 0.4208\n",
            "Epoch 137/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.2422 - accuracy: 0.4193 - val_loss: 1.2397 - val_accuracy: 0.4207\n",
            "Epoch 138/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.2403 - accuracy: 0.4203 - val_loss: 1.2397 - val_accuracy: 0.4208\n",
            "Epoch 139/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.2401 - accuracy: 0.4204 - val_loss: 1.2400 - val_accuracy: 0.4198\n",
            "Epoch 140/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.2401 - accuracy: 0.4204 - val_loss: 1.2400 - val_accuracy: 0.4209\n",
            "Epoch 141/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2392 - accuracy: 0.4209 - val_loss: 1.2396 - val_accuracy: 0.4209\n",
            "Epoch 142/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.2391 - accuracy: 0.4210 - val_loss: 1.2382 - val_accuracy: 0.4206\n",
            "Epoch 143/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2420 - accuracy: 0.4194 - val_loss: 1.2378 - val_accuracy: 0.4209\n",
            "Epoch 144/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2378 - accuracy: 0.4218 - val_loss: 1.2383 - val_accuracy: 0.4209\n",
            "Epoch 145/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.2377 - accuracy: 0.4218 - val_loss: 1.2381 - val_accuracy: 0.4211\n",
            "Epoch 146/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.2456 - accuracy: 0.4176 - val_loss: 1.2390 - val_accuracy: 0.4207\n",
            "Epoch 147/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.2371 - accuracy: 0.4222 - val_loss: 1.2388 - val_accuracy: 0.4224\n",
            "Epoch 148/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.2391 - accuracy: 0.4210 - val_loss: 1.2362 - val_accuracy: 0.4224\n",
            "Epoch 149/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.2367 - accuracy: 0.4224 - val_loss: 1.2358 - val_accuracy: 0.4230\n",
            "Epoch 150/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.2370 - accuracy: 0.4222 - val_loss: 1.2361 - val_accuracy: 0.4233\n",
            "Epoch 151/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2424 - accuracy: 0.4195 - val_loss: 1.2404 - val_accuracy: 0.4203\n",
            "Epoch 152/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.2363 - accuracy: 0.4226 - val_loss: 1.2352 - val_accuracy: 0.4239\n",
            "Epoch 153/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2360 - accuracy: 0.4229 - val_loss: 1.2349 - val_accuracy: 0.4232\n",
            "Epoch 154/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.2358 - accuracy: 0.4229 - val_loss: 1.2363 - val_accuracy: 0.4230\n",
            "Epoch 155/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.2355 - accuracy: 0.4232 - val_loss: 1.2347 - val_accuracy: 0.4233\n",
            "Epoch 156/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.2355 - accuracy: 0.4232 - val_loss: 1.2351 - val_accuracy: 0.4231\n",
            "Epoch 157/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2349 - accuracy: 0.4234 - val_loss: 1.2339 - val_accuracy: 0.4242\n",
            "Epoch 158/3000\n",
            "76/76 [==============================] - 15s 193ms/step - loss: 1.2348 - accuracy: 0.4236 - val_loss: 1.2351 - val_accuracy: 0.4244\n",
            "Epoch 159/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.2347 - accuracy: 0.4236 - val_loss: 1.2334 - val_accuracy: 0.4240\n",
            "Epoch 160/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.2342 - accuracy: 0.4239 - val_loss: 1.2350 - val_accuracy: 0.4226\n",
            "Epoch 161/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.2340 - accuracy: 0.4239 - val_loss: 1.2327 - val_accuracy: 0.4243\n",
            "Epoch 162/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2377 - accuracy: 0.4218 - val_loss: 1.2391 - val_accuracy: 0.4204\n",
            "Epoch 163/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.2334 - accuracy: 0.4243 - val_loss: 1.2322 - val_accuracy: 0.4256\n",
            "Epoch 164/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.2345 - accuracy: 0.4238 - val_loss: 1.2474 - val_accuracy: 0.4166\n",
            "Epoch 165/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.2350 - accuracy: 0.4233 - val_loss: 1.2318 - val_accuracy: 0.4257\n",
            "Epoch 166/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.2320 - accuracy: 0.4253 - val_loss: 1.2319 - val_accuracy: 0.4245\n",
            "Epoch 167/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.2325 - accuracy: 0.4250 - val_loss: 1.2323 - val_accuracy: 0.4241\n",
            "Epoch 168/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2325 - accuracy: 0.4249 - val_loss: 1.2315 - val_accuracy: 0.4251\n",
            "Epoch 169/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.2322 - accuracy: 0.4252 - val_loss: 1.2330 - val_accuracy: 0.4247\n",
            "Epoch 170/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.2352 - accuracy: 0.4234 - val_loss: 1.2508 - val_accuracy: 0.4158\n",
            "Epoch 171/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.2349 - accuracy: 0.4235 - val_loss: 1.2321 - val_accuracy: 0.4249\n",
            "Epoch 172/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.2329 - accuracy: 0.4247 - val_loss: 1.2390 - val_accuracy: 0.4214\n",
            "Epoch 173/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.2310 - accuracy: 0.4259 - val_loss: 1.2299 - val_accuracy: 0.4263\n",
            "Epoch 174/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2300 - accuracy: 0.4266 - val_loss: 1.2295 - val_accuracy: 0.4274\n",
            "Epoch 175/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2307 - accuracy: 0.4262 - val_loss: 1.2301 - val_accuracy: 0.4274\n",
            "Epoch 176/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.2299 - accuracy: 0.4267 - val_loss: 1.2317 - val_accuracy: 0.4265\n",
            "Epoch 177/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.2308 - accuracy: 0.4261 - val_loss: 1.2542 - val_accuracy: 0.4149\n",
            "Epoch 178/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2316 - accuracy: 0.4255 - val_loss: 1.2283 - val_accuracy: 0.4280\n",
            "Epoch 179/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.2352 - accuracy: 0.4235 - val_loss: 1.2311 - val_accuracy: 0.4257\n",
            "Epoch 180/3000\n",
            "76/76 [==============================] - 14s 190ms/step - loss: 1.2288 - accuracy: 0.4273 - val_loss: 1.2281 - val_accuracy: 0.4280\n",
            "Epoch 181/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.2279 - accuracy: 0.4280 - val_loss: 1.2285 - val_accuracy: 0.4288\n",
            "Epoch 182/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.2349 - accuracy: 0.4243 - val_loss: 1.2372 - val_accuracy: 0.4243\n",
            "Epoch 183/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.2297 - accuracy: 0.4271 - val_loss: 1.2273 - val_accuracy: 0.4281\n",
            "Epoch 184/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2274 - accuracy: 0.4284 - val_loss: 1.2283 - val_accuracy: 0.4289\n",
            "Epoch 185/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2324 - accuracy: 0.4257 - val_loss: 1.2298 - val_accuracy: 0.4279\n",
            "Epoch 186/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2267 - accuracy: 0.4288 - val_loss: 1.2273 - val_accuracy: 0.4284\n",
            "Epoch 187/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.2327 - accuracy: 0.4255 - val_loss: 1.2361 - val_accuracy: 0.4243\n",
            "Epoch 188/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.2306 - accuracy: 0.4269 - val_loss: 1.2268 - val_accuracy: 0.4292\n",
            "Epoch 189/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.2266 - accuracy: 0.4289 - val_loss: 1.2289 - val_accuracy: 0.4272\n",
            "Epoch 190/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2315 - accuracy: 0.4263 - val_loss: 1.2257 - val_accuracy: 0.4296\n",
            "Epoch 191/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2255 - accuracy: 0.4295 - val_loss: 1.2266 - val_accuracy: 0.4292\n",
            "Epoch 192/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.2298 - accuracy: 0.4273 - val_loss: 1.2281 - val_accuracy: 0.4277\n",
            "Epoch 193/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.2260 - accuracy: 0.4292 - val_loss: 1.2246 - val_accuracy: 0.4304\n",
            "Epoch 194/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.2247 - accuracy: 0.4301 - val_loss: 1.2256 - val_accuracy: 0.4299\n",
            "Epoch 195/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.2246 - accuracy: 0.4301 - val_loss: 1.2278 - val_accuracy: 0.4280\n",
            "Epoch 196/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.2289 - accuracy: 0.4276 - val_loss: 1.2239 - val_accuracy: 0.4305\n",
            "Epoch 197/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.2233 - accuracy: 0.4309 - val_loss: 1.2233 - val_accuracy: 0.4315\n",
            "Epoch 198/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.2239 - accuracy: 0.4306 - val_loss: 1.2234 - val_accuracy: 0.4303\n",
            "Epoch 199/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.2236 - accuracy: 0.4307 - val_loss: 1.2240 - val_accuracy: 0.4298\n",
            "Epoch 200/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.2238 - accuracy: 0.4306 - val_loss: 1.2231 - val_accuracy: 0.4316\n",
            "Epoch 201/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.2329 - accuracy: 0.4258 - val_loss: 1.2296 - val_accuracy: 0.4285\n",
            "Epoch 202/3000\n",
            "76/76 [==============================] - 15s 193ms/step - loss: 1.2246 - accuracy: 0.4304 - val_loss: 1.2227 - val_accuracy: 0.4312\n",
            "Epoch 203/3000\n",
            "76/76 [==============================] - 14s 190ms/step - loss: 1.2226 - accuracy: 0.4314 - val_loss: 1.2221 - val_accuracy: 0.4319\n",
            "Epoch 204/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.2228 - accuracy: 0.4313 - val_loss: 1.2222 - val_accuracy: 0.4320\n",
            "Epoch 205/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.2223 - accuracy: 0.4316 - val_loss: 1.2220 - val_accuracy: 0.4319\n",
            "Epoch 206/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.2266 - accuracy: 0.4293 - val_loss: 1.2251 - val_accuracy: 0.4305\n",
            "Epoch 207/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.2239 - accuracy: 0.4307 - val_loss: 1.2212 - val_accuracy: 0.4317\n",
            "Epoch 208/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.2210 - accuracy: 0.4323 - val_loss: 1.2215 - val_accuracy: 0.4318\n",
            "Epoch 209/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.2213 - accuracy: 0.4323 - val_loss: 1.2211 - val_accuracy: 0.4329\n",
            "Epoch 210/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.2257 - accuracy: 0.4295 - val_loss: 1.2227 - val_accuracy: 0.4314\n",
            "Epoch 211/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.2204 - accuracy: 0.4328 - val_loss: 1.2202 - val_accuracy: 0.4322\n",
            "Epoch 212/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.2206 - accuracy: 0.4328 - val_loss: 1.2206 - val_accuracy: 0.4327\n",
            "Epoch 213/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.2226 - accuracy: 0.4317 - val_loss: 1.2356 - val_accuracy: 0.4255\n",
            "Epoch 214/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.2228 - accuracy: 0.4315 - val_loss: 1.2199 - val_accuracy: 0.4325\n",
            "Epoch 215/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.2198 - accuracy: 0.4331 - val_loss: 1.2203 - val_accuracy: 0.4332\n",
            "Epoch 216/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.2248 - accuracy: 0.4303 - val_loss: 1.2191 - val_accuracy: 0.4335\n",
            "Epoch 217/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.2189 - accuracy: 0.4337 - val_loss: 1.2196 - val_accuracy: 0.4338\n",
            "Epoch 218/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.2188 - accuracy: 0.4338 - val_loss: 1.2198 - val_accuracy: 0.4330\n",
            "Epoch 219/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.2192 - accuracy: 0.4336 - val_loss: 1.2197 - val_accuracy: 0.4339\n",
            "Epoch 220/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.2187 - accuracy: 0.4339 - val_loss: 1.2190 - val_accuracy: 0.4344\n",
            "Epoch 221/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.2186 - accuracy: 0.4340 - val_loss: 1.2186 - val_accuracy: 0.4351\n",
            "Epoch 222/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.2183 - accuracy: 0.4342 - val_loss: 1.2177 - val_accuracy: 0.4346\n",
            "Epoch 223/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.2178 - accuracy: 0.4346 - val_loss: 1.2193 - val_accuracy: 0.4340\n",
            "Epoch 224/3000\n",
            "76/76 [==============================] - 15s 196ms/step - loss: 1.2175 - accuracy: 0.4347 - val_loss: 1.2172 - val_accuracy: 0.4363\n",
            "Epoch 225/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.2243 - accuracy: 0.4308 - val_loss: 1.2178 - val_accuracy: 0.4345\n",
            "Epoch 226/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.2162 - accuracy: 0.4355 - val_loss: 1.2166 - val_accuracy: 0.4353\n",
            "Epoch 227/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.2167 - accuracy: 0.4352 - val_loss: 1.2173 - val_accuracy: 0.4348\n",
            "Epoch 228/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.2164 - accuracy: 0.4355 - val_loss: 1.2164 - val_accuracy: 0.4351\n",
            "Epoch 229/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.2161 - accuracy: 0.4355 - val_loss: 1.2159 - val_accuracy: 0.4366\n",
            "Epoch 230/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.2195 - accuracy: 0.4337 - val_loss: 1.2157 - val_accuracy: 0.4363\n",
            "Epoch 231/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.2148 - accuracy: 0.4364 - val_loss: 1.2167 - val_accuracy: 0.4346\n",
            "Epoch 232/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.2191 - accuracy: 0.4337 - val_loss: 1.2148 - val_accuracy: 0.4367\n",
            "Epoch 233/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.2145 - accuracy: 0.4367 - val_loss: 1.2151 - val_accuracy: 0.4370\n",
            "Epoch 234/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.2149 - accuracy: 0.4365 - val_loss: 1.2144 - val_accuracy: 0.4371\n",
            "Epoch 235/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.2147 - accuracy: 0.4365 - val_loss: 1.2146 - val_accuracy: 0.4371\n",
            "Epoch 236/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.2144 - accuracy: 0.4367 - val_loss: 1.2157 - val_accuracy: 0.4360\n",
            "Epoch 237/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2182 - accuracy: 0.4346 - val_loss: 1.2137 - val_accuracy: 0.4371\n",
            "Epoch 238/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.2138 - accuracy: 0.4371 - val_loss: 1.2136 - val_accuracy: 0.4387\n",
            "Epoch 239/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.2135 - accuracy: 0.4373 - val_loss: 1.2129 - val_accuracy: 0.4383\n",
            "Epoch 240/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.2132 - accuracy: 0.4375 - val_loss: 1.2173 - val_accuracy: 0.4358\n",
            "Epoch 241/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.2172 - accuracy: 0.4353 - val_loss: 1.2122 - val_accuracy: 0.4381\n",
            "Epoch 242/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.2122 - accuracy: 0.4381 - val_loss: 1.2125 - val_accuracy: 0.4384\n",
            "Epoch 243/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.2128 - accuracy: 0.4377 - val_loss: 1.2125 - val_accuracy: 0.4377\n",
            "Epoch 244/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.2124 - accuracy: 0.4381 - val_loss: 1.2155 - val_accuracy: 0.4365\n",
            "Epoch 245/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.2129 - accuracy: 0.4378 - val_loss: 1.2142 - val_accuracy: 0.4355\n",
            "Epoch 246/3000\n",
            "76/76 [==============================] - 15s 202ms/step - loss: 1.2121 - accuracy: 0.4383 - val_loss: 1.2116 - val_accuracy: 0.4383\n",
            "Epoch 247/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.2115 - accuracy: 0.4387 - val_loss: 1.2133 - val_accuracy: 0.4380\n",
            "Epoch 248/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.2114 - accuracy: 0.4388 - val_loss: 1.2111 - val_accuracy: 0.4386\n",
            "Epoch 249/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.2110 - accuracy: 0.4390 - val_loss: 1.2111 - val_accuracy: 0.4389\n",
            "Epoch 250/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.2112 - accuracy: 0.4389 - val_loss: 1.2125 - val_accuracy: 0.4384\n",
            "Epoch 251/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.2106 - accuracy: 0.4393 - val_loss: 1.2104 - val_accuracy: 0.4392\n",
            "Epoch 252/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.2104 - accuracy: 0.4395 - val_loss: 1.2105 - val_accuracy: 0.4393\n",
            "Epoch 253/3000\n",
            "76/76 [==============================] - 14s 190ms/step - loss: 1.2141 - accuracy: 0.4373 - val_loss: 1.2085 - val_accuracy: 0.4407\n",
            "Epoch 254/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.2094 - accuracy: 0.4400 - val_loss: 1.2090 - val_accuracy: 0.4403\n",
            "Epoch 255/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.2097 - accuracy: 0.4398 - val_loss: 1.2096 - val_accuracy: 0.4389\n",
            "Epoch 256/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.2167 - accuracy: 0.4361 - val_loss: 1.2079 - val_accuracy: 0.4406\n",
            "Epoch 257/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.2085 - accuracy: 0.4406 - val_loss: 1.2090 - val_accuracy: 0.4396\n",
            "Epoch 258/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.2087 - accuracy: 0.4404 - val_loss: 1.2079 - val_accuracy: 0.4409\n",
            "Epoch 259/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.2087 - accuracy: 0.4405 - val_loss: 1.2072 - val_accuracy: 0.4406\n",
            "Epoch 260/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.2087 - accuracy: 0.4405 - val_loss: 1.2086 - val_accuracy: 0.4405\n",
            "Epoch 261/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.2084 - accuracy: 0.4406 - val_loss: 1.2085 - val_accuracy: 0.4396\n",
            "Epoch 262/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.2164 - accuracy: 0.4364 - val_loss: 1.2115 - val_accuracy: 0.4386\n",
            "Epoch 263/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.2072 - accuracy: 0.4413 - val_loss: 1.2056 - val_accuracy: 0.4423\n",
            "Epoch 264/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.2071 - accuracy: 0.4415 - val_loss: 1.2063 - val_accuracy: 0.4421\n",
            "Epoch 265/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.2071 - accuracy: 0.4415 - val_loss: 1.2061 - val_accuracy: 0.4423\n",
            "Epoch 266/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.2068 - accuracy: 0.4418 - val_loss: 1.2055 - val_accuracy: 0.4421\n",
            "Epoch 267/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.2068 - accuracy: 0.4417 - val_loss: 1.2061 - val_accuracy: 0.4421\n",
            "Epoch 268/3000\n",
            "76/76 [==============================] - 15s 202ms/step - loss: 1.2063 - accuracy: 0.4420 - val_loss: 1.2058 - val_accuracy: 0.4414\n",
            "Epoch 269/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.2129 - accuracy: 0.4382 - val_loss: 1.2107 - val_accuracy: 0.4390\n",
            "Epoch 270/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.2060 - accuracy: 0.4421 - val_loss: 1.2038 - val_accuracy: 0.4422\n",
            "Epoch 271/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.2050 - accuracy: 0.4428 - val_loss: 1.2061 - val_accuracy: 0.4417\n",
            "Epoch 272/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.2054 - accuracy: 0.4426 - val_loss: 1.2051 - val_accuracy: 0.4410\n",
            "Epoch 273/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.2052 - accuracy: 0.4427 - val_loss: 1.2045 - val_accuracy: 0.4434\n",
            "Epoch 274/3000\n",
            "76/76 [==============================] - 14s 190ms/step - loss: 1.2049 - accuracy: 0.4428 - val_loss: 1.2062 - val_accuracy: 0.4423\n",
            "Epoch 275/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.2195 - accuracy: 0.4353 - val_loss: 1.2113 - val_accuracy: 0.4389\n",
            "Epoch 276/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.2060 - accuracy: 0.4424 - val_loss: 1.2033 - val_accuracy: 0.4438\n",
            "Epoch 277/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.2043 - accuracy: 0.4431 - val_loss: 1.2024 - val_accuracy: 0.4436\n",
            "Epoch 278/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.2041 - accuracy: 0.4432 - val_loss: 1.2040 - val_accuracy: 0.4422\n",
            "Epoch 279/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.2042 - accuracy: 0.4434 - val_loss: 1.2022 - val_accuracy: 0.4440\n",
            "Epoch 280/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.2099 - accuracy: 0.4403 - val_loss: 1.2327 - val_accuracy: 0.4286\n",
            "Epoch 281/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.2132 - accuracy: 0.4389 - val_loss: 1.2037 - val_accuracy: 0.4423\n",
            "Epoch 282/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.2031 - accuracy: 0.4440 - val_loss: 1.2023 - val_accuracy: 0.4445\n",
            "Epoch 283/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.2035 - accuracy: 0.4437 - val_loss: 1.2027 - val_accuracy: 0.4435\n",
            "Epoch 284/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.2031 - accuracy: 0.4439 - val_loss: 1.2024 - val_accuracy: 0.4452\n",
            "Epoch 285/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.2028 - accuracy: 0.4442 - val_loss: 1.2028 - val_accuracy: 0.4440\n",
            "Epoch 286/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.2087 - accuracy: 0.4410 - val_loss: 1.2033 - val_accuracy: 0.4432\n",
            "Epoch 287/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.2015 - accuracy: 0.4448 - val_loss: 1.2016 - val_accuracy: 0.4446\n",
            "Epoch 288/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.2022 - accuracy: 0.4445 - val_loss: 1.2004 - val_accuracy: 0.4450\n",
            "Epoch 289/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.2020 - accuracy: 0.4447 - val_loss: 1.2300 - val_accuracy: 0.4316\n",
            "Epoch 290/3000\n",
            "76/76 [==============================] - 15s 204ms/step - loss: 1.2150 - accuracy: 0.4380 - val_loss: 1.2008 - val_accuracy: 0.4449\n",
            "Epoch 291/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.2013 - accuracy: 0.4450 - val_loss: 1.2018 - val_accuracy: 0.4449\n",
            "Epoch 292/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.2011 - accuracy: 0.4452 - val_loss: 1.2024 - val_accuracy: 0.4454\n",
            "Epoch 293/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.2120 - accuracy: 0.4395 - val_loss: 1.2120 - val_accuracy: 0.4394\n",
            "Epoch 294/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.2084 - accuracy: 0.4416 - val_loss: 1.2061 - val_accuracy: 0.4419\n",
            "Epoch 295/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.2032 - accuracy: 0.4439 - val_loss: 1.2009 - val_accuracy: 0.4450\n",
            "Epoch 296/3000\n",
            "76/76 [==============================] - 15s 191ms/step - loss: 1.2006 - accuracy: 0.4454 - val_loss: 1.2019 - val_accuracy: 0.4446\n",
            "Epoch 297/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.2011 - accuracy: 0.4451 - val_loss: 1.2010 - val_accuracy: 0.4456\n",
            "Epoch 298/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.2005 - accuracy: 0.4455 - val_loss: 1.1989 - val_accuracy: 0.4450\n",
            "Epoch 299/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.2098 - accuracy: 0.4409 - val_loss: 1.2036 - val_accuracy: 0.4435\n",
            "Epoch 300/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.2002 - accuracy: 0.4456 - val_loss: 1.2005 - val_accuracy: 0.4460\n",
            "Epoch 301/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.2000 - accuracy: 0.4457 - val_loss: 1.1986 - val_accuracy: 0.4456\n",
            "Epoch 302/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.2082 - accuracy: 0.4416 - val_loss: 1.1993 - val_accuracy: 0.4459\n",
            "Epoch 303/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1994 - accuracy: 0.4460 - val_loss: 1.2016 - val_accuracy: 0.4447\n",
            "Epoch 304/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.2006 - accuracy: 0.4454 - val_loss: 1.2011 - val_accuracy: 0.4451\n",
            "Epoch 305/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.2022 - accuracy: 0.4447 - val_loss: 1.1975 - val_accuracy: 0.4466\n",
            "Epoch 306/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1987 - accuracy: 0.4465 - val_loss: 1.1981 - val_accuracy: 0.4473\n",
            "Epoch 307/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1988 - accuracy: 0.4464 - val_loss: 1.1991 - val_accuracy: 0.4468\n",
            "Epoch 308/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1989 - accuracy: 0.4464 - val_loss: 1.1995 - val_accuracy: 0.4459\n",
            "Epoch 309/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1985 - accuracy: 0.4467 - val_loss: 1.1988 - val_accuracy: 0.4465\n",
            "Epoch 310/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.2063 - accuracy: 0.4424 - val_loss: 1.1998 - val_accuracy: 0.4459\n",
            "Epoch 311/3000\n",
            "76/76 [==============================] - 15s 194ms/step - loss: 1.1976 - accuracy: 0.4470 - val_loss: 1.1967 - val_accuracy: 0.4473\n",
            "Epoch 312/3000\n",
            "76/76 [==============================] - 15s 195ms/step - loss: 1.1974 - accuracy: 0.4473 - val_loss: 1.1977 - val_accuracy: 0.4469\n",
            "Epoch 313/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1979 - accuracy: 0.4470 - val_loss: 1.2000 - val_accuracy: 0.4461\n",
            "Epoch 314/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1979 - accuracy: 0.4470 - val_loss: 1.1975 - val_accuracy: 0.4471\n",
            "Epoch 315/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1975 - accuracy: 0.4472 - val_loss: 1.1969 - val_accuracy: 0.4479\n",
            "Epoch 316/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.2036 - accuracy: 0.4441 - val_loss: 1.1974 - val_accuracy: 0.4474\n",
            "Epoch 317/3000\n",
            "76/76 [==============================] - 14s 191ms/step - loss: 1.1967 - accuracy: 0.4478 - val_loss: 1.1960 - val_accuracy: 0.4476\n",
            "Epoch 318/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1972 - accuracy: 0.4474 - val_loss: 1.1955 - val_accuracy: 0.4484\n",
            "Epoch 319/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1974 - accuracy: 0.4473 - val_loss: 1.1982 - val_accuracy: 0.4467\n",
            "Epoch 320/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.2080 - accuracy: 0.4419 - val_loss: 1.2075 - val_accuracy: 0.4420\n",
            "Epoch 321/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.2003 - accuracy: 0.4459 - val_loss: 1.1959 - val_accuracy: 0.4485\n",
            "Epoch 322/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1969 - accuracy: 0.4476 - val_loss: 1.1976 - val_accuracy: 0.4468\n",
            "Epoch 323/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1967 - accuracy: 0.4477 - val_loss: 1.1963 - val_accuracy: 0.4483\n",
            "Epoch 324/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.2148 - accuracy: 0.4382 - val_loss: 1.2113 - val_accuracy: 0.4413\n",
            "Epoch 325/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.2067 - accuracy: 0.4430 - val_loss: 1.2038 - val_accuracy: 0.4441\n",
            "Epoch 326/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.2032 - accuracy: 0.4447 - val_loss: 1.2024 - val_accuracy: 0.4445\n",
            "Epoch 327/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.2017 - accuracy: 0.4451 - val_loss: 1.1975 - val_accuracy: 0.4473\n",
            "Epoch 328/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1969 - accuracy: 0.4476 - val_loss: 1.1952 - val_accuracy: 0.4487\n",
            "Epoch 329/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1964 - accuracy: 0.4478 - val_loss: 1.1963 - val_accuracy: 0.4485\n",
            "Epoch 330/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.2135 - accuracy: 0.4393 - val_loss: 1.2042 - val_accuracy: 0.4442\n",
            "Epoch 331/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.2029 - accuracy: 0.4449 - val_loss: 1.2017 - val_accuracy: 0.4449\n",
            "Epoch 332/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.2011 - accuracy: 0.4455 - val_loss: 1.1963 - val_accuracy: 0.4482\n",
            "Epoch 333/3000\n",
            "76/76 [==============================] - 15s 202ms/step - loss: 1.2022 - accuracy: 0.4449 - val_loss: 1.1998 - val_accuracy: 0.4464\n",
            "Epoch 334/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1961 - accuracy: 0.4480 - val_loss: 1.1944 - val_accuracy: 0.4493\n",
            "Epoch 335/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1963 - accuracy: 0.4478 - val_loss: 1.1944 - val_accuracy: 0.4493\n",
            "Epoch 336/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.2011 - accuracy: 0.4455 - val_loss: 1.2196 - val_accuracy: 0.4359\n",
            "Epoch 337/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.2009 - accuracy: 0.4454 - val_loss: 1.2003 - val_accuracy: 0.4459\n",
            "Epoch 338/3000\n",
            "76/76 [==============================] - 14s 189ms/step - loss: 1.1971 - accuracy: 0.4474 - val_loss: 1.1939 - val_accuracy: 0.4495\n",
            "Epoch 339/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1945 - accuracy: 0.4490 - val_loss: 1.1950 - val_accuracy: 0.4489\n",
            "Epoch 340/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1949 - accuracy: 0.4488 - val_loss: 1.1943 - val_accuracy: 0.4502\n",
            "Epoch 341/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1947 - accuracy: 0.4489 - val_loss: 1.1944 - val_accuracy: 0.4497\n",
            "Epoch 342/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1951 - accuracy: 0.4487 - val_loss: 1.1935 - val_accuracy: 0.4501\n",
            "Epoch 343/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1945 - accuracy: 0.4491 - val_loss: 1.1955 - val_accuracy: 0.4497\n",
            "Epoch 344/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1947 - accuracy: 0.4489 - val_loss: 1.1950 - val_accuracy: 0.4491\n",
            "Epoch 345/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1946 - accuracy: 0.4490 - val_loss: 1.1938 - val_accuracy: 0.4505\n",
            "Epoch 346/3000\n",
            "76/76 [==============================] - 14s 191ms/step - loss: 1.1949 - accuracy: 0.4489 - val_loss: 1.2005 - val_accuracy: 0.4463\n",
            "Epoch 347/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1944 - accuracy: 0.4491 - val_loss: 1.1936 - val_accuracy: 0.4500\n",
            "Epoch 348/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1941 - accuracy: 0.4493 - val_loss: 1.1992 - val_accuracy: 0.4467\n",
            "Epoch 349/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.2077 - accuracy: 0.4425 - val_loss: 1.1985 - val_accuracy: 0.4472\n",
            "Epoch 350/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1943 - accuracy: 0.4492 - val_loss: 1.1921 - val_accuracy: 0.4506\n",
            "Epoch 351/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1937 - accuracy: 0.4495 - val_loss: 1.1928 - val_accuracy: 0.4499\n",
            "Epoch 352/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.2002 - accuracy: 0.4461 - val_loss: 1.2027 - val_accuracy: 0.4454\n",
            "Epoch 353/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1942 - accuracy: 0.4492 - val_loss: 1.1924 - val_accuracy: 0.4507\n",
            "Epoch 354/3000\n",
            "76/76 [==============================] - 14s 190ms/step - loss: 1.1929 - accuracy: 0.4500 - val_loss: 1.1923 - val_accuracy: 0.4511\n",
            "Epoch 355/3000\n",
            "76/76 [==============================] - 15s 198ms/step - loss: 1.1937 - accuracy: 0.4496 - val_loss: 1.1928 - val_accuracy: 0.4503\n",
            "Epoch 356/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1931 - accuracy: 0.4499 - val_loss: 1.1921 - val_accuracy: 0.4512\n",
            "Epoch 357/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1937 - accuracy: 0.4495 - val_loss: 1.1922 - val_accuracy: 0.4511\n",
            "Epoch 358/3000\n",
            "76/76 [==============================] - 14s 189ms/step - loss: 1.2098 - accuracy: 0.4413 - val_loss: 1.2108 - val_accuracy: 0.4416\n",
            "Epoch 359/3000\n",
            "76/76 [==============================] - 14s 190ms/step - loss: 1.2036 - accuracy: 0.4449 - val_loss: 1.2000 - val_accuracy: 0.4464\n",
            "Epoch 360/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1996 - accuracy: 0.4468 - val_loss: 1.1979 - val_accuracy: 0.4474\n",
            "Epoch 361/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1950 - accuracy: 0.4488 - val_loss: 1.1927 - val_accuracy: 0.4505\n",
            "Epoch 362/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1933 - accuracy: 0.4498 - val_loss: 1.1918 - val_accuracy: 0.4513\n",
            "Epoch 363/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1934 - accuracy: 0.4497 - val_loss: 1.1921 - val_accuracy: 0.4511\n",
            "Epoch 364/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1929 - accuracy: 0.4501 - val_loss: 1.1927 - val_accuracy: 0.4510\n",
            "Epoch 365/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1929 - accuracy: 0.4501 - val_loss: 1.1922 - val_accuracy: 0.4512\n",
            "Epoch 366/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1929 - accuracy: 0.4501 - val_loss: 1.1925 - val_accuracy: 0.4514\n",
            "Epoch 367/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1924 - accuracy: 0.4504 - val_loss: 1.1912 - val_accuracy: 0.4516\n",
            "Epoch 368/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1945 - accuracy: 0.4492 - val_loss: 1.1907 - val_accuracy: 0.4519\n",
            "Epoch 369/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1920 - accuracy: 0.4507 - val_loss: 1.1907 - val_accuracy: 0.4517\n",
            "Epoch 370/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1924 - accuracy: 0.4505 - val_loss: 1.1909 - val_accuracy: 0.4530\n",
            "Epoch 371/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1920 - accuracy: 0.4507 - val_loss: 1.1919 - val_accuracy: 0.4522\n",
            "Epoch 372/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1919 - accuracy: 0.4508 - val_loss: 1.1902 - val_accuracy: 0.4526\n",
            "Epoch 373/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1918 - accuracy: 0.4509 - val_loss: 1.1903 - val_accuracy: 0.4530\n",
            "Epoch 374/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.2099 - accuracy: 0.4416 - val_loss: 1.2013 - val_accuracy: 0.4462\n",
            "Epoch 375/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1986 - accuracy: 0.4475 - val_loss: 1.1964 - val_accuracy: 0.4489\n",
            "Epoch 376/3000\n",
            "76/76 [==============================] - 16s 205ms/step - loss: 1.1929 - accuracy: 0.4503 - val_loss: 1.1911 - val_accuracy: 0.4516\n",
            "Epoch 377/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1913 - accuracy: 0.4512 - val_loss: 1.1903 - val_accuracy: 0.4525\n",
            "Epoch 378/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1915 - accuracy: 0.4511 - val_loss: 1.1943 - val_accuracy: 0.4507\n",
            "Epoch 379/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1918 - accuracy: 0.4508 - val_loss: 1.1929 - val_accuracy: 0.4513\n",
            "Epoch 380/3000\n",
            "76/76 [==============================] - 14s 191ms/step - loss: 1.2093 - accuracy: 0.4418 - val_loss: 1.2016 - val_accuracy: 0.4462\n",
            "Epoch 381/3000\n",
            "76/76 [==============================] - 14s 189ms/step - loss: 1.1987 - accuracy: 0.4475 - val_loss: 1.2040 - val_accuracy: 0.4440\n",
            "Epoch 382/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1971 - accuracy: 0.4482 - val_loss: 1.1930 - val_accuracy: 0.4499\n",
            "Epoch 383/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1911 - accuracy: 0.4513 - val_loss: 1.1907 - val_accuracy: 0.4524\n",
            "Epoch 384/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1982 - accuracy: 0.4476 - val_loss: 1.2036 - val_accuracy: 0.4460\n",
            "Epoch 385/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1962 - accuracy: 0.4482 - val_loss: 1.1900 - val_accuracy: 0.4522\n",
            "Epoch 386/3000\n",
            "76/76 [==============================] - 14s 189ms/step - loss: 1.1897 - accuracy: 0.4521 - val_loss: 1.1896 - val_accuracy: 0.4531\n",
            "Epoch 387/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1938 - accuracy: 0.4499 - val_loss: 1.1909 - val_accuracy: 0.4509\n",
            "Epoch 388/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1897 - accuracy: 0.4521 - val_loss: 1.1895 - val_accuracy: 0.4526\n",
            "Epoch 389/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1904 - accuracy: 0.4517 - val_loss: 1.1900 - val_accuracy: 0.4526\n",
            "Epoch 390/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1903 - accuracy: 0.4519 - val_loss: 1.1899 - val_accuracy: 0.4530\n",
            "Epoch 391/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1899 - accuracy: 0.4522 - val_loss: 1.1891 - val_accuracy: 0.4535\n",
            "Epoch 392/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1903 - accuracy: 0.4519 - val_loss: 1.1892 - val_accuracy: 0.4528\n",
            "Epoch 393/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1901 - accuracy: 0.4520 - val_loss: 1.1901 - val_accuracy: 0.4524\n",
            "Epoch 394/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1899 - accuracy: 0.4522 - val_loss: 1.1936 - val_accuracy: 0.4515\n",
            "Epoch 395/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1965 - accuracy: 0.4485 - val_loss: 1.1881 - val_accuracy: 0.4536\n",
            "Epoch 396/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1884 - accuracy: 0.4530 - val_loss: 1.1887 - val_accuracy: 0.4542\n",
            "Epoch 397/3000\n",
            "76/76 [==============================] - 15s 198ms/step - loss: 1.1891 - accuracy: 0.4527 - val_loss: 1.1900 - val_accuracy: 0.4533\n",
            "Epoch 398/3000\n",
            "76/76 [==============================] - 15s 196ms/step - loss: 1.1895 - accuracy: 0.4524 - val_loss: 1.1887 - val_accuracy: 0.4542\n",
            "Epoch 399/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1956 - accuracy: 0.4493 - val_loss: 1.1879 - val_accuracy: 0.4540\n",
            "Epoch 400/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1884 - accuracy: 0.4530 - val_loss: 1.1877 - val_accuracy: 0.4539\n",
            "Epoch 401/3000\n",
            "76/76 [==============================] - 14s 189ms/step - loss: 1.1893 - accuracy: 0.4525 - val_loss: 1.1932 - val_accuracy: 0.4511\n",
            "Epoch 402/3000\n",
            "76/76 [==============================] - 14s 190ms/step - loss: 1.1889 - accuracy: 0.4528 - val_loss: 1.1889 - val_accuracy: 0.4537\n",
            "Epoch 403/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1892 - accuracy: 0.4526 - val_loss: 1.1876 - val_accuracy: 0.4550\n",
            "Epoch 404/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1883 - accuracy: 0.4531 - val_loss: 1.1876 - val_accuracy: 0.4543\n",
            "Epoch 405/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1887 - accuracy: 0.4530 - val_loss: 1.1893 - val_accuracy: 0.4540\n",
            "Epoch 406/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1883 - accuracy: 0.4531 - val_loss: 1.1898 - val_accuracy: 0.4529\n",
            "Epoch 407/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1886 - accuracy: 0.4529 - val_loss: 1.1874 - val_accuracy: 0.4544\n",
            "Epoch 408/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1883 - accuracy: 0.4532 - val_loss: 1.1877 - val_accuracy: 0.4540\n",
            "Epoch 409/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1875 - accuracy: 0.4535 - val_loss: 1.1889 - val_accuracy: 0.4536\n",
            "Epoch 410/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1911 - accuracy: 0.4518 - val_loss: 1.1866 - val_accuracy: 0.4556\n",
            "Epoch 411/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1876 - accuracy: 0.4535 - val_loss: 1.1891 - val_accuracy: 0.4530\n",
            "Epoch 412/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1876 - accuracy: 0.4535 - val_loss: 1.1873 - val_accuracy: 0.4549\n",
            "Epoch 413/3000\n",
            "76/76 [==============================] - 14s 189ms/step - loss: 1.2047 - accuracy: 0.4448 - val_loss: 1.1984 - val_accuracy: 0.4488\n",
            "Epoch 414/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1943 - accuracy: 0.4502 - val_loss: 1.1914 - val_accuracy: 0.4529\n",
            "Epoch 415/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1878 - accuracy: 0.4534 - val_loss: 1.1870 - val_accuracy: 0.4547\n",
            "Epoch 416/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1875 - accuracy: 0.4536 - val_loss: 1.1870 - val_accuracy: 0.4546\n",
            "Epoch 417/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1873 - accuracy: 0.4537 - val_loss: 1.1867 - val_accuracy: 0.4548\n",
            "Epoch 418/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1871 - accuracy: 0.4539 - val_loss: 1.1897 - val_accuracy: 0.4534\n",
            "Epoch 419/3000\n",
            "76/76 [==============================] - 16s 206ms/step - loss: 1.1871 - accuracy: 0.4538 - val_loss: 1.1895 - val_accuracy: 0.4532\n",
            "Epoch 420/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1866 - accuracy: 0.4541 - val_loss: 1.1862 - val_accuracy: 0.4547\n",
            "Epoch 421/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1870 - accuracy: 0.4539 - val_loss: 1.1863 - val_accuracy: 0.4550\n",
            "Epoch 422/3000\n",
            "76/76 [==============================] - 14s 190ms/step - loss: 1.1866 - accuracy: 0.4542 - val_loss: 1.1861 - val_accuracy: 0.4557\n",
            "Epoch 423/3000\n",
            "76/76 [==============================] - 14s 190ms/step - loss: 1.1866 - accuracy: 0.4542 - val_loss: 1.1878 - val_accuracy: 0.4545\n",
            "Epoch 424/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1859 - accuracy: 0.4545 - val_loss: 1.1875 - val_accuracy: 0.4547\n",
            "Epoch 425/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1866 - accuracy: 0.4541 - val_loss: 1.1853 - val_accuracy: 0.4558\n",
            "Epoch 426/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1857 - accuracy: 0.4547 - val_loss: 1.2070 - val_accuracy: 0.4445\n",
            "Epoch 427/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1996 - accuracy: 0.4470 - val_loss: 1.1901 - val_accuracy: 0.4529\n",
            "Epoch 428/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1848 - accuracy: 0.4550 - val_loss: 1.1846 - val_accuracy: 0.4560\n",
            "Epoch 429/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1849 - accuracy: 0.4551 - val_loss: 1.1855 - val_accuracy: 0.4559\n",
            "Epoch 430/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1853 - accuracy: 0.4549 - val_loss: 1.1869 - val_accuracy: 0.4548\n",
            "Epoch 431/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1857 - accuracy: 0.4547 - val_loss: 1.1864 - val_accuracy: 0.4549\n",
            "Epoch 432/3000\n",
            "76/76 [==============================] - 14s 189ms/step - loss: 1.1850 - accuracy: 0.4552 - val_loss: 1.1869 - val_accuracy: 0.4549\n",
            "Epoch 433/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1855 - accuracy: 0.4549 - val_loss: 1.1852 - val_accuracy: 0.4552\n",
            "Epoch 434/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1981 - accuracy: 0.4483 - val_loss: 1.1865 - val_accuracy: 0.4551\n",
            "Epoch 435/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1844 - accuracy: 0.4553 - val_loss: 1.1852 - val_accuracy: 0.4547\n",
            "Epoch 436/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1850 - accuracy: 0.4551 - val_loss: 1.1842 - val_accuracy: 0.4555\n",
            "Epoch 437/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1852 - accuracy: 0.4551 - val_loss: 1.1857 - val_accuracy: 0.4548\n",
            "Epoch 438/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1848 - accuracy: 0.4552 - val_loss: 1.1864 - val_accuracy: 0.4547\n",
            "Epoch 439/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.2028 - accuracy: 0.4460 - val_loss: 1.1990 - val_accuracy: 0.4484\n",
            "Epoch 440/3000\n",
            "76/76 [==============================] - 15s 195ms/step - loss: 1.1912 - accuracy: 0.4519 - val_loss: 1.1853 - val_accuracy: 0.4556\n",
            "Epoch 441/3000\n",
            "76/76 [==============================] - 15s 198ms/step - loss: 1.1845 - accuracy: 0.4554 - val_loss: 1.1846 - val_accuracy: 0.4559\n",
            "Epoch 442/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1846 - accuracy: 0.4553 - val_loss: 1.1838 - val_accuracy: 0.4566\n",
            "Epoch 443/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1848 - accuracy: 0.4552 - val_loss: 1.1864 - val_accuracy: 0.4554\n",
            "Epoch 444/3000\n",
            "76/76 [==============================] - 15s 191ms/step - loss: 1.1844 - accuracy: 0.4555 - val_loss: 1.1858 - val_accuracy: 0.4558\n",
            "Epoch 445/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1846 - accuracy: 0.4554 - val_loss: 1.1877 - val_accuracy: 0.4545\n",
            "Epoch 446/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1847 - accuracy: 0.4553 - val_loss: 1.1853 - val_accuracy: 0.4551\n",
            "Epoch 447/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.2077 - accuracy: 0.4435 - val_loss: 1.1976 - val_accuracy: 0.4493\n",
            "Epoch 448/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1932 - accuracy: 0.4511 - val_loss: 1.1911 - val_accuracy: 0.4531\n",
            "Epoch 449/3000\n",
            "76/76 [==============================] - 14s 189ms/step - loss: 1.1879 - accuracy: 0.4534 - val_loss: 1.1853 - val_accuracy: 0.4559\n",
            "Epoch 450/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1844 - accuracy: 0.4554 - val_loss: 1.1849 - val_accuracy: 0.4555\n",
            "Epoch 451/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1845 - accuracy: 0.4555 - val_loss: 1.1842 - val_accuracy: 0.4567\n",
            "Epoch 452/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1843 - accuracy: 0.4555 - val_loss: 1.1852 - val_accuracy: 0.4553\n",
            "Epoch 453/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1844 - accuracy: 0.4555 - val_loss: 1.1837 - val_accuracy: 0.4565\n",
            "Epoch 454/3000\n",
            "76/76 [==============================] - 14s 189ms/step - loss: 1.1838 - accuracy: 0.4558 - val_loss: 1.1854 - val_accuracy: 0.4568\n",
            "Epoch 455/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1841 - accuracy: 0.4557 - val_loss: 1.1879 - val_accuracy: 0.4537\n",
            "Epoch 456/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1917 - accuracy: 0.4516 - val_loss: 1.1835 - val_accuracy: 0.4564\n",
            "Epoch 457/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1828 - accuracy: 0.4564 - val_loss: 1.1831 - val_accuracy: 0.4566\n",
            "Epoch 458/3000\n",
            "76/76 [==============================] - 15s 191ms/step - loss: 1.1837 - accuracy: 0.4559 - val_loss: 1.1841 - val_accuracy: 0.4569\n",
            "Epoch 459/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1835 - accuracy: 0.4560 - val_loss: 1.1837 - val_accuracy: 0.4559\n",
            "Epoch 460/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1838 - accuracy: 0.4557 - val_loss: 1.1850 - val_accuracy: 0.4569\n",
            "Epoch 461/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1833 - accuracy: 0.4561 - val_loss: 1.1862 - val_accuracy: 0.4550\n",
            "Epoch 462/3000\n",
            "76/76 [==============================] - 16s 207ms/step - loss: 1.1833 - accuracy: 0.4562 - val_loss: 1.1868 - val_accuracy: 0.4552\n",
            "Epoch 463/3000\n",
            "76/76 [==============================] - 14s 189ms/step - loss: 1.1832 - accuracy: 0.4563 - val_loss: 1.1840 - val_accuracy: 0.4567\n",
            "Epoch 464/3000\n",
            "76/76 [==============================] - 15s 192ms/step - loss: 1.1831 - accuracy: 0.4563 - val_loss: 1.1833 - val_accuracy: 0.4572\n",
            "Epoch 465/3000\n",
            "76/76 [==============================] - 14s 189ms/step - loss: 1.1830 - accuracy: 0.4563 - val_loss: 1.1832 - val_accuracy: 0.4563\n",
            "Epoch 466/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1833 - accuracy: 0.4561 - val_loss: 1.1979 - val_accuracy: 0.4495\n",
            "Epoch 467/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.2089 - accuracy: 0.4431 - val_loss: 1.1953 - val_accuracy: 0.4506\n",
            "Epoch 468/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1889 - accuracy: 0.4533 - val_loss: 1.1842 - val_accuracy: 0.4567\n",
            "Epoch 469/3000\n",
            "76/76 [==============================] - 14s 190ms/step - loss: 1.1828 - accuracy: 0.4564 - val_loss: 1.1835 - val_accuracy: 0.4563\n",
            "Epoch 470/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1825 - accuracy: 0.4565 - val_loss: 1.1837 - val_accuracy: 0.4569\n",
            "Epoch 471/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1827 - accuracy: 0.4565 - val_loss: 1.1877 - val_accuracy: 0.4534\n",
            "Epoch 472/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1832 - accuracy: 0.4562 - val_loss: 1.1829 - val_accuracy: 0.4558\n",
            "Epoch 473/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1826 - accuracy: 0.4566 - val_loss: 1.1847 - val_accuracy: 0.4562\n",
            "Epoch 474/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1830 - accuracy: 0.4564 - val_loss: 1.1822 - val_accuracy: 0.4568\n",
            "Epoch 475/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1823 - accuracy: 0.4568 - val_loss: 1.1829 - val_accuracy: 0.4572\n",
            "Epoch 476/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1827 - accuracy: 0.4566 - val_loss: 1.1866 - val_accuracy: 0.4547\n",
            "Epoch 477/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.2103 - accuracy: 0.4422 - val_loss: 1.1985 - val_accuracy: 0.4489\n",
            "Epoch 478/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1944 - accuracy: 0.4507 - val_loss: 1.1932 - val_accuracy: 0.4517\n",
            "Epoch 479/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1906 - accuracy: 0.4526 - val_loss: 1.1907 - val_accuracy: 0.4529\n",
            "Epoch 480/3000\n",
            "76/76 [==============================] - 14s 190ms/step - loss: 1.1878 - accuracy: 0.4538 - val_loss: 1.1874 - val_accuracy: 0.4549\n",
            "Epoch 481/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1853 - accuracy: 0.4551 - val_loss: 1.1851 - val_accuracy: 0.4554\n",
            "Epoch 482/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1824 - accuracy: 0.4567 - val_loss: 1.1831 - val_accuracy: 0.4570\n",
            "Epoch 483/3000\n",
            "76/76 [==============================] - 15s 199ms/step - loss: 1.1821 - accuracy: 0.4569 - val_loss: 1.1826 - val_accuracy: 0.4574\n",
            "Epoch 484/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1827 - accuracy: 0.4565 - val_loss: 1.1848 - val_accuracy: 0.4558\n",
            "Epoch 485/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1820 - accuracy: 0.4571 - val_loss: 1.1845 - val_accuracy: 0.4560\n",
            "Epoch 486/3000\n",
            "76/76 [==============================] - 15s 192ms/step - loss: 1.1823 - accuracy: 0.4568 - val_loss: 1.1824 - val_accuracy: 0.4576\n",
            "Epoch 487/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1815 - accuracy: 0.4573 - val_loss: 1.1843 - val_accuracy: 0.4575\n",
            "Epoch 488/3000\n",
            "76/76 [==============================] - 14s 189ms/step - loss: 1.1818 - accuracy: 0.4572 - val_loss: 1.1834 - val_accuracy: 0.4569\n",
            "Epoch 489/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1820 - accuracy: 0.4571 - val_loss: 1.1970 - val_accuracy: 0.4494\n",
            "Epoch 490/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.2083 - accuracy: 0.4436 - val_loss: 1.1959 - val_accuracy: 0.4495\n",
            "Epoch 491/3000\n",
            "76/76 [==============================] - 14s 190ms/step - loss: 1.1915 - accuracy: 0.4522 - val_loss: 1.1893 - val_accuracy: 0.4539\n",
            "Epoch 492/3000\n",
            "76/76 [==============================] - 14s 189ms/step - loss: 1.1872 - accuracy: 0.4542 - val_loss: 1.1864 - val_accuracy: 0.4559\n",
            "Epoch 493/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1822 - accuracy: 0.4569 - val_loss: 1.1839 - val_accuracy: 0.4566\n",
            "Epoch 494/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1818 - accuracy: 0.4570 - val_loss: 1.1818 - val_accuracy: 0.4573\n",
            "Epoch 495/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1815 - accuracy: 0.4573 - val_loss: 1.1848 - val_accuracy: 0.4555\n",
            "Epoch 496/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1817 - accuracy: 0.4573 - val_loss: 1.1934 - val_accuracy: 0.4510\n",
            "Epoch 497/3000\n",
            "76/76 [==============================] - 14s 189ms/step - loss: 1.1989 - accuracy: 0.4483 - val_loss: 1.1840 - val_accuracy: 0.4557\n",
            "Epoch 498/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1805 - accuracy: 0.4578 - val_loss: 1.1808 - val_accuracy: 0.4576\n",
            "Epoch 499/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1807 - accuracy: 0.4578 - val_loss: 1.1822 - val_accuracy: 0.4574\n",
            "Epoch 500/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1816 - accuracy: 0.4574 - val_loss: 1.2091 - val_accuracy: 0.4436\n",
            "Epoch 501/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1850 - accuracy: 0.4555 - val_loss: 1.1809 - val_accuracy: 0.4581\n",
            "Epoch 502/3000\n",
            "76/76 [==============================] - 15s 191ms/step - loss: 1.1810 - accuracy: 0.4576 - val_loss: 1.1889 - val_accuracy: 0.4533\n",
            "Epoch 503/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1810 - accuracy: 0.4576 - val_loss: 1.1825 - val_accuracy: 0.4568\n",
            "Epoch 504/3000\n",
            "76/76 [==============================] - 15s 195ms/step - loss: 1.1815 - accuracy: 0.4575 - val_loss: 1.1801 - val_accuracy: 0.4585\n",
            "Epoch 505/3000\n",
            "76/76 [==============================] - 15s 196ms/step - loss: 1.1806 - accuracy: 0.4580 - val_loss: 1.1810 - val_accuracy: 0.4581\n",
            "Epoch 506/3000\n",
            "76/76 [==============================] - 15s 192ms/step - loss: 1.1806 - accuracy: 0.4579 - val_loss: 1.1840 - val_accuracy: 0.4565\n",
            "Epoch 507/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1808 - accuracy: 0.4579 - val_loss: 1.1804 - val_accuracy: 0.4581\n",
            "Epoch 508/3000\n",
            "76/76 [==============================] - 14s 190ms/step - loss: 1.1810 - accuracy: 0.4577 - val_loss: 1.1809 - val_accuracy: 0.4576\n",
            "Epoch 509/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1802 - accuracy: 0.4581 - val_loss: 1.1813 - val_accuracy: 0.4575\n",
            "Epoch 510/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1804 - accuracy: 0.4581 - val_loss: 1.1800 - val_accuracy: 0.4586\n",
            "Epoch 511/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1807 - accuracy: 0.4579 - val_loss: 1.1825 - val_accuracy: 0.4563\n",
            "Epoch 512/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1803 - accuracy: 0.4581 - val_loss: 1.1808 - val_accuracy: 0.4578\n",
            "Epoch 513/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1801 - accuracy: 0.4582 - val_loss: 1.1794 - val_accuracy: 0.4592\n",
            "Epoch 514/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1801 - accuracy: 0.4582 - val_loss: 1.1812 - val_accuracy: 0.4574\n",
            "Epoch 515/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1802 - accuracy: 0.4581 - val_loss: 1.1793 - val_accuracy: 0.4588\n",
            "Epoch 516/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1799 - accuracy: 0.4584 - val_loss: 1.1803 - val_accuracy: 0.4577\n",
            "Epoch 517/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1799 - accuracy: 0.4584 - val_loss: 1.1800 - val_accuracy: 0.4581\n",
            "Epoch 518/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1805 - accuracy: 0.4580 - val_loss: 1.1795 - val_accuracy: 0.4588\n",
            "Epoch 519/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1797 - accuracy: 0.4585 - val_loss: 1.1793 - val_accuracy: 0.4592\n",
            "Epoch 520/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1795 - accuracy: 0.4587 - val_loss: 1.1801 - val_accuracy: 0.4592\n",
            "Epoch 521/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1798 - accuracy: 0.4585 - val_loss: 1.1824 - val_accuracy: 0.4575\n",
            "Epoch 522/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1796 - accuracy: 0.4585 - val_loss: 1.1790 - val_accuracy: 0.4590\n",
            "Epoch 523/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1795 - accuracy: 0.4585 - val_loss: 1.1800 - val_accuracy: 0.4583\n",
            "Epoch 524/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1797 - accuracy: 0.4585 - val_loss: 1.1802 - val_accuracy: 0.4580\n",
            "Epoch 525/3000\n",
            "76/76 [==============================] - 14s 189ms/step - loss: 1.1794 - accuracy: 0.4587 - val_loss: 1.1813 - val_accuracy: 0.4579\n",
            "Epoch 526/3000\n",
            "76/76 [==============================] - 15s 202ms/step - loss: 1.1793 - accuracy: 0.4587 - val_loss: 1.1787 - val_accuracy: 0.4591\n",
            "Epoch 527/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1793 - accuracy: 0.4587 - val_loss: 1.1792 - val_accuracy: 0.4592\n",
            "Epoch 528/3000\n",
            "76/76 [==============================] - 14s 189ms/step - loss: 1.1790 - accuracy: 0.4589 - val_loss: 1.1793 - val_accuracy: 0.4601\n",
            "Epoch 529/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1793 - accuracy: 0.4588 - val_loss: 1.1792 - val_accuracy: 0.4601\n",
            "Epoch 530/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1793 - accuracy: 0.4588 - val_loss: 1.1790 - val_accuracy: 0.4583\n",
            "Epoch 531/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1789 - accuracy: 0.4590 - val_loss: 1.1793 - val_accuracy: 0.4581\n",
            "Epoch 532/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1789 - accuracy: 0.4589 - val_loss: 1.1802 - val_accuracy: 0.4586\n",
            "Epoch 533/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1786 - accuracy: 0.4592 - val_loss: 1.1805 - val_accuracy: 0.4585\n",
            "Epoch 534/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1789 - accuracy: 0.4590 - val_loss: 1.1788 - val_accuracy: 0.4592\n",
            "Epoch 535/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1787 - accuracy: 0.4592 - val_loss: 1.1799 - val_accuracy: 0.4592\n",
            "Epoch 536/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1786 - accuracy: 0.4592 - val_loss: 1.1794 - val_accuracy: 0.4598\n",
            "Epoch 537/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1781 - accuracy: 0.4595 - val_loss: 1.1796 - val_accuracy: 0.4595\n",
            "Epoch 538/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1828 - accuracy: 0.4570 - val_loss: 1.1777 - val_accuracy: 0.4603\n",
            "Epoch 539/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1780 - accuracy: 0.4595 - val_loss: 1.1796 - val_accuracy: 0.4596\n",
            "Epoch 540/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1781 - accuracy: 0.4594 - val_loss: 1.1779 - val_accuracy: 0.4596\n",
            "Epoch 541/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1784 - accuracy: 0.4592 - val_loss: 1.1785 - val_accuracy: 0.4586\n",
            "Epoch 542/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1781 - accuracy: 0.4594 - val_loss: 1.1775 - val_accuracy: 0.4601\n",
            "Epoch 543/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1779 - accuracy: 0.4596 - val_loss: 1.1797 - val_accuracy: 0.4588\n",
            "Epoch 544/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1778 - accuracy: 0.4596 - val_loss: 1.1773 - val_accuracy: 0.4606\n",
            "Epoch 545/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1782 - accuracy: 0.4594 - val_loss: 1.1791 - val_accuracy: 0.4589\n",
            "Epoch 546/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1780 - accuracy: 0.4595 - val_loss: 1.1827 - val_accuracy: 0.4582\n",
            "Epoch 547/3000\n",
            "76/76 [==============================] - 15s 193ms/step - loss: 1.1776 - accuracy: 0.4598 - val_loss: 1.1786 - val_accuracy: 0.4589\n",
            "Epoch 548/3000\n",
            "76/76 [==============================] - 15s 198ms/step - loss: 1.1777 - accuracy: 0.4597 - val_loss: 1.1773 - val_accuracy: 0.4609\n",
            "Epoch 549/3000\n",
            "76/76 [==============================] - 15s 191ms/step - loss: 1.1778 - accuracy: 0.4597 - val_loss: 1.1785 - val_accuracy: 0.4582\n",
            "Epoch 550/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1775 - accuracy: 0.4598 - val_loss: 1.1794 - val_accuracy: 0.4584\n",
            "Epoch 551/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1778 - accuracy: 0.4597 - val_loss: 1.1796 - val_accuracy: 0.4589\n",
            "Epoch 552/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1771 - accuracy: 0.4599 - val_loss: 1.1769 - val_accuracy: 0.4604\n",
            "Epoch 553/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1776 - accuracy: 0.4598 - val_loss: 1.1791 - val_accuracy: 0.4583\n",
            "Epoch 554/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1772 - accuracy: 0.4600 - val_loss: 1.1776 - val_accuracy: 0.4591\n",
            "Epoch 555/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1771 - accuracy: 0.4600 - val_loss: 1.1779 - val_accuracy: 0.4596\n",
            "Epoch 556/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1773 - accuracy: 0.4599 - val_loss: 1.1797 - val_accuracy: 0.4597\n",
            "Epoch 557/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1773 - accuracy: 0.4600 - val_loss: 1.1772 - val_accuracy: 0.4610\n",
            "Epoch 558/3000\n",
            "76/76 [==============================] - 14s 189ms/step - loss: 1.1768 - accuracy: 0.4602 - val_loss: 1.1774 - val_accuracy: 0.4610\n",
            "Epoch 559/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1766 - accuracy: 0.4603 - val_loss: 1.1767 - val_accuracy: 0.4603\n",
            "Epoch 560/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1770 - accuracy: 0.4601 - val_loss: 1.1759 - val_accuracy: 0.4606\n",
            "Epoch 561/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1766 - accuracy: 0.4604 - val_loss: 1.1760 - val_accuracy: 0.4602\n",
            "Epoch 562/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1765 - accuracy: 0.4603 - val_loss: 1.1758 - val_accuracy: 0.4606\n",
            "Epoch 563/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1767 - accuracy: 0.4602 - val_loss: 1.1764 - val_accuracy: 0.4601\n",
            "Epoch 564/3000\n",
            "76/76 [==============================] - 14s 189ms/step - loss: 1.1767 - accuracy: 0.4603 - val_loss: 1.1770 - val_accuracy: 0.4604\n",
            "Epoch 565/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1761 - accuracy: 0.4606 - val_loss: 1.1758 - val_accuracy: 0.4608\n",
            "Epoch 566/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1761 - accuracy: 0.4607 - val_loss: 1.1758 - val_accuracy: 0.4614\n",
            "Epoch 567/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1763 - accuracy: 0.4606 - val_loss: 1.1759 - val_accuracy: 0.4611\n",
            "Epoch 568/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1761 - accuracy: 0.4606 - val_loss: 1.1768 - val_accuracy: 0.4607\n",
            "Epoch 569/3000\n",
            "76/76 [==============================] - 15s 202ms/step - loss: 1.1758 - accuracy: 0.4608 - val_loss: 1.1750 - val_accuracy: 0.4617\n",
            "Epoch 570/3000\n",
            "76/76 [==============================] - 15s 191ms/step - loss: 1.1764 - accuracy: 0.4605 - val_loss: 1.1753 - val_accuracy: 0.4615\n",
            "Epoch 571/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1755 - accuracy: 0.4610 - val_loss: 1.1748 - val_accuracy: 0.4623\n",
            "Epoch 572/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1758 - accuracy: 0.4608 - val_loss: 1.1790 - val_accuracy: 0.4594\n",
            "Epoch 573/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1761 - accuracy: 0.4607 - val_loss: 1.1792 - val_accuracy: 0.4597\n",
            "Epoch 574/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1758 - accuracy: 0.4608 - val_loss: 1.1767 - val_accuracy: 0.4611\n",
            "Epoch 575/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1753 - accuracy: 0.4611 - val_loss: 1.1754 - val_accuracy: 0.4612\n",
            "Epoch 576/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1753 - accuracy: 0.4610 - val_loss: 1.1750 - val_accuracy: 0.4616\n",
            "Epoch 577/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1754 - accuracy: 0.4610 - val_loss: 1.1752 - val_accuracy: 0.4619\n",
            "Epoch 578/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1755 - accuracy: 0.4610 - val_loss: 1.1769 - val_accuracy: 0.4613\n",
            "Epoch 579/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1751 - accuracy: 0.4613 - val_loss: 1.1750 - val_accuracy: 0.4621\n",
            "Epoch 580/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1788 - accuracy: 0.4593 - val_loss: 1.1966 - val_accuracy: 0.4511\n",
            "Epoch 581/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1793 - accuracy: 0.4589 - val_loss: 1.1739 - val_accuracy: 0.4627\n",
            "Epoch 582/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1743 - accuracy: 0.4617 - val_loss: 1.1765 - val_accuracy: 0.4617\n",
            "Epoch 583/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1748 - accuracy: 0.4615 - val_loss: 1.1762 - val_accuracy: 0.4619\n",
            "Epoch 584/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1746 - accuracy: 0.4616 - val_loss: 1.1742 - val_accuracy: 0.4633\n",
            "Epoch 585/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1747 - accuracy: 0.4615 - val_loss: 1.1761 - val_accuracy: 0.4616\n",
            "Epoch 586/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1743 - accuracy: 0.4616 - val_loss: 1.1740 - val_accuracy: 0.4628\n",
            "Epoch 587/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1745 - accuracy: 0.4616 - val_loss: 1.1744 - val_accuracy: 0.4627\n",
            "Epoch 588/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1742 - accuracy: 0.4617 - val_loss: 1.1739 - val_accuracy: 0.4629\n",
            "Epoch 589/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1744 - accuracy: 0.4617 - val_loss: 1.1739 - val_accuracy: 0.4633\n",
            "Epoch 590/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1740 - accuracy: 0.4619 - val_loss: 1.1734 - val_accuracy: 0.4634\n",
            "Epoch 591/3000\n",
            "76/76 [==============================] - 15s 201ms/step - loss: 1.1743 - accuracy: 0.4617 - val_loss: 1.1768 - val_accuracy: 0.4609\n",
            "Epoch 592/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1736 - accuracy: 0.4622 - val_loss: 1.1758 - val_accuracy: 0.4621\n",
            "Epoch 593/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1735 - accuracy: 0.4623 - val_loss: 1.1727 - val_accuracy: 0.4628\n",
            "Epoch 594/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1739 - accuracy: 0.4620 - val_loss: 1.1724 - val_accuracy: 0.4636\n",
            "Epoch 595/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1737 - accuracy: 0.4621 - val_loss: 1.1725 - val_accuracy: 0.4641\n",
            "Epoch 596/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1843 - accuracy: 0.4566 - val_loss: 1.1728 - val_accuracy: 0.4639\n",
            "Epoch 597/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1720 - accuracy: 0.4630 - val_loss: 1.1746 - val_accuracy: 0.4632\n",
            "Epoch 598/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1729 - accuracy: 0.4626 - val_loss: 1.1731 - val_accuracy: 0.4638\n",
            "Epoch 599/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1732 - accuracy: 0.4623 - val_loss: 1.1723 - val_accuracy: 0.4628\n",
            "Epoch 600/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1727 - accuracy: 0.4626 - val_loss: 1.1726 - val_accuracy: 0.4633\n",
            "Epoch 601/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1732 - accuracy: 0.4624 - val_loss: 1.1724 - val_accuracy: 0.4638\n",
            "Epoch 602/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1726 - accuracy: 0.4628 - val_loss: 1.1732 - val_accuracy: 0.4635\n",
            "Epoch 603/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1727 - accuracy: 0.4627 - val_loss: 1.1719 - val_accuracy: 0.4638\n",
            "Epoch 604/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1725 - accuracy: 0.4627 - val_loss: 1.1712 - val_accuracy: 0.4644\n",
            "Epoch 605/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1724 - accuracy: 0.4629 - val_loss: 1.1715 - val_accuracy: 0.4646\n",
            "Epoch 606/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1933 - accuracy: 0.4516 - val_loss: 1.2182 - val_accuracy: 0.4369\n",
            "Epoch 607/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1979 - accuracy: 0.4494 - val_loss: 1.1910 - val_accuracy: 0.4537\n",
            "Epoch 608/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1880 - accuracy: 0.4549 - val_loss: 1.1861 - val_accuracy: 0.4561\n",
            "Epoch 609/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1827 - accuracy: 0.4578 - val_loss: 1.1785 - val_accuracy: 0.4603\n",
            "Epoch 610/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1756 - accuracy: 0.4614 - val_loss: 1.1720 - val_accuracy: 0.4637\n",
            "Epoch 611/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1724 - accuracy: 0.4629 - val_loss: 1.1712 - val_accuracy: 0.4637\n",
            "Epoch 612/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1713 - accuracy: 0.4635 - val_loss: 1.1725 - val_accuracy: 0.4641\n",
            "Epoch 613/3000\n",
            "76/76 [==============================] - 15s 202ms/step - loss: 1.1720 - accuracy: 0.4630 - val_loss: 1.1735 - val_accuracy: 0.4624\n",
            "Epoch 614/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1947 - accuracy: 0.4511 - val_loss: 1.2006 - val_accuracy: 0.4483\n",
            "Epoch 615/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1913 - accuracy: 0.4532 - val_loss: 1.1874 - val_accuracy: 0.4556\n",
            "Epoch 616/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1850 - accuracy: 0.4567 - val_loss: 1.1827 - val_accuracy: 0.4577\n",
            "Epoch 617/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1798 - accuracy: 0.4592 - val_loss: 1.1775 - val_accuracy: 0.4613\n",
            "Epoch 618/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1788 - accuracy: 0.4596 - val_loss: 1.1747 - val_accuracy: 0.4627\n",
            "Epoch 619/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1712 - accuracy: 0.4635 - val_loss: 1.1715 - val_accuracy: 0.4640\n",
            "Epoch 620/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1715 - accuracy: 0.4634 - val_loss: 1.1704 - val_accuracy: 0.4647\n",
            "Epoch 621/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1710 - accuracy: 0.4637 - val_loss: 1.1709 - val_accuracy: 0.4649\n",
            "Epoch 622/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1714 - accuracy: 0.4634 - val_loss: 1.1704 - val_accuracy: 0.4643\n",
            "Epoch 623/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1708 - accuracy: 0.4639 - val_loss: 1.1710 - val_accuracy: 0.4642\n",
            "Epoch 624/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1712 - accuracy: 0.4635 - val_loss: 1.1795 - val_accuracy: 0.4599\n",
            "Epoch 625/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1707 - accuracy: 0.4639 - val_loss: 1.1706 - val_accuracy: 0.4644\n",
            "Epoch 626/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1708 - accuracy: 0.4638 - val_loss: 1.1694 - val_accuracy: 0.4645\n",
            "Epoch 627/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1704 - accuracy: 0.4640 - val_loss: 1.1704 - val_accuracy: 0.4643\n",
            "Epoch 628/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1699 - accuracy: 0.4642 - val_loss: 1.1696 - val_accuracy: 0.4650\n",
            "Epoch 629/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1702 - accuracy: 0.4641 - val_loss: 1.1695 - val_accuracy: 0.4649\n",
            "Epoch 630/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1710 - accuracy: 0.4636 - val_loss: 1.1697 - val_accuracy: 0.4646\n",
            "Epoch 631/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1695 - accuracy: 0.4644 - val_loss: 1.1692 - val_accuracy: 0.4649\n",
            "Epoch 632/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1695 - accuracy: 0.4645 - val_loss: 1.1691 - val_accuracy: 0.4649\n",
            "Epoch 633/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1698 - accuracy: 0.4644 - val_loss: 1.1701 - val_accuracy: 0.4651\n",
            "Epoch 634/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1697 - accuracy: 0.4644 - val_loss: 1.1694 - val_accuracy: 0.4648\n",
            "Epoch 635/3000\n",
            "76/76 [==============================] - 16s 204ms/step - loss: 1.1731 - accuracy: 0.4626 - val_loss: 1.1696 - val_accuracy: 0.4659\n",
            "Epoch 636/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1746 - accuracy: 0.4617 - val_loss: 1.1724 - val_accuracy: 0.4634\n",
            "Epoch 637/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1684 - accuracy: 0.4650 - val_loss: 1.1685 - val_accuracy: 0.4655\n",
            "Epoch 638/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1841 - accuracy: 0.4570 - val_loss: 1.2001 - val_accuracy: 0.4496\n",
            "Epoch 639/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1854 - accuracy: 0.4565 - val_loss: 1.1767 - val_accuracy: 0.4618\n",
            "Epoch 640/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1746 - accuracy: 0.4619 - val_loss: 1.1717 - val_accuracy: 0.4635\n",
            "Epoch 641/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1681 - accuracy: 0.4653 - val_loss: 1.1684 - val_accuracy: 0.4658\n",
            "Epoch 642/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1689 - accuracy: 0.4649 - val_loss: 1.1688 - val_accuracy: 0.4652\n",
            "Epoch 643/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1694 - accuracy: 0.4647 - val_loss: 1.1680 - val_accuracy: 0.4668\n",
            "Epoch 644/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1683 - accuracy: 0.4653 - val_loss: 1.1694 - val_accuracy: 0.4651\n",
            "Epoch 645/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1687 - accuracy: 0.4651 - val_loss: 1.1681 - val_accuracy: 0.4665\n",
            "Epoch 646/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1889 - accuracy: 0.4545 - val_loss: 1.1966 - val_accuracy: 0.4501\n",
            "Epoch 647/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1869 - accuracy: 0.4557 - val_loss: 1.1822 - val_accuracy: 0.4588\n",
            "Epoch 648/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1762 - accuracy: 0.4613 - val_loss: 1.1780 - val_accuracy: 0.4606\n",
            "Epoch 649/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1721 - accuracy: 0.4634 - val_loss: 1.1718 - val_accuracy: 0.4643\n",
            "Epoch 650/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1710 - accuracy: 0.4641 - val_loss: 1.1705 - val_accuracy: 0.4645\n",
            "Epoch 651/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1706 - accuracy: 0.4642 - val_loss: 1.1700 - val_accuracy: 0.4653\n",
            "Epoch 652/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1702 - accuracy: 0.4644 - val_loss: 1.1719 - val_accuracy: 0.4644\n",
            "Epoch 653/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1702 - accuracy: 0.4644 - val_loss: 1.1715 - val_accuracy: 0.4651\n",
            "Epoch 654/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1697 - accuracy: 0.4647 - val_loss: 1.1702 - val_accuracy: 0.4652\n",
            "Epoch 655/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1697 - accuracy: 0.4647 - val_loss: 1.1706 - val_accuracy: 0.4649\n",
            "Epoch 656/3000\n",
            "76/76 [==============================] - 14s 189ms/step - loss: 1.1699 - accuracy: 0.4645 - val_loss: 1.1700 - val_accuracy: 0.4654\n",
            "Epoch 657/3000\n",
            "76/76 [==============================] - 15s 197ms/step - loss: 1.1694 - accuracy: 0.4647 - val_loss: 1.1706 - val_accuracy: 0.4647\n",
            "Epoch 658/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1693 - accuracy: 0.4648 - val_loss: 1.1705 - val_accuracy: 0.4648\n",
            "Epoch 659/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1696 - accuracy: 0.4646 - val_loss: 1.1684 - val_accuracy: 0.4660\n",
            "Epoch 660/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1687 - accuracy: 0.4652 - val_loss: 1.1733 - val_accuracy: 0.4639\n",
            "Epoch 661/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1692 - accuracy: 0.4648 - val_loss: 1.1695 - val_accuracy: 0.4659\n",
            "Epoch 662/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1686 - accuracy: 0.4652 - val_loss: 1.1723 - val_accuracy: 0.4640\n",
            "Epoch 663/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1691 - accuracy: 0.4649 - val_loss: 1.1707 - val_accuracy: 0.4655\n",
            "Epoch 664/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1689 - accuracy: 0.4650 - val_loss: 1.1693 - val_accuracy: 0.4660\n",
            "Epoch 665/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1685 - accuracy: 0.4653 - val_loss: 1.1680 - val_accuracy: 0.4653\n",
            "Epoch 666/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1686 - accuracy: 0.4652 - val_loss: 1.1685 - val_accuracy: 0.4662\n",
            "Epoch 667/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1682 - accuracy: 0.4654 - val_loss: 1.1692 - val_accuracy: 0.4661\n",
            "Epoch 668/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1688 - accuracy: 0.4651 - val_loss: 1.1683 - val_accuracy: 0.4661\n",
            "Epoch 669/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1680 - accuracy: 0.4656 - val_loss: 1.1695 - val_accuracy: 0.4651\n",
            "Epoch 670/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1681 - accuracy: 0.4655 - val_loss: 1.1711 - val_accuracy: 0.4645\n",
            "Epoch 671/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1681 - accuracy: 0.4655 - val_loss: 1.1690 - val_accuracy: 0.4657\n",
            "Epoch 672/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1676 - accuracy: 0.4658 - val_loss: 1.1714 - val_accuracy: 0.4637\n",
            "Epoch 673/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1681 - accuracy: 0.4655 - val_loss: 1.1702 - val_accuracy: 0.4654\n",
            "Epoch 674/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1677 - accuracy: 0.4657 - val_loss: 1.1681 - val_accuracy: 0.4657\n",
            "Epoch 675/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1689 - accuracy: 0.4651 - val_loss: 1.1668 - val_accuracy: 0.4672\n",
            "Epoch 676/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1672 - accuracy: 0.4660 - val_loss: 1.1683 - val_accuracy: 0.4663\n",
            "Epoch 677/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1680 - accuracy: 0.4656 - val_loss: 1.1691 - val_accuracy: 0.4650\n",
            "Epoch 678/3000\n",
            "76/76 [==============================] - 14s 190ms/step - loss: 1.1670 - accuracy: 0.4661 - val_loss: 1.1684 - val_accuracy: 0.4662\n",
            "Epoch 679/3000\n",
            "76/76 [==============================] - 15s 193ms/step - loss: 1.1674 - accuracy: 0.4659 - val_loss: 1.1670 - val_accuracy: 0.4670\n",
            "Epoch 680/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1673 - accuracy: 0.4660 - val_loss: 1.1671 - val_accuracy: 0.4663\n",
            "Epoch 681/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1758 - accuracy: 0.4615 - val_loss: 1.1778 - val_accuracy: 0.4610\n",
            "Epoch 682/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1674 - accuracy: 0.4658 - val_loss: 1.1672 - val_accuracy: 0.4666\n",
            "Epoch 683/3000\n",
            "76/76 [==============================] - 14s 189ms/step - loss: 1.1668 - accuracy: 0.4662 - val_loss: 1.1669 - val_accuracy: 0.4668\n",
            "Epoch 684/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1668 - accuracy: 0.4661 - val_loss: 1.1672 - val_accuracy: 0.4667\n",
            "Epoch 685/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1680 - accuracy: 0.4656 - val_loss: 1.1674 - val_accuracy: 0.4671\n",
            "Epoch 686/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1672 - accuracy: 0.4659 - val_loss: 1.1680 - val_accuracy: 0.4661\n",
            "Epoch 687/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1664 - accuracy: 0.4664 - val_loss: 1.1671 - val_accuracy: 0.4664\n",
            "Epoch 688/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1667 - accuracy: 0.4663 - val_loss: 1.1707 - val_accuracy: 0.4650\n",
            "Epoch 689/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1881 - accuracy: 0.4550 - val_loss: 1.1690 - val_accuracy: 0.4655\n",
            "Epoch 690/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1657 - accuracy: 0.4668 - val_loss: 1.1664 - val_accuracy: 0.4672\n",
            "Epoch 691/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1663 - accuracy: 0.4664 - val_loss: 1.1676 - val_accuracy: 0.4672\n",
            "Epoch 692/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1660 - accuracy: 0.4666 - val_loss: 1.1660 - val_accuracy: 0.4674\n",
            "Epoch 693/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1754 - accuracy: 0.4618 - val_loss: 1.1914 - val_accuracy: 0.4538\n",
            "Epoch 694/3000\n",
            "76/76 [==============================] - 14s 189ms/step - loss: 1.1696 - accuracy: 0.4646 - val_loss: 1.1666 - val_accuracy: 0.4667\n",
            "Epoch 695/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1656 - accuracy: 0.4669 - val_loss: 1.1663 - val_accuracy: 0.4665\n",
            "Epoch 696/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1660 - accuracy: 0.4667 - val_loss: 1.1680 - val_accuracy: 0.4664\n",
            "Epoch 697/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1662 - accuracy: 0.4665 - val_loss: 1.1681 - val_accuracy: 0.4660\n",
            "Epoch 698/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1664 - accuracy: 0.4664 - val_loss: 1.1665 - val_accuracy: 0.4672\n",
            "Epoch 699/3000\n",
            "76/76 [==============================] - 15s 192ms/step - loss: 1.1663 - accuracy: 0.4665 - val_loss: 1.1664 - val_accuracy: 0.4670\n",
            "Epoch 700/3000\n",
            "76/76 [==============================] - 15s 202ms/step - loss: 1.1663 - accuracy: 0.4665 - val_loss: 1.1671 - val_accuracy: 0.4664\n",
            "Epoch 701/3000\n",
            "76/76 [==============================] - 14s 189ms/step - loss: 1.1664 - accuracy: 0.4663 - val_loss: 1.1662 - val_accuracy: 0.4670\n",
            "Epoch 702/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1658 - accuracy: 0.4668 - val_loss: 1.1685 - val_accuracy: 0.4660\n",
            "Epoch 703/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1912 - accuracy: 0.4533 - val_loss: 1.2043 - val_accuracy: 0.4463\n",
            "Epoch 704/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1889 - accuracy: 0.4548 - val_loss: 1.1843 - val_accuracy: 0.4582\n",
            "Epoch 705/3000\n",
            "76/76 [==============================] - 14s 190ms/step - loss: 1.1812 - accuracy: 0.4592 - val_loss: 1.1804 - val_accuracy: 0.4606\n",
            "Epoch 706/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1786 - accuracy: 0.4605 - val_loss: 1.1780 - val_accuracy: 0.4610\n",
            "Epoch 707/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1774 - accuracy: 0.4611 - val_loss: 1.1800 - val_accuracy: 0.4593\n",
            "Epoch 708/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1761 - accuracy: 0.4616 - val_loss: 1.1757 - val_accuracy: 0.4621\n",
            "Epoch 709/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1748 - accuracy: 0.4621 - val_loss: 1.1745 - val_accuracy: 0.4623\n",
            "Epoch 710/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1731 - accuracy: 0.4629 - val_loss: 1.1883 - val_accuracy: 0.4548\n",
            "Epoch 711/3000\n",
            "76/76 [==============================] - 14s 190ms/step - loss: 1.1715 - accuracy: 0.4637 - val_loss: 1.1740 - val_accuracy: 0.4630\n",
            "Epoch 712/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1683 - accuracy: 0.4653 - val_loss: 1.1679 - val_accuracy: 0.4668\n",
            "Epoch 713/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1657 - accuracy: 0.4668 - val_loss: 1.1663 - val_accuracy: 0.4670\n",
            "Epoch 714/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1663 - accuracy: 0.4665 - val_loss: 1.1655 - val_accuracy: 0.4676\n",
            "Epoch 715/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1656 - accuracy: 0.4669 - val_loss: 1.1658 - val_accuracy: 0.4671\n",
            "Epoch 716/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1654 - accuracy: 0.4670 - val_loss: 1.1652 - val_accuracy: 0.4673\n",
            "Epoch 717/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1656 - accuracy: 0.4669 - val_loss: 1.1661 - val_accuracy: 0.4670\n",
            "Epoch 718/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1663 - accuracy: 0.4664 - val_loss: 1.1657 - val_accuracy: 0.4677\n",
            "Epoch 719/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1650 - accuracy: 0.4671 - val_loss: 1.1653 - val_accuracy: 0.4675\n",
            "Epoch 720/3000\n",
            "76/76 [==============================] - 15s 192ms/step - loss: 1.1654 - accuracy: 0.4669 - val_loss: 1.1651 - val_accuracy: 0.4673\n",
            "Epoch 721/3000\n",
            "76/76 [==============================] - 14s 189ms/step - loss: 1.1652 - accuracy: 0.4670 - val_loss: 1.1672 - val_accuracy: 0.4665\n",
            "Epoch 722/3000\n",
            "76/76 [==============================] - 15s 204ms/step - loss: 1.1653 - accuracy: 0.4670 - val_loss: 1.1653 - val_accuracy: 0.4675\n",
            "Epoch 723/3000\n",
            "76/76 [==============================] - 14s 189ms/step - loss: 1.1839 - accuracy: 0.4572 - val_loss: 1.1994 - val_accuracy: 0.4491\n",
            "Epoch 724/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1846 - accuracy: 0.4572 - val_loss: 1.1805 - val_accuracy: 0.4606\n",
            "Epoch 725/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1779 - accuracy: 0.4608 - val_loss: 1.1852 - val_accuracy: 0.4578\n",
            "Epoch 726/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1752 - accuracy: 0.4622 - val_loss: 1.1749 - val_accuracy: 0.4618\n",
            "Epoch 727/3000\n",
            "76/76 [==============================] - 14s 190ms/step - loss: 1.1721 - accuracy: 0.4633 - val_loss: 1.1674 - val_accuracy: 0.4665\n",
            "Epoch 728/3000\n",
            "76/76 [==============================] - 15s 191ms/step - loss: 1.1654 - accuracy: 0.4669 - val_loss: 1.1659 - val_accuracy: 0.4676\n",
            "Epoch 729/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1647 - accuracy: 0.4674 - val_loss: 1.1651 - val_accuracy: 0.4675\n",
            "Epoch 730/3000\n",
            "76/76 [==============================] - 14s 191ms/step - loss: 1.1685 - accuracy: 0.4654 - val_loss: 1.1851 - val_accuracy: 0.4569\n",
            "Epoch 731/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1681 - accuracy: 0.4656 - val_loss: 1.1652 - val_accuracy: 0.4670\n",
            "Epoch 732/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1648 - accuracy: 0.4673 - val_loss: 1.1651 - val_accuracy: 0.4677\n",
            "Epoch 733/3000\n",
            "76/76 [==============================] - 15s 192ms/step - loss: 1.1651 - accuracy: 0.4671 - val_loss: 1.1653 - val_accuracy: 0.4673\n",
            "Epoch 734/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1687 - accuracy: 0.4651 - val_loss: 1.1688 - val_accuracy: 0.4661\n",
            "Epoch 735/3000\n",
            "76/76 [==============================] - 14s 189ms/step - loss: 1.1644 - accuracy: 0.4674 - val_loss: 1.1654 - val_accuracy: 0.4662\n",
            "Epoch 736/3000\n",
            "76/76 [==============================] - 15s 192ms/step - loss: 1.1646 - accuracy: 0.4673 - val_loss: 1.1650 - val_accuracy: 0.4667\n",
            "Epoch 737/3000\n",
            "76/76 [==============================] - 15s 191ms/step - loss: 1.1649 - accuracy: 0.4672 - val_loss: 1.1646 - val_accuracy: 0.4680\n",
            "Epoch 738/3000\n",
            "76/76 [==============================] - 15s 191ms/step - loss: 1.1646 - accuracy: 0.4673 - val_loss: 1.1653 - val_accuracy: 0.4670\n",
            "Epoch 739/3000\n",
            "76/76 [==============================] - 15s 193ms/step - loss: 1.1804 - accuracy: 0.4592 - val_loss: 1.1682 - val_accuracy: 0.4666\n",
            "Epoch 740/3000\n",
            "76/76 [==============================] - 14s 189ms/step - loss: 1.1641 - accuracy: 0.4676 - val_loss: 1.1645 - val_accuracy: 0.4682\n",
            "Epoch 741/3000\n",
            "76/76 [==============================] - 15s 192ms/step - loss: 1.1641 - accuracy: 0.4677 - val_loss: 1.1646 - val_accuracy: 0.4674\n",
            "Epoch 742/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1767 - accuracy: 0.4612 - val_loss: 1.1888 - val_accuracy: 0.4561\n",
            "Epoch 743/3000\n",
            "76/76 [==============================] - 16s 204ms/step - loss: 1.1754 - accuracy: 0.4619 - val_loss: 1.1666 - val_accuracy: 0.4671\n",
            "Epoch 744/3000\n",
            "76/76 [==============================] - 14s 191ms/step - loss: 1.1640 - accuracy: 0.4677 - val_loss: 1.1661 - val_accuracy: 0.4663\n",
            "Epoch 745/3000\n",
            "76/76 [==============================] - 14s 190ms/step - loss: 1.1646 - accuracy: 0.4674 - val_loss: 1.1646 - val_accuracy: 0.4685\n",
            "Epoch 746/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1639 - accuracy: 0.4676 - val_loss: 1.1644 - val_accuracy: 0.4679\n",
            "Epoch 747/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1648 - accuracy: 0.4672 - val_loss: 1.1640 - val_accuracy: 0.4679\n",
            "Epoch 748/3000\n",
            "76/76 [==============================] - 14s 191ms/step - loss: 1.1643 - accuracy: 0.4675 - val_loss: 1.1646 - val_accuracy: 0.4673\n",
            "Epoch 749/3000\n",
            "76/76 [==============================] - 14s 191ms/step - loss: 1.1746 - accuracy: 0.4621 - val_loss: 1.1658 - val_accuracy: 0.4673\n",
            "Epoch 750/3000\n",
            "76/76 [==============================] - 15s 191ms/step - loss: 1.1633 - accuracy: 0.4680 - val_loss: 1.1642 - val_accuracy: 0.4684\n",
            "Epoch 751/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1738 - accuracy: 0.4626 - val_loss: 1.1779 - val_accuracy: 0.4614\n",
            "Epoch 752/3000\n",
            "76/76 [==============================] - 14s 189ms/step - loss: 1.1664 - accuracy: 0.4665 - val_loss: 1.1650 - val_accuracy: 0.4674\n",
            "Epoch 753/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1642 - accuracy: 0.4676 - val_loss: 1.1643 - val_accuracy: 0.4691\n",
            "Epoch 754/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1679 - accuracy: 0.4656 - val_loss: 1.1679 - val_accuracy: 0.4654\n",
            "Epoch 755/3000\n",
            "76/76 [==============================] - 14s 190ms/step - loss: 1.1641 - accuracy: 0.4675 - val_loss: 1.1670 - val_accuracy: 0.4654\n",
            "Epoch 756/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1646 - accuracy: 0.4672 - val_loss: 1.1640 - val_accuracy: 0.4685\n",
            "Epoch 757/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1639 - accuracy: 0.4677 - val_loss: 1.1642 - val_accuracy: 0.4678\n",
            "Epoch 758/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1687 - accuracy: 0.4652 - val_loss: 1.1697 - val_accuracy: 0.4650\n",
            "Epoch 759/3000\n",
            "76/76 [==============================] - 14s 189ms/step - loss: 1.1636 - accuracy: 0.4678 - val_loss: 1.1646 - val_accuracy: 0.4674\n",
            "Epoch 760/3000\n",
            "76/76 [==============================] - 14s 190ms/step - loss: 1.1705 - accuracy: 0.4642 - val_loss: 1.1768 - val_accuracy: 0.4616\n",
            "Epoch 761/3000\n",
            "76/76 [==============================] - 15s 193ms/step - loss: 1.1648 - accuracy: 0.4671 - val_loss: 1.1637 - val_accuracy: 0.4692\n",
            "Epoch 762/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1631 - accuracy: 0.4681 - val_loss: 1.1636 - val_accuracy: 0.4680\n",
            "Epoch 763/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1637 - accuracy: 0.4678 - val_loss: 1.1639 - val_accuracy: 0.4681\n",
            "Epoch 764/3000\n",
            "76/76 [==============================] - 15s 202ms/step - loss: 1.1682 - accuracy: 0.4654 - val_loss: 1.1691 - val_accuracy: 0.4654\n",
            "Epoch 765/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1634 - accuracy: 0.4680 - val_loss: 1.1641 - val_accuracy: 0.4680\n",
            "Epoch 766/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1798 - accuracy: 0.4597 - val_loss: 1.2271 - val_accuracy: 0.4317\n",
            "Epoch 767/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1930 - accuracy: 0.4523 - val_loss: 1.1831 - val_accuracy: 0.4588\n",
            "Epoch 768/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1790 - accuracy: 0.4603 - val_loss: 1.1779 - val_accuracy: 0.4611\n",
            "Epoch 769/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1765 - accuracy: 0.4615 - val_loss: 1.1756 - val_accuracy: 0.4629\n",
            "Epoch 770/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1749 - accuracy: 0.4623 - val_loss: 1.1741 - val_accuracy: 0.4630\n",
            "Epoch 771/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1742 - accuracy: 0.4625 - val_loss: 1.1749 - val_accuracy: 0.4622\n",
            "Epoch 772/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1730 - accuracy: 0.4631 - val_loss: 1.1753 - val_accuracy: 0.4617\n",
            "Epoch 773/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1736 - accuracy: 0.4628 - val_loss: 1.1758 - val_accuracy: 0.4618\n",
            "Epoch 774/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1721 - accuracy: 0.4634 - val_loss: 1.1717 - val_accuracy: 0.4641\n",
            "Epoch 775/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1725 - accuracy: 0.4632 - val_loss: 1.1744 - val_accuracy: 0.4627\n",
            "Epoch 776/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1720 - accuracy: 0.4634 - val_loss: 1.1794 - val_accuracy: 0.4598\n",
            "Epoch 777/3000\n",
            "76/76 [==============================] - 15s 192ms/step - loss: 1.1717 - accuracy: 0.4636 - val_loss: 1.1723 - val_accuracy: 0.4640\n",
            "Epoch 778/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1714 - accuracy: 0.4638 - val_loss: 1.1731 - val_accuracy: 0.4626\n",
            "Epoch 779/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1711 - accuracy: 0.4639 - val_loss: 1.1723 - val_accuracy: 0.4629\n",
            "Epoch 780/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1707 - accuracy: 0.4641 - val_loss: 1.1711 - val_accuracy: 0.4640\n",
            "Epoch 781/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1703 - accuracy: 0.4643 - val_loss: 1.1691 - val_accuracy: 0.4654\n",
            "Epoch 782/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1676 - accuracy: 0.4657 - val_loss: 1.1648 - val_accuracy: 0.4687\n",
            "Epoch 783/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1673 - accuracy: 0.4659 - val_loss: 1.1636 - val_accuracy: 0.4689\n",
            "Epoch 784/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1705 - accuracy: 0.4643 - val_loss: 1.1968 - val_accuracy: 0.4504\n",
            "Epoch 785/3000\n",
            "76/76 [==============================] - 14s 189ms/step - loss: 1.1697 - accuracy: 0.4646 - val_loss: 1.1634 - val_accuracy: 0.4691\n",
            "Epoch 786/3000\n",
            "76/76 [==============================] - 15s 192ms/step - loss: 1.1799 - accuracy: 0.4595 - val_loss: 1.2012 - val_accuracy: 0.4484\n",
            "Epoch 787/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1821 - accuracy: 0.4586 - val_loss: 1.1764 - val_accuracy: 0.4625\n",
            "Epoch 788/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1730 - accuracy: 0.4632 - val_loss: 1.1715 - val_accuracy: 0.4643\n",
            "Epoch 789/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1692 - accuracy: 0.4649 - val_loss: 1.1650 - val_accuracy: 0.4682\n",
            "Epoch 790/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1638 - accuracy: 0.4677 - val_loss: 1.1650 - val_accuracy: 0.4677\n",
            "Epoch 791/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1635 - accuracy: 0.4679 - val_loss: 1.1665 - val_accuracy: 0.4663\n",
            "Epoch 792/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1717 - accuracy: 0.4636 - val_loss: 1.1634 - val_accuracy: 0.4692\n",
            "Epoch 793/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1627 - accuracy: 0.4684 - val_loss: 1.1631 - val_accuracy: 0.4688\n",
            "Epoch 794/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1630 - accuracy: 0.4682 - val_loss: 1.1632 - val_accuracy: 0.4693\n",
            "Epoch 795/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1667 - accuracy: 0.4663 - val_loss: 1.1796 - val_accuracy: 0.4598\n",
            "Epoch 796/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1645 - accuracy: 0.4674 - val_loss: 1.1626 - val_accuracy: 0.4702\n",
            "Epoch 797/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1630 - accuracy: 0.4682 - val_loss: 1.1644 - val_accuracy: 0.4675\n",
            "Epoch 798/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1630 - accuracy: 0.4682 - val_loss: 1.1642 - val_accuracy: 0.4671\n",
            "Epoch 799/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1682 - accuracy: 0.4654 - val_loss: 1.1722 - val_accuracy: 0.4644\n",
            "Epoch 800/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1631 - accuracy: 0.4680 - val_loss: 1.1630 - val_accuracy: 0.4693\n",
            "Epoch 801/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1629 - accuracy: 0.4681 - val_loss: 1.1645 - val_accuracy: 0.4672\n",
            "Epoch 802/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1751 - accuracy: 0.4619 - val_loss: 1.1789 - val_accuracy: 0.4595\n",
            "Epoch 803/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1677 - accuracy: 0.4656 - val_loss: 1.1627 - val_accuracy: 0.4692\n",
            "Epoch 804/3000\n",
            "76/76 [==============================] - 14s 190ms/step - loss: 1.1626 - accuracy: 0.4685 - val_loss: 1.1626 - val_accuracy: 0.4694\n",
            "Epoch 805/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1626 - accuracy: 0.4684 - val_loss: 1.1627 - val_accuracy: 0.4692\n",
            "Epoch 806/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1707 - accuracy: 0.4641 - val_loss: 1.1880 - val_accuracy: 0.4550\n",
            "Epoch 807/3000\n",
            "76/76 [==============================] - 15s 196ms/step - loss: 1.1677 - accuracy: 0.4657 - val_loss: 1.1627 - val_accuracy: 0.4685\n",
            "Epoch 808/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1625 - accuracy: 0.4685 - val_loss: 1.1651 - val_accuracy: 0.4670\n",
            "Epoch 809/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1625 - accuracy: 0.4683 - val_loss: 1.1642 - val_accuracy: 0.4674\n",
            "Epoch 810/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1629 - accuracy: 0.4682 - val_loss: 1.1646 - val_accuracy: 0.4675\n",
            "Epoch 811/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1663 - accuracy: 0.4664 - val_loss: 1.1684 - val_accuracy: 0.4667\n",
            "Epoch 812/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1624 - accuracy: 0.4685 - val_loss: 1.1633 - val_accuracy: 0.4689\n",
            "Epoch 813/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1690 - accuracy: 0.4650 - val_loss: 1.1766 - val_accuracy: 0.4610\n",
            "Epoch 814/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1636 - accuracy: 0.4678 - val_loss: 1.1621 - val_accuracy: 0.4693\n",
            "Epoch 815/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1625 - accuracy: 0.4685 - val_loss: 1.1630 - val_accuracy: 0.4683\n",
            "Epoch 816/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1624 - accuracy: 0.4685 - val_loss: 1.1656 - val_accuracy: 0.4672\n",
            "Epoch 817/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1627 - accuracy: 0.4683 - val_loss: 1.1633 - val_accuracy: 0.4679\n",
            "Epoch 818/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1686 - accuracy: 0.4652 - val_loss: 1.1729 - val_accuracy: 0.4614\n",
            "Epoch 819/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1627 - accuracy: 0.4683 - val_loss: 1.1631 - val_accuracy: 0.4686\n",
            "Epoch 820/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1624 - accuracy: 0.4685 - val_loss: 1.1628 - val_accuracy: 0.4684\n",
            "Epoch 821/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1722 - accuracy: 0.4634 - val_loss: 1.1853 - val_accuracy: 0.4566\n",
            "Epoch 822/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1666 - accuracy: 0.4663 - val_loss: 1.1620 - val_accuracy: 0.4692\n",
            "Epoch 823/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1617 - accuracy: 0.4689 - val_loss: 1.1623 - val_accuracy: 0.4693\n",
            "Epoch 824/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1621 - accuracy: 0.4686 - val_loss: 1.1636 - val_accuracy: 0.4681\n",
            "Epoch 825/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1692 - accuracy: 0.4649 - val_loss: 1.1753 - val_accuracy: 0.4621\n",
            "Epoch 826/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1629 - accuracy: 0.4681 - val_loss: 1.1619 - val_accuracy: 0.4692\n",
            "Epoch 827/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1618 - accuracy: 0.4688 - val_loss: 1.1626 - val_accuracy: 0.4686\n",
            "Epoch 828/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1770 - accuracy: 0.4610 - val_loss: 1.1743 - val_accuracy: 0.4630\n",
            "Epoch 829/3000\n",
            "76/76 [==============================] - 15s 198ms/step - loss: 1.1658 - accuracy: 0.4667 - val_loss: 1.1619 - val_accuracy: 0.4691\n",
            "Epoch 830/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1617 - accuracy: 0.4688 - val_loss: 1.1652 - val_accuracy: 0.4668\n",
            "Epoch 831/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1620 - accuracy: 0.4687 - val_loss: 1.1620 - val_accuracy: 0.4687\n",
            "Epoch 832/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1621 - accuracy: 0.4685 - val_loss: 1.1625 - val_accuracy: 0.4683\n",
            "Epoch 833/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1622 - accuracy: 0.4685 - val_loss: 1.1626 - val_accuracy: 0.4683\n",
            "Epoch 834/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1710 - accuracy: 0.4639 - val_loss: 1.1657 - val_accuracy: 0.4666\n",
            "Epoch 835/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1615 - accuracy: 0.4689 - val_loss: 1.1621 - val_accuracy: 0.4686\n",
            "Epoch 836/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1640 - accuracy: 0.4676 - val_loss: 1.1789 - val_accuracy: 0.4589\n",
            "Epoch 837/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1646 - accuracy: 0.4672 - val_loss: 1.1617 - val_accuracy: 0.4691\n",
            "Epoch 838/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1685 - accuracy: 0.4654 - val_loss: 1.1760 - val_accuracy: 0.4618\n",
            "Epoch 839/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1630 - accuracy: 0.4681 - val_loss: 1.1618 - val_accuracy: 0.4691\n",
            "Epoch 840/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1618 - accuracy: 0.4687 - val_loss: 1.1626 - val_accuracy: 0.4683\n",
            "Epoch 841/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1616 - accuracy: 0.4688 - val_loss: 1.1627 - val_accuracy: 0.4678\n",
            "Epoch 842/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1678 - accuracy: 0.4656 - val_loss: 1.1725 - val_accuracy: 0.4621\n",
            "Epoch 843/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1622 - accuracy: 0.4685 - val_loss: 1.1620 - val_accuracy: 0.4687\n",
            "Epoch 844/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1646 - accuracy: 0.4672 - val_loss: 1.1653 - val_accuracy: 0.4664\n",
            "Epoch 845/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1614 - accuracy: 0.4689 - val_loss: 1.1629 - val_accuracy: 0.4683\n",
            "Epoch 846/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1617 - accuracy: 0.4688 - val_loss: 1.1617 - val_accuracy: 0.4688\n",
            "Epoch 847/3000\n",
            "76/76 [==============================] - 14s 190ms/step - loss: 1.1615 - accuracy: 0.4690 - val_loss: 1.1620 - val_accuracy: 0.4685\n",
            "Epoch 848/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1826 - accuracy: 0.4580 - val_loss: 1.2116 - val_accuracy: 0.4409\n",
            "Epoch 849/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1862 - accuracy: 0.4560 - val_loss: 1.1783 - val_accuracy: 0.4608\n",
            "Epoch 850/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1744 - accuracy: 0.4625 - val_loss: 1.1732 - val_accuracy: 0.4632\n",
            "Epoch 851/3000\n",
            "76/76 [==============================] - 15s 202ms/step - loss: 1.1722 - accuracy: 0.4635 - val_loss: 1.1734 - val_accuracy: 0.4633\n",
            "Epoch 852/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1710 - accuracy: 0.4642 - val_loss: 1.1711 - val_accuracy: 0.4636\n",
            "Epoch 853/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1708 - accuracy: 0.4641 - val_loss: 1.1743 - val_accuracy: 0.4611\n",
            "Epoch 854/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1702 - accuracy: 0.4643 - val_loss: 1.1742 - val_accuracy: 0.4616\n",
            "Epoch 855/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1704 - accuracy: 0.4642 - val_loss: 1.1705 - val_accuracy: 0.4640\n",
            "Epoch 856/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1694 - accuracy: 0.4647 - val_loss: 1.1713 - val_accuracy: 0.4643\n",
            "Epoch 857/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1693 - accuracy: 0.4647 - val_loss: 1.1692 - val_accuracy: 0.4648\n",
            "Epoch 858/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1689 - accuracy: 0.4650 - val_loss: 1.1695 - val_accuracy: 0.4644\n",
            "Epoch 859/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1689 - accuracy: 0.4649 - val_loss: 1.1691 - val_accuracy: 0.4644\n",
            "Epoch 860/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1683 - accuracy: 0.4652 - val_loss: 1.1679 - val_accuracy: 0.4660\n",
            "Epoch 861/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1696 - accuracy: 0.4647 - val_loss: 1.1664 - val_accuracy: 0.4662\n",
            "Epoch 862/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1676 - accuracy: 0.4657 - val_loss: 1.1791 - val_accuracy: 0.4588\n",
            "Epoch 863/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1642 - accuracy: 0.4673 - val_loss: 1.1616 - val_accuracy: 0.4692\n",
            "Epoch 864/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1664 - accuracy: 0.4663 - val_loss: 1.1646 - val_accuracy: 0.4665\n",
            "Epoch 865/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1617 - accuracy: 0.4687 - val_loss: 1.1631 - val_accuracy: 0.4687\n",
            "Epoch 866/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1666 - accuracy: 0.4662 - val_loss: 1.1757 - val_accuracy: 0.4612\n",
            "Epoch 867/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1631 - accuracy: 0.4680 - val_loss: 1.1613 - val_accuracy: 0.4693\n",
            "Epoch 868/3000\n",
            "76/76 [==============================] - 14s 189ms/step - loss: 1.1611 - accuracy: 0.4690 - val_loss: 1.1641 - val_accuracy: 0.4676\n",
            "Epoch 869/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1617 - accuracy: 0.4688 - val_loss: 1.1614 - val_accuracy: 0.4691\n",
            "Epoch 870/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1741 - accuracy: 0.4623 - val_loss: 1.1713 - val_accuracy: 0.4635\n",
            "Epoch 871/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1619 - accuracy: 0.4686 - val_loss: 1.1613 - val_accuracy: 0.4696\n",
            "Epoch 872/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1607 - accuracy: 0.4694 - val_loss: 1.1620 - val_accuracy: 0.4690\n",
            "Epoch 873/3000\n",
            "76/76 [==============================] - 15s 203ms/step - loss: 1.1611 - accuracy: 0.4691 - val_loss: 1.1621 - val_accuracy: 0.4693\n",
            "Epoch 874/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1761 - accuracy: 0.4614 - val_loss: 1.1732 - val_accuracy: 0.4634\n",
            "Epoch 875/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1648 - accuracy: 0.4672 - val_loss: 1.1608 - val_accuracy: 0.4700\n",
            "Epoch 876/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1610 - accuracy: 0.4691 - val_loss: 1.1634 - val_accuracy: 0.4682\n",
            "Epoch 877/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1609 - accuracy: 0.4691 - val_loss: 1.1615 - val_accuracy: 0.4693\n",
            "Epoch 878/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1614 - accuracy: 0.4689 - val_loss: 1.1620 - val_accuracy: 0.4687\n",
            "Epoch 879/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1629 - accuracy: 0.4680 - val_loss: 1.1615 - val_accuracy: 0.4688\n",
            "Epoch 880/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1605 - accuracy: 0.4695 - val_loss: 1.1612 - val_accuracy: 0.4694\n",
            "Epoch 881/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1663 - accuracy: 0.4664 - val_loss: 1.1620 - val_accuracy: 0.4693\n",
            "Epoch 882/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1605 - accuracy: 0.4694 - val_loss: 1.1614 - val_accuracy: 0.4692\n",
            "Epoch 883/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1609 - accuracy: 0.4691 - val_loss: 1.1615 - val_accuracy: 0.4682\n",
            "Epoch 884/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1642 - accuracy: 0.4673 - val_loss: 1.1617 - val_accuracy: 0.4686\n",
            "Epoch 885/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1600 - accuracy: 0.4697 - val_loss: 1.1608 - val_accuracy: 0.4701\n",
            "Epoch 886/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1608 - accuracy: 0.4692 - val_loss: 1.1620 - val_accuracy: 0.4694\n",
            "Epoch 887/3000\n",
            "76/76 [==============================] - 13s 178ms/step - loss: 1.1668 - accuracy: 0.4660 - val_loss: 1.1630 - val_accuracy: 0.4670\n",
            "Epoch 888/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1602 - accuracy: 0.4695 - val_loss: 1.1603 - val_accuracy: 0.4698\n",
            "Epoch 889/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1607 - accuracy: 0.4691 - val_loss: 1.1605 - val_accuracy: 0.4696\n",
            "Epoch 890/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1609 - accuracy: 0.4691 - val_loss: 1.1615 - val_accuracy: 0.4687\n",
            "Epoch 891/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1765 - accuracy: 0.4610 - val_loss: 1.1907 - val_accuracy: 0.4539\n",
            "Epoch 892/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1751 - accuracy: 0.4620 - val_loss: 1.1692 - val_accuracy: 0.4648\n",
            "Epoch 893/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1628 - accuracy: 0.4681 - val_loss: 1.1616 - val_accuracy: 0.4691\n",
            "Epoch 894/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1605 - accuracy: 0.4694 - val_loss: 1.1612 - val_accuracy: 0.4685\n",
            "Epoch 895/3000\n",
            "76/76 [==============================] - 15s 200ms/step - loss: 1.1608 - accuracy: 0.4692 - val_loss: 1.1616 - val_accuracy: 0.4685\n",
            "Epoch 896/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1608 - accuracy: 0.4691 - val_loss: 1.1610 - val_accuracy: 0.4694\n",
            "Epoch 897/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1606 - accuracy: 0.4692 - val_loss: 1.1614 - val_accuracy: 0.4687\n",
            "Epoch 898/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1740 - accuracy: 0.4623 - val_loss: 1.1704 - val_accuracy: 0.4645\n",
            "Epoch 899/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1613 - accuracy: 0.4689 - val_loss: 1.1600 - val_accuracy: 0.4701\n",
            "Epoch 900/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1601 - accuracy: 0.4696 - val_loss: 1.1613 - val_accuracy: 0.4698\n",
            "Epoch 901/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1606 - accuracy: 0.4692 - val_loss: 1.1610 - val_accuracy: 0.4689\n",
            "Epoch 902/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1605 - accuracy: 0.4693 - val_loss: 1.1614 - val_accuracy: 0.4686\n",
            "Epoch 903/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1925 - accuracy: 0.4525 - val_loss: 1.1938 - val_accuracy: 0.4514\n",
            "Epoch 904/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1805 - accuracy: 0.4590 - val_loss: 1.1748 - val_accuracy: 0.4630\n",
            "Epoch 905/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1715 - accuracy: 0.4640 - val_loss: 1.1703 - val_accuracy: 0.4648\n",
            "Epoch 906/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1694 - accuracy: 0.4649 - val_loss: 1.1698 - val_accuracy: 0.4644\n",
            "Epoch 907/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1691 - accuracy: 0.4649 - val_loss: 1.1692 - val_accuracy: 0.4650\n",
            "Epoch 908/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1684 - accuracy: 0.4652 - val_loss: 1.1685 - val_accuracy: 0.4647\n",
            "Epoch 909/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1678 - accuracy: 0.4654 - val_loss: 1.1675 - val_accuracy: 0.4651\n",
            "Epoch 910/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1678 - accuracy: 0.4656 - val_loss: 1.1674 - val_accuracy: 0.4658\n",
            "Epoch 911/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1675 - accuracy: 0.4657 - val_loss: 1.1681 - val_accuracy: 0.4650\n",
            "Epoch 912/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1672 - accuracy: 0.4659 - val_loss: 1.1684 - val_accuracy: 0.4659\n",
            "Epoch 913/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1665 - accuracy: 0.4661 - val_loss: 1.1659 - val_accuracy: 0.4666\n",
            "Epoch 914/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1665 - accuracy: 0.4663 - val_loss: 1.1659 - val_accuracy: 0.4670\n",
            "Epoch 915/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1652 - accuracy: 0.4669 - val_loss: 1.1660 - val_accuracy: 0.4667\n",
            "Epoch 916/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1636 - accuracy: 0.4677 - val_loss: 1.1621 - val_accuracy: 0.4689\n",
            "Epoch 917/3000\n",
            "76/76 [==============================] - 15s 197ms/step - loss: 1.1740 - accuracy: 0.4624 - val_loss: 1.1618 - val_accuracy: 0.4691\n",
            "Epoch 918/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1609 - accuracy: 0.4692 - val_loss: 1.1613 - val_accuracy: 0.4689\n",
            "Epoch 919/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1607 - accuracy: 0.4693 - val_loss: 1.1604 - val_accuracy: 0.4703\n",
            "Epoch 920/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1689 - accuracy: 0.4651 - val_loss: 1.1602 - val_accuracy: 0.4700\n",
            "Epoch 921/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1602 - accuracy: 0.4695 - val_loss: 1.1606 - val_accuracy: 0.4698\n",
            "Epoch 922/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1639 - accuracy: 0.4676 - val_loss: 1.1597 - val_accuracy: 0.4697\n",
            "Epoch 923/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1603 - accuracy: 0.4695 - val_loss: 1.1643 - val_accuracy: 0.4675\n",
            "Epoch 924/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1605 - accuracy: 0.4693 - val_loss: 1.1612 - val_accuracy: 0.4693\n",
            "Epoch 925/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1604 - accuracy: 0.4695 - val_loss: 1.1613 - val_accuracy: 0.4699\n",
            "Epoch 926/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1798 - accuracy: 0.4595 - val_loss: 1.1680 - val_accuracy: 0.4657\n",
            "Epoch 927/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1612 - accuracy: 0.4690 - val_loss: 1.1597 - val_accuracy: 0.4701\n",
            "Epoch 928/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1598 - accuracy: 0.4697 - val_loss: 1.1598 - val_accuracy: 0.4707\n",
            "Epoch 929/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1602 - accuracy: 0.4695 - val_loss: 1.1621 - val_accuracy: 0.4683\n",
            "Epoch 930/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1602 - accuracy: 0.4696 - val_loss: 1.1626 - val_accuracy: 0.4675\n",
            "Epoch 931/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1605 - accuracy: 0.4693 - val_loss: 1.1601 - val_accuracy: 0.4698\n",
            "Epoch 932/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1599 - accuracy: 0.4697 - val_loss: 1.1610 - val_accuracy: 0.4693\n",
            "Epoch 933/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1633 - accuracy: 0.4678 - val_loss: 1.1599 - val_accuracy: 0.4702\n",
            "Epoch 934/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1596 - accuracy: 0.4699 - val_loss: 1.1611 - val_accuracy: 0.4692\n",
            "Epoch 935/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1787 - accuracy: 0.4598 - val_loss: 1.1801 - val_accuracy: 0.4600\n",
            "Epoch 936/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1692 - accuracy: 0.4649 - val_loss: 1.1626 - val_accuracy: 0.4690\n",
            "Epoch 937/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1595 - accuracy: 0.4700 - val_loss: 1.1594 - val_accuracy: 0.4706\n",
            "Epoch 938/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1601 - accuracy: 0.4695 - val_loss: 1.1598 - val_accuracy: 0.4697\n",
            "Epoch 939/3000\n",
            "76/76 [==============================] - 15s 193ms/step - loss: 1.1597 - accuracy: 0.4697 - val_loss: 1.1604 - val_accuracy: 0.4699\n",
            "Epoch 940/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1601 - accuracy: 0.4695 - val_loss: 1.1612 - val_accuracy: 0.4694\n",
            "Epoch 941/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1710 - accuracy: 0.4639 - val_loss: 1.1669 - val_accuracy: 0.4666\n",
            "Epoch 942/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1599 - accuracy: 0.4697 - val_loss: 1.1592 - val_accuracy: 0.4707\n",
            "Epoch 943/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1596 - accuracy: 0.4698 - val_loss: 1.1595 - val_accuracy: 0.4700\n",
            "Epoch 944/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1598 - accuracy: 0.4696 - val_loss: 1.1600 - val_accuracy: 0.4699\n",
            "Epoch 945/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1598 - accuracy: 0.4696 - val_loss: 1.1599 - val_accuracy: 0.4699\n",
            "Epoch 946/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1602 - accuracy: 0.4694 - val_loss: 1.1597 - val_accuracy: 0.4700\n",
            "Epoch 947/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1597 - accuracy: 0.4697 - val_loss: 1.1604 - val_accuracy: 0.4693\n",
            "Epoch 948/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1599 - accuracy: 0.4696 - val_loss: 1.1604 - val_accuracy: 0.4697\n",
            "Epoch 949/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1598 - accuracy: 0.4696 - val_loss: 1.1598 - val_accuracy: 0.4704\n",
            "Epoch 950/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1623 - accuracy: 0.4685 - val_loss: 1.2330 - val_accuracy: 0.4342\n",
            "Epoch 951/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1842 - accuracy: 0.4571 - val_loss: 1.1703 - val_accuracy: 0.4647\n",
            "Epoch 952/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1672 - accuracy: 0.4660 - val_loss: 1.1676 - val_accuracy: 0.4658\n",
            "Epoch 953/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1617 - accuracy: 0.4688 - val_loss: 1.1595 - val_accuracy: 0.4702\n",
            "Epoch 954/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1597 - accuracy: 0.4699 - val_loss: 1.1596 - val_accuracy: 0.4701\n",
            "Epoch 955/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1602 - accuracy: 0.4695 - val_loss: 1.1594 - val_accuracy: 0.4694\n",
            "Epoch 956/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1596 - accuracy: 0.4698 - val_loss: 1.1593 - val_accuracy: 0.4701\n",
            "Epoch 957/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1599 - accuracy: 0.4697 - val_loss: 1.1599 - val_accuracy: 0.4695\n",
            "Epoch 958/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1595 - accuracy: 0.4699 - val_loss: 1.1597 - val_accuracy: 0.4704\n",
            "Epoch 959/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1594 - accuracy: 0.4699 - val_loss: 1.1596 - val_accuracy: 0.4701\n",
            "Epoch 960/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1600 - accuracy: 0.4697 - val_loss: 1.1606 - val_accuracy: 0.4691\n",
            "Epoch 961/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1596 - accuracy: 0.4697 - val_loss: 1.1592 - val_accuracy: 0.4709\n",
            "Epoch 962/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1732 - accuracy: 0.4627 - val_loss: 1.1697 - val_accuracy: 0.4643\n",
            "Epoch 963/3000\n",
            "76/76 [==============================] - 13s 178ms/step - loss: 1.1609 - accuracy: 0.4691 - val_loss: 1.1588 - val_accuracy: 0.4707\n",
            "Epoch 964/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1590 - accuracy: 0.4702 - val_loss: 1.1587 - val_accuracy: 0.4709\n",
            "Epoch 965/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1714 - accuracy: 0.4637 - val_loss: 1.1669 - val_accuracy: 0.4660\n",
            "Epoch 966/3000\n",
            "76/76 [==============================] - 13s 178ms/step - loss: 1.1595 - accuracy: 0.4699 - val_loss: 1.1590 - val_accuracy: 0.4707\n",
            "Epoch 967/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1593 - accuracy: 0.4699 - val_loss: 1.1586 - val_accuracy: 0.4704\n",
            "Epoch 968/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1593 - accuracy: 0.4700 - val_loss: 1.1588 - val_accuracy: 0.4703\n",
            "Epoch 969/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1838 - accuracy: 0.4572 - val_loss: 1.1812 - val_accuracy: 0.4581\n",
            "Epoch 970/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1719 - accuracy: 0.4636 - val_loss: 1.1682 - val_accuracy: 0.4650\n",
            "Epoch 971/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1663 - accuracy: 0.4664 - val_loss: 1.1660 - val_accuracy: 0.4664\n",
            "Epoch 972/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1617 - accuracy: 0.4688 - val_loss: 1.1592 - val_accuracy: 0.4705\n",
            "Epoch 973/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1597 - accuracy: 0.4698 - val_loss: 1.1591 - val_accuracy: 0.4698\n",
            "Epoch 974/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1599 - accuracy: 0.4696 - val_loss: 1.1589 - val_accuracy: 0.4708\n",
            "Epoch 975/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1591 - accuracy: 0.4701 - val_loss: 1.1587 - val_accuracy: 0.4702\n",
            "Epoch 976/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1595 - accuracy: 0.4698 - val_loss: 1.1588 - val_accuracy: 0.4702\n",
            "Epoch 977/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1676 - accuracy: 0.4657 - val_loss: 1.1623 - val_accuracy: 0.4683\n",
            "Epoch 978/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1586 - accuracy: 0.4704 - val_loss: 1.1588 - val_accuracy: 0.4698\n",
            "Epoch 979/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1590 - accuracy: 0.4702 - val_loss: 1.1590 - val_accuracy: 0.4697\n",
            "Epoch 980/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1592 - accuracy: 0.4701 - val_loss: 1.1589 - val_accuracy: 0.4699\n",
            "Epoch 981/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1593 - accuracy: 0.4699 - val_loss: 1.1587 - val_accuracy: 0.4705\n",
            "Epoch 982/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1591 - accuracy: 0.4700 - val_loss: 1.1587 - val_accuracy: 0.4703\n",
            "Epoch 983/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1592 - accuracy: 0.4700 - val_loss: 1.1585 - val_accuracy: 0.4705\n",
            "Epoch 984/3000\n",
            "76/76 [==============================] - 15s 192ms/step - loss: 1.1710 - accuracy: 0.4639 - val_loss: 1.1672 - val_accuracy: 0.4660\n",
            "Epoch 985/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1592 - accuracy: 0.4700 - val_loss: 1.1581 - val_accuracy: 0.4712\n",
            "Epoch 986/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1583 - accuracy: 0.4705 - val_loss: 1.1588 - val_accuracy: 0.4705\n",
            "Epoch 987/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1589 - accuracy: 0.4702 - val_loss: 1.1586 - val_accuracy: 0.4704\n",
            "Epoch 988/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1590 - accuracy: 0.4701 - val_loss: 1.1590 - val_accuracy: 0.4702\n",
            "Epoch 989/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1590 - accuracy: 0.4701 - val_loss: 1.1586 - val_accuracy: 0.4705\n",
            "Epoch 990/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1596 - accuracy: 0.4697 - val_loss: 1.1587 - val_accuracy: 0.4703\n",
            "Epoch 991/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1588 - accuracy: 0.4703 - val_loss: 1.1587 - val_accuracy: 0.4705\n",
            "Epoch 992/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1589 - accuracy: 0.4701 - val_loss: 1.1587 - val_accuracy: 0.4702\n",
            "Epoch 993/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1587 - accuracy: 0.4703 - val_loss: 1.1587 - val_accuracy: 0.4705\n",
            "Epoch 994/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1591 - accuracy: 0.4701 - val_loss: 1.1587 - val_accuracy: 0.4704\n",
            "Epoch 995/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1717 - accuracy: 0.4636 - val_loss: 1.1676 - val_accuracy: 0.4654\n",
            "Epoch 996/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1592 - accuracy: 0.4701 - val_loss: 1.1579 - val_accuracy: 0.4709\n",
            "Epoch 997/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1585 - accuracy: 0.4705 - val_loss: 1.1584 - val_accuracy: 0.4706\n",
            "Epoch 998/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1792 - accuracy: 0.4597 - val_loss: 1.1750 - val_accuracy: 0.4611\n",
            "Epoch 999/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1675 - accuracy: 0.4658 - val_loss: 1.1633 - val_accuracy: 0.4680\n",
            "Epoch 1000/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1586 - accuracy: 0.4703 - val_loss: 1.1581 - val_accuracy: 0.4704\n",
            "Epoch 1001/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1584 - accuracy: 0.4705 - val_loss: 1.1581 - val_accuracy: 0.4709\n",
            "Epoch 1002/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1587 - accuracy: 0.4703 - val_loss: 1.1590 - val_accuracy: 0.4698\n",
            "Epoch 1003/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1587 - accuracy: 0.4702 - val_loss: 1.1582 - val_accuracy: 0.4711\n",
            "Epoch 1004/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1682 - accuracy: 0.4654 - val_loss: 1.1626 - val_accuracy: 0.4681\n",
            "Epoch 1005/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1582 - accuracy: 0.4706 - val_loss: 1.1580 - val_accuracy: 0.4707\n",
            "Epoch 1006/3000\n",
            "76/76 [==============================] - 15s 197ms/step - loss: 1.1582 - accuracy: 0.4706 - val_loss: 1.1581 - val_accuracy: 0.4705\n",
            "Epoch 1007/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1588 - accuracy: 0.4702 - val_loss: 1.1581 - val_accuracy: 0.4704\n",
            "Epoch 1008/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1584 - accuracy: 0.4704 - val_loss: 1.1595 - val_accuracy: 0.4695\n",
            "Epoch 1009/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1589 - accuracy: 0.4702 - val_loss: 1.1581 - val_accuracy: 0.4704\n",
            "Epoch 1010/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1801 - accuracy: 0.4593 - val_loss: 1.1760 - val_accuracy: 0.4611\n",
            "Epoch 1011/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1680 - accuracy: 0.4656 - val_loss: 1.1644 - val_accuracy: 0.4673\n",
            "Epoch 1012/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1592 - accuracy: 0.4701 - val_loss: 1.1582 - val_accuracy: 0.4707\n",
            "Epoch 1013/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1580 - accuracy: 0.4707 - val_loss: 1.1581 - val_accuracy: 0.4710\n",
            "Epoch 1014/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1588 - accuracy: 0.4702 - val_loss: 1.1586 - val_accuracy: 0.4706\n",
            "Epoch 1015/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1582 - accuracy: 0.4706 - val_loss: 1.1580 - val_accuracy: 0.4710\n",
            "Epoch 1016/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1587 - accuracy: 0.4703 - val_loss: 1.1588 - val_accuracy: 0.4707\n",
            "Epoch 1017/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1582 - accuracy: 0.4706 - val_loss: 1.1588 - val_accuracy: 0.4700\n",
            "Epoch 1018/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1584 - accuracy: 0.4704 - val_loss: 1.1586 - val_accuracy: 0.4708\n",
            "Epoch 1019/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1583 - accuracy: 0.4705 - val_loss: 1.1589 - val_accuracy: 0.4703\n",
            "Epoch 1020/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1583 - accuracy: 0.4705 - val_loss: 1.1590 - val_accuracy: 0.4701\n",
            "Epoch 1021/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1582 - accuracy: 0.4706 - val_loss: 1.1587 - val_accuracy: 0.4702\n",
            "Epoch 1022/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1588 - accuracy: 0.4703 - val_loss: 1.1576 - val_accuracy: 0.4712\n",
            "Epoch 1023/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1579 - accuracy: 0.4707 - val_loss: 1.1584 - val_accuracy: 0.4703\n",
            "Epoch 1024/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1790 - accuracy: 0.4598 - val_loss: 1.1761 - val_accuracy: 0.4612\n",
            "Epoch 1025/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1678 - accuracy: 0.4657 - val_loss: 1.1633 - val_accuracy: 0.4678\n",
            "Epoch 1026/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1583 - accuracy: 0.4707 - val_loss: 1.1582 - val_accuracy: 0.4711\n",
            "Epoch 1027/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1578 - accuracy: 0.4709 - val_loss: 1.1584 - val_accuracy: 0.4711\n",
            "Epoch 1028/3000\n",
            "76/76 [==============================] - 15s 200ms/step - loss: 1.1580 - accuracy: 0.4708 - val_loss: 1.1586 - val_accuracy: 0.4702\n",
            "Epoch 1029/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1579 - accuracy: 0.4707 - val_loss: 1.1576 - val_accuracy: 0.4705\n",
            "Epoch 1030/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1580 - accuracy: 0.4707 - val_loss: 1.1578 - val_accuracy: 0.4704\n",
            "Epoch 1031/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1580 - accuracy: 0.4708 - val_loss: 1.1578 - val_accuracy: 0.4707\n",
            "Epoch 1032/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1714 - accuracy: 0.4638 - val_loss: 1.1713 - val_accuracy: 0.4639\n",
            "Epoch 1033/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1608 - accuracy: 0.4692 - val_loss: 1.1571 - val_accuracy: 0.4713\n",
            "Epoch 1034/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1571 - accuracy: 0.4713 - val_loss: 1.1577 - val_accuracy: 0.4715\n",
            "Epoch 1035/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1577 - accuracy: 0.4710 - val_loss: 1.1582 - val_accuracy: 0.4705\n",
            "Epoch 1036/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1579 - accuracy: 0.4708 - val_loss: 1.1577 - val_accuracy: 0.4712\n",
            "Epoch 1037/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1578 - accuracy: 0.4709 - val_loss: 1.1583 - val_accuracy: 0.4704\n",
            "Epoch 1038/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1577 - accuracy: 0.4709 - val_loss: 1.1574 - val_accuracy: 0.4716\n",
            "Epoch 1039/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1579 - accuracy: 0.4709 - val_loss: 1.1573 - val_accuracy: 0.4709\n",
            "Epoch 1040/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1578 - accuracy: 0.4708 - val_loss: 1.1574 - val_accuracy: 0.4715\n",
            "Epoch 1041/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1577 - accuracy: 0.4710 - val_loss: 1.1574 - val_accuracy: 0.4714\n",
            "Epoch 1042/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1864 - accuracy: 0.4563 - val_loss: 1.1712 - val_accuracy: 0.4641\n",
            "Epoch 1043/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1667 - accuracy: 0.4664 - val_loss: 1.1647 - val_accuracy: 0.4666\n",
            "Epoch 1044/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1620 - accuracy: 0.4689 - val_loss: 1.1591 - val_accuracy: 0.4703\n",
            "Epoch 1045/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1576 - accuracy: 0.4712 - val_loss: 1.1570 - val_accuracy: 0.4716\n",
            "Epoch 1046/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1575 - accuracy: 0.4712 - val_loss: 1.1570 - val_accuracy: 0.4718\n",
            "Epoch 1047/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1577 - accuracy: 0.4710 - val_loss: 1.1575 - val_accuracy: 0.4715\n",
            "Epoch 1048/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1575 - accuracy: 0.4711 - val_loss: 1.1574 - val_accuracy: 0.4717\n",
            "Epoch 1049/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1577 - accuracy: 0.4711 - val_loss: 1.1573 - val_accuracy: 0.4713\n",
            "Epoch 1050/3000\n",
            "76/76 [==============================] - 15s 194ms/step - loss: 1.1576 - accuracy: 0.4711 - val_loss: 1.1577 - val_accuracy: 0.4713\n",
            "Epoch 1051/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1806 - accuracy: 0.4593 - val_loss: 1.1683 - val_accuracy: 0.4652\n",
            "Epoch 1052/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1632 - accuracy: 0.4682 - val_loss: 1.1586 - val_accuracy: 0.4708\n",
            "Epoch 1053/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1571 - accuracy: 0.4714 - val_loss: 1.1567 - val_accuracy: 0.4719\n",
            "Epoch 1054/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1573 - accuracy: 0.4713 - val_loss: 1.1571 - val_accuracy: 0.4716\n",
            "Epoch 1055/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1576 - accuracy: 0.4711 - val_loss: 1.1573 - val_accuracy: 0.4714\n",
            "Epoch 1056/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1572 - accuracy: 0.4713 - val_loss: 1.1569 - val_accuracy: 0.4721\n",
            "Epoch 1057/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1576 - accuracy: 0.4711 - val_loss: 1.1576 - val_accuracy: 0.4718\n",
            "Epoch 1058/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1572 - accuracy: 0.4713 - val_loss: 1.1576 - val_accuracy: 0.4714\n",
            "Epoch 1059/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1630 - accuracy: 0.4682 - val_loss: 1.1563 - val_accuracy: 0.4722\n",
            "Epoch 1060/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1567 - accuracy: 0.4716 - val_loss: 1.1570 - val_accuracy: 0.4714\n",
            "Epoch 1061/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1575 - accuracy: 0.4712 - val_loss: 1.1569 - val_accuracy: 0.4710\n",
            "Epoch 1062/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1572 - accuracy: 0.4714 - val_loss: 1.1572 - val_accuracy: 0.4716\n",
            "Epoch 1063/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1573 - accuracy: 0.4713 - val_loss: 1.1575 - val_accuracy: 0.4713\n",
            "Epoch 1064/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1572 - accuracy: 0.4714 - val_loss: 1.1574 - val_accuracy: 0.4717\n",
            "Epoch 1065/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1573 - accuracy: 0.4713 - val_loss: 1.1564 - val_accuracy: 0.4717\n",
            "Epoch 1066/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1571 - accuracy: 0.4714 - val_loss: 1.1566 - val_accuracy: 0.4719\n",
            "Epoch 1067/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1576 - accuracy: 0.4713 - val_loss: 1.1562 - val_accuracy: 0.4721\n",
            "Epoch 1068/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1602 - accuracy: 0.4699 - val_loss: 1.1582 - val_accuracy: 0.4703\n",
            "Epoch 1069/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1563 - accuracy: 0.4719 - val_loss: 1.1561 - val_accuracy: 0.4722\n",
            "Epoch 1070/3000\n",
            "76/76 [==============================] - 14s 189ms/step - loss: 1.1565 - accuracy: 0.4718 - val_loss: 1.1567 - val_accuracy: 0.4721\n",
            "Epoch 1071/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1603 - accuracy: 0.4698 - val_loss: 1.1556 - val_accuracy: 0.4722\n",
            "Epoch 1072/3000\n",
            "76/76 [==============================] - 16s 205ms/step - loss: 1.1563 - accuracy: 0.4719 - val_loss: 1.1573 - val_accuracy: 0.4715\n",
            "Epoch 1073/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1567 - accuracy: 0.4717 - val_loss: 1.1563 - val_accuracy: 0.4717\n",
            "Epoch 1074/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1571 - accuracy: 0.4715 - val_loss: 1.1563 - val_accuracy: 0.4714\n",
            "Epoch 1075/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1569 - accuracy: 0.4717 - val_loss: 1.1565 - val_accuracy: 0.4715\n",
            "Epoch 1076/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1648 - accuracy: 0.4675 - val_loss: 1.1558 - val_accuracy: 0.4724\n",
            "Epoch 1077/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1561 - accuracy: 0.4721 - val_loss: 1.1562 - val_accuracy: 0.4717\n",
            "Epoch 1078/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1569 - accuracy: 0.4716 - val_loss: 1.1565 - val_accuracy: 0.4720\n",
            "Epoch 1079/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1569 - accuracy: 0.4716 - val_loss: 1.1570 - val_accuracy: 0.4715\n",
            "Epoch 1080/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1564 - accuracy: 0.4720 - val_loss: 1.1564 - val_accuracy: 0.4714\n",
            "Epoch 1081/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1568 - accuracy: 0.4717 - val_loss: 1.1568 - val_accuracy: 0.4720\n",
            "Epoch 1082/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1567 - accuracy: 0.4717 - val_loss: 1.1562 - val_accuracy: 0.4718\n",
            "Epoch 1083/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1681 - accuracy: 0.4659 - val_loss: 1.1566 - val_accuracy: 0.4716\n",
            "Epoch 1084/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1560 - accuracy: 0.4722 - val_loss: 1.1559 - val_accuracy: 0.4725\n",
            "Epoch 1085/3000\n",
            "76/76 [==============================] - 15s 192ms/step - loss: 1.1565 - accuracy: 0.4720 - val_loss: 1.1564 - val_accuracy: 0.4722\n",
            "Epoch 1086/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1566 - accuracy: 0.4718 - val_loss: 1.1562 - val_accuracy: 0.4722\n",
            "Epoch 1087/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1564 - accuracy: 0.4720 - val_loss: 1.1574 - val_accuracy: 0.4714\n",
            "Epoch 1088/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1564 - accuracy: 0.4719 - val_loss: 1.1561 - val_accuracy: 0.4720\n",
            "Epoch 1089/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1890 - accuracy: 0.4550 - val_loss: 1.1730 - val_accuracy: 0.4632\n",
            "Epoch 1090/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1672 - accuracy: 0.4665 - val_loss: 1.1642 - val_accuracy: 0.4683\n",
            "Epoch 1091/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1607 - accuracy: 0.4700 - val_loss: 1.1569 - val_accuracy: 0.4721\n",
            "Epoch 1092/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1561 - accuracy: 0.4722 - val_loss: 1.1562 - val_accuracy: 0.4725\n",
            "Epoch 1093/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1566 - accuracy: 0.4720 - val_loss: 1.1554 - val_accuracy: 0.4726\n",
            "Epoch 1094/3000\n",
            "76/76 [==============================] - 15s 195ms/step - loss: 1.1564 - accuracy: 0.4720 - val_loss: 1.1555 - val_accuracy: 0.4729\n",
            "Epoch 1095/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1564 - accuracy: 0.4719 - val_loss: 1.1554 - val_accuracy: 0.4733\n",
            "Epoch 1096/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1563 - accuracy: 0.4720 - val_loss: 1.1558 - val_accuracy: 0.4724\n",
            "Epoch 1097/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1561 - accuracy: 0.4722 - val_loss: 1.1560 - val_accuracy: 0.4726\n",
            "Epoch 1098/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1565 - accuracy: 0.4720 - val_loss: 1.1558 - val_accuracy: 0.4724\n",
            "Epoch 1099/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1577 - accuracy: 0.4713 - val_loss: 1.1570 - val_accuracy: 0.4712\n",
            "Epoch 1100/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1556 - accuracy: 0.4725 - val_loss: 1.1550 - val_accuracy: 0.4724\n",
            "Epoch 1101/3000\n",
            "76/76 [==============================] - 13s 178ms/step - loss: 1.1561 - accuracy: 0.4722 - val_loss: 1.1560 - val_accuracy: 0.4720\n",
            "Epoch 1102/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1679 - accuracy: 0.4662 - val_loss: 1.1553 - val_accuracy: 0.4726\n",
            "Epoch 1103/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1552 - accuracy: 0.4727 - val_loss: 1.1550 - val_accuracy: 0.4729\n",
            "Epoch 1104/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1555 - accuracy: 0.4725 - val_loss: 1.1553 - val_accuracy: 0.4728\n",
            "Epoch 1105/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1560 - accuracy: 0.4723 - val_loss: 1.1556 - val_accuracy: 0.4721\n",
            "Epoch 1106/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1559 - accuracy: 0.4723 - val_loss: 1.1553 - val_accuracy: 0.4719\n",
            "Epoch 1107/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1563 - accuracy: 0.4722 - val_loss: 1.1558 - val_accuracy: 0.4726\n",
            "Epoch 1108/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1597 - accuracy: 0.4703 - val_loss: 1.1545 - val_accuracy: 0.4730\n",
            "Epoch 1109/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1568 - accuracy: 0.4720 - val_loss: 1.1883 - val_accuracy: 0.4557\n",
            "Epoch 1110/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1613 - accuracy: 0.4696 - val_loss: 1.1551 - val_accuracy: 0.4733\n",
            "Epoch 1111/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1554 - accuracy: 0.4727 - val_loss: 1.1548 - val_accuracy: 0.4727\n",
            "Epoch 1112/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1557 - accuracy: 0.4725 - val_loss: 1.1548 - val_accuracy: 0.4722\n",
            "Epoch 1113/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1799 - accuracy: 0.4599 - val_loss: 1.1641 - val_accuracy: 0.4671\n",
            "Epoch 1114/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1577 - accuracy: 0.4716 - val_loss: 1.1547 - val_accuracy: 0.4733\n",
            "Epoch 1115/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1550 - accuracy: 0.4729 - val_loss: 1.1559 - val_accuracy: 0.4722\n",
            "Epoch 1116/3000\n",
            "76/76 [==============================] - 15s 200ms/step - loss: 1.1557 - accuracy: 0.4724 - val_loss: 1.1548 - val_accuracy: 0.4729\n",
            "Epoch 1117/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1555 - accuracy: 0.4726 - val_loss: 1.1551 - val_accuracy: 0.4726\n",
            "Epoch 1118/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1555 - accuracy: 0.4726 - val_loss: 1.1633 - val_accuracy: 0.4683\n",
            "Epoch 1119/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1785 - accuracy: 0.4607 - val_loss: 1.1613 - val_accuracy: 0.4693\n",
            "Epoch 1120/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1566 - accuracy: 0.4722 - val_loss: 1.1546 - val_accuracy: 0.4735\n",
            "Epoch 1121/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1549 - accuracy: 0.4730 - val_loss: 1.1548 - val_accuracy: 0.4728\n",
            "Epoch 1122/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1553 - accuracy: 0.4728 - val_loss: 1.1547 - val_accuracy: 0.4726\n",
            "Epoch 1123/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1556 - accuracy: 0.4726 - val_loss: 1.1552 - val_accuracy: 0.4731\n",
            "Epoch 1124/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1558 - accuracy: 0.4724 - val_loss: 1.1548 - val_accuracy: 0.4730\n",
            "Epoch 1125/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1661 - accuracy: 0.4674 - val_loss: 1.1955 - val_accuracy: 0.4512\n",
            "Epoch 1126/3000\n",
            "76/76 [==============================] - 13s 178ms/step - loss: 1.1703 - accuracy: 0.4649 - val_loss: 1.1612 - val_accuracy: 0.4697\n",
            "Epoch 1127/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1568 - accuracy: 0.4721 - val_loss: 1.1548 - val_accuracy: 0.4737\n",
            "Epoch 1128/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1549 - accuracy: 0.4730 - val_loss: 1.1544 - val_accuracy: 0.4728\n",
            "Epoch 1129/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1552 - accuracy: 0.4729 - val_loss: 1.1547 - val_accuracy: 0.4729\n",
            "Epoch 1130/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1553 - accuracy: 0.4727 - val_loss: 1.1541 - val_accuracy: 0.4734\n",
            "Epoch 1131/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1554 - accuracy: 0.4728 - val_loss: 1.1537 - val_accuracy: 0.4740\n",
            "Epoch 1132/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1554 - accuracy: 0.4727 - val_loss: 1.1543 - val_accuracy: 0.4738\n",
            "Epoch 1133/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1556 - accuracy: 0.4727 - val_loss: 1.1557 - val_accuracy: 0.4728\n",
            "Epoch 1134/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1555 - accuracy: 0.4725 - val_loss: 1.1545 - val_accuracy: 0.4730\n",
            "Epoch 1135/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1553 - accuracy: 0.4728 - val_loss: 1.1543 - val_accuracy: 0.4737\n",
            "Epoch 1136/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1553 - accuracy: 0.4727 - val_loss: 1.1548 - val_accuracy: 0.4730\n",
            "Epoch 1137/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1552 - accuracy: 0.4728 - val_loss: 1.1548 - val_accuracy: 0.4725\n",
            "Epoch 1138/3000\n",
            "76/76 [==============================] - 15s 196ms/step - loss: 1.1557 - accuracy: 0.4727 - val_loss: 1.1542 - val_accuracy: 0.4736\n",
            "Epoch 1139/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.1548 - accuracy: 0.4730 - val_loss: 1.1552 - val_accuracy: 0.4722\n",
            "Epoch 1140/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1563 - accuracy: 0.4724 - val_loss: 1.1538 - val_accuracy: 0.4732\n",
            "Epoch 1141/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1551 - accuracy: 0.4729 - val_loss: 1.1537 - val_accuracy: 0.4733\n",
            "Epoch 1142/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1552 - accuracy: 0.4729 - val_loss: 1.1548 - val_accuracy: 0.4731\n",
            "Epoch 1143/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1551 - accuracy: 0.4730 - val_loss: 1.1570 - val_accuracy: 0.4720\n",
            "Epoch 1144/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1552 - accuracy: 0.4728 - val_loss: 1.1539 - val_accuracy: 0.4735\n",
            "Epoch 1145/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1585 - accuracy: 0.4711 - val_loss: 1.1684 - val_accuracy: 0.4650\n",
            "Epoch 1146/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1568 - accuracy: 0.4719 - val_loss: 1.1537 - val_accuracy: 0.4734\n",
            "Epoch 1147/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.1544 - accuracy: 0.4733 - val_loss: 1.1544 - val_accuracy: 0.4733\n",
            "Epoch 1148/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1549 - accuracy: 0.4731 - val_loss: 1.1552 - val_accuracy: 0.4729\n",
            "Epoch 1149/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1547 - accuracy: 0.4731 - val_loss: 1.1543 - val_accuracy: 0.4743\n",
            "Epoch 1150/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1549 - accuracy: 0.4730 - val_loss: 1.1533 - val_accuracy: 0.4744\n",
            "Epoch 1151/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1553 - accuracy: 0.4728 - val_loss: 1.1541 - val_accuracy: 0.4735\n",
            "Epoch 1152/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1548 - accuracy: 0.4731 - val_loss: 1.1540 - val_accuracy: 0.4740\n",
            "Epoch 1153/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1549 - accuracy: 0.4730 - val_loss: 1.1536 - val_accuracy: 0.4737\n",
            "Epoch 1154/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1587 - accuracy: 0.4710 - val_loss: 1.1656 - val_accuracy: 0.4677\n",
            "Epoch 1155/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1561 - accuracy: 0.4724 - val_loss: 1.1540 - val_accuracy: 0.4736\n",
            "Epoch 1156/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1546 - accuracy: 0.4732 - val_loss: 1.1543 - val_accuracy: 0.4735\n",
            "Epoch 1157/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1548 - accuracy: 0.4731 - val_loss: 1.1544 - val_accuracy: 0.4729\n",
            "Epoch 1158/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1548 - accuracy: 0.4731 - val_loss: 1.1549 - val_accuracy: 0.4727\n",
            "Epoch 1159/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1553 - accuracy: 0.4728 - val_loss: 1.1561 - val_accuracy: 0.4732\n",
            "Epoch 1160/3000\n",
            "76/76 [==============================] - 15s 191ms/step - loss: 1.1545 - accuracy: 0.4732 - val_loss: 1.1545 - val_accuracy: 0.4733\n",
            "Epoch 1161/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1652 - accuracy: 0.4677 - val_loss: 1.1536 - val_accuracy: 0.4745\n",
            "Epoch 1162/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1539 - accuracy: 0.4736 - val_loss: 1.1537 - val_accuracy: 0.4739\n",
            "Epoch 1163/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1543 - accuracy: 0.4734 - val_loss: 1.1541 - val_accuracy: 0.4729\n",
            "Epoch 1164/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.1544 - accuracy: 0.4733 - val_loss: 1.1537 - val_accuracy: 0.4741\n",
            "Epoch 1165/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1547 - accuracy: 0.4732 - val_loss: 1.1562 - val_accuracy: 0.4724\n",
            "Epoch 1166/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1546 - accuracy: 0.4732 - val_loss: 1.1550 - val_accuracy: 0.4732\n",
            "Epoch 1167/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.1548 - accuracy: 0.4730 - val_loss: 1.1537 - val_accuracy: 0.4735\n",
            "Epoch 1168/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1549 - accuracy: 0.4730 - val_loss: 1.1546 - val_accuracy: 0.4726\n",
            "Epoch 1169/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1545 - accuracy: 0.4732 - val_loss: 1.1538 - val_accuracy: 0.4735\n",
            "Epoch 1170/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1547 - accuracy: 0.4731 - val_loss: 1.1552 - val_accuracy: 0.4730\n",
            "Epoch 1171/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1546 - accuracy: 0.4732 - val_loss: 1.1542 - val_accuracy: 0.4732\n",
            "Epoch 1172/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1546 - accuracy: 0.4732 - val_loss: 1.1554 - val_accuracy: 0.4725\n",
            "Epoch 1173/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1546 - accuracy: 0.4732 - val_loss: 1.1540 - val_accuracy: 0.4735\n",
            "Epoch 1174/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1561 - accuracy: 0.4724 - val_loss: 1.1532 - val_accuracy: 0.4737\n",
            "Epoch 1175/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.1542 - accuracy: 0.4734 - val_loss: 1.1547 - val_accuracy: 0.4726\n",
            "Epoch 1176/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1542 - accuracy: 0.4734 - val_loss: 1.1535 - val_accuracy: 0.4732\n",
            "Epoch 1177/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1548 - accuracy: 0.4731 - val_loss: 1.1539 - val_accuracy: 0.4737\n",
            "Epoch 1178/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1543 - accuracy: 0.4733 - val_loss: 1.1547 - val_accuracy: 0.4731\n",
            "Epoch 1179/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.1544 - accuracy: 0.4733 - val_loss: 1.1535 - val_accuracy: 0.4735\n",
            "Epoch 1180/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1545 - accuracy: 0.4732 - val_loss: 1.1543 - val_accuracy: 0.4739\n",
            "Epoch 1181/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1544 - accuracy: 0.4733 - val_loss: 1.1547 - val_accuracy: 0.4733\n",
            "Epoch 1182/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1548 - accuracy: 0.4731 - val_loss: 1.1856 - val_accuracy: 0.4580\n",
            "Epoch 1183/3000\n",
            "76/76 [==============================] - 15s 197ms/step - loss: 1.1592 - accuracy: 0.4708 - val_loss: 1.1529 - val_accuracy: 0.4748\n",
            "Epoch 1184/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1538 - accuracy: 0.4736 - val_loss: 1.1540 - val_accuracy: 0.4733\n",
            "Epoch 1185/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.1541 - accuracy: 0.4734 - val_loss: 1.1564 - val_accuracy: 0.4731\n",
            "Epoch 1186/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.1543 - accuracy: 0.4733 - val_loss: 1.1536 - val_accuracy: 0.4735\n",
            "Epoch 1187/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.1542 - accuracy: 0.4734 - val_loss: 1.1539 - val_accuracy: 0.4736\n",
            "Epoch 1188/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1543 - accuracy: 0.4732 - val_loss: 1.1547 - val_accuracy: 0.4734\n",
            "Epoch 1189/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1543 - accuracy: 0.4733 - val_loss: 1.1534 - val_accuracy: 0.4739\n",
            "Epoch 1190/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1543 - accuracy: 0.4732 - val_loss: 1.1535 - val_accuracy: 0.4738\n",
            "Epoch 1191/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1543 - accuracy: 0.4733 - val_loss: 1.1532 - val_accuracy: 0.4738\n",
            "Epoch 1192/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1543 - accuracy: 0.4733 - val_loss: 1.1538 - val_accuracy: 0.4731\n",
            "Epoch 1193/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1542 - accuracy: 0.4733 - val_loss: 1.1538 - val_accuracy: 0.4736\n",
            "Epoch 1194/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1782 - accuracy: 0.4608 - val_loss: 1.1772 - val_accuracy: 0.4604\n",
            "Epoch 1195/3000\n",
            "76/76 [==============================] - 15s 195ms/step - loss: 1.1664 - accuracy: 0.4672 - val_loss: 1.1602 - val_accuracy: 0.4704\n",
            "Epoch 1196/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1560 - accuracy: 0.4727 - val_loss: 1.1527 - val_accuracy: 0.4745\n",
            "Epoch 1197/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1538 - accuracy: 0.4736 - val_loss: 1.1536 - val_accuracy: 0.4742\n",
            "Epoch 1198/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1539 - accuracy: 0.4735 - val_loss: 1.1544 - val_accuracy: 0.4737\n",
            "Epoch 1199/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1537 - accuracy: 0.4736 - val_loss: 1.1529 - val_accuracy: 0.4739\n",
            "Epoch 1200/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1543 - accuracy: 0.4733 - val_loss: 1.1552 - val_accuracy: 0.4720\n",
            "Epoch 1201/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1539 - accuracy: 0.4735 - val_loss: 1.1536 - val_accuracy: 0.4734\n",
            "Epoch 1202/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1541 - accuracy: 0.4735 - val_loss: 1.1525 - val_accuracy: 0.4747\n",
            "Epoch 1203/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1541 - accuracy: 0.4734 - val_loss: 1.1532 - val_accuracy: 0.4737\n",
            "Epoch 1204/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1542 - accuracy: 0.4733 - val_loss: 1.1536 - val_accuracy: 0.4737\n",
            "Epoch 1205/3000\n",
            "76/76 [==============================] - 15s 200ms/step - loss: 1.1542 - accuracy: 0.4733 - val_loss: 1.1537 - val_accuracy: 0.4732\n",
            "Epoch 1206/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1538 - accuracy: 0.4736 - val_loss: 1.1530 - val_accuracy: 0.4738\n",
            "Epoch 1207/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1542 - accuracy: 0.4733 - val_loss: 1.1533 - val_accuracy: 0.4734\n",
            "Epoch 1208/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1545 - accuracy: 0.4732 - val_loss: 1.1536 - val_accuracy: 0.4737\n",
            "Epoch 1209/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1542 - accuracy: 0.4734 - val_loss: 1.1538 - val_accuracy: 0.4729\n",
            "Epoch 1210/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1536 - accuracy: 0.4737 - val_loss: 1.1536 - val_accuracy: 0.4733\n",
            "Epoch 1211/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1537 - accuracy: 0.4736 - val_loss: 1.1535 - val_accuracy: 0.4730\n",
            "Epoch 1212/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1538 - accuracy: 0.4735 - val_loss: 1.1528 - val_accuracy: 0.4744\n",
            "Epoch 1213/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1541 - accuracy: 0.4734 - val_loss: 1.1528 - val_accuracy: 0.4738\n",
            "Epoch 1214/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1579 - accuracy: 0.4714 - val_loss: 1.1544 - val_accuracy: 0.4723\n",
            "Epoch 1215/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1533 - accuracy: 0.4738 - val_loss: 1.1534 - val_accuracy: 0.4738\n",
            "Epoch 1216/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1536 - accuracy: 0.4736 - val_loss: 1.1528 - val_accuracy: 0.4742\n",
            "Epoch 1217/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1537 - accuracy: 0.4736 - val_loss: 1.1539 - val_accuracy: 0.4744\n",
            "Epoch 1218/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1540 - accuracy: 0.4734 - val_loss: 1.1531 - val_accuracy: 0.4737\n",
            "Epoch 1219/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1538 - accuracy: 0.4735 - val_loss: 1.1538 - val_accuracy: 0.4737\n",
            "Epoch 1220/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1538 - accuracy: 0.4735 - val_loss: 1.1560 - val_accuracy: 0.4720\n",
            "Epoch 1221/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1537 - accuracy: 0.4736 - val_loss: 1.1537 - val_accuracy: 0.4732\n",
            "Epoch 1222/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1537 - accuracy: 0.4736 - val_loss: 1.1540 - val_accuracy: 0.4732\n",
            "Epoch 1223/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1539 - accuracy: 0.4735 - val_loss: 1.1549 - val_accuracy: 0.4722\n",
            "Epoch 1224/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1537 - accuracy: 0.4735 - val_loss: 1.1537 - val_accuracy: 0.4736\n",
            "Epoch 1225/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1621 - accuracy: 0.4694 - val_loss: 1.1522 - val_accuracy: 0.4743\n",
            "Epoch 1226/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1530 - accuracy: 0.4739 - val_loss: 1.1535 - val_accuracy: 0.4736\n",
            "Epoch 1227/3000\n",
            "76/76 [==============================] - 15s 199ms/step - loss: 1.1534 - accuracy: 0.4738 - val_loss: 1.1538 - val_accuracy: 0.4737\n",
            "Epoch 1228/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1536 - accuracy: 0.4736 - val_loss: 1.1552 - val_accuracy: 0.4725\n",
            "Epoch 1229/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1535 - accuracy: 0.4736 - val_loss: 1.1537 - val_accuracy: 0.4728\n",
            "Epoch 1230/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1628 - accuracy: 0.4688 - val_loss: 1.1547 - val_accuracy: 0.4732\n",
            "Epoch 1231/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1532 - accuracy: 0.4739 - val_loss: 1.1518 - val_accuracy: 0.4748\n",
            "Epoch 1232/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1532 - accuracy: 0.4739 - val_loss: 1.1529 - val_accuracy: 0.4739\n",
            "Epoch 1233/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1534 - accuracy: 0.4737 - val_loss: 1.1532 - val_accuracy: 0.4735\n",
            "Epoch 1234/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1535 - accuracy: 0.4737 - val_loss: 1.1548 - val_accuracy: 0.4721\n",
            "Epoch 1235/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1536 - accuracy: 0.4736 - val_loss: 1.1537 - val_accuracy: 0.4734\n",
            "Epoch 1236/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1535 - accuracy: 0.4737 - val_loss: 1.1557 - val_accuracy: 0.4725\n",
            "Epoch 1237/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1537 - accuracy: 0.4735 - val_loss: 1.1540 - val_accuracy: 0.4730\n",
            "Epoch 1238/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1535 - accuracy: 0.4736 - val_loss: 1.1531 - val_accuracy: 0.4735\n",
            "Epoch 1239/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1538 - accuracy: 0.4734 - val_loss: 1.1532 - val_accuracy: 0.4735\n",
            "Epoch 1240/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1536 - accuracy: 0.4736 - val_loss: 1.1533 - val_accuracy: 0.4732\n",
            "Epoch 1241/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1536 - accuracy: 0.4736 - val_loss: 1.1545 - val_accuracy: 0.4724\n",
            "Epoch 1242/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1537 - accuracy: 0.4735 - val_loss: 1.1531 - val_accuracy: 0.4736\n",
            "Epoch 1243/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1555 - accuracy: 0.4726 - val_loss: 1.1721 - val_accuracy: 0.4641\n",
            "Epoch 1244/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1557 - accuracy: 0.4723 - val_loss: 1.1520 - val_accuracy: 0.4738\n",
            "Epoch 1245/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1527 - accuracy: 0.4740 - val_loss: 1.1530 - val_accuracy: 0.4741\n",
            "Epoch 1246/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1530 - accuracy: 0.4739 - val_loss: 1.1531 - val_accuracy: 0.4729\n",
            "Epoch 1247/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1533 - accuracy: 0.4738 - val_loss: 1.1550 - val_accuracy: 0.4729\n",
            "Epoch 1248/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1536 - accuracy: 0.4736 - val_loss: 1.1524 - val_accuracy: 0.4742\n",
            "Epoch 1249/3000\n",
            "76/76 [==============================] - 15s 195ms/step - loss: 1.1532 - accuracy: 0.4738 - val_loss: 1.1530 - val_accuracy: 0.4731\n",
            "Epoch 1250/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1535 - accuracy: 0.4736 - val_loss: 1.1527 - val_accuracy: 0.4737\n",
            "Epoch 1251/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1535 - accuracy: 0.4736 - val_loss: 1.1525 - val_accuracy: 0.4744\n",
            "Epoch 1252/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1552 - accuracy: 0.4728 - val_loss: 1.1517 - val_accuracy: 0.4743\n",
            "Epoch 1253/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1526 - accuracy: 0.4741 - val_loss: 1.1524 - val_accuracy: 0.4742\n",
            "Epoch 1254/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1530 - accuracy: 0.4739 - val_loss: 1.1524 - val_accuracy: 0.4743\n",
            "Epoch 1255/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1531 - accuracy: 0.4739 - val_loss: 1.1529 - val_accuracy: 0.4740\n",
            "Epoch 1256/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1532 - accuracy: 0.4737 - val_loss: 1.1546 - val_accuracy: 0.4730\n",
            "Epoch 1257/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1533 - accuracy: 0.4737 - val_loss: 1.1539 - val_accuracy: 0.4728\n",
            "Epoch 1258/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1531 - accuracy: 0.4738 - val_loss: 1.1529 - val_accuracy: 0.4729\n",
            "Epoch 1259/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1533 - accuracy: 0.4737 - val_loss: 1.1532 - val_accuracy: 0.4735\n",
            "Epoch 1260/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1532 - accuracy: 0.4737 - val_loss: 1.1536 - val_accuracy: 0.4735\n",
            "Epoch 1261/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1532 - accuracy: 0.4738 - val_loss: 1.1540 - val_accuracy: 0.4723\n",
            "Epoch 1262/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1579 - accuracy: 0.4715 - val_loss: 1.1519 - val_accuracy: 0.4743\n",
            "Epoch 1263/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1527 - accuracy: 0.4739 - val_loss: 1.1525 - val_accuracy: 0.4732\n",
            "Epoch 1264/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1528 - accuracy: 0.4740 - val_loss: 1.1531 - val_accuracy: 0.4727\n",
            "Epoch 1265/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1531 - accuracy: 0.4738 - val_loss: 1.1535 - val_accuracy: 0.4735\n",
            "Epoch 1266/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1534 - accuracy: 0.4737 - val_loss: 1.1532 - val_accuracy: 0.4730\n",
            "Epoch 1267/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1533 - accuracy: 0.4737 - val_loss: 1.1543 - val_accuracy: 0.4731\n",
            "Epoch 1268/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1530 - accuracy: 0.4739 - val_loss: 1.1527 - val_accuracy: 0.4739\n",
            "Epoch 1269/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1532 - accuracy: 0.4738 - val_loss: 1.1537 - val_accuracy: 0.4728\n",
            "Epoch 1270/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1532 - accuracy: 0.4737 - val_loss: 1.1534 - val_accuracy: 0.4737\n",
            "Epoch 1271/3000\n",
            "76/76 [==============================] - 14s 190ms/step - loss: 1.1574 - accuracy: 0.4716 - val_loss: 1.1512 - val_accuracy: 0.4748\n",
            "Epoch 1272/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1523 - accuracy: 0.4743 - val_loss: 1.1528 - val_accuracy: 0.4743\n",
            "Epoch 1273/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1526 - accuracy: 0.4741 - val_loss: 1.1526 - val_accuracy: 0.4735\n",
            "Epoch 1274/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1528 - accuracy: 0.4739 - val_loss: 1.1527 - val_accuracy: 0.4737\n",
            "Epoch 1275/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1528 - accuracy: 0.4739 - val_loss: 1.1527 - val_accuracy: 0.4732\n",
            "Epoch 1276/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1530 - accuracy: 0.4738 - val_loss: 1.1534 - val_accuracy: 0.4731\n",
            "Epoch 1277/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1533 - accuracy: 0.4736 - val_loss: 1.1530 - val_accuracy: 0.4735\n",
            "Epoch 1278/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1967 - accuracy: 0.4512 - val_loss: 1.1744 - val_accuracy: 0.4638\n",
            "Epoch 1279/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1676 - accuracy: 0.4664 - val_loss: 1.1627 - val_accuracy: 0.4684\n",
            "Epoch 1280/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1611 - accuracy: 0.4698 - val_loss: 1.1590 - val_accuracy: 0.4709\n",
            "Epoch 1281/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1586 - accuracy: 0.4713 - val_loss: 1.1593 - val_accuracy: 0.4711\n",
            "Epoch 1282/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.1571 - accuracy: 0.4719 - val_loss: 1.1537 - val_accuracy: 0.4737\n",
            "Epoch 1283/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1531 - accuracy: 0.4739 - val_loss: 1.1526 - val_accuracy: 0.4745\n",
            "Epoch 1284/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1527 - accuracy: 0.4741 - val_loss: 1.1527 - val_accuracy: 0.4742\n",
            "Epoch 1285/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1528 - accuracy: 0.4739 - val_loss: 1.1522 - val_accuracy: 0.4735\n",
            "Epoch 1286/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1532 - accuracy: 0.4739 - val_loss: 1.1524 - val_accuracy: 0.4736\n",
            "Epoch 1287/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1527 - accuracy: 0.4740 - val_loss: 1.1531 - val_accuracy: 0.4730\n",
            "Epoch 1288/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1530 - accuracy: 0.4738 - val_loss: 1.1537 - val_accuracy: 0.4738\n",
            "Epoch 1289/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1530 - accuracy: 0.4738 - val_loss: 1.1530 - val_accuracy: 0.4731\n",
            "Epoch 1290/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1529 - accuracy: 0.4739 - val_loss: 1.1529 - val_accuracy: 0.4734\n",
            "Epoch 1291/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1529 - accuracy: 0.4738 - val_loss: 1.1529 - val_accuracy: 0.4731\n",
            "Epoch 1292/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1529 - accuracy: 0.4739 - val_loss: 1.1531 - val_accuracy: 0.4727\n",
            "Epoch 1293/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1527 - accuracy: 0.4740 - val_loss: 1.1526 - val_accuracy: 0.4729\n",
            "Epoch 1294/3000\n",
            "76/76 [==============================] - 14s 190ms/step - loss: 1.1533 - accuracy: 0.4737 - val_loss: 1.1519 - val_accuracy: 0.4738\n",
            "Epoch 1295/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1527 - accuracy: 0.4740 - val_loss: 1.1525 - val_accuracy: 0.4740\n",
            "Epoch 1296/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1526 - accuracy: 0.4741 - val_loss: 1.1529 - val_accuracy: 0.4735\n",
            "Epoch 1297/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1528 - accuracy: 0.4739 - val_loss: 1.1526 - val_accuracy: 0.4734\n",
            "Epoch 1298/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1529 - accuracy: 0.4739 - val_loss: 1.1535 - val_accuracy: 0.4735\n",
            "Epoch 1299/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1529 - accuracy: 0.4739 - val_loss: 1.1527 - val_accuracy: 0.4736\n",
            "Epoch 1300/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1526 - accuracy: 0.4740 - val_loss: 1.1538 - val_accuracy: 0.4729\n",
            "Epoch 1301/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1526 - accuracy: 0.4741 - val_loss: 1.1523 - val_accuracy: 0.4738\n",
            "Epoch 1302/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1603 - accuracy: 0.4701 - val_loss: 1.1539 - val_accuracy: 0.4735\n",
            "Epoch 1303/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1522 - accuracy: 0.4742 - val_loss: 1.1514 - val_accuracy: 0.4739\n",
            "Epoch 1304/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1524 - accuracy: 0.4742 - val_loss: 1.1530 - val_accuracy: 0.4737\n",
            "Epoch 1305/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1525 - accuracy: 0.4741 - val_loss: 1.1540 - val_accuracy: 0.4737\n",
            "Epoch 1306/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1526 - accuracy: 0.4740 - val_loss: 1.1526 - val_accuracy: 0.4740\n",
            "Epoch 1307/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1524 - accuracy: 0.4741 - val_loss: 1.1534 - val_accuracy: 0.4737\n",
            "Epoch 1308/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1527 - accuracy: 0.4739 - val_loss: 1.1525 - val_accuracy: 0.4740\n",
            "Epoch 1309/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1529 - accuracy: 0.4738 - val_loss: 1.1528 - val_accuracy: 0.4735\n",
            "Epoch 1310/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1523 - accuracy: 0.4742 - val_loss: 1.1530 - val_accuracy: 0.4741\n",
            "Epoch 1311/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1525 - accuracy: 0.4740 - val_loss: 1.1550 - val_accuracy: 0.4725\n",
            "Epoch 1312/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1525 - accuracy: 0.4740 - val_loss: 1.1525 - val_accuracy: 0.4735\n",
            "Epoch 1313/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1527 - accuracy: 0.4740 - val_loss: 1.1523 - val_accuracy: 0.4742\n",
            "Epoch 1314/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1659 - accuracy: 0.4672 - val_loss: 1.1527 - val_accuracy: 0.4741\n",
            "Epoch 1315/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1519 - accuracy: 0.4744 - val_loss: 1.1507 - val_accuracy: 0.4745\n",
            "Epoch 1316/3000\n",
            "76/76 [==============================] - 15s 197ms/step - loss: 1.1519 - accuracy: 0.4744 - val_loss: 1.1508 - val_accuracy: 0.4747\n",
            "Epoch 1317/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1521 - accuracy: 0.4743 - val_loss: 1.1523 - val_accuracy: 0.4738\n",
            "Epoch 1318/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1525 - accuracy: 0.4742 - val_loss: 1.1515 - val_accuracy: 0.4742\n",
            "Epoch 1319/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1523 - accuracy: 0.4741 - val_loss: 1.1524 - val_accuracy: 0.4739\n",
            "Epoch 1320/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1523 - accuracy: 0.4741 - val_loss: 1.1528 - val_accuracy: 0.4735\n",
            "Epoch 1321/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1524 - accuracy: 0.4741 - val_loss: 1.1535 - val_accuracy: 0.4734\n",
            "Epoch 1322/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1526 - accuracy: 0.4740 - val_loss: 1.1524 - val_accuracy: 0.4737\n",
            "Epoch 1323/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1523 - accuracy: 0.4741 - val_loss: 1.1537 - val_accuracy: 0.4735\n",
            "Epoch 1324/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1523 - accuracy: 0.4741 - val_loss: 1.1528 - val_accuracy: 0.4738\n",
            "Epoch 1325/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1525 - accuracy: 0.4741 - val_loss: 1.1528 - val_accuracy: 0.4743\n",
            "Epoch 1326/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1525 - accuracy: 0.4741 - val_loss: 1.1516 - val_accuracy: 0.4736\n",
            "Epoch 1327/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1525 - accuracy: 0.4741 - val_loss: 1.1520 - val_accuracy: 0.4740\n",
            "Epoch 1328/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1521 - accuracy: 0.4742 - val_loss: 1.1520 - val_accuracy: 0.4733\n",
            "Epoch 1329/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1525 - accuracy: 0.4741 - val_loss: 1.1520 - val_accuracy: 0.4738\n",
            "Epoch 1330/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1524 - accuracy: 0.4740 - val_loss: 1.1523 - val_accuracy: 0.4738\n",
            "Epoch 1331/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1523 - accuracy: 0.4741 - val_loss: 1.1521 - val_accuracy: 0.4738\n",
            "Epoch 1332/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1528 - accuracy: 0.4739 - val_loss: 1.1543 - val_accuracy: 0.4728\n",
            "Epoch 1333/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1524 - accuracy: 0.4740 - val_loss: 1.1505 - val_accuracy: 0.4749\n",
            "Epoch 1334/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1520 - accuracy: 0.4743 - val_loss: 1.1537 - val_accuracy: 0.4733\n",
            "Epoch 1335/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.1522 - accuracy: 0.4742 - val_loss: 1.1521 - val_accuracy: 0.4739\n",
            "Epoch 1336/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1520 - accuracy: 0.4743 - val_loss: 1.1528 - val_accuracy: 0.4734\n",
            "Epoch 1337/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1524 - accuracy: 0.4741 - val_loss: 1.1525 - val_accuracy: 0.4739\n",
            "Epoch 1338/3000\n",
            "76/76 [==============================] - 15s 195ms/step - loss: 1.1522 - accuracy: 0.4741 - val_loss: 1.1527 - val_accuracy: 0.4733\n",
            "Epoch 1339/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1521 - accuracy: 0.4742 - val_loss: 1.1526 - val_accuracy: 0.4739\n",
            "Epoch 1340/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1522 - accuracy: 0.4742 - val_loss: 1.1526 - val_accuracy: 0.4737\n",
            "Epoch 1341/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1523 - accuracy: 0.4742 - val_loss: 1.1536 - val_accuracy: 0.4738\n",
            "Epoch 1342/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1521 - accuracy: 0.4742 - val_loss: 1.1516 - val_accuracy: 0.4743\n",
            "Epoch 1343/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1521 - accuracy: 0.4742 - val_loss: 1.1520 - val_accuracy: 0.4737\n",
            "Epoch 1344/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1520 - accuracy: 0.4743 - val_loss: 1.1515 - val_accuracy: 0.4739\n",
            "Epoch 1345/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1520 - accuracy: 0.4743 - val_loss: 1.1522 - val_accuracy: 0.4737\n",
            "Epoch 1346/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1521 - accuracy: 0.4743 - val_loss: 1.1516 - val_accuracy: 0.4749\n",
            "Epoch 1347/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1521 - accuracy: 0.4742 - val_loss: 1.1522 - val_accuracy: 0.4734\n",
            "Epoch 1348/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.1519 - accuracy: 0.4743 - val_loss: 1.1518 - val_accuracy: 0.4743\n",
            "Epoch 1349/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1525 - accuracy: 0.4740 - val_loss: 1.1522 - val_accuracy: 0.4738\n",
            "Epoch 1350/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.1519 - accuracy: 0.4743 - val_loss: 1.1517 - val_accuracy: 0.4743\n",
            "Epoch 1351/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1520 - accuracy: 0.4743 - val_loss: 1.1529 - val_accuracy: 0.4741\n",
            "Epoch 1352/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1519 - accuracy: 0.4743 - val_loss: 1.1527 - val_accuracy: 0.4736\n",
            "Epoch 1353/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1520 - accuracy: 0.4743 - val_loss: 1.1523 - val_accuracy: 0.4737\n",
            "Epoch 1354/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1521 - accuracy: 0.4742 - val_loss: 1.1526 - val_accuracy: 0.4731\n",
            "Epoch 1355/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1519 - accuracy: 0.4743 - val_loss: 1.1520 - val_accuracy: 0.4736\n",
            "Epoch 1356/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1521 - accuracy: 0.4743 - val_loss: 1.1528 - val_accuracy: 0.4740\n",
            "Epoch 1357/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1519 - accuracy: 0.4744 - val_loss: 1.1514 - val_accuracy: 0.4747\n",
            "Epoch 1358/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1518 - accuracy: 0.4743 - val_loss: 1.1519 - val_accuracy: 0.4739\n",
            "Epoch 1359/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1520 - accuracy: 0.4743 - val_loss: 1.1523 - val_accuracy: 0.4741\n",
            "Epoch 1360/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1516 - accuracy: 0.4745 - val_loss: 1.1528 - val_accuracy: 0.4742\n",
            "Epoch 1361/3000\n",
            "76/76 [==============================] - 15s 193ms/step - loss: 1.1521 - accuracy: 0.4742 - val_loss: 1.1520 - val_accuracy: 0.4738\n",
            "Epoch 1362/3000\n",
            "76/76 [==============================] - 14s 184ms/step - loss: 1.1517 - accuracy: 0.4744 - val_loss: 1.1516 - val_accuracy: 0.4739\n",
            "Epoch 1363/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1519 - accuracy: 0.4743 - val_loss: 1.1529 - val_accuracy: 0.4736\n",
            "Epoch 1364/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.1518 - accuracy: 0.4743 - val_loss: 1.1530 - val_accuracy: 0.4739\n",
            "Epoch 1365/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1518 - accuracy: 0.4744 - val_loss: 1.1525 - val_accuracy: 0.4741\n",
            "Epoch 1366/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1518 - accuracy: 0.4744 - val_loss: 1.1523 - val_accuracy: 0.4739\n",
            "Epoch 1367/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1517 - accuracy: 0.4744 - val_loss: 1.1522 - val_accuracy: 0.4737\n",
            "Epoch 1368/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1518 - accuracy: 0.4744 - val_loss: 1.1521 - val_accuracy: 0.4738\n",
            "Epoch 1369/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1518 - accuracy: 0.4743 - val_loss: 1.1520 - val_accuracy: 0.4743\n",
            "Epoch 1370/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1517 - accuracy: 0.4744 - val_loss: 1.1523 - val_accuracy: 0.4735\n",
            "Epoch 1371/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1517 - accuracy: 0.4744 - val_loss: 1.1524 - val_accuracy: 0.4742\n",
            "Epoch 1372/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1517 - accuracy: 0.4744 - val_loss: 1.1520 - val_accuracy: 0.4742\n",
            "Epoch 1373/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1518 - accuracy: 0.4743 - val_loss: 1.1524 - val_accuracy: 0.4739\n",
            "Epoch 1374/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1516 - accuracy: 0.4744 - val_loss: 1.1520 - val_accuracy: 0.4738\n",
            "Epoch 1375/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.1519 - accuracy: 0.4743 - val_loss: 1.1520 - val_accuracy: 0.4736\n",
            "Epoch 1376/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1515 - accuracy: 0.4745 - val_loss: 1.1521 - val_accuracy: 0.4744\n",
            "Epoch 1377/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1517 - accuracy: 0.4744 - val_loss: 1.1507 - val_accuracy: 0.4752\n",
            "Epoch 1378/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1518 - accuracy: 0.4743 - val_loss: 1.1522 - val_accuracy: 0.4736\n",
            "Epoch 1379/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1513 - accuracy: 0.4746 - val_loss: 1.1514 - val_accuracy: 0.4749\n",
            "Epoch 1380/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1516 - accuracy: 0.4744 - val_loss: 1.1519 - val_accuracy: 0.4739\n",
            "Epoch 1381/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1515 - accuracy: 0.4745 - val_loss: 1.1512 - val_accuracy: 0.4744\n",
            "Epoch 1382/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1515 - accuracy: 0.4745 - val_loss: 1.1509 - val_accuracy: 0.4749\n",
            "Epoch 1383/3000\n",
            "76/76 [==============================] - 15s 196ms/step - loss: 1.1515 - accuracy: 0.4745 - val_loss: 1.1506 - val_accuracy: 0.4751\n",
            "Epoch 1384/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1517 - accuracy: 0.4743 - val_loss: 1.1520 - val_accuracy: 0.4736\n",
            "Epoch 1385/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1514 - accuracy: 0.4745 - val_loss: 1.1515 - val_accuracy: 0.4743\n",
            "Epoch 1386/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1515 - accuracy: 0.4744 - val_loss: 1.1521 - val_accuracy: 0.4735\n",
            "Epoch 1387/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1514 - accuracy: 0.4745 - val_loss: 1.1516 - val_accuracy: 0.4742\n",
            "Epoch 1388/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1514 - accuracy: 0.4745 - val_loss: 1.1517 - val_accuracy: 0.4742\n",
            "Epoch 1389/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1514 - accuracy: 0.4745 - val_loss: 1.1515 - val_accuracy: 0.4743\n",
            "Epoch 1390/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1514 - accuracy: 0.4745 - val_loss: 1.1513 - val_accuracy: 0.4745\n",
            "Epoch 1391/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1514 - accuracy: 0.4746 - val_loss: 1.1516 - val_accuracy: 0.4743\n",
            "Epoch 1392/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1515 - accuracy: 0.4745 - val_loss: 1.1522 - val_accuracy: 0.4740\n",
            "Epoch 1393/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1514 - accuracy: 0.4745 - val_loss: 1.1512 - val_accuracy: 0.4745\n",
            "Epoch 1394/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.1514 - accuracy: 0.4745 - val_loss: 1.1508 - val_accuracy: 0.4743\n",
            "Epoch 1395/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1513 - accuracy: 0.4746 - val_loss: 1.1506 - val_accuracy: 0.4747\n",
            "Epoch 1396/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1512 - accuracy: 0.4747 - val_loss: 1.1505 - val_accuracy: 0.4748\n",
            "Epoch 1397/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1515 - accuracy: 0.4745 - val_loss: 1.1518 - val_accuracy: 0.4736\n",
            "Epoch 1398/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1513 - accuracy: 0.4746 - val_loss: 1.1501 - val_accuracy: 0.4752\n",
            "Epoch 1399/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1513 - accuracy: 0.4746 - val_loss: 1.1503 - val_accuracy: 0.4748\n",
            "Epoch 1400/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.1513 - accuracy: 0.4746 - val_loss: 1.1506 - val_accuracy: 0.4745\n",
            "Epoch 1401/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1511 - accuracy: 0.4747 - val_loss: 1.1506 - val_accuracy: 0.4746\n",
            "Epoch 1402/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1512 - accuracy: 0.4746 - val_loss: 1.1502 - val_accuracy: 0.4753\n",
            "Epoch 1403/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.1512 - accuracy: 0.4746 - val_loss: 1.1505 - val_accuracy: 0.4750\n",
            "Epoch 1404/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1513 - accuracy: 0.4745 - val_loss: 1.1502 - val_accuracy: 0.4748\n",
            "Epoch 1405/3000\n",
            "76/76 [==============================] - 14s 189ms/step - loss: 1.1512 - accuracy: 0.4746 - val_loss: 1.1511 - val_accuracy: 0.4743\n",
            "Epoch 1406/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1510 - accuracy: 0.4747 - val_loss: 1.1517 - val_accuracy: 0.4743\n",
            "Epoch 1407/3000\n",
            "76/76 [==============================] - 13s 178ms/step - loss: 1.1513 - accuracy: 0.4746 - val_loss: 1.1506 - val_accuracy: 0.4745\n",
            "Epoch 1408/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1511 - accuracy: 0.4747 - val_loss: 1.1505 - val_accuracy: 0.4748\n",
            "Epoch 1409/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1511 - accuracy: 0.4747 - val_loss: 1.1507 - val_accuracy: 0.4748\n",
            "Epoch 1410/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1511 - accuracy: 0.4747 - val_loss: 1.1503 - val_accuracy: 0.4751\n",
            "Epoch 1411/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1511 - accuracy: 0.4747 - val_loss: 1.1501 - val_accuracy: 0.4748\n",
            "Epoch 1412/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.1509 - accuracy: 0.4747 - val_loss: 1.1502 - val_accuracy: 0.4750\n",
            "Epoch 1413/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1511 - accuracy: 0.4747 - val_loss: 1.1507 - val_accuracy: 0.4750\n",
            "Epoch 1414/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1510 - accuracy: 0.4747 - val_loss: 1.1506 - val_accuracy: 0.4749\n",
            "Epoch 1415/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.1510 - accuracy: 0.4747 - val_loss: 1.1505 - val_accuracy: 0.4743\n",
            "Epoch 1416/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1511 - accuracy: 0.4747 - val_loss: 1.1514 - val_accuracy: 0.4740\n",
            "Epoch 1417/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1510 - accuracy: 0.4747 - val_loss: 1.1506 - val_accuracy: 0.4747\n",
            "Epoch 1418/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.1510 - accuracy: 0.4747 - val_loss: 1.1501 - val_accuracy: 0.4747\n",
            "Epoch 1419/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1510 - accuracy: 0.4747 - val_loss: 1.1505 - val_accuracy: 0.4743\n",
            "Epoch 1420/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1508 - accuracy: 0.4748 - val_loss: 1.1499 - val_accuracy: 0.4751\n",
            "Epoch 1421/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1511 - accuracy: 0.4747 - val_loss: 1.1496 - val_accuracy: 0.4753\n",
            "Epoch 1422/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1508 - accuracy: 0.4748 - val_loss: 1.1498 - val_accuracy: 0.4752\n",
            "Epoch 1423/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.1509 - accuracy: 0.4748 - val_loss: 1.1497 - val_accuracy: 0.4755\n",
            "Epoch 1424/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1509 - accuracy: 0.4747 - val_loss: 1.1511 - val_accuracy: 0.4744\n",
            "Epoch 1425/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.1508 - accuracy: 0.4748 - val_loss: 1.1502 - val_accuracy: 0.4747\n",
            "Epoch 1426/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.1507 - accuracy: 0.4749 - val_loss: 1.1504 - val_accuracy: 0.4743\n",
            "Epoch 1427/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1509 - accuracy: 0.4748 - val_loss: 1.1504 - val_accuracy: 0.4749\n",
            "Epoch 1428/3000\n",
            "76/76 [==============================] - 15s 191ms/step - loss: 1.1509 - accuracy: 0.4747 - val_loss: 1.1511 - val_accuracy: 0.4735\n",
            "Epoch 1429/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.1508 - accuracy: 0.4748 - val_loss: 1.1506 - val_accuracy: 0.4740\n",
            "Epoch 1430/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1507 - accuracy: 0.4749 - val_loss: 1.1506 - val_accuracy: 0.4738\n",
            "Epoch 1431/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1507 - accuracy: 0.4749 - val_loss: 1.1502 - val_accuracy: 0.4747\n",
            "Epoch 1432/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1507 - accuracy: 0.4748 - val_loss: 1.1498 - val_accuracy: 0.4748\n",
            "Epoch 1433/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1507 - accuracy: 0.4748 - val_loss: 1.1497 - val_accuracy: 0.4744\n",
            "Epoch 1434/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1506 - accuracy: 0.4749 - val_loss: 1.1496 - val_accuracy: 0.4751\n",
            "Epoch 1435/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1507 - accuracy: 0.4749 - val_loss: 1.1502 - val_accuracy: 0.4749\n",
            "Epoch 1436/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1507 - accuracy: 0.4748 - val_loss: 1.1504 - val_accuracy: 0.4745\n",
            "Epoch 1437/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1507 - accuracy: 0.4749 - val_loss: 1.1500 - val_accuracy: 0.4748\n",
            "Epoch 1438/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1507 - accuracy: 0.4749 - val_loss: 1.1499 - val_accuracy: 0.4748\n",
            "Epoch 1439/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.1505 - accuracy: 0.4749 - val_loss: 1.1497 - val_accuracy: 0.4752\n",
            "Epoch 1440/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.1507 - accuracy: 0.4748 - val_loss: 1.1494 - val_accuracy: 0.4765\n",
            "Epoch 1441/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1505 - accuracy: 0.4749 - val_loss: 1.1509 - val_accuracy: 0.4743\n",
            "Epoch 1442/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1507 - accuracy: 0.4748 - val_loss: 1.1498 - val_accuracy: 0.4748\n",
            "Epoch 1443/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1503 - accuracy: 0.4750 - val_loss: 1.1512 - val_accuracy: 0.4750\n",
            "Epoch 1444/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1506 - accuracy: 0.4749 - val_loss: 1.1505 - val_accuracy: 0.4750\n",
            "Epoch 1445/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1507 - accuracy: 0.4748 - val_loss: 1.1508 - val_accuracy: 0.4755\n",
            "Epoch 1446/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1502 - accuracy: 0.4751 - val_loss: 1.1506 - val_accuracy: 0.4752\n",
            "Epoch 1447/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1506 - accuracy: 0.4750 - val_loss: 1.1497 - val_accuracy: 0.4754\n",
            "Epoch 1448/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1504 - accuracy: 0.4750 - val_loss: 1.1504 - val_accuracy: 0.4749\n",
            "Epoch 1449/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1508 - accuracy: 0.4748 - val_loss: 1.1514 - val_accuracy: 0.4750\n",
            "Epoch 1450/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1502 - accuracy: 0.4750 - val_loss: 1.1492 - val_accuracy: 0.4761\n",
            "Epoch 1451/3000\n",
            "76/76 [==============================] - 14s 189ms/step - loss: 1.1504 - accuracy: 0.4750 - val_loss: 1.1494 - val_accuracy: 0.4767\n",
            "Epoch 1452/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1505 - accuracy: 0.4750 - val_loss: 1.1500 - val_accuracy: 0.4760\n",
            "Epoch 1453/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1502 - accuracy: 0.4751 - val_loss: 1.1496 - val_accuracy: 0.4763\n",
            "Epoch 1454/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1503 - accuracy: 0.4751 - val_loss: 1.1496 - val_accuracy: 0.4761\n",
            "Epoch 1455/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1502 - accuracy: 0.4751 - val_loss: 1.1491 - val_accuracy: 0.4763\n",
            "Epoch 1456/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1501 - accuracy: 0.4751 - val_loss: 1.1486 - val_accuracy: 0.4759\n",
            "Epoch 1457/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1728 - accuracy: 0.4636 - val_loss: 1.1779 - val_accuracy: 0.4614\n",
            "Epoch 1458/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1653 - accuracy: 0.4672 - val_loss: 1.1593 - val_accuracy: 0.4707\n",
            "Epoch 1459/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1573 - accuracy: 0.4717 - val_loss: 1.1538 - val_accuracy: 0.4743\n",
            "Epoch 1460/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1510 - accuracy: 0.4748 - val_loss: 1.1490 - val_accuracy: 0.4759\n",
            "Epoch 1461/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1502 - accuracy: 0.4752 - val_loss: 1.1496 - val_accuracy: 0.4759\n",
            "Epoch 1462/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1500 - accuracy: 0.4753 - val_loss: 1.1497 - val_accuracy: 0.4760\n",
            "Epoch 1463/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1503 - accuracy: 0.4751 - val_loss: 1.1497 - val_accuracy: 0.4755\n",
            "Epoch 1464/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1502 - accuracy: 0.4751 - val_loss: 1.1499 - val_accuracy: 0.4750\n",
            "Epoch 1465/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1503 - accuracy: 0.4750 - val_loss: 1.1501 - val_accuracy: 0.4756\n",
            "Epoch 1466/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1500 - accuracy: 0.4752 - val_loss: 1.1495 - val_accuracy: 0.4754\n",
            "Epoch 1467/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.1502 - accuracy: 0.4751 - val_loss: 1.1500 - val_accuracy: 0.4747\n",
            "Epoch 1468/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1503 - accuracy: 0.4750 - val_loss: 1.1502 - val_accuracy: 0.4750\n",
            "Epoch 1469/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1501 - accuracy: 0.4752 - val_loss: 1.1498 - val_accuracy: 0.4755\n",
            "Epoch 1470/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1505 - accuracy: 0.4749 - val_loss: 1.1522 - val_accuracy: 0.4747\n",
            "Epoch 1471/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1499 - accuracy: 0.4752 - val_loss: 1.1495 - val_accuracy: 0.4758\n",
            "Epoch 1472/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1501 - accuracy: 0.4752 - val_loss: 1.1493 - val_accuracy: 0.4761\n",
            "Epoch 1473/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1501 - accuracy: 0.4751 - val_loss: 1.1499 - val_accuracy: 0.4755\n",
            "Epoch 1474/3000\n",
            "76/76 [==============================] - 14s 188ms/step - loss: 1.1501 - accuracy: 0.4751 - val_loss: 1.1499 - val_accuracy: 0.4752\n",
            "Epoch 1475/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1499 - accuracy: 0.4752 - val_loss: 1.1490 - val_accuracy: 0.4762\n",
            "Epoch 1476/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1504 - accuracy: 0.4749 - val_loss: 1.1503 - val_accuracy: 0.4749\n",
            "Epoch 1477/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1500 - accuracy: 0.4751 - val_loss: 1.1505 - val_accuracy: 0.4749\n",
            "Epoch 1478/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1498 - accuracy: 0.4753 - val_loss: 1.1490 - val_accuracy: 0.4756\n",
            "Epoch 1479/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1499 - accuracy: 0.4752 - val_loss: 1.1496 - val_accuracy: 0.4758\n",
            "Epoch 1480/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1499 - accuracy: 0.4753 - val_loss: 1.1492 - val_accuracy: 0.4759\n",
            "Epoch 1481/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1498 - accuracy: 0.4753 - val_loss: 1.1491 - val_accuracy: 0.4764\n",
            "Epoch 1482/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1499 - accuracy: 0.4751 - val_loss: 1.1492 - val_accuracy: 0.4757\n",
            "Epoch 1483/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1497 - accuracy: 0.4753 - val_loss: 1.1488 - val_accuracy: 0.4765\n",
            "Epoch 1484/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1498 - accuracy: 0.4753 - val_loss: 1.1488 - val_accuracy: 0.4757\n",
            "Epoch 1485/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1498 - accuracy: 0.4752 - val_loss: 1.1491 - val_accuracy: 0.4762\n",
            "Epoch 1486/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1499 - accuracy: 0.4752 - val_loss: 1.1493 - val_accuracy: 0.4759\n",
            "Epoch 1487/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1498 - accuracy: 0.4752 - val_loss: 1.1493 - val_accuracy: 0.4761\n",
            "Epoch 1488/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1496 - accuracy: 0.4754 - val_loss: 1.1495 - val_accuracy: 0.4758\n",
            "Epoch 1489/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1498 - accuracy: 0.4752 - val_loss: 1.1495 - val_accuracy: 0.4758\n",
            "Epoch 1490/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1496 - accuracy: 0.4754 - val_loss: 1.1490 - val_accuracy: 0.4759\n",
            "Epoch 1491/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1498 - accuracy: 0.4753 - val_loss: 1.1490 - val_accuracy: 0.4759\n",
            "Epoch 1492/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1495 - accuracy: 0.4754 - val_loss: 1.1481 - val_accuracy: 0.4769\n",
            "Epoch 1493/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1498 - accuracy: 0.4752 - val_loss: 1.1494 - val_accuracy: 0.4764\n",
            "Epoch 1494/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1501 - accuracy: 0.4751 - val_loss: 1.1595 - val_accuracy: 0.4718\n",
            "Epoch 1495/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1523 - accuracy: 0.4740 - val_loss: 1.1488 - val_accuracy: 0.4769\n",
            "Epoch 1496/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1490 - accuracy: 0.4757 - val_loss: 1.1488 - val_accuracy: 0.4758\n",
            "Epoch 1497/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1491 - accuracy: 0.4757 - val_loss: 1.1484 - val_accuracy: 0.4763\n",
            "Epoch 1498/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1493 - accuracy: 0.4756 - val_loss: 1.1487 - val_accuracy: 0.4762\n",
            "Epoch 1499/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1492 - accuracy: 0.4756 - val_loss: 1.1484 - val_accuracy: 0.4757\n",
            "Epoch 1500/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1493 - accuracy: 0.4755 - val_loss: 1.1484 - val_accuracy: 0.4757\n",
            "Epoch 1501/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1494 - accuracy: 0.4754 - val_loss: 1.1511 - val_accuracy: 0.4751\n",
            "Epoch 1502/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1497 - accuracy: 0.4754 - val_loss: 1.1488 - val_accuracy: 0.4760\n",
            "Epoch 1503/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1494 - accuracy: 0.4754 - val_loss: 1.1485 - val_accuracy: 0.4765\n",
            "Epoch 1504/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1493 - accuracy: 0.4755 - val_loss: 1.1488 - val_accuracy: 0.4761\n",
            "Epoch 1505/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1493 - accuracy: 0.4755 - val_loss: 1.1486 - val_accuracy: 0.4763\n",
            "Epoch 1506/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1499 - accuracy: 0.4751 - val_loss: 1.1490 - val_accuracy: 0.4757\n",
            "Epoch 1507/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1489 - accuracy: 0.4757 - val_loss: 1.1480 - val_accuracy: 0.4766\n",
            "Epoch 1508/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1493 - accuracy: 0.4755 - val_loss: 1.1483 - val_accuracy: 0.4756\n",
            "Epoch 1509/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1495 - accuracy: 0.4754 - val_loss: 1.1485 - val_accuracy: 0.4764\n",
            "Epoch 1510/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1491 - accuracy: 0.4755 - val_loss: 1.1480 - val_accuracy: 0.4766\n",
            "Epoch 1511/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1498 - accuracy: 0.4752 - val_loss: 1.1506 - val_accuracy: 0.4755\n",
            "Epoch 1512/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1492 - accuracy: 0.4754 - val_loss: 1.1486 - val_accuracy: 0.4757\n",
            "Epoch 1513/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1491 - accuracy: 0.4756 - val_loss: 1.1481 - val_accuracy: 0.4761\n",
            "Epoch 1514/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1491 - accuracy: 0.4756 - val_loss: 1.1490 - val_accuracy: 0.4760\n",
            "Epoch 1515/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.1490 - accuracy: 0.4755 - val_loss: 1.1491 - val_accuracy: 0.4757\n",
            "Epoch 1516/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1492 - accuracy: 0.4755 - val_loss: 1.1552 - val_accuracy: 0.4732\n",
            "Epoch 1517/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1499 - accuracy: 0.4752 - val_loss: 1.1504 - val_accuracy: 0.4749\n",
            "Epoch 1518/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1503 - accuracy: 0.4750 - val_loss: 1.1482 - val_accuracy: 0.4770\n",
            "Epoch 1519/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1489 - accuracy: 0.4757 - val_loss: 1.1486 - val_accuracy: 0.4764\n",
            "Epoch 1520/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1489 - accuracy: 0.4757 - val_loss: 1.1490 - val_accuracy: 0.4763\n",
            "Epoch 1521/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1489 - accuracy: 0.4757 - val_loss: 1.1485 - val_accuracy: 0.4759\n",
            "Epoch 1522/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1489 - accuracy: 0.4757 - val_loss: 1.1488 - val_accuracy: 0.4751\n",
            "Epoch 1523/3000\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 1.1489 - accuracy: 0.4757 - val_loss: 1.1485 - val_accuracy: 0.4756\n",
            "Epoch 1524/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1490 - accuracy: 0.4756 - val_loss: 1.1486 - val_accuracy: 0.4762\n",
            "Epoch 1525/3000\n",
            "76/76 [==============================] - 13s 168ms/step - loss: 1.1487 - accuracy: 0.4758 - val_loss: 1.1478 - val_accuracy: 0.4764\n",
            "Epoch 1526/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.1490 - accuracy: 0.4756 - val_loss: 1.1477 - val_accuracy: 0.4776\n",
            "Epoch 1527/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1489 - accuracy: 0.4757 - val_loss: 1.1488 - val_accuracy: 0.4766\n",
            "Epoch 1528/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1490 - accuracy: 0.4756 - val_loss: 1.1484 - val_accuracy: 0.4763\n",
            "Epoch 1529/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1487 - accuracy: 0.4758 - val_loss: 1.1494 - val_accuracy: 0.4756\n",
            "Epoch 1530/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1488 - accuracy: 0.4757 - val_loss: 1.1496 - val_accuracy: 0.4761\n",
            "Epoch 1531/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1488 - accuracy: 0.4756 - val_loss: 1.1489 - val_accuracy: 0.4761\n",
            "Epoch 1532/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1487 - accuracy: 0.4757 - val_loss: 1.1483 - val_accuracy: 0.4765\n",
            "Epoch 1533/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1488 - accuracy: 0.4757 - val_loss: 1.1521 - val_accuracy: 0.4747\n",
            "Epoch 1534/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1495 - accuracy: 0.4754 - val_loss: 1.1508 - val_accuracy: 0.4749\n",
            "Epoch 1535/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1564 - accuracy: 0.4718 - val_loss: 1.1468 - val_accuracy: 0.4776\n",
            "Epoch 1536/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1480 - accuracy: 0.4762 - val_loss: 1.1478 - val_accuracy: 0.4767\n",
            "Epoch 1537/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1481 - accuracy: 0.4761 - val_loss: 1.1468 - val_accuracy: 0.4773\n",
            "Epoch 1538/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1483 - accuracy: 0.4760 - val_loss: 1.1481 - val_accuracy: 0.4766\n",
            "Epoch 1539/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1484 - accuracy: 0.4760 - val_loss: 1.1478 - val_accuracy: 0.4764\n",
            "Epoch 1540/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1485 - accuracy: 0.4759 - val_loss: 1.1482 - val_accuracy: 0.4767\n",
            "Epoch 1541/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1484 - accuracy: 0.4759 - val_loss: 1.1490 - val_accuracy: 0.4760\n",
            "Epoch 1542/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.1485 - accuracy: 0.4759 - val_loss: 1.1485 - val_accuracy: 0.4764\n",
            "Epoch 1543/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1486 - accuracy: 0.4758 - val_loss: 1.1544 - val_accuracy: 0.4739\n",
            "Epoch 1544/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1486 - accuracy: 0.4758 - val_loss: 1.1481 - val_accuracy: 0.4760\n",
            "Epoch 1545/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1485 - accuracy: 0.4759 - val_loss: 1.1490 - val_accuracy: 0.4758\n",
            "Epoch 1546/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1485 - accuracy: 0.4759 - val_loss: 1.1483 - val_accuracy: 0.4756\n",
            "Epoch 1547/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1485 - accuracy: 0.4759 - val_loss: 1.1480 - val_accuracy: 0.4762\n",
            "Epoch 1548/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1484 - accuracy: 0.4759 - val_loss: 1.1471 - val_accuracy: 0.4767\n",
            "Epoch 1549/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1485 - accuracy: 0.4759 - val_loss: 1.1474 - val_accuracy: 0.4772\n",
            "Epoch 1550/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1483 - accuracy: 0.4760 - val_loss: 1.1521 - val_accuracy: 0.4746\n",
            "Epoch 1551/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1483 - accuracy: 0.4760 - val_loss: 1.1473 - val_accuracy: 0.4764\n",
            "Epoch 1552/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1489 - accuracy: 0.4757 - val_loss: 1.1494 - val_accuracy: 0.4751\n",
            "Epoch 1553/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1507 - accuracy: 0.4750 - val_loss: 1.2421 - val_accuracy: 0.4396\n",
            "Epoch 1554/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1772 - accuracy: 0.4612 - val_loss: 1.1585 - val_accuracy: 0.4719\n",
            "Epoch 1555/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1558 - accuracy: 0.4722 - val_loss: 1.1485 - val_accuracy: 0.4768\n",
            "Epoch 1556/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1480 - accuracy: 0.4763 - val_loss: 1.1472 - val_accuracy: 0.4776\n",
            "Epoch 1557/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1478 - accuracy: 0.4763 - val_loss: 1.1477 - val_accuracy: 0.4774\n",
            "Epoch 1558/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1491 - accuracy: 0.4756 - val_loss: 1.1795 - val_accuracy: 0.4652\n",
            "Epoch 1559/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1764 - accuracy: 0.4614 - val_loss: 1.1572 - val_accuracy: 0.4725\n",
            "Epoch 1560/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1553 - accuracy: 0.4726 - val_loss: 1.1530 - val_accuracy: 0.4747\n",
            "Epoch 1561/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1496 - accuracy: 0.4753 - val_loss: 1.1479 - val_accuracy: 0.4772\n",
            "Epoch 1562/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1479 - accuracy: 0.4762 - val_loss: 1.1479 - val_accuracy: 0.4774\n",
            "Epoch 1563/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1480 - accuracy: 0.4761 - val_loss: 1.1471 - val_accuracy: 0.4764\n",
            "Epoch 1564/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1480 - accuracy: 0.4761 - val_loss: 1.1477 - val_accuracy: 0.4770\n",
            "Epoch 1565/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1482 - accuracy: 0.4760 - val_loss: 1.1482 - val_accuracy: 0.4765\n",
            "Epoch 1566/3000\n",
            "76/76 [==============================] - 14s 186ms/step - loss: 1.1483 - accuracy: 0.4759 - val_loss: 1.1473 - val_accuracy: 0.4762\n",
            "Epoch 1567/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1480 - accuracy: 0.4761 - val_loss: 1.1471 - val_accuracy: 0.4767\n",
            "Epoch 1568/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1499 - accuracy: 0.4752 - val_loss: 1.1483 - val_accuracy: 0.4765\n",
            "Epoch 1569/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.1479 - accuracy: 0.4761 - val_loss: 1.1464 - val_accuracy: 0.4779\n",
            "Epoch 1570/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1477 - accuracy: 0.4763 - val_loss: 1.1476 - val_accuracy: 0.4769\n",
            "Epoch 1571/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1482 - accuracy: 0.4760 - val_loss: 1.1482 - val_accuracy: 0.4765\n",
            "Epoch 1572/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1480 - accuracy: 0.4760 - val_loss: 1.1915 - val_accuracy: 0.4598\n",
            "Epoch 1573/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1696 - accuracy: 0.4650 - val_loss: 1.1554 - val_accuracy: 0.4731\n",
            "Epoch 1574/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1526 - accuracy: 0.4739 - val_loss: 1.1490 - val_accuracy: 0.4770\n",
            "Epoch 1575/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1479 - accuracy: 0.4762 - val_loss: 1.1470 - val_accuracy: 0.4778\n",
            "Epoch 1576/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1477 - accuracy: 0.4762 - val_loss: 1.1472 - val_accuracy: 0.4778\n",
            "Epoch 1577/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1477 - accuracy: 0.4763 - val_loss: 1.1475 - val_accuracy: 0.4773\n",
            "Epoch 1578/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1479 - accuracy: 0.4761 - val_loss: 1.1470 - val_accuracy: 0.4775\n",
            "Epoch 1579/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1479 - accuracy: 0.4762 - val_loss: 1.1475 - val_accuracy: 0.4772\n",
            "Epoch 1580/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1512 - accuracy: 0.4748 - val_loss: 1.2730 - val_accuracy: 0.4179\n",
            "Epoch 1581/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1850 - accuracy: 0.4571 - val_loss: 1.1614 - val_accuracy: 0.4690\n",
            "Epoch 1582/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1579 - accuracy: 0.4711 - val_loss: 1.1560 - val_accuracy: 0.4726\n",
            "Epoch 1583/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1546 - accuracy: 0.4731 - val_loss: 1.1547 - val_accuracy: 0.4743\n",
            "Epoch 1584/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1525 - accuracy: 0.4741 - val_loss: 1.1499 - val_accuracy: 0.4770\n",
            "Epoch 1585/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1484 - accuracy: 0.4760 - val_loss: 1.1475 - val_accuracy: 0.4776\n",
            "Epoch 1586/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1479 - accuracy: 0.4762 - val_loss: 1.1472 - val_accuracy: 0.4772\n",
            "Epoch 1587/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1480 - accuracy: 0.4761 - val_loss: 1.1467 - val_accuracy: 0.4775\n",
            "Epoch 1588/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1480 - accuracy: 0.4760 - val_loss: 1.1472 - val_accuracy: 0.4769\n",
            "Epoch 1589/3000\n",
            "76/76 [==============================] - 15s 191ms/step - loss: 1.1485 - accuracy: 0.4758 - val_loss: 1.1527 - val_accuracy: 0.4740\n",
            "Epoch 1590/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1487 - accuracy: 0.4757 - val_loss: 1.1480 - val_accuracy: 0.4770\n",
            "Epoch 1591/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1483 - accuracy: 0.4759 - val_loss: 1.1590 - val_accuracy: 0.4700\n",
            "Epoch 1592/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1489 - accuracy: 0.4754 - val_loss: 1.1460 - val_accuracy: 0.4783\n",
            "Epoch 1593/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.1473 - accuracy: 0.4764 - val_loss: 1.1469 - val_accuracy: 0.4772\n",
            "Epoch 1594/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1473 - accuracy: 0.4763 - val_loss: 1.1465 - val_accuracy: 0.4778\n",
            "Epoch 1595/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1476 - accuracy: 0.4761 - val_loss: 1.1472 - val_accuracy: 0.4772\n",
            "Epoch 1596/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1479 - accuracy: 0.4761 - val_loss: 1.1521 - val_accuracy: 0.4745\n",
            "Epoch 1597/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1478 - accuracy: 0.4761 - val_loss: 1.1474 - val_accuracy: 0.4774\n",
            "Epoch 1598/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1520 - accuracy: 0.4745 - val_loss: 1.2807 - val_accuracy: 0.4127\n",
            "Epoch 1599/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1935 - accuracy: 0.4520 - val_loss: 1.1687 - val_accuracy: 0.4657\n",
            "Epoch 1600/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1612 - accuracy: 0.4694 - val_loss: 1.1563 - val_accuracy: 0.4721\n",
            "Epoch 1601/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1552 - accuracy: 0.4726 - val_loss: 1.1539 - val_accuracy: 0.4743\n",
            "Epoch 1602/3000\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 1.1531 - accuracy: 0.4737 - val_loss: 1.1531 - val_accuracy: 0.4747\n",
            "Epoch 1603/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1523 - accuracy: 0.4741 - val_loss: 1.1503 - val_accuracy: 0.4761\n",
            "Epoch 1604/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1488 - accuracy: 0.4757 - val_loss: 1.1480 - val_accuracy: 0.4774\n",
            "Epoch 1605/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1477 - accuracy: 0.4762 - val_loss: 1.1473 - val_accuracy: 0.4778\n",
            "Epoch 1606/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1477 - accuracy: 0.4761 - val_loss: 1.1469 - val_accuracy: 0.4770\n",
            "Epoch 1607/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1478 - accuracy: 0.4761 - val_loss: 1.1466 - val_accuracy: 0.4767\n",
            "Epoch 1608/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1478 - accuracy: 0.4761 - val_loss: 1.1470 - val_accuracy: 0.4768\n",
            "Epoch 1609/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1475 - accuracy: 0.4762 - val_loss: 1.1468 - val_accuracy: 0.4771\n",
            "Epoch 1610/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1477 - accuracy: 0.4761 - val_loss: 1.1481 - val_accuracy: 0.4766\n",
            "Epoch 1611/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1549 - accuracy: 0.4731 - val_loss: 1.2574 - val_accuracy: 0.4245\n",
            "Epoch 1612/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1833 - accuracy: 0.4573 - val_loss: 1.1592 - val_accuracy: 0.4702\n",
            "Epoch 1613/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1554 - accuracy: 0.4723 - val_loss: 1.1534 - val_accuracy: 0.4738\n",
            "Epoch 1614/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1523 - accuracy: 0.4739 - val_loss: 1.1517 - val_accuracy: 0.4755\n",
            "Epoch 1615/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1500 - accuracy: 0.4751 - val_loss: 1.1486 - val_accuracy: 0.4768\n",
            "Epoch 1616/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1476 - accuracy: 0.4762 - val_loss: 1.1474 - val_accuracy: 0.4775\n",
            "Epoch 1617/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.1475 - accuracy: 0.4762 - val_loss: 1.1469 - val_accuracy: 0.4774\n",
            "Epoch 1618/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1476 - accuracy: 0.4762 - val_loss: 1.1474 - val_accuracy: 0.4773\n",
            "Epoch 1619/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1902 - accuracy: 0.4540 - val_loss: 1.1710 - val_accuracy: 0.4634\n",
            "Epoch 1620/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1596 - accuracy: 0.4698 - val_loss: 1.1525 - val_accuracy: 0.4740\n",
            "Epoch 1621/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1516 - accuracy: 0.4743 - val_loss: 1.1500 - val_accuracy: 0.4755\n",
            "Epoch 1622/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1482 - accuracy: 0.4760 - val_loss: 1.1467 - val_accuracy: 0.4779\n",
            "Epoch 1623/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.1473 - accuracy: 0.4764 - val_loss: 1.1468 - val_accuracy: 0.4774\n",
            "Epoch 1624/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1474 - accuracy: 0.4762 - val_loss: 1.1474 - val_accuracy: 0.4771\n",
            "Epoch 1625/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1476 - accuracy: 0.4761 - val_loss: 1.1473 - val_accuracy: 0.4771\n",
            "Epoch 1626/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1479 - accuracy: 0.4760 - val_loss: 1.1494 - val_accuracy: 0.4756\n",
            "Epoch 1627/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1472 - accuracy: 0.4763 - val_loss: 1.1471 - val_accuracy: 0.4771\n",
            "Epoch 1628/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1474 - accuracy: 0.4762 - val_loss: 1.1471 - val_accuracy: 0.4773\n",
            "Epoch 1629/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1642 - accuracy: 0.4678 - val_loss: 1.1529 - val_accuracy: 0.4738\n",
            "Epoch 1630/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1516 - accuracy: 0.4742 - val_loss: 1.1488 - val_accuracy: 0.4765\n",
            "Epoch 1631/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1477 - accuracy: 0.4762 - val_loss: 1.1473 - val_accuracy: 0.4772\n",
            "Epoch 1632/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1473 - accuracy: 0.4764 - val_loss: 1.1469 - val_accuracy: 0.4775\n",
            "Epoch 1633/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1473 - accuracy: 0.4764 - val_loss: 1.1468 - val_accuracy: 0.4774\n",
            "Epoch 1634/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1474 - accuracy: 0.4762 - val_loss: 1.1466 - val_accuracy: 0.4776\n",
            "Epoch 1635/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1473 - accuracy: 0.4763 - val_loss: 1.1473 - val_accuracy: 0.4769\n",
            "Epoch 1636/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1473 - accuracy: 0.4763 - val_loss: 1.1472 - val_accuracy: 0.4771\n",
            "Epoch 1637/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1683 - accuracy: 0.4657 - val_loss: 1.1534 - val_accuracy: 0.4747\n",
            "Epoch 1638/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1480 - accuracy: 0.4759 - val_loss: 1.1454 - val_accuracy: 0.4780\n",
            "Epoch 1639/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1465 - accuracy: 0.4767 - val_loss: 1.1465 - val_accuracy: 0.4783\n",
            "Epoch 1640/3000\n",
            "76/76 [==============================] - 13s 168ms/step - loss: 1.1501 - accuracy: 0.4751 - val_loss: 1.2458 - val_accuracy: 0.4290\n",
            "Epoch 1641/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1795 - accuracy: 0.4596 - val_loss: 1.1549 - val_accuracy: 0.4728\n",
            "Epoch 1642/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1524 - accuracy: 0.4738 - val_loss: 1.1516 - val_accuracy: 0.4750\n",
            "Epoch 1643/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1491 - accuracy: 0.4755 - val_loss: 1.1476 - val_accuracy: 0.4771\n",
            "Epoch 1644/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1472 - accuracy: 0.4764 - val_loss: 1.1462 - val_accuracy: 0.4771\n",
            "Epoch 1645/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1471 - accuracy: 0.4764 - val_loss: 1.1467 - val_accuracy: 0.4777\n",
            "Epoch 1646/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1471 - accuracy: 0.4764 - val_loss: 1.1465 - val_accuracy: 0.4774\n",
            "Epoch 1647/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1471 - accuracy: 0.4764 - val_loss: 1.1471 - val_accuracy: 0.4778\n",
            "Epoch 1648/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1476 - accuracy: 0.4760 - val_loss: 1.1484 - val_accuracy: 0.4764\n",
            "Epoch 1649/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1473 - accuracy: 0.4763 - val_loss: 1.1495 - val_accuracy: 0.4759\n",
            "Epoch 1650/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1512 - accuracy: 0.4744 - val_loss: 1.2170 - val_accuracy: 0.4394\n",
            "Epoch 1651/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1690 - accuracy: 0.4651 - val_loss: 1.1539 - val_accuracy: 0.4732\n",
            "Epoch 1652/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1520 - accuracy: 0.4740 - val_loss: 1.1503 - val_accuracy: 0.4755\n",
            "Epoch 1653/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1476 - accuracy: 0.4761 - val_loss: 1.1466 - val_accuracy: 0.4773\n",
            "Epoch 1654/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1469 - accuracy: 0.4764 - val_loss: 1.1466 - val_accuracy: 0.4776\n",
            "Epoch 1655/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1476 - accuracy: 0.4761 - val_loss: 1.1464 - val_accuracy: 0.4777\n",
            "Epoch 1656/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1467 - accuracy: 0.4765 - val_loss: 1.1468 - val_accuracy: 0.4774\n",
            "Epoch 1657/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1471 - accuracy: 0.4763 - val_loss: 1.1474 - val_accuracy: 0.4772\n",
            "Epoch 1658/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1504 - accuracy: 0.4750 - val_loss: 1.1844 - val_accuracy: 0.4567\n",
            "Epoch 1659/3000\n",
            "76/76 [==============================] - 14s 190ms/step - loss: 1.1563 - accuracy: 0.4715 - val_loss: 1.1481 - val_accuracy: 0.4769\n",
            "Epoch 1660/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1473 - accuracy: 0.4763 - val_loss: 1.1470 - val_accuracy: 0.4777\n",
            "Epoch 1661/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1468 - accuracy: 0.4765 - val_loss: 1.1471 - val_accuracy: 0.4768\n",
            "Epoch 1662/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1506 - accuracy: 0.4748 - val_loss: 1.1752 - val_accuracy: 0.4628\n",
            "Epoch 1663/3000\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 1.1534 - accuracy: 0.4730 - val_loss: 1.1452 - val_accuracy: 0.4784\n",
            "Epoch 1664/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1463 - accuracy: 0.4768 - val_loss: 1.1467 - val_accuracy: 0.4780\n",
            "Epoch 1665/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1466 - accuracy: 0.4765 - val_loss: 1.1466 - val_accuracy: 0.4777\n",
            "Epoch 1666/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1465 - accuracy: 0.4766 - val_loss: 1.1460 - val_accuracy: 0.4779\n",
            "Epoch 1667/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1476 - accuracy: 0.4762 - val_loss: 1.1502 - val_accuracy: 0.4745\n",
            "Epoch 1668/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1477 - accuracy: 0.4760 - val_loss: 1.1514 - val_accuracy: 0.4742\n",
            "Epoch 1669/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1467 - accuracy: 0.4765 - val_loss: 1.1456 - val_accuracy: 0.4771\n",
            "Epoch 1670/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1466 - accuracy: 0.4765 - val_loss: 1.1455 - val_accuracy: 0.4770\n",
            "Epoch 1671/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1463 - accuracy: 0.4767 - val_loss: 1.1460 - val_accuracy: 0.4772\n",
            "Epoch 1672/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1526 - accuracy: 0.4740 - val_loss: 1.2296 - val_accuracy: 0.4346\n",
            "Epoch 1673/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1740 - accuracy: 0.4624 - val_loss: 1.1545 - val_accuracy: 0.4730\n",
            "Epoch 1674/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1524 - accuracy: 0.4738 - val_loss: 1.1513 - val_accuracy: 0.4748\n",
            "Epoch 1675/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1493 - accuracy: 0.4754 - val_loss: 1.1471 - val_accuracy: 0.4766\n",
            "Epoch 1676/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1463 - accuracy: 0.4768 - val_loss: 1.1473 - val_accuracy: 0.4760\n",
            "Epoch 1677/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1464 - accuracy: 0.4766 - val_loss: 1.1461 - val_accuracy: 0.4772\n",
            "Epoch 1678/3000\n",
            "76/76 [==============================] - 13s 168ms/step - loss: 1.1466 - accuracy: 0.4765 - val_loss: 1.1465 - val_accuracy: 0.4771\n",
            "Epoch 1679/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1504 - accuracy: 0.4749 - val_loss: 1.1856 - val_accuracy: 0.4565\n",
            "Epoch 1680/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1557 - accuracy: 0.4718 - val_loss: 1.1475 - val_accuracy: 0.4768\n",
            "Epoch 1681/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1468 - accuracy: 0.4765 - val_loss: 1.1469 - val_accuracy: 0.4773\n",
            "Epoch 1682/3000\n",
            "76/76 [==============================] - 14s 187ms/step - loss: 1.1464 - accuracy: 0.4766 - val_loss: 1.1458 - val_accuracy: 0.4772\n",
            "Epoch 1683/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1465 - accuracy: 0.4764 - val_loss: 1.1474 - val_accuracy: 0.4766\n",
            "Epoch 1684/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1464 - accuracy: 0.4766 - val_loss: 1.1470 - val_accuracy: 0.4772\n",
            "Epoch 1685/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.1531 - accuracy: 0.4735 - val_loss: 1.1971 - val_accuracy: 0.4516\n",
            "Epoch 1686/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1600 - accuracy: 0.4696 - val_loss: 1.1503 - val_accuracy: 0.4758\n",
            "Epoch 1687/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1477 - accuracy: 0.4761 - val_loss: 1.1467 - val_accuracy: 0.4774\n",
            "Epoch 1688/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1463 - accuracy: 0.4766 - val_loss: 1.1473 - val_accuracy: 0.4772\n",
            "Epoch 1689/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1464 - accuracy: 0.4766 - val_loss: 1.1457 - val_accuracy: 0.4776\n",
            "Epoch 1690/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1466 - accuracy: 0.4765 - val_loss: 1.1462 - val_accuracy: 0.4776\n",
            "Epoch 1691/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1467 - accuracy: 0.4764 - val_loss: 1.1475 - val_accuracy: 0.4767\n",
            "Epoch 1692/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1527 - accuracy: 0.4738 - val_loss: 1.2552 - val_accuracy: 0.4226\n",
            "Epoch 1693/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1936 - accuracy: 0.4519 - val_loss: 1.1700 - val_accuracy: 0.4649\n",
            "Epoch 1694/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1616 - accuracy: 0.4689 - val_loss: 1.1539 - val_accuracy: 0.4732\n",
            "Epoch 1695/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1495 - accuracy: 0.4752 - val_loss: 1.1453 - val_accuracy: 0.4777\n",
            "Epoch 1696/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1461 - accuracy: 0.4768 - val_loss: 1.1461 - val_accuracy: 0.4772\n",
            "Epoch 1697/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1462 - accuracy: 0.4767 - val_loss: 1.1451 - val_accuracy: 0.4783\n",
            "Epoch 1698/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1460 - accuracy: 0.4768 - val_loss: 1.1463 - val_accuracy: 0.4773\n",
            "Epoch 1699/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1462 - accuracy: 0.4767 - val_loss: 1.1488 - val_accuracy: 0.4761\n",
            "Epoch 1700/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1925 - accuracy: 0.4530 - val_loss: 1.1746 - val_accuracy: 0.4622\n",
            "Epoch 1701/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1635 - accuracy: 0.4677 - val_loss: 1.1537 - val_accuracy: 0.4730\n",
            "Epoch 1702/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1513 - accuracy: 0.4743 - val_loss: 1.1486 - val_accuracy: 0.4757\n",
            "Epoch 1703/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1468 - accuracy: 0.4766 - val_loss: 1.1456 - val_accuracy: 0.4774\n",
            "Epoch 1704/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1462 - accuracy: 0.4768 - val_loss: 1.1459 - val_accuracy: 0.4770\n",
            "Epoch 1705/3000\n",
            "76/76 [==============================] - 13s 177ms/step - loss: 1.1461 - accuracy: 0.4769 - val_loss: 1.1460 - val_accuracy: 0.4770\n",
            "Epoch 1706/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1463 - accuracy: 0.4766 - val_loss: 1.1461 - val_accuracy: 0.4773\n",
            "Epoch 1707/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1463 - accuracy: 0.4767 - val_loss: 1.1466 - val_accuracy: 0.4769\n",
            "Epoch 1708/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1465 - accuracy: 0.4765 - val_loss: 1.1477 - val_accuracy: 0.4765\n",
            "Epoch 1709/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1459 - accuracy: 0.4768 - val_loss: 1.1474 - val_accuracy: 0.4762\n",
            "Epoch 1710/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1508 - accuracy: 0.4746 - val_loss: 1.2122 - val_accuracy: 0.4429\n",
            "Epoch 1711/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1628 - accuracy: 0.4683 - val_loss: 1.1506 - val_accuracy: 0.4753\n",
            "Epoch 1712/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1497 - accuracy: 0.4751 - val_loss: 1.1475 - val_accuracy: 0.4767\n",
            "Epoch 1713/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1484 - accuracy: 0.4758 - val_loss: 1.1831 - val_accuracy: 0.4580\n",
            "Epoch 1714/3000\n",
            "76/76 [==============================] - 13s 168ms/step - loss: 1.1521 - accuracy: 0.4737 - val_loss: 1.1445 - val_accuracy: 0.4778\n",
            "Epoch 1715/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1456 - accuracy: 0.4770 - val_loss: 1.1450 - val_accuracy: 0.4777\n",
            "Epoch 1716/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1457 - accuracy: 0.4770 - val_loss: 1.1465 - val_accuracy: 0.4761\n",
            "Epoch 1717/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1458 - accuracy: 0.4768 - val_loss: 1.1453 - val_accuracy: 0.4769\n",
            "Epoch 1718/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1460 - accuracy: 0.4768 - val_loss: 1.1471 - val_accuracy: 0.4765\n",
            "Epoch 1719/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1484 - accuracy: 0.4758 - val_loss: 1.1805 - val_accuracy: 0.4585\n",
            "Epoch 1720/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1700 - accuracy: 0.4645 - val_loss: 1.1519 - val_accuracy: 0.4743\n",
            "Epoch 1721/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1471 - accuracy: 0.4762 - val_loss: 1.1442 - val_accuracy: 0.4781\n",
            "Epoch 1722/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1451 - accuracy: 0.4774 - val_loss: 1.1444 - val_accuracy: 0.4779\n",
            "Epoch 1723/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1466 - accuracy: 0.4766 - val_loss: 1.1520 - val_accuracy: 0.4762\n",
            "Epoch 1724/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1461 - accuracy: 0.4767 - val_loss: 1.1450 - val_accuracy: 0.4772\n",
            "Epoch 1725/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1541 - accuracy: 0.4732 - val_loss: 1.2645 - val_accuracy: 0.4151\n",
            "Epoch 1726/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.2103 - accuracy: 0.4424 - val_loss: 1.1857 - val_accuracy: 0.4565\n",
            "Epoch 1727/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1816 - accuracy: 0.4589 - val_loss: 1.1773 - val_accuracy: 0.4605\n",
            "Epoch 1728/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1726 - accuracy: 0.4637 - val_loss: 1.1680 - val_accuracy: 0.4665\n",
            "Epoch 1729/3000\n",
            "76/76 [==============================] - 14s 189ms/step - loss: 1.1614 - accuracy: 0.4691 - val_loss: 1.1542 - val_accuracy: 0.4729\n",
            "Epoch 1730/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1516 - accuracy: 0.4741 - val_loss: 1.1487 - val_accuracy: 0.4756\n",
            "Epoch 1731/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1468 - accuracy: 0.4766 - val_loss: 1.1453 - val_accuracy: 0.4778\n",
            "Epoch 1732/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1458 - accuracy: 0.4770 - val_loss: 1.1446 - val_accuracy: 0.4778\n",
            "Epoch 1733/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1496 - accuracy: 0.4756 - val_loss: 1.2514 - val_accuracy: 0.4296\n",
            "Epoch 1734/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1764 - accuracy: 0.4614 - val_loss: 1.1524 - val_accuracy: 0.4732\n",
            "Epoch 1735/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1502 - accuracy: 0.4746 - val_loss: 1.1484 - val_accuracy: 0.4761\n",
            "Epoch 1736/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1468 - accuracy: 0.4765 - val_loss: 1.1461 - val_accuracy: 0.4772\n",
            "Epoch 1737/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1458 - accuracy: 0.4769 - val_loss: 1.1452 - val_accuracy: 0.4776\n",
            "Epoch 1738/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1456 - accuracy: 0.4770 - val_loss: 1.1468 - val_accuracy: 0.4765\n",
            "Epoch 1739/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1457 - accuracy: 0.4769 - val_loss: 1.1451 - val_accuracy: 0.4770\n",
            "Epoch 1740/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1502 - accuracy: 0.4750 - val_loss: 1.1895 - val_accuracy: 0.4537\n",
            "Epoch 1741/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1559 - accuracy: 0.4716 - val_loss: 1.1483 - val_accuracy: 0.4763\n",
            "Epoch 1742/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1465 - accuracy: 0.4766 - val_loss: 1.1458 - val_accuracy: 0.4769\n",
            "Epoch 1743/3000\n",
            "76/76 [==============================] - 13s 165ms/step - loss: 1.1458 - accuracy: 0.4769 - val_loss: 1.1451 - val_accuracy: 0.4771\n",
            "Epoch 1744/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1457 - accuracy: 0.4769 - val_loss: 1.1455 - val_accuracy: 0.4775\n",
            "Epoch 1745/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1490 - accuracy: 0.4757 - val_loss: 1.2837 - val_accuracy: 0.4162\n",
            "Epoch 1746/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1904 - accuracy: 0.4538 - val_loss: 1.1628 - val_accuracy: 0.4683\n",
            "Epoch 1747/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1535 - accuracy: 0.4729 - val_loss: 1.1492 - val_accuracy: 0.4760\n",
            "Epoch 1748/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1478 - accuracy: 0.4760 - val_loss: 1.1451 - val_accuracy: 0.4775\n",
            "Epoch 1749/3000\n",
            "76/76 [==============================] - 13s 168ms/step - loss: 1.1454 - accuracy: 0.4772 - val_loss: 1.1455 - val_accuracy: 0.4770\n",
            "Epoch 1750/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1456 - accuracy: 0.4770 - val_loss: 1.1455 - val_accuracy: 0.4772\n",
            "Epoch 1751/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1457 - accuracy: 0.4770 - val_loss: 1.1454 - val_accuracy: 0.4774\n",
            "Epoch 1752/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1460 - accuracy: 0.4768 - val_loss: 1.1477 - val_accuracy: 0.4764\n",
            "Epoch 1753/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1454 - accuracy: 0.4770 - val_loss: 1.1449 - val_accuracy: 0.4778\n",
            "Epoch 1754/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1540 - accuracy: 0.4734 - val_loss: 1.2462 - val_accuracy: 0.4252\n",
            "Epoch 1755/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1989 - accuracy: 0.4486 - val_loss: 1.1806 - val_accuracy: 0.4601\n",
            "Epoch 1756/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1723 - accuracy: 0.4636 - val_loss: 1.1621 - val_accuracy: 0.4694\n",
            "Epoch 1757/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1542 - accuracy: 0.4727 - val_loss: 1.1502 - val_accuracy: 0.4750\n",
            "Epoch 1758/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1487 - accuracy: 0.4756 - val_loss: 1.1461 - val_accuracy: 0.4773\n",
            "Epoch 1759/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1456 - accuracy: 0.4771 - val_loss: 1.1456 - val_accuracy: 0.4764\n",
            "Epoch 1760/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1457 - accuracy: 0.4769 - val_loss: 1.1462 - val_accuracy: 0.4769\n",
            "Epoch 1761/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1454 - accuracy: 0.4770 - val_loss: 1.1447 - val_accuracy: 0.4772\n",
            "Epoch 1762/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1548 - accuracy: 0.4731 - val_loss: 1.2581 - val_accuracy: 0.4191\n",
            "Epoch 1763/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.2018 - accuracy: 0.4470 - val_loss: 1.1823 - val_accuracy: 0.4587\n",
            "Epoch 1764/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1758 - accuracy: 0.4618 - val_loss: 1.1684 - val_accuracy: 0.4664\n",
            "Epoch 1765/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1593 - accuracy: 0.4701 - val_loss: 1.1508 - val_accuracy: 0.4744\n",
            "Epoch 1766/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1496 - accuracy: 0.4751 - val_loss: 1.1469 - val_accuracy: 0.4765\n",
            "Epoch 1767/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1457 - accuracy: 0.4770 - val_loss: 1.1458 - val_accuracy: 0.4770\n",
            "Epoch 1768/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1455 - accuracy: 0.4770 - val_loss: 1.1452 - val_accuracy: 0.4769\n",
            "Epoch 1769/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1455 - accuracy: 0.4770 - val_loss: 1.1454 - val_accuracy: 0.4768\n",
            "Epoch 1770/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1483 - accuracy: 0.4759 - val_loss: 1.2150 - val_accuracy: 0.4467\n",
            "Epoch 1771/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1615 - accuracy: 0.4690 - val_loss: 1.1490 - val_accuracy: 0.4757\n",
            "Epoch 1772/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1485 - accuracy: 0.4756 - val_loss: 1.1479 - val_accuracy: 0.4763\n",
            "Epoch 1773/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1459 - accuracy: 0.4769 - val_loss: 1.1454 - val_accuracy: 0.4770\n",
            "Epoch 1774/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1454 - accuracy: 0.4771 - val_loss: 1.1446 - val_accuracy: 0.4779\n",
            "Epoch 1775/3000\n",
            "76/76 [==============================] - 14s 179ms/step - loss: 1.1488 - accuracy: 0.4756 - val_loss: 1.2120 - val_accuracy: 0.4461\n",
            "Epoch 1776/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1722 - accuracy: 0.4635 - val_loss: 1.1550 - val_accuracy: 0.4719\n",
            "Epoch 1777/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.1503 - accuracy: 0.4746 - val_loss: 1.1479 - val_accuracy: 0.4756\n",
            "Epoch 1778/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1506 - accuracy: 0.4751 - val_loss: 1.3004 - val_accuracy: 0.4028\n",
            "Epoch 1779/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.2104 - accuracy: 0.4421 - val_loss: 1.1858 - val_accuracy: 0.4567\n",
            "Epoch 1780/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1812 - accuracy: 0.4590 - val_loss: 1.1775 - val_accuracy: 0.4608\n",
            "Epoch 1781/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1740 - accuracy: 0.4629 - val_loss: 1.1706 - val_accuracy: 0.4653\n",
            "Epoch 1782/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1674 - accuracy: 0.4661 - val_loss: 1.1618 - val_accuracy: 0.4694\n",
            "Epoch 1783/3000\n",
            "76/76 [==============================] - 13s 168ms/step - loss: 1.1538 - accuracy: 0.4729 - val_loss: 1.1493 - val_accuracy: 0.4754\n",
            "Epoch 1784/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1467 - accuracy: 0.4766 - val_loss: 1.1452 - val_accuracy: 0.4775\n",
            "Epoch 1785/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1457 - accuracy: 0.4769 - val_loss: 1.1444 - val_accuracy: 0.4780\n",
            "Epoch 1786/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1565 - accuracy: 0.4718 - val_loss: 1.2199 - val_accuracy: 0.4376\n",
            "Epoch 1787/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1876 - accuracy: 0.4552 - val_loss: 1.1739 - val_accuracy: 0.4632\n",
            "Epoch 1788/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1671 - accuracy: 0.4663 - val_loss: 1.1564 - val_accuracy: 0.4719\n",
            "Epoch 1789/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1510 - accuracy: 0.4744 - val_loss: 1.1457 - val_accuracy: 0.4775\n",
            "Epoch 1790/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1487 - accuracy: 0.4758 - val_loss: 1.1949 - val_accuracy: 0.4569\n",
            "Epoch 1791/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1612 - accuracy: 0.4692 - val_loss: 1.1512 - val_accuracy: 0.4741\n",
            "Epoch 1792/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1506 - accuracy: 0.4745 - val_loss: 1.1467 - val_accuracy: 0.4767\n",
            "Epoch 1793/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1459 - accuracy: 0.4769 - val_loss: 1.1459 - val_accuracy: 0.4768\n",
            "Epoch 1794/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1456 - accuracy: 0.4770 - val_loss: 1.1446 - val_accuracy: 0.4775\n",
            "Epoch 1795/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1505 - accuracy: 0.4753 - val_loss: 1.2940 - val_accuracy: 0.4039\n",
            "Epoch 1796/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1994 - accuracy: 0.4485 - val_loss: 1.1768 - val_accuracy: 0.4611\n",
            "Epoch 1797/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1671 - accuracy: 0.4661 - val_loss: 1.1542 - val_accuracy: 0.4720\n",
            "Epoch 1798/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1502 - accuracy: 0.4747 - val_loss: 1.1477 - val_accuracy: 0.4765\n",
            "Epoch 1799/3000\n",
            "76/76 [==============================] - 14s 189ms/step - loss: 1.1462 - accuracy: 0.4768 - val_loss: 1.1456 - val_accuracy: 0.4774\n",
            "Epoch 1800/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.1454 - accuracy: 0.4771 - val_loss: 1.1462 - val_accuracy: 0.4762\n",
            "Epoch 1801/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1458 - accuracy: 0.4769 - val_loss: 1.1452 - val_accuracy: 0.4766\n",
            "Epoch 1802/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1452 - accuracy: 0.4771 - val_loss: 1.1445 - val_accuracy: 0.4777\n",
            "Epoch 1803/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1540 - accuracy: 0.4736 - val_loss: 1.2593 - val_accuracy: 0.4191\n",
            "Epoch 1804/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1970 - accuracy: 0.4496 - val_loss: 1.1787 - val_accuracy: 0.4609\n",
            "Epoch 1805/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1716 - accuracy: 0.4640 - val_loss: 1.1631 - val_accuracy: 0.4690\n",
            "Epoch 1806/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1537 - accuracy: 0.4729 - val_loss: 1.1505 - val_accuracy: 0.4750\n",
            "Epoch 1807/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1474 - accuracy: 0.4762 - val_loss: 1.1446 - val_accuracy: 0.4786\n",
            "Epoch 1808/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1450 - accuracy: 0.4772 - val_loss: 1.1451 - val_accuracy: 0.4775\n",
            "Epoch 1809/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1450 - accuracy: 0.4772 - val_loss: 1.1462 - val_accuracy: 0.4762\n",
            "Epoch 1810/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1457 - accuracy: 0.4768 - val_loss: 1.1441 - val_accuracy: 0.4775\n",
            "Epoch 1811/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1477 - accuracy: 0.4763 - val_loss: 1.2228 - val_accuracy: 0.4468\n",
            "Epoch 1812/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1785 - accuracy: 0.4605 - val_loss: 1.1591 - val_accuracy: 0.4709\n",
            "Epoch 1813/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1543 - accuracy: 0.4726 - val_loss: 1.1502 - val_accuracy: 0.4753\n",
            "Epoch 1814/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1503 - accuracy: 0.4746 - val_loss: 1.1464 - val_accuracy: 0.4771\n",
            "Epoch 1815/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1452 - accuracy: 0.4772 - val_loss: 1.1443 - val_accuracy: 0.4780\n",
            "Epoch 1816/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1448 - accuracy: 0.4774 - val_loss: 1.1448 - val_accuracy: 0.4773\n",
            "Epoch 1817/3000\n",
            "76/76 [==============================] - 13s 174ms/step - loss: 1.1448 - accuracy: 0.4773 - val_loss: 1.1462 - val_accuracy: 0.4763\n",
            "Epoch 1818/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.2037 - accuracy: 0.4467 - val_loss: 1.1860 - val_accuracy: 0.4559\n",
            "Epoch 1819/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1793 - accuracy: 0.4596 - val_loss: 1.1739 - val_accuracy: 0.4623\n",
            "Epoch 1820/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1688 - accuracy: 0.4654 - val_loss: 1.1610 - val_accuracy: 0.4698\n",
            "Epoch 1821/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1528 - accuracy: 0.4734 - val_loss: 1.1501 - val_accuracy: 0.4747\n",
            "Epoch 1822/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1477 - accuracy: 0.4759 - val_loss: 1.1445 - val_accuracy: 0.4780\n",
            "Epoch 1823/3000\n",
            "76/76 [==============================] - 14s 182ms/step - loss: 1.1448 - accuracy: 0.4773 - val_loss: 1.1451 - val_accuracy: 0.4774\n",
            "Epoch 1824/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1448 - accuracy: 0.4773 - val_loss: 1.1460 - val_accuracy: 0.4765\n",
            "Epoch 1825/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1655 - accuracy: 0.4672 - val_loss: 1.1485 - val_accuracy: 0.4754\n",
            "Epoch 1826/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1468 - accuracy: 0.4764 - val_loss: 1.1443 - val_accuracy: 0.4784\n",
            "Epoch 1827/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1446 - accuracy: 0.4774 - val_loss: 1.1439 - val_accuracy: 0.4777\n",
            "Epoch 1828/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1446 - accuracy: 0.4774 - val_loss: 1.1461 - val_accuracy: 0.4759\n",
            "Epoch 1829/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1678 - accuracy: 0.4663 - val_loss: 1.1555 - val_accuracy: 0.4719\n",
            "Epoch 1830/3000\n",
            "76/76 [==============================] - 13s 168ms/step - loss: 1.1499 - accuracy: 0.4748 - val_loss: 1.1474 - val_accuracy: 0.4759\n",
            "Epoch 1831/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1546 - accuracy: 0.4735 - val_loss: 1.2423 - val_accuracy: 0.4279\n",
            "Epoch 1832/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1883 - accuracy: 0.4547 - val_loss: 1.1671 - val_accuracy: 0.4668\n",
            "Epoch 1833/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1567 - accuracy: 0.4713 - val_loss: 1.1481 - val_accuracy: 0.4761\n",
            "Epoch 1834/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1459 - accuracy: 0.4770 - val_loss: 1.1445 - val_accuracy: 0.4782\n",
            "Epoch 1835/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1445 - accuracy: 0.4775 - val_loss: 1.1448 - val_accuracy: 0.4773\n",
            "Epoch 1836/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1446 - accuracy: 0.4774 - val_loss: 1.1457 - val_accuracy: 0.4767\n",
            "Epoch 1837/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1854 - accuracy: 0.4568 - val_loss: 1.1689 - val_accuracy: 0.4653\n",
            "Epoch 1838/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1574 - accuracy: 0.4708 - val_loss: 1.1477 - val_accuracy: 0.4765\n",
            "Epoch 1839/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1450 - accuracy: 0.4773 - val_loss: 1.1438 - val_accuracy: 0.4790\n",
            "Epoch 1840/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1441 - accuracy: 0.4777 - val_loss: 1.1436 - val_accuracy: 0.4786\n",
            "Epoch 1841/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1445 - accuracy: 0.4775 - val_loss: 1.1445 - val_accuracy: 0.4775\n",
            "Epoch 1842/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1446 - accuracy: 0.4774 - val_loss: 1.1446 - val_accuracy: 0.4777\n",
            "Epoch 1843/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1447 - accuracy: 0.4773 - val_loss: 1.1440 - val_accuracy: 0.4777\n",
            "Epoch 1844/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1445 - accuracy: 0.4774 - val_loss: 1.1438 - val_accuracy: 0.4781\n",
            "Epoch 1845/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1446 - accuracy: 0.4774 - val_loss: 1.1437 - val_accuracy: 0.4778\n",
            "Epoch 1846/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1612 - accuracy: 0.4693 - val_loss: 1.2148 - val_accuracy: 0.4397\n",
            "Epoch 1847/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1819 - accuracy: 0.4583 - val_loss: 1.1683 - val_accuracy: 0.4661\n",
            "Epoch 1848/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1564 - accuracy: 0.4715 - val_loss: 1.1509 - val_accuracy: 0.4746\n",
            "Epoch 1849/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1478 - accuracy: 0.4759 - val_loss: 1.1436 - val_accuracy: 0.4790\n",
            "Epoch 1850/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1440 - accuracy: 0.4777 - val_loss: 1.1441 - val_accuracy: 0.4781\n",
            "Epoch 1851/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1442 - accuracy: 0.4776 - val_loss: 1.1434 - val_accuracy: 0.4781\n",
            "Epoch 1852/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1497 - accuracy: 0.4752 - val_loss: 1.2240 - val_accuracy: 0.4355\n",
            "Epoch 1853/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1750 - accuracy: 0.4622 - val_loss: 1.1568 - val_accuracy: 0.4722\n",
            "Epoch 1854/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1522 - accuracy: 0.4736 - val_loss: 1.1488 - val_accuracy: 0.4752\n",
            "Epoch 1855/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1455 - accuracy: 0.4770 - val_loss: 1.1451 - val_accuracy: 0.4769\n",
            "Epoch 1856/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1444 - accuracy: 0.4775 - val_loss: 1.1436 - val_accuracy: 0.4783\n",
            "Epoch 1857/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1500 - accuracy: 0.4751 - val_loss: 1.2278 - val_accuracy: 0.4351\n",
            "Epoch 1858/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1746 - accuracy: 0.4624 - val_loss: 1.1567 - val_accuracy: 0.4714\n",
            "Epoch 1859/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1521 - accuracy: 0.4737 - val_loss: 1.1510 - val_accuracy: 0.4745\n",
            "Epoch 1860/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1465 - accuracy: 0.4765 - val_loss: 1.1456 - val_accuracy: 0.4765\n",
            "Epoch 1861/3000\n",
            "76/76 [==============================] - 13s 168ms/step - loss: 1.1444 - accuracy: 0.4775 - val_loss: 1.1439 - val_accuracy: 0.4774\n",
            "Epoch 1862/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1443 - accuracy: 0.4776 - val_loss: 1.1441 - val_accuracy: 0.4766\n",
            "Epoch 1863/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1754 - accuracy: 0.4614 - val_loss: 1.2638 - val_accuracy: 0.4075\n",
            "Epoch 1864/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.2036 - accuracy: 0.4457 - val_loss: 1.1852 - val_accuracy: 0.4571\n",
            "Epoch 1865/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1806 - accuracy: 0.4592 - val_loss: 1.1777 - val_accuracy: 0.4605\n",
            "Epoch 1866/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1744 - accuracy: 0.4627 - val_loss: 1.1719 - val_accuracy: 0.4636\n",
            "Epoch 1867/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1702 - accuracy: 0.4649 - val_loss: 1.1751 - val_accuracy: 0.4627\n",
            "Epoch 1868/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1682 - accuracy: 0.4657 - val_loss: 1.1675 - val_accuracy: 0.4661\n",
            "Epoch 1869/3000\n",
            "76/76 [==============================] - 14s 185ms/step - loss: 1.1668 - accuracy: 0.4662 - val_loss: 1.1678 - val_accuracy: 0.4660\n",
            "Epoch 1870/3000\n",
            "76/76 [==============================] - 13s 175ms/step - loss: 1.1653 - accuracy: 0.4669 - val_loss: 1.1640 - val_accuracy: 0.4681\n",
            "Epoch 1871/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1692 - accuracy: 0.4652 - val_loss: 1.1611 - val_accuracy: 0.4698\n",
            "Epoch 1872/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1579 - accuracy: 0.4709 - val_loss: 1.1564 - val_accuracy: 0.4719\n",
            "Epoch 1873/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1558 - accuracy: 0.4719 - val_loss: 1.1547 - val_accuracy: 0.4732\n",
            "Epoch 1874/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1547 - accuracy: 0.4725 - val_loss: 1.1550 - val_accuracy: 0.4728\n",
            "Epoch 1875/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1538 - accuracy: 0.4727 - val_loss: 1.1528 - val_accuracy: 0.4737\n",
            "Epoch 1876/3000\n",
            "76/76 [==============================] - 13s 168ms/step - loss: 1.1690 - accuracy: 0.4656 - val_loss: 1.1629 - val_accuracy: 0.4687\n",
            "Epoch 1877/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1538 - accuracy: 0.4726 - val_loss: 1.1499 - val_accuracy: 0.4755\n",
            "Epoch 1878/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1643 - accuracy: 0.4674 - val_loss: 1.2160 - val_accuracy: 0.4387\n",
            "Epoch 1879/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1832 - accuracy: 0.4576 - val_loss: 1.1733 - val_accuracy: 0.4629\n",
            "Epoch 1880/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1700 - accuracy: 0.4649 - val_loss: 1.1682 - val_accuracy: 0.4654\n",
            "Epoch 1881/3000\n",
            "76/76 [==============================] - 13s 168ms/step - loss: 1.1670 - accuracy: 0.4662 - val_loss: 1.1678 - val_accuracy: 0.4653\n",
            "Epoch 1882/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1593 - accuracy: 0.4700 - val_loss: 1.1529 - val_accuracy: 0.4730\n",
            "Epoch 1883/3000\n",
            "76/76 [==============================] - 13s 168ms/step - loss: 1.1704 - accuracy: 0.4645 - val_loss: 1.1763 - val_accuracy: 0.4627\n",
            "Epoch 1884/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1652 - accuracy: 0.4673 - val_loss: 1.1561 - val_accuracy: 0.4722\n",
            "Epoch 1885/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1536 - accuracy: 0.4729 - val_loss: 1.1523 - val_accuracy: 0.4739\n",
            "Epoch 1886/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1512 - accuracy: 0.4740 - val_loss: 1.1493 - val_accuracy: 0.4752\n",
            "Epoch 1887/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1680 - accuracy: 0.4656 - val_loss: 1.2213 - val_accuracy: 0.4367\n",
            "Epoch 1888/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1860 - accuracy: 0.4560 - val_loss: 1.1764 - val_accuracy: 0.4611\n",
            "Epoch 1889/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1728 - accuracy: 0.4634 - val_loss: 1.1707 - val_accuracy: 0.4648\n",
            "Epoch 1890/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1691 - accuracy: 0.4653 - val_loss: 1.1713 - val_accuracy: 0.4639\n",
            "Epoch 1891/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1672 - accuracy: 0.4662 - val_loss: 1.1665 - val_accuracy: 0.4665\n",
            "Epoch 1892/3000\n",
            "76/76 [==============================] - 14s 180ms/step - loss: 1.1662 - accuracy: 0.4665 - val_loss: 1.1656 - val_accuracy: 0.4663\n",
            "Epoch 1893/3000\n",
            "76/76 [==============================] - 14s 181ms/step - loss: 1.1650 - accuracy: 0.4669 - val_loss: 1.1638 - val_accuracy: 0.4670\n",
            "Epoch 1894/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1634 - accuracy: 0.4677 - val_loss: 1.1615 - val_accuracy: 0.4686\n",
            "Epoch 1895/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1854 - accuracy: 0.4562 - val_loss: 1.1814 - val_accuracy: 0.4593\n",
            "Epoch 1896/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1720 - accuracy: 0.4637 - val_loss: 1.1674 - val_accuracy: 0.4655\n",
            "Epoch 1897/3000\n",
            "76/76 [==============================] - 13s 168ms/step - loss: 1.1663 - accuracy: 0.4667 - val_loss: 1.1649 - val_accuracy: 0.4675\n",
            "Epoch 1898/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1630 - accuracy: 0.4684 - val_loss: 1.1618 - val_accuracy: 0.4689\n",
            "Epoch 1899/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1571 - accuracy: 0.4712 - val_loss: 1.1539 - val_accuracy: 0.4724\n",
            "Epoch 1900/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1538 - accuracy: 0.4728 - val_loss: 1.1524 - val_accuracy: 0.4736\n",
            "Epoch 1901/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1526 - accuracy: 0.4734 - val_loss: 1.1516 - val_accuracy: 0.4737\n",
            "Epoch 1902/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1521 - accuracy: 0.4736 - val_loss: 1.1503 - val_accuracy: 0.4751\n",
            "Epoch 1903/3000\n",
            "76/76 [==============================] - 13s 168ms/step - loss: 1.1511 - accuracy: 0.4740 - val_loss: 1.1501 - val_accuracy: 0.4748\n",
            "Epoch 1904/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1734 - accuracy: 0.4632 - val_loss: 1.1693 - val_accuracy: 0.4655\n",
            "Epoch 1905/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1596 - accuracy: 0.4699 - val_loss: 1.1508 - val_accuracy: 0.4742\n",
            "Epoch 1906/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1498 - accuracy: 0.4748 - val_loss: 1.1488 - val_accuracy: 0.4754\n",
            "Epoch 1907/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1503 - accuracy: 0.4746 - val_loss: 1.1507 - val_accuracy: 0.4746\n",
            "Epoch 1908/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1483 - accuracy: 0.4755 - val_loss: 1.1489 - val_accuracy: 0.4749\n",
            "Epoch 1909/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1481 - accuracy: 0.4755 - val_loss: 1.1473 - val_accuracy: 0.4760\n",
            "Epoch 1910/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1726 - accuracy: 0.4637 - val_loss: 1.1616 - val_accuracy: 0.4690\n",
            "Epoch 1911/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1526 - accuracy: 0.4733 - val_loss: 1.1472 - val_accuracy: 0.4760\n",
            "Epoch 1912/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1471 - accuracy: 0.4761 - val_loss: 1.1478 - val_accuracy: 0.4757\n",
            "Epoch 1913/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1472 - accuracy: 0.4760 - val_loss: 1.1465 - val_accuracy: 0.4756\n",
            "Epoch 1914/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1589 - accuracy: 0.4704 - val_loss: 1.1788 - val_accuracy: 0.4616\n",
            "Epoch 1915/3000\n",
            "76/76 [==============================] - 13s 176ms/step - loss: 1.1633 - accuracy: 0.4683 - val_loss: 1.1545 - val_accuracy: 0.4724\n",
            "Epoch 1916/3000\n",
            "76/76 [==============================] - 14s 189ms/step - loss: 1.1495 - accuracy: 0.4749 - val_loss: 1.1463 - val_accuracy: 0.4769\n",
            "Epoch 1917/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1486 - accuracy: 0.4754 - val_loss: 1.1470 - val_accuracy: 0.4768\n",
            "Epoch 1918/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1667 - accuracy: 0.4667 - val_loss: 1.2391 - val_accuracy: 0.4257\n",
            "Epoch 1919/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1921 - accuracy: 0.4523 - val_loss: 1.1793 - val_accuracy: 0.4589\n",
            "Epoch 1920/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1743 - accuracy: 0.4625 - val_loss: 1.1707 - val_accuracy: 0.4645\n",
            "Epoch 1921/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1686 - accuracy: 0.4657 - val_loss: 1.1676 - val_accuracy: 0.4661\n",
            "Epoch 1922/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1659 - accuracy: 0.4670 - val_loss: 1.1639 - val_accuracy: 0.4684\n",
            "Epoch 1923/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1587 - accuracy: 0.4704 - val_loss: 1.1510 - val_accuracy: 0.4748\n",
            "Epoch 1924/3000\n",
            "76/76 [==============================] - 13s 167ms/step - loss: 1.1490 - accuracy: 0.4751 - val_loss: 1.1474 - val_accuracy: 0.4761\n",
            "Epoch 1925/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1471 - accuracy: 0.4761 - val_loss: 1.1470 - val_accuracy: 0.4766\n",
            "Epoch 1926/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1699 - accuracy: 0.4648 - val_loss: 1.2423 - val_accuracy: 0.4238\n",
            "Epoch 1927/3000\n",
            "76/76 [==============================] - 13s 173ms/step - loss: 1.1993 - accuracy: 0.4481 - val_loss: 1.1833 - val_accuracy: 0.4570\n",
            "Epoch 1928/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1784 - accuracy: 0.4602 - val_loss: 1.1754 - val_accuracy: 0.4624\n",
            "Epoch 1929/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1720 - accuracy: 0.4638 - val_loss: 1.1698 - val_accuracy: 0.4649\n",
            "Epoch 1930/3000\n",
            "76/76 [==============================] - 13s 168ms/step - loss: 1.1683 - accuracy: 0.4657 - val_loss: 1.1675 - val_accuracy: 0.4660\n",
            "Epoch 1931/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1665 - accuracy: 0.4665 - val_loss: 1.1653 - val_accuracy: 0.4675\n",
            "Epoch 1932/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1637 - accuracy: 0.4679 - val_loss: 1.1619 - val_accuracy: 0.4688\n",
            "Epoch 1933/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1560 - accuracy: 0.4718 - val_loss: 1.1528 - val_accuracy: 0.4735\n",
            "Epoch 1934/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1494 - accuracy: 0.4749 - val_loss: 1.2239 - val_accuracy: 0.4506\n",
            "Epoch 1935/3000\n",
            "76/76 [==============================] - 13s 168ms/step - loss: 1.1825 - accuracy: 0.4586 - val_loss: 1.1639 - val_accuracy: 0.4685\n",
            "Epoch 1936/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1599 - accuracy: 0.4701 - val_loss: 1.1547 - val_accuracy: 0.4718\n",
            "Epoch 1937/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1509 - accuracy: 0.4741 - val_loss: 1.1477 - val_accuracy: 0.4760\n",
            "Epoch 1938/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1473 - accuracy: 0.4760 - val_loss: 1.1468 - val_accuracy: 0.4762\n",
            "Epoch 1939/3000\n",
            "76/76 [==============================] - 14s 178ms/step - loss: 1.1682 - accuracy: 0.4650 - val_loss: 1.2140 - val_accuracy: 0.4408\n",
            "Epoch 1940/3000\n",
            "76/76 [==============================] - 14s 183ms/step - loss: 1.1810 - accuracy: 0.4587 - val_loss: 1.1713 - val_accuracy: 0.4646\n",
            "Epoch 1941/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1686 - accuracy: 0.4655 - val_loss: 1.1672 - val_accuracy: 0.4664\n",
            "Epoch 1942/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1658 - accuracy: 0.4669 - val_loss: 1.1647 - val_accuracy: 0.4673\n",
            "Epoch 1943/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1625 - accuracy: 0.4684 - val_loss: 1.1615 - val_accuracy: 0.4691\n",
            "Epoch 1944/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1545 - accuracy: 0.4724 - val_loss: 1.1498 - val_accuracy: 0.4748\n",
            "Epoch 1945/3000\n",
            "76/76 [==============================] - 13s 171ms/step - loss: 1.1661 - accuracy: 0.4666 - val_loss: 1.1704 - val_accuracy: 0.4655\n",
            "Epoch 1946/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1623 - accuracy: 0.4691 - val_loss: 1.1581 - val_accuracy: 0.4713\n",
            "Epoch 1947/3000\n",
            "76/76 [==============================] - 13s 170ms/step - loss: 1.1550 - accuracy: 0.4723 - val_loss: 1.1529 - val_accuracy: 0.4731\n",
            "Epoch 1948/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1501 - accuracy: 0.4746 - val_loss: 1.1478 - val_accuracy: 0.4752\n",
            "Epoch 1949/3000\n",
            "76/76 [==============================] - 13s 169ms/step - loss: 1.1587 - accuracy: 0.4702 - val_loss: 1.1790 - val_accuracy: 0.4623\n",
            "Epoch 1950/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1631 - accuracy: 0.4687 - val_loss: 1.1567 - val_accuracy: 0.4723\n",
            "Epoch 1951/3000\n",
            "76/76 [==============================] - 13s 172ms/step - loss: 1.1528 - accuracy: 0.4733 - val_loss: 1.1506 - val_accuracy: 0.4746\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utCqK9OeXysf"
      },
      "source": [
        "model_path = '/content/gdrive/My Drive/Colab Notebooks/models/'\n",
        "recurrent_ae.save(model_path + 'ae(1)_chip_adam1024.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5Cx01EEYGI5"
      },
      "source": [
        "def save_hist():\n",
        "  filename = data_path + \"ae_chip_adam1024_reconstruction_history.csv\"\n",
        "  hist_df = pd.DataFrame(ae_hist.history) \n",
        "  with open(filename, mode='w') as f:\n",
        "    hist_df.to_csv(f)\n",
        "save_hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXRSsdEzcog7"
      },
      "source": [
        "# # can continue training\n",
        "# loaded_ae_model = keras.models.load_model('/content/gdrive/My Drive/Colab Notebooks/models/lstm1_chip.0030.h5')\n",
        "# reconstructed_encoder = keras.Model(loaded_ae_model.layers[0].input, loaded_ae_model.layers[0].output)\n",
        "# reconstructed_decoder = keras.Model(loaded_ae_model.layers[1].input, loaded_ae_model.layers[1].output)\n",
        "# reconstructed_autoencoder = keras.Sequential([reconstructed_encoder, reconstructed_decoder])\n",
        "# reconstructed_autoencoder.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "# ae_hist2 = reconstructed_autoencoder.fit(xtrain_seq, validation_data=xval_seq, epochs=200, callbacks=[es_cb,model_checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjiRiXQHwNOS",
        "outputId": "e3b3c3e2-f856-48ef-c0be-58c612622414",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "for i in range(1):\n",
        "  ax1 = axes[0]\n",
        "  ax2 = axes[1]\n",
        "\n",
        "  ax1.plot(ae_hist.history['loss'], label='training')\n",
        "  ax1.plot(ae_hist.history['val_loss'], label='validation')\n",
        "  ax1.set_title('lstm autoencoder loss')\n",
        "  ax1.set_xlabel('epoch')\n",
        "  ax1.set_ylabel('loss')\n",
        "  ax1.legend(['train', 'validation'], loc='upper left')\n",
        "  \n",
        "  ax2.plot(ae_hist.history['accuracy'], label='training')\n",
        "  ax2.plot(ae_hist.history['val_accuracy'], label='validation')\n",
        "  ax2.set_title('lstm autoencoder accuracy')\n",
        "  ax2.set_xlabel('epoch')\n",
        "  ax2.set_ylabel('accuracy')\n",
        "  ax2.legend(['train', 'validation'], loc='upper left')\n",
        "fig.tight_layout()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y98IDmGbxTqx"
      },
      "source": [
        "# # how to reconstruct the sequence\n",
        "# idx_to_char = {'0':'T', '1':'G', '2':'C', '3':'A'}\n",
        "# def show_reconstructions(model, x_seq=xtrain_seq, original_data=chip_train, samples=10):\n",
        "#   reconstructions = model.predict(x_seq)\n",
        "#   print('The shape of reconstructions', reconstructions.shape)\n",
        "#   recon_softmax = np.argmax(reconstructions, axis=-1)\n",
        "#   for i in range(samples):\n",
        "#     seq = ''\n",
        "#     for idx in recon_softmax[i]:\n",
        "#       seq += idx_to_char[str(idx)]\n",
        "#     print()\n",
        "#     print('The {}-th original sequence vs after reconstruction'.format(i))\n",
        "#     print(original_data['seq'].iloc[i])\n",
        "#     print(seq)\n",
        "\n",
        "# show_reconstructions(recurrent_ae, xval_seq, chip_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvND3IYxU967",
        "outputId": "fa02fa79-537e-49fa-e95e-8907c055cd35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "xtrain_vec = encoder.predict(xtrain_seq)\n",
        "xval_vec = encoder.predict(xval_seq)\n",
        "xtest_vec = encoder.predict(xtest_seq)\n",
        "print('The shape of xtrain/xval/xtest_seq is', xtrain_vec.shape, xval_vec.shape, xtest_vec.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of xtrain/xval/xtest_seq is (77174, 30) (1000, 30) (19544, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kUn_jsA-ne1"
      },
      "source": [
        "def plotVec(ax, x, y, title=\"title\"):\n",
        "  scatter = ax.scatter(x[:, 0], x[:, 1], c=y, \n",
        "             cmap=matplotlib.colors.ListedColormap([\"red\", \"blue\", \"yellow\"]))\n",
        "  ax.set_title(title)\n",
        "  ax.legend(*scatter.legend_elements(), loc=0, title=\"Classes\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmoSauXnU-Gf"
      },
      "source": [
        "# # too many training example\n",
        "# xtrain_tsne = TSNE(n_components=2, metric=\"cosine\").fit_transform(xtrain_vec[:1000])\n",
        "# xval_tsne = TSNE(n_components=2, metric=\"cosine\").fit_transform(xval_vec)\n",
        "# xtest_tsne = TSNE(n_components=2, metric=\"cosine\").fit_transform(xtest_vec[:1000])\n",
        "\n",
        "# fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "# plotVec(axes[0], xtrain_tsne, chip_train[:1000][\"id\"], title=\"TSNE, training\")\n",
        "# plotVec(axes[1], xval_tsne, chip_val[\"id\"], title=\"TSNE, validation\")\n",
        "# plotVec(axes[2], xtest_tsne, chip_test[:1000][\"id\"], title=\"TSNE, test\")\n",
        "# fig.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kbo0bGNU-Em"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "  keras.layers.Dense(128, activation=\"relu\", input_shape=[latent_size]),\n",
        "  keras.layers.Dropout(0.2),\n",
        "  keras.layers.Dense(64, activation=\"relu\"),    \n",
        "  keras.layers.Dropout(0.2),\n",
        "  keras.layers.Dense(32, activation=\"relu\"),  \n",
        "  keras.layers.Dropout(0.2), \n",
        "  keras.layers.Dense(16, activation=\"relu\"), \n",
        "  keras.layers.Dropout(0.2),   \n",
        "  keras.layers.Dense(1, activation=\"sigmoid\")                               \n",
        "])\n",
        "model.compile(keras.optimizers.SGD(momentum=0.9), loss=keras.losses.BinaryCrossentropy(), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shzjYa-MlBuj",
        "outputId": "8a0b5651-0062-4b7a-f38a-d5a2ea6001c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_hist = model.fit(xtrain_vec, chip_train['id'], validation_data=(xval_vec, chip_val['id']), epochs=1000, callbacks=[es_cb])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6935 - accuracy: 0.5007 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 2/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6930 - accuracy: 0.5090 - val_loss: 0.6912 - val_accuracy: 0.5500\n",
            "Epoch 3/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6915 - accuracy: 0.5237 - val_loss: 0.6898 - val_accuracy: 0.5440\n",
            "Epoch 4/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6893 - accuracy: 0.5356 - val_loss: 0.6897 - val_accuracy: 0.5410\n",
            "Epoch 5/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6873 - accuracy: 0.5480 - val_loss: 0.6868 - val_accuracy: 0.5510\n",
            "Epoch 6/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6861 - accuracy: 0.5505 - val_loss: 0.6817 - val_accuracy: 0.5610\n",
            "Epoch 7/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6852 - accuracy: 0.5530 - val_loss: 0.6838 - val_accuracy: 0.5510\n",
            "Epoch 8/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6841 - accuracy: 0.5554 - val_loss: 0.6821 - val_accuracy: 0.5810\n",
            "Epoch 9/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6840 - accuracy: 0.5563 - val_loss: 0.6842 - val_accuracy: 0.5580\n",
            "Epoch 10/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6828 - accuracy: 0.5606 - val_loss: 0.6815 - val_accuracy: 0.5580\n",
            "Epoch 11/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6825 - accuracy: 0.5621 - val_loss: 0.6783 - val_accuracy: 0.5600\n",
            "Epoch 12/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6818 - accuracy: 0.5629 - val_loss: 0.6788 - val_accuracy: 0.5860\n",
            "Epoch 13/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6808 - accuracy: 0.5648 - val_loss: 0.6770 - val_accuracy: 0.5650\n",
            "Epoch 14/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6811 - accuracy: 0.5623 - val_loss: 0.6777 - val_accuracy: 0.5610\n",
            "Epoch 15/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6803 - accuracy: 0.5637 - val_loss: 0.6744 - val_accuracy: 0.5790\n",
            "Epoch 16/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6798 - accuracy: 0.5668 - val_loss: 0.6783 - val_accuracy: 0.5670\n",
            "Epoch 17/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6798 - accuracy: 0.5671 - val_loss: 0.6763 - val_accuracy: 0.5660\n",
            "Epoch 18/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6784 - accuracy: 0.5709 - val_loss: 0.6737 - val_accuracy: 0.5710\n",
            "Epoch 19/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6782 - accuracy: 0.5687 - val_loss: 0.6709 - val_accuracy: 0.5890\n",
            "Epoch 20/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6782 - accuracy: 0.5709 - val_loss: 0.6792 - val_accuracy: 0.5670\n",
            "Epoch 21/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6777 - accuracy: 0.5699 - val_loss: 0.6681 - val_accuracy: 0.5870\n",
            "Epoch 22/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6767 - accuracy: 0.5739 - val_loss: 0.6755 - val_accuracy: 0.5550\n",
            "Epoch 23/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6761 - accuracy: 0.5723 - val_loss: 0.6650 - val_accuracy: 0.5820\n",
            "Epoch 24/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6754 - accuracy: 0.5763 - val_loss: 0.6735 - val_accuracy: 0.5710\n",
            "Epoch 25/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6747 - accuracy: 0.5762 - val_loss: 0.6697 - val_accuracy: 0.5910\n",
            "Epoch 26/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6740 - accuracy: 0.5772 - val_loss: 0.6664 - val_accuracy: 0.5940\n",
            "Epoch 27/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6736 - accuracy: 0.5796 - val_loss: 0.6663 - val_accuracy: 0.5810\n",
            "Epoch 28/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6724 - accuracy: 0.5810 - val_loss: 0.6590 - val_accuracy: 0.5920\n",
            "Epoch 29/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6718 - accuracy: 0.5831 - val_loss: 0.6710 - val_accuracy: 0.5720\n",
            "Epoch 30/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6711 - accuracy: 0.5858 - val_loss: 0.6708 - val_accuracy: 0.5830\n",
            "Epoch 31/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6704 - accuracy: 0.5864 - val_loss: 0.6599 - val_accuracy: 0.5800\n",
            "Epoch 32/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6694 - accuracy: 0.5895 - val_loss: 0.6571 - val_accuracy: 0.6060\n",
            "Epoch 33/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6690 - accuracy: 0.5881 - val_loss: 0.6600 - val_accuracy: 0.6150\n",
            "Epoch 34/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6685 - accuracy: 0.5884 - val_loss: 0.6594 - val_accuracy: 0.5970\n",
            "Epoch 35/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6669 - accuracy: 0.5908 - val_loss: 0.6605 - val_accuracy: 0.6130\n",
            "Epoch 36/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6667 - accuracy: 0.5917 - val_loss: 0.6603 - val_accuracy: 0.5870\n",
            "Epoch 37/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6655 - accuracy: 0.5940 - val_loss: 0.6616 - val_accuracy: 0.5940\n",
            "Epoch 38/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6648 - accuracy: 0.5979 - val_loss: 0.6636 - val_accuracy: 0.5900\n",
            "Epoch 39/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6635 - accuracy: 0.5988 - val_loss: 0.6526 - val_accuracy: 0.6250\n",
            "Epoch 40/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6633 - accuracy: 0.5987 - val_loss: 0.6544 - val_accuracy: 0.6250\n",
            "Epoch 41/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6632 - accuracy: 0.5991 - val_loss: 0.6496 - val_accuracy: 0.6260\n",
            "Epoch 42/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6619 - accuracy: 0.6033 - val_loss: 0.6488 - val_accuracy: 0.6170\n",
            "Epoch 43/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6610 - accuracy: 0.6041 - val_loss: 0.6617 - val_accuracy: 0.5920\n",
            "Epoch 44/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6611 - accuracy: 0.6023 - val_loss: 0.6541 - val_accuracy: 0.6170\n",
            "Epoch 45/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6601 - accuracy: 0.6050 - val_loss: 0.6452 - val_accuracy: 0.6290\n",
            "Epoch 46/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6592 - accuracy: 0.6078 - val_loss: 0.6529 - val_accuracy: 0.6080\n",
            "Epoch 47/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6590 - accuracy: 0.6081 - val_loss: 0.6483 - val_accuracy: 0.6280\n",
            "Epoch 48/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6580 - accuracy: 0.6083 - val_loss: 0.6426 - val_accuracy: 0.6400\n",
            "Epoch 49/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6572 - accuracy: 0.6087 - val_loss: 0.6485 - val_accuracy: 0.6190\n",
            "Epoch 50/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6570 - accuracy: 0.6089 - val_loss: 0.6496 - val_accuracy: 0.6310\n",
            "Epoch 51/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6571 - accuracy: 0.6098 - val_loss: 0.6580 - val_accuracy: 0.5910\n",
            "Epoch 52/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6556 - accuracy: 0.6110 - val_loss: 0.6495 - val_accuracy: 0.6270\n",
            "Epoch 53/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6569 - accuracy: 0.6114 - val_loss: 0.6473 - val_accuracy: 0.6300\n",
            "Epoch 54/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6561 - accuracy: 0.6116 - val_loss: 0.6563 - val_accuracy: 0.6060\n",
            "Epoch 55/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6561 - accuracy: 0.6128 - val_loss: 0.6464 - val_accuracy: 0.6290\n",
            "Epoch 56/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6552 - accuracy: 0.6128 - val_loss: 0.6418 - val_accuracy: 0.6330\n",
            "Epoch 57/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6544 - accuracy: 0.6123 - val_loss: 0.6473 - val_accuracy: 0.6260\n",
            "Epoch 58/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6544 - accuracy: 0.6127 - val_loss: 0.6557 - val_accuracy: 0.6220\n",
            "Epoch 59/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6542 - accuracy: 0.6144 - val_loss: 0.6422 - val_accuracy: 0.6310\n",
            "Epoch 60/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6536 - accuracy: 0.6160 - val_loss: 0.6407 - val_accuracy: 0.6280\n",
            "Epoch 61/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6532 - accuracy: 0.6156 - val_loss: 0.6480 - val_accuracy: 0.6250\n",
            "Epoch 62/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6526 - accuracy: 0.6171 - val_loss: 0.6554 - val_accuracy: 0.6130\n",
            "Epoch 63/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6525 - accuracy: 0.6180 - val_loss: 0.6435 - val_accuracy: 0.6400\n",
            "Epoch 64/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6532 - accuracy: 0.6153 - val_loss: 0.6422 - val_accuracy: 0.6530\n",
            "Epoch 65/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6518 - accuracy: 0.6171 - val_loss: 0.6416 - val_accuracy: 0.6480\n",
            "Epoch 66/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6523 - accuracy: 0.6152 - val_loss: 0.6423 - val_accuracy: 0.6280\n",
            "Epoch 67/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6521 - accuracy: 0.6174 - val_loss: 0.6443 - val_accuracy: 0.6300\n",
            "Epoch 68/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6512 - accuracy: 0.6188 - val_loss: 0.6455 - val_accuracy: 0.6290\n",
            "Epoch 69/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6514 - accuracy: 0.6172 - val_loss: 0.6390 - val_accuracy: 0.6390\n",
            "Epoch 70/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6501 - accuracy: 0.6209 - val_loss: 0.6426 - val_accuracy: 0.6350\n",
            "Epoch 71/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6504 - accuracy: 0.6185 - val_loss: 0.6526 - val_accuracy: 0.6270\n",
            "Epoch 72/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6510 - accuracy: 0.6187 - val_loss: 0.6407 - val_accuracy: 0.6400\n",
            "Epoch 73/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6503 - accuracy: 0.6197 - val_loss: 0.6411 - val_accuracy: 0.6430\n",
            "Epoch 74/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6495 - accuracy: 0.6206 - val_loss: 0.6427 - val_accuracy: 0.6340\n",
            "Epoch 75/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6502 - accuracy: 0.6214 - val_loss: 0.6409 - val_accuracy: 0.6290\n",
            "Epoch 76/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6492 - accuracy: 0.6202 - val_loss: 0.6391 - val_accuracy: 0.6460\n",
            "Epoch 77/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6486 - accuracy: 0.6203 - val_loss: 0.6388 - val_accuracy: 0.6460\n",
            "Epoch 78/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6479 - accuracy: 0.6235 - val_loss: 0.6357 - val_accuracy: 0.6410\n",
            "Epoch 79/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6482 - accuracy: 0.6228 - val_loss: 0.6459 - val_accuracy: 0.6290\n",
            "Epoch 80/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6482 - accuracy: 0.6230 - val_loss: 0.6436 - val_accuracy: 0.6340\n",
            "Epoch 81/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6475 - accuracy: 0.6229 - val_loss: 0.6462 - val_accuracy: 0.6170\n",
            "Epoch 82/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6471 - accuracy: 0.6233 - val_loss: 0.6390 - val_accuracy: 0.6370\n",
            "Epoch 83/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6475 - accuracy: 0.6239 - val_loss: 0.6432 - val_accuracy: 0.6330\n",
            "Epoch 84/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6481 - accuracy: 0.6241 - val_loss: 0.6394 - val_accuracy: 0.6370\n",
            "Epoch 85/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6471 - accuracy: 0.6252 - val_loss: 0.6474 - val_accuracy: 0.6170\n",
            "Epoch 86/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6466 - accuracy: 0.6266 - val_loss: 0.6407 - val_accuracy: 0.6280\n",
            "Epoch 87/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6462 - accuracy: 0.6262 - val_loss: 0.6489 - val_accuracy: 0.6340\n",
            "Epoch 88/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6465 - accuracy: 0.6246 - val_loss: 0.6338 - val_accuracy: 0.6400\n",
            "Epoch 89/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6452 - accuracy: 0.6288 - val_loss: 0.6396 - val_accuracy: 0.6190\n",
            "Epoch 90/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6469 - accuracy: 0.6255 - val_loss: 0.6459 - val_accuracy: 0.6240\n",
            "Epoch 91/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6456 - accuracy: 0.6267 - val_loss: 0.6430 - val_accuracy: 0.6250\n",
            "Epoch 92/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6461 - accuracy: 0.6265 - val_loss: 0.6385 - val_accuracy: 0.6490\n",
            "Epoch 93/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6461 - accuracy: 0.6268 - val_loss: 0.6326 - val_accuracy: 0.6460\n",
            "Epoch 94/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6453 - accuracy: 0.6287 - val_loss: 0.6361 - val_accuracy: 0.6460\n",
            "Epoch 95/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6449 - accuracy: 0.6284 - val_loss: 0.6349 - val_accuracy: 0.6520\n",
            "Epoch 96/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6442 - accuracy: 0.6281 - val_loss: 0.6510 - val_accuracy: 0.6070\n",
            "Epoch 97/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6443 - accuracy: 0.6283 - val_loss: 0.6408 - val_accuracy: 0.6330\n",
            "Epoch 98/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6448 - accuracy: 0.6281 - val_loss: 0.6393 - val_accuracy: 0.6420\n",
            "Epoch 99/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6439 - accuracy: 0.6297 - val_loss: 0.6362 - val_accuracy: 0.6460\n",
            "Epoch 100/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6442 - accuracy: 0.6306 - val_loss: 0.6398 - val_accuracy: 0.6500\n",
            "Epoch 101/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6446 - accuracy: 0.6281 - val_loss: 0.6396 - val_accuracy: 0.6310\n",
            "Epoch 102/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6435 - accuracy: 0.6296 - val_loss: 0.6283 - val_accuracy: 0.6560\n",
            "Epoch 103/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6437 - accuracy: 0.6296 - val_loss: 0.6406 - val_accuracy: 0.6200\n",
            "Epoch 104/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6439 - accuracy: 0.6297 - val_loss: 0.6489 - val_accuracy: 0.6300\n",
            "Epoch 105/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6426 - accuracy: 0.6319 - val_loss: 0.6420 - val_accuracy: 0.6220\n",
            "Epoch 106/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6428 - accuracy: 0.6308 - val_loss: 0.6478 - val_accuracy: 0.6120\n",
            "Epoch 107/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6429 - accuracy: 0.6300 - val_loss: 0.6376 - val_accuracy: 0.6440\n",
            "Epoch 108/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6431 - accuracy: 0.6305 - val_loss: 0.6349 - val_accuracy: 0.6390\n",
            "Epoch 109/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6421 - accuracy: 0.6323 - val_loss: 0.6394 - val_accuracy: 0.6270\n",
            "Epoch 110/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6423 - accuracy: 0.6315 - val_loss: 0.6380 - val_accuracy: 0.6450\n",
            "Epoch 111/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6419 - accuracy: 0.6320 - val_loss: 0.6394 - val_accuracy: 0.6300\n",
            "Epoch 112/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6421 - accuracy: 0.6323 - val_loss: 0.6376 - val_accuracy: 0.6390\n",
            "Epoch 113/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6422 - accuracy: 0.6314 - val_loss: 0.6397 - val_accuracy: 0.6450\n",
            "Epoch 114/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6409 - accuracy: 0.6322 - val_loss: 0.6361 - val_accuracy: 0.6330\n",
            "Epoch 115/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6411 - accuracy: 0.6340 - val_loss: 0.6293 - val_accuracy: 0.6470\n",
            "Epoch 116/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6411 - accuracy: 0.6333 - val_loss: 0.6446 - val_accuracy: 0.6390\n",
            "Epoch 117/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6414 - accuracy: 0.6345 - val_loss: 0.6320 - val_accuracy: 0.6470\n",
            "Epoch 118/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6403 - accuracy: 0.6335 - val_loss: 0.6319 - val_accuracy: 0.6430\n",
            "Epoch 119/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6412 - accuracy: 0.6333 - val_loss: 0.6349 - val_accuracy: 0.6510\n",
            "Epoch 120/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6401 - accuracy: 0.6361 - val_loss: 0.6348 - val_accuracy: 0.6470\n",
            "Epoch 121/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6403 - accuracy: 0.6334 - val_loss: 0.6343 - val_accuracy: 0.6560\n",
            "Epoch 122/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6395 - accuracy: 0.6345 - val_loss: 0.6329 - val_accuracy: 0.6510\n",
            "Epoch 123/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6405 - accuracy: 0.6337 - val_loss: 0.6334 - val_accuracy: 0.6520\n",
            "Epoch 124/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6397 - accuracy: 0.6361 - val_loss: 0.6393 - val_accuracy: 0.6340\n",
            "Epoch 125/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6394 - accuracy: 0.6369 - val_loss: 0.6445 - val_accuracy: 0.6270\n",
            "Epoch 126/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6396 - accuracy: 0.6360 - val_loss: 0.6327 - val_accuracy: 0.6550\n",
            "Epoch 127/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6393 - accuracy: 0.6367 - val_loss: 0.6342 - val_accuracy: 0.6360\n",
            "Epoch 128/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6398 - accuracy: 0.6356 - val_loss: 0.6348 - val_accuracy: 0.6370\n",
            "Epoch 129/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6396 - accuracy: 0.6355 - val_loss: 0.6260 - val_accuracy: 0.6580\n",
            "Epoch 130/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6384 - accuracy: 0.6361 - val_loss: 0.6283 - val_accuracy: 0.6500\n",
            "Epoch 131/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6389 - accuracy: 0.6363 - val_loss: 0.6336 - val_accuracy: 0.6340\n",
            "Epoch 132/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6386 - accuracy: 0.6372 - val_loss: 0.6264 - val_accuracy: 0.6570\n",
            "Epoch 133/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6374 - accuracy: 0.6381 - val_loss: 0.6338 - val_accuracy: 0.6370\n",
            "Epoch 134/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6378 - accuracy: 0.6381 - val_loss: 0.6345 - val_accuracy: 0.6480\n",
            "Epoch 135/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6385 - accuracy: 0.6388 - val_loss: 0.6315 - val_accuracy: 0.6500\n",
            "Epoch 136/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6377 - accuracy: 0.6371 - val_loss: 0.6344 - val_accuracy: 0.6450\n",
            "Epoch 137/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6381 - accuracy: 0.6382 - val_loss: 0.6329 - val_accuracy: 0.6410\n",
            "Epoch 138/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6377 - accuracy: 0.6374 - val_loss: 0.6322 - val_accuracy: 0.6540\n",
            "Epoch 139/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6378 - accuracy: 0.6373 - val_loss: 0.6296 - val_accuracy: 0.6580\n",
            "Epoch 140/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6374 - accuracy: 0.6369 - val_loss: 0.6280 - val_accuracy: 0.6640\n",
            "Epoch 141/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6374 - accuracy: 0.6371 - val_loss: 0.6365 - val_accuracy: 0.6390\n",
            "Epoch 142/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6378 - accuracy: 0.6376 - val_loss: 0.6343 - val_accuracy: 0.6610\n",
            "Epoch 143/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6370 - accuracy: 0.6374 - val_loss: 0.6342 - val_accuracy: 0.6310\n",
            "Epoch 144/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6367 - accuracy: 0.6383 - val_loss: 0.6314 - val_accuracy: 0.6360\n",
            "Epoch 145/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6370 - accuracy: 0.6386 - val_loss: 0.6297 - val_accuracy: 0.6380\n",
            "Epoch 146/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6368 - accuracy: 0.6403 - val_loss: 0.6333 - val_accuracy: 0.6610\n",
            "Epoch 147/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6356 - accuracy: 0.6400 - val_loss: 0.6285 - val_accuracy: 0.6490\n",
            "Epoch 148/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6361 - accuracy: 0.6387 - val_loss: 0.6300 - val_accuracy: 0.6480\n",
            "Epoch 149/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6351 - accuracy: 0.6425 - val_loss: 0.6288 - val_accuracy: 0.6520\n",
            "Epoch 150/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6363 - accuracy: 0.6412 - val_loss: 0.6274 - val_accuracy: 0.6530\n",
            "Epoch 151/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6355 - accuracy: 0.6408 - val_loss: 0.6300 - val_accuracy: 0.6430\n",
            "Epoch 152/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6357 - accuracy: 0.6408 - val_loss: 0.6280 - val_accuracy: 0.6550\n",
            "Epoch 153/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6361 - accuracy: 0.6405 - val_loss: 0.6322 - val_accuracy: 0.6560\n",
            "Epoch 154/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6348 - accuracy: 0.6400 - val_loss: 0.6351 - val_accuracy: 0.6420\n",
            "Epoch 155/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6342 - accuracy: 0.6423 - val_loss: 0.6264 - val_accuracy: 0.6530\n",
            "Epoch 156/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6355 - accuracy: 0.6424 - val_loss: 0.6276 - val_accuracy: 0.6680\n",
            "Epoch 157/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6345 - accuracy: 0.6403 - val_loss: 0.6348 - val_accuracy: 0.6350\n",
            "Epoch 158/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6348 - accuracy: 0.6428 - val_loss: 0.6288 - val_accuracy: 0.6470\n",
            "Epoch 159/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6340 - accuracy: 0.6447 - val_loss: 0.6322 - val_accuracy: 0.6490\n",
            "Epoch 160/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6347 - accuracy: 0.6430 - val_loss: 0.6302 - val_accuracy: 0.6530\n",
            "Epoch 161/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6340 - accuracy: 0.6430 - val_loss: 0.6266 - val_accuracy: 0.6550\n",
            "Epoch 162/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6331 - accuracy: 0.6447 - val_loss: 0.6300 - val_accuracy: 0.6490\n",
            "Epoch 163/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6341 - accuracy: 0.6417 - val_loss: 0.6304 - val_accuracy: 0.6400\n",
            "Epoch 164/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6330 - accuracy: 0.6437 - val_loss: 0.6298 - val_accuracy: 0.6520\n",
            "Epoch 165/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6333 - accuracy: 0.6452 - val_loss: 0.6285 - val_accuracy: 0.6510\n",
            "Epoch 166/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6329 - accuracy: 0.6450 - val_loss: 0.6200 - val_accuracy: 0.6610\n",
            "Epoch 167/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6330 - accuracy: 0.6427 - val_loss: 0.6269 - val_accuracy: 0.6410\n",
            "Epoch 168/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6343 - accuracy: 0.6426 - val_loss: 0.6304 - val_accuracy: 0.6570\n",
            "Epoch 169/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6335 - accuracy: 0.6424 - val_loss: 0.6280 - val_accuracy: 0.6500\n",
            "Epoch 170/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6335 - accuracy: 0.6437 - val_loss: 0.6259 - val_accuracy: 0.6490\n",
            "Epoch 171/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6338 - accuracy: 0.6435 - val_loss: 0.6284 - val_accuracy: 0.6480\n",
            "Epoch 172/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6332 - accuracy: 0.6462 - val_loss: 0.6353 - val_accuracy: 0.6410\n",
            "Epoch 173/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6326 - accuracy: 0.6434 - val_loss: 0.6241 - val_accuracy: 0.6580\n",
            "Epoch 174/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6328 - accuracy: 0.6427 - val_loss: 0.6252 - val_accuracy: 0.6560\n",
            "Epoch 175/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6324 - accuracy: 0.6441 - val_loss: 0.6245 - val_accuracy: 0.6540\n",
            "Epoch 176/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6317 - accuracy: 0.6458 - val_loss: 0.6253 - val_accuracy: 0.6680\n",
            "Epoch 177/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6333 - accuracy: 0.6450 - val_loss: 0.6341 - val_accuracy: 0.6440\n",
            "Epoch 178/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6317 - accuracy: 0.6459 - val_loss: 0.6265 - val_accuracy: 0.6530\n",
            "Epoch 179/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6316 - accuracy: 0.6465 - val_loss: 0.6286 - val_accuracy: 0.6590\n",
            "Epoch 180/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6322 - accuracy: 0.6454 - val_loss: 0.6309 - val_accuracy: 0.6620\n",
            "Epoch 181/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6313 - accuracy: 0.6450 - val_loss: 0.6293 - val_accuracy: 0.6560\n",
            "Epoch 182/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6309 - accuracy: 0.6462 - val_loss: 0.6304 - val_accuracy: 0.6600\n",
            "Epoch 183/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6313 - accuracy: 0.6470 - val_loss: 0.6300 - val_accuracy: 0.6530\n",
            "Epoch 184/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6321 - accuracy: 0.6462 - val_loss: 0.6295 - val_accuracy: 0.6410\n",
            "Epoch 185/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6312 - accuracy: 0.6464 - val_loss: 0.6240 - val_accuracy: 0.6470\n",
            "Epoch 186/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6309 - accuracy: 0.6485 - val_loss: 0.6285 - val_accuracy: 0.6540\n",
            "Epoch 187/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6311 - accuracy: 0.6467 - val_loss: 0.6297 - val_accuracy: 0.6520\n",
            "Epoch 188/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6303 - accuracy: 0.6492 - val_loss: 0.6236 - val_accuracy: 0.6520\n",
            "Epoch 189/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6297 - accuracy: 0.6488 - val_loss: 0.6239 - val_accuracy: 0.6610\n",
            "Epoch 190/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6316 - accuracy: 0.6451 - val_loss: 0.6197 - val_accuracy: 0.6710\n",
            "Epoch 191/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6303 - accuracy: 0.6474 - val_loss: 0.6255 - val_accuracy: 0.6620\n",
            "Epoch 192/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6306 - accuracy: 0.6468 - val_loss: 0.6231 - val_accuracy: 0.6510\n",
            "Epoch 193/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6305 - accuracy: 0.6471 - val_loss: 0.6239 - val_accuracy: 0.6450\n",
            "Epoch 194/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6313 - accuracy: 0.6463 - val_loss: 0.6285 - val_accuracy: 0.6350\n",
            "Epoch 195/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6305 - accuracy: 0.6470 - val_loss: 0.6282 - val_accuracy: 0.6460\n",
            "Epoch 196/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6296 - accuracy: 0.6485 - val_loss: 0.6293 - val_accuracy: 0.6320\n",
            "Epoch 197/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6303 - accuracy: 0.6465 - val_loss: 0.6457 - val_accuracy: 0.6220\n",
            "Epoch 198/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6293 - accuracy: 0.6488 - val_loss: 0.6201 - val_accuracy: 0.6630\n",
            "Epoch 199/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6303 - accuracy: 0.6464 - val_loss: 0.6301 - val_accuracy: 0.6520\n",
            "Epoch 200/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6298 - accuracy: 0.6469 - val_loss: 0.6255 - val_accuracy: 0.6590\n",
            "Epoch 201/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6294 - accuracy: 0.6493 - val_loss: 0.6269 - val_accuracy: 0.6590\n",
            "Epoch 202/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6297 - accuracy: 0.6479 - val_loss: 0.6210 - val_accuracy: 0.6590\n",
            "Epoch 203/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6299 - accuracy: 0.6467 - val_loss: 0.6246 - val_accuracy: 0.6620\n",
            "Epoch 204/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6291 - accuracy: 0.6507 - val_loss: 0.6233 - val_accuracy: 0.6580\n",
            "Epoch 205/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6283 - accuracy: 0.6499 - val_loss: 0.6219 - val_accuracy: 0.6630\n",
            "Epoch 206/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6291 - accuracy: 0.6506 - val_loss: 0.6273 - val_accuracy: 0.6600\n",
            "Epoch 207/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6305 - accuracy: 0.6478 - val_loss: 0.6254 - val_accuracy: 0.6490\n",
            "Epoch 208/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6290 - accuracy: 0.6498 - val_loss: 0.6222 - val_accuracy: 0.6470\n",
            "Epoch 209/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6289 - accuracy: 0.6500 - val_loss: 0.6182 - val_accuracy: 0.6740\n",
            "Epoch 210/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6288 - accuracy: 0.6480 - val_loss: 0.6264 - val_accuracy: 0.6520\n",
            "Epoch 211/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6287 - accuracy: 0.6492 - val_loss: 0.6206 - val_accuracy: 0.6530\n",
            "Epoch 212/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6288 - accuracy: 0.6505 - val_loss: 0.6265 - val_accuracy: 0.6490\n",
            "Epoch 213/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6284 - accuracy: 0.6482 - val_loss: 0.6173 - val_accuracy: 0.6600\n",
            "Epoch 214/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6287 - accuracy: 0.6500 - val_loss: 0.6281 - val_accuracy: 0.6350\n",
            "Epoch 215/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6278 - accuracy: 0.6499 - val_loss: 0.6187 - val_accuracy: 0.6600\n",
            "Epoch 216/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6283 - accuracy: 0.6483 - val_loss: 0.6201 - val_accuracy: 0.6700\n",
            "Epoch 217/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6286 - accuracy: 0.6499 - val_loss: 0.6199 - val_accuracy: 0.6620\n",
            "Epoch 218/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6274 - accuracy: 0.6495 - val_loss: 0.6231 - val_accuracy: 0.6580\n",
            "Epoch 219/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6283 - accuracy: 0.6496 - val_loss: 0.6199 - val_accuracy: 0.6680\n",
            "Epoch 220/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6280 - accuracy: 0.6493 - val_loss: 0.6277 - val_accuracy: 0.6550\n",
            "Epoch 221/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6276 - accuracy: 0.6518 - val_loss: 0.6196 - val_accuracy: 0.6570\n",
            "Epoch 222/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6270 - accuracy: 0.6519 - val_loss: 0.6215 - val_accuracy: 0.6480\n",
            "Epoch 223/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6280 - accuracy: 0.6495 - val_loss: 0.6289 - val_accuracy: 0.6590\n",
            "Epoch 224/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6266 - accuracy: 0.6508 - val_loss: 0.6216 - val_accuracy: 0.6610\n",
            "Epoch 225/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6274 - accuracy: 0.6511 - val_loss: 0.6226 - val_accuracy: 0.6550\n",
            "Epoch 226/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6272 - accuracy: 0.6527 - val_loss: 0.6189 - val_accuracy: 0.6740\n",
            "Epoch 227/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6265 - accuracy: 0.6511 - val_loss: 0.6212 - val_accuracy: 0.6670\n",
            "Epoch 228/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6273 - accuracy: 0.6506 - val_loss: 0.6279 - val_accuracy: 0.6430\n",
            "Epoch 229/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6269 - accuracy: 0.6539 - val_loss: 0.6251 - val_accuracy: 0.6450\n",
            "Epoch 230/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6265 - accuracy: 0.6519 - val_loss: 0.6320 - val_accuracy: 0.6520\n",
            "Epoch 231/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6276 - accuracy: 0.6507 - val_loss: 0.6185 - val_accuracy: 0.6490\n",
            "Epoch 232/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6273 - accuracy: 0.6516 - val_loss: 0.6218 - val_accuracy: 0.6630\n",
            "Epoch 233/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6271 - accuracy: 0.6521 - val_loss: 0.6248 - val_accuracy: 0.6620\n",
            "Epoch 234/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6266 - accuracy: 0.6543 - val_loss: 0.6207 - val_accuracy: 0.6580\n",
            "Epoch 235/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6264 - accuracy: 0.6519 - val_loss: 0.6172 - val_accuracy: 0.6600\n",
            "Epoch 236/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6264 - accuracy: 0.6526 - val_loss: 0.6142 - val_accuracy: 0.6660\n",
            "Epoch 237/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6260 - accuracy: 0.6520 - val_loss: 0.6210 - val_accuracy: 0.6560\n",
            "Epoch 238/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6273 - accuracy: 0.6503 - val_loss: 0.6236 - val_accuracy: 0.6440\n",
            "Epoch 239/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6269 - accuracy: 0.6537 - val_loss: 0.6217 - val_accuracy: 0.6600\n",
            "Epoch 240/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6269 - accuracy: 0.6492 - val_loss: 0.6229 - val_accuracy: 0.6570\n",
            "Epoch 241/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6266 - accuracy: 0.6531 - val_loss: 0.6264 - val_accuracy: 0.6340\n",
            "Epoch 242/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6262 - accuracy: 0.6524 - val_loss: 0.6272 - val_accuracy: 0.6590\n",
            "Epoch 243/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6253 - accuracy: 0.6520 - val_loss: 0.6267 - val_accuracy: 0.6430\n",
            "Epoch 244/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6256 - accuracy: 0.6523 - val_loss: 0.6252 - val_accuracy: 0.6580\n",
            "Epoch 245/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6255 - accuracy: 0.6530 - val_loss: 0.6161 - val_accuracy: 0.6420\n",
            "Epoch 246/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6254 - accuracy: 0.6527 - val_loss: 0.6177 - val_accuracy: 0.6720\n",
            "Epoch 247/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6256 - accuracy: 0.6512 - val_loss: 0.6201 - val_accuracy: 0.6590\n",
            "Epoch 248/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6261 - accuracy: 0.6524 - val_loss: 0.6253 - val_accuracy: 0.6570\n",
            "Epoch 249/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6251 - accuracy: 0.6529 - val_loss: 0.6229 - val_accuracy: 0.6550\n",
            "Epoch 250/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6267 - accuracy: 0.6516 - val_loss: 0.6248 - val_accuracy: 0.6590\n",
            "Epoch 251/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6249 - accuracy: 0.6539 - val_loss: 0.6269 - val_accuracy: 0.6620\n",
            "Epoch 252/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6249 - accuracy: 0.6540 - val_loss: 0.6204 - val_accuracy: 0.6510\n",
            "Epoch 253/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6239 - accuracy: 0.6551 - val_loss: 0.6243 - val_accuracy: 0.6390\n",
            "Epoch 254/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6254 - accuracy: 0.6543 - val_loss: 0.6190 - val_accuracy: 0.6700\n",
            "Epoch 255/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6243 - accuracy: 0.6543 - val_loss: 0.6170 - val_accuracy: 0.6620\n",
            "Epoch 256/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6258 - accuracy: 0.6543 - val_loss: 0.6166 - val_accuracy: 0.6700\n",
            "Epoch 257/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6244 - accuracy: 0.6549 - val_loss: 0.6170 - val_accuracy: 0.6630\n",
            "Epoch 258/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6251 - accuracy: 0.6529 - val_loss: 0.6201 - val_accuracy: 0.6650\n",
            "Epoch 259/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6251 - accuracy: 0.6545 - val_loss: 0.6171 - val_accuracy: 0.6730\n",
            "Epoch 260/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6247 - accuracy: 0.6539 - val_loss: 0.6195 - val_accuracy: 0.6580\n",
            "Epoch 261/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6234 - accuracy: 0.6565 - val_loss: 0.6196 - val_accuracy: 0.6710\n",
            "Epoch 262/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6243 - accuracy: 0.6549 - val_loss: 0.6202 - val_accuracy: 0.6720\n",
            "Epoch 263/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6252 - accuracy: 0.6544 - val_loss: 0.6228 - val_accuracy: 0.6600\n",
            "Epoch 264/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6240 - accuracy: 0.6550 - val_loss: 0.6200 - val_accuracy: 0.6530\n",
            "Epoch 265/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6249 - accuracy: 0.6535 - val_loss: 0.6164 - val_accuracy: 0.6630\n",
            "Epoch 266/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6241 - accuracy: 0.6565 - val_loss: 0.6258 - val_accuracy: 0.6490\n",
            "Epoch 267/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6242 - accuracy: 0.6568 - val_loss: 0.6227 - val_accuracy: 0.6660\n",
            "Epoch 268/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6234 - accuracy: 0.6545 - val_loss: 0.6262 - val_accuracy: 0.6680\n",
            "Epoch 269/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6243 - accuracy: 0.6529 - val_loss: 0.6209 - val_accuracy: 0.6520\n",
            "Epoch 270/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6250 - accuracy: 0.6528 - val_loss: 0.6174 - val_accuracy: 0.6790\n",
            "Epoch 271/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6243 - accuracy: 0.6565 - val_loss: 0.6181 - val_accuracy: 0.6700\n",
            "Epoch 272/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6242 - accuracy: 0.6566 - val_loss: 0.6188 - val_accuracy: 0.6610\n",
            "Epoch 273/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6239 - accuracy: 0.6543 - val_loss: 0.6124 - val_accuracy: 0.6600\n",
            "Epoch 274/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6231 - accuracy: 0.6540 - val_loss: 0.6179 - val_accuracy: 0.6460\n",
            "Epoch 275/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6240 - accuracy: 0.6546 - val_loss: 0.6156 - val_accuracy: 0.6770\n",
            "Epoch 276/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6227 - accuracy: 0.6548 - val_loss: 0.6216 - val_accuracy: 0.6600\n",
            "Epoch 277/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6237 - accuracy: 0.6542 - val_loss: 0.6237 - val_accuracy: 0.6580\n",
            "Epoch 278/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6245 - accuracy: 0.6543 - val_loss: 0.6201 - val_accuracy: 0.6610\n",
            "Epoch 279/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6236 - accuracy: 0.6551 - val_loss: 0.6206 - val_accuracy: 0.6470\n",
            "Epoch 280/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6237 - accuracy: 0.6575 - val_loss: 0.6200 - val_accuracy: 0.6700\n",
            "Epoch 281/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6235 - accuracy: 0.6558 - val_loss: 0.6168 - val_accuracy: 0.6680\n",
            "Epoch 282/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6231 - accuracy: 0.6572 - val_loss: 0.6183 - val_accuracy: 0.6630\n",
            "Epoch 283/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6233 - accuracy: 0.6565 - val_loss: 0.6221 - val_accuracy: 0.6490\n",
            "Epoch 284/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6244 - accuracy: 0.6547 - val_loss: 0.6207 - val_accuracy: 0.6590\n",
            "Epoch 285/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6233 - accuracy: 0.6569 - val_loss: 0.6274 - val_accuracy: 0.6540\n",
            "Epoch 286/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6215 - accuracy: 0.6574 - val_loss: 0.6187 - val_accuracy: 0.6580\n",
            "Epoch 287/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6235 - accuracy: 0.6572 - val_loss: 0.6177 - val_accuracy: 0.6640\n",
            "Epoch 288/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6225 - accuracy: 0.6574 - val_loss: 0.6205 - val_accuracy: 0.6560\n",
            "Epoch 289/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6224 - accuracy: 0.6579 - val_loss: 0.6181 - val_accuracy: 0.6510\n",
            "Epoch 290/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6232 - accuracy: 0.6572 - val_loss: 0.6210 - val_accuracy: 0.6390\n",
            "Epoch 291/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6222 - accuracy: 0.6556 - val_loss: 0.6197 - val_accuracy: 0.6720\n",
            "Epoch 292/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6236 - accuracy: 0.6544 - val_loss: 0.6244 - val_accuracy: 0.6580\n",
            "Epoch 293/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6231 - accuracy: 0.6567 - val_loss: 0.6201 - val_accuracy: 0.6620\n",
            "Epoch 294/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6227 - accuracy: 0.6576 - val_loss: 0.6221 - val_accuracy: 0.6560\n",
            "Epoch 295/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6225 - accuracy: 0.6575 - val_loss: 0.6239 - val_accuracy: 0.6650\n",
            "Epoch 296/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6215 - accuracy: 0.6583 - val_loss: 0.6162 - val_accuracy: 0.6670\n",
            "Epoch 297/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6215 - accuracy: 0.6579 - val_loss: 0.6181 - val_accuracy: 0.6620\n",
            "Epoch 298/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6222 - accuracy: 0.6566 - val_loss: 0.6220 - val_accuracy: 0.6490\n",
            "Epoch 299/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6212 - accuracy: 0.6580 - val_loss: 0.6193 - val_accuracy: 0.6650\n",
            "Epoch 300/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6227 - accuracy: 0.6568 - val_loss: 0.6139 - val_accuracy: 0.6670\n",
            "Epoch 301/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6221 - accuracy: 0.6589 - val_loss: 0.6155 - val_accuracy: 0.6710\n",
            "Epoch 302/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6223 - accuracy: 0.6573 - val_loss: 0.6166 - val_accuracy: 0.6720\n",
            "Epoch 303/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6216 - accuracy: 0.6571 - val_loss: 0.6192 - val_accuracy: 0.6590\n",
            "Epoch 304/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6212 - accuracy: 0.6589 - val_loss: 0.6220 - val_accuracy: 0.6550\n",
            "Epoch 305/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6217 - accuracy: 0.6563 - val_loss: 0.6202 - val_accuracy: 0.6740\n",
            "Epoch 306/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6232 - accuracy: 0.6554 - val_loss: 0.6193 - val_accuracy: 0.6720\n",
            "Epoch 307/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6227 - accuracy: 0.6573 - val_loss: 0.6209 - val_accuracy: 0.6640\n",
            "Epoch 308/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6213 - accuracy: 0.6597 - val_loss: 0.6193 - val_accuracy: 0.6790\n",
            "Epoch 309/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6217 - accuracy: 0.6558 - val_loss: 0.6157 - val_accuracy: 0.6540\n",
            "Epoch 310/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6209 - accuracy: 0.6592 - val_loss: 0.6249 - val_accuracy: 0.6670\n",
            "Epoch 311/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6215 - accuracy: 0.6598 - val_loss: 0.6191 - val_accuracy: 0.6680\n",
            "Epoch 312/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6212 - accuracy: 0.6577 - val_loss: 0.6128 - val_accuracy: 0.6620\n",
            "Epoch 313/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6209 - accuracy: 0.6597 - val_loss: 0.6216 - val_accuracy: 0.6650\n",
            "Epoch 314/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6213 - accuracy: 0.6566 - val_loss: 0.6162 - val_accuracy: 0.6650\n",
            "Epoch 315/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6224 - accuracy: 0.6580 - val_loss: 0.6285 - val_accuracy: 0.6610\n",
            "Epoch 316/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6214 - accuracy: 0.6582 - val_loss: 0.6237 - val_accuracy: 0.6580\n",
            "Epoch 317/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6210 - accuracy: 0.6584 - val_loss: 0.6202 - val_accuracy: 0.6680\n",
            "Epoch 318/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6213 - accuracy: 0.6580 - val_loss: 0.6144 - val_accuracy: 0.6580\n",
            "Epoch 319/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6215 - accuracy: 0.6576 - val_loss: 0.6201 - val_accuracy: 0.6710\n",
            "Epoch 320/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6216 - accuracy: 0.6567 - val_loss: 0.6160 - val_accuracy: 0.6640\n",
            "Epoch 321/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6206 - accuracy: 0.6593 - val_loss: 0.6218 - val_accuracy: 0.6560\n",
            "Epoch 322/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6210 - accuracy: 0.6590 - val_loss: 0.6211 - val_accuracy: 0.6490\n",
            "Epoch 323/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6217 - accuracy: 0.6585 - val_loss: 0.6144 - val_accuracy: 0.6680\n",
            "Epoch 324/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6202 - accuracy: 0.6611 - val_loss: 0.6251 - val_accuracy: 0.6410\n",
            "Epoch 325/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6195 - accuracy: 0.6585 - val_loss: 0.6198 - val_accuracy: 0.6590\n",
            "Epoch 326/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6218 - accuracy: 0.6571 - val_loss: 0.6204 - val_accuracy: 0.6590\n",
            "Epoch 327/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6203 - accuracy: 0.6585 - val_loss: 0.6167 - val_accuracy: 0.6460\n",
            "Epoch 328/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6196 - accuracy: 0.6603 - val_loss: 0.6168 - val_accuracy: 0.6660\n",
            "Epoch 329/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6208 - accuracy: 0.6587 - val_loss: 0.6191 - val_accuracy: 0.6690\n",
            "Epoch 330/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6198 - accuracy: 0.6602 - val_loss: 0.6273 - val_accuracy: 0.6520\n",
            "Epoch 331/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6199 - accuracy: 0.6603 - val_loss: 0.6179 - val_accuracy: 0.6560\n",
            "Epoch 332/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6199 - accuracy: 0.6586 - val_loss: 0.6187 - val_accuracy: 0.6670\n",
            "Epoch 333/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6204 - accuracy: 0.6602 - val_loss: 0.6145 - val_accuracy: 0.6750\n",
            "Epoch 334/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6202 - accuracy: 0.6589 - val_loss: 0.6179 - val_accuracy: 0.6570\n",
            "Epoch 335/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6203 - accuracy: 0.6589 - val_loss: 0.6180 - val_accuracy: 0.6460\n",
            "Epoch 336/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6191 - accuracy: 0.6601 - val_loss: 0.6099 - val_accuracy: 0.6610\n",
            "Epoch 337/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6201 - accuracy: 0.6592 - val_loss: 0.6174 - val_accuracy: 0.6690\n",
            "Epoch 338/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6211 - accuracy: 0.6593 - val_loss: 0.6137 - val_accuracy: 0.6700\n",
            "Epoch 339/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6202 - accuracy: 0.6588 - val_loss: 0.6195 - val_accuracy: 0.6650\n",
            "Epoch 340/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6198 - accuracy: 0.6590 - val_loss: 0.6200 - val_accuracy: 0.6580\n",
            "Epoch 341/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6204 - accuracy: 0.6582 - val_loss: 0.6188 - val_accuracy: 0.6670\n",
            "Epoch 342/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6193 - accuracy: 0.6613 - val_loss: 0.6196 - val_accuracy: 0.6650\n",
            "Epoch 343/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6200 - accuracy: 0.6591 - val_loss: 0.6199 - val_accuracy: 0.6560\n",
            "Epoch 344/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6196 - accuracy: 0.6609 - val_loss: 0.6168 - val_accuracy: 0.6610\n",
            "Epoch 345/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6198 - accuracy: 0.6598 - val_loss: 0.6209 - val_accuracy: 0.6650\n",
            "Epoch 346/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6202 - accuracy: 0.6580 - val_loss: 0.6244 - val_accuracy: 0.6680\n",
            "Epoch 347/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6194 - accuracy: 0.6593 - val_loss: 0.6179 - val_accuracy: 0.6590\n",
            "Epoch 348/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6198 - accuracy: 0.6584 - val_loss: 0.6093 - val_accuracy: 0.6610\n",
            "Epoch 349/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6202 - accuracy: 0.6584 - val_loss: 0.6147 - val_accuracy: 0.6610\n",
            "Epoch 350/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6185 - accuracy: 0.6594 - val_loss: 0.6140 - val_accuracy: 0.6670\n",
            "Epoch 351/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6190 - accuracy: 0.6595 - val_loss: 0.6177 - val_accuracy: 0.6700\n",
            "Epoch 352/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6199 - accuracy: 0.6590 - val_loss: 0.6164 - val_accuracy: 0.6500\n",
            "Epoch 353/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6196 - accuracy: 0.6596 - val_loss: 0.6123 - val_accuracy: 0.6640\n",
            "Epoch 354/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6195 - accuracy: 0.6601 - val_loss: 0.6195 - val_accuracy: 0.6610\n",
            "Epoch 355/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6187 - accuracy: 0.6614 - val_loss: 0.6165 - val_accuracy: 0.6680\n",
            "Epoch 356/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6191 - accuracy: 0.6598 - val_loss: 0.6097 - val_accuracy: 0.6770\n",
            "Epoch 357/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6190 - accuracy: 0.6603 - val_loss: 0.6180 - val_accuracy: 0.6590\n",
            "Epoch 358/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6187 - accuracy: 0.6613 - val_loss: 0.6105 - val_accuracy: 0.6730\n",
            "Epoch 359/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6188 - accuracy: 0.6587 - val_loss: 0.6135 - val_accuracy: 0.6630\n",
            "Epoch 360/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6190 - accuracy: 0.6591 - val_loss: 0.6171 - val_accuracy: 0.6730\n",
            "Epoch 361/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6194 - accuracy: 0.6621 - val_loss: 0.6147 - val_accuracy: 0.6760\n",
            "Epoch 362/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6187 - accuracy: 0.6622 - val_loss: 0.6116 - val_accuracy: 0.6620\n",
            "Epoch 363/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6192 - accuracy: 0.6611 - val_loss: 0.6121 - val_accuracy: 0.6730\n",
            "Epoch 364/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6190 - accuracy: 0.6604 - val_loss: 0.6241 - val_accuracy: 0.6610\n",
            "Epoch 365/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6189 - accuracy: 0.6613 - val_loss: 0.6146 - val_accuracy: 0.6750\n",
            "Epoch 366/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6190 - accuracy: 0.6601 - val_loss: 0.6165 - val_accuracy: 0.6700\n",
            "Epoch 367/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6173 - accuracy: 0.6612 - val_loss: 0.6179 - val_accuracy: 0.6610\n",
            "Epoch 368/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6183 - accuracy: 0.6602 - val_loss: 0.6123 - val_accuracy: 0.6700\n",
            "Epoch 369/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6192 - accuracy: 0.6592 - val_loss: 0.6131 - val_accuracy: 0.6610\n",
            "Epoch 370/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6183 - accuracy: 0.6603 - val_loss: 0.6146 - val_accuracy: 0.6730\n",
            "Epoch 371/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6182 - accuracy: 0.6602 - val_loss: 0.6152 - val_accuracy: 0.6640\n",
            "Epoch 372/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6188 - accuracy: 0.6606 - val_loss: 0.6159 - val_accuracy: 0.6610\n",
            "Epoch 373/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6174 - accuracy: 0.6618 - val_loss: 0.6166 - val_accuracy: 0.6580\n",
            "Epoch 374/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6180 - accuracy: 0.6613 - val_loss: 0.6187 - val_accuracy: 0.6630\n",
            "Epoch 375/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6195 - accuracy: 0.6603 - val_loss: 0.6210 - val_accuracy: 0.6650\n",
            "Epoch 376/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6182 - accuracy: 0.6631 - val_loss: 0.6209 - val_accuracy: 0.6590\n",
            "Epoch 377/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6198 - accuracy: 0.6598 - val_loss: 0.6126 - val_accuracy: 0.6810\n",
            "Epoch 378/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6176 - accuracy: 0.6602 - val_loss: 0.6228 - val_accuracy: 0.6650\n",
            "Epoch 379/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6171 - accuracy: 0.6616 - val_loss: 0.6080 - val_accuracy: 0.6670\n",
            "Epoch 380/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6188 - accuracy: 0.6625 - val_loss: 0.6163 - val_accuracy: 0.6710\n",
            "Epoch 381/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6183 - accuracy: 0.6626 - val_loss: 0.6155 - val_accuracy: 0.6610\n",
            "Epoch 382/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6189 - accuracy: 0.6609 - val_loss: 0.6192 - val_accuracy: 0.6590\n",
            "Epoch 383/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6189 - accuracy: 0.6610 - val_loss: 0.6175 - val_accuracy: 0.6590\n",
            "Epoch 384/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6186 - accuracy: 0.6606 - val_loss: 0.6133 - val_accuracy: 0.6630\n",
            "Epoch 385/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6174 - accuracy: 0.6629 - val_loss: 0.6157 - val_accuracy: 0.6630\n",
            "Epoch 386/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6175 - accuracy: 0.6612 - val_loss: 0.6264 - val_accuracy: 0.6450\n",
            "Epoch 387/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6179 - accuracy: 0.6604 - val_loss: 0.6127 - val_accuracy: 0.6730\n",
            "Epoch 388/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6185 - accuracy: 0.6600 - val_loss: 0.6200 - val_accuracy: 0.6720\n",
            "Epoch 389/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6181 - accuracy: 0.6615 - val_loss: 0.6140 - val_accuracy: 0.6760\n",
            "Epoch 390/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6184 - accuracy: 0.6611 - val_loss: 0.6194 - val_accuracy: 0.6710\n",
            "Epoch 391/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6168 - accuracy: 0.6638 - val_loss: 0.6123 - val_accuracy: 0.6670\n",
            "Epoch 392/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6180 - accuracy: 0.6628 - val_loss: 0.6156 - val_accuracy: 0.6630\n",
            "Epoch 393/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6178 - accuracy: 0.6619 - val_loss: 0.6181 - val_accuracy: 0.6670\n",
            "Epoch 394/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6179 - accuracy: 0.6616 - val_loss: 0.6151 - val_accuracy: 0.6660\n",
            "Epoch 395/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6173 - accuracy: 0.6634 - val_loss: 0.6141 - val_accuracy: 0.6720\n",
            "Epoch 396/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6174 - accuracy: 0.6623 - val_loss: 0.6136 - val_accuracy: 0.6750\n",
            "Epoch 397/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6168 - accuracy: 0.6633 - val_loss: 0.6117 - val_accuracy: 0.6740\n",
            "Epoch 398/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6162 - accuracy: 0.6642 - val_loss: 0.6088 - val_accuracy: 0.6650\n",
            "Epoch 399/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6177 - accuracy: 0.6619 - val_loss: 0.6155 - val_accuracy: 0.6540\n",
            "Epoch 400/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6171 - accuracy: 0.6618 - val_loss: 0.6153 - val_accuracy: 0.6580\n",
            "Epoch 401/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6181 - accuracy: 0.6608 - val_loss: 0.6152 - val_accuracy: 0.6710\n",
            "Epoch 402/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6172 - accuracy: 0.6625 - val_loss: 0.6136 - val_accuracy: 0.6670\n",
            "Epoch 403/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6180 - accuracy: 0.6627 - val_loss: 0.6203 - val_accuracy: 0.6660\n",
            "Epoch 404/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6176 - accuracy: 0.6624 - val_loss: 0.6168 - val_accuracy: 0.6600\n",
            "Epoch 405/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6181 - accuracy: 0.6622 - val_loss: 0.6216 - val_accuracy: 0.6530\n",
            "Epoch 406/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6167 - accuracy: 0.6636 - val_loss: 0.6160 - val_accuracy: 0.6680\n",
            "Epoch 407/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6159 - accuracy: 0.6646 - val_loss: 0.6114 - val_accuracy: 0.6660\n",
            "Epoch 408/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6170 - accuracy: 0.6641 - val_loss: 0.6114 - val_accuracy: 0.6720\n",
            "Epoch 409/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6172 - accuracy: 0.6633 - val_loss: 0.6072 - val_accuracy: 0.6750\n",
            "Epoch 410/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6163 - accuracy: 0.6625 - val_loss: 0.6121 - val_accuracy: 0.6540\n",
            "Epoch 411/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6164 - accuracy: 0.6628 - val_loss: 0.6231 - val_accuracy: 0.6620\n",
            "Epoch 412/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6171 - accuracy: 0.6625 - val_loss: 0.6168 - val_accuracy: 0.6630\n",
            "Epoch 413/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6159 - accuracy: 0.6646 - val_loss: 0.6118 - val_accuracy: 0.6760\n",
            "Epoch 414/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6170 - accuracy: 0.6616 - val_loss: 0.6158 - val_accuracy: 0.6620\n",
            "Epoch 415/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6159 - accuracy: 0.6645 - val_loss: 0.6142 - val_accuracy: 0.6800\n",
            "Epoch 416/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6160 - accuracy: 0.6631 - val_loss: 0.6258 - val_accuracy: 0.6620\n",
            "Epoch 417/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6156 - accuracy: 0.6639 - val_loss: 0.6131 - val_accuracy: 0.6690\n",
            "Epoch 418/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6173 - accuracy: 0.6628 - val_loss: 0.6116 - val_accuracy: 0.6640\n",
            "Epoch 419/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6161 - accuracy: 0.6621 - val_loss: 0.6172 - val_accuracy: 0.6630\n",
            "Epoch 420/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6162 - accuracy: 0.6629 - val_loss: 0.6196 - val_accuracy: 0.6540\n",
            "Epoch 421/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6166 - accuracy: 0.6609 - val_loss: 0.6163 - val_accuracy: 0.6640\n",
            "Epoch 422/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6173 - accuracy: 0.6620 - val_loss: 0.6207 - val_accuracy: 0.6680\n",
            "Epoch 423/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6162 - accuracy: 0.6641 - val_loss: 0.6162 - val_accuracy: 0.6740\n",
            "Epoch 424/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6165 - accuracy: 0.6637 - val_loss: 0.6122 - val_accuracy: 0.6660\n",
            "Epoch 425/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6157 - accuracy: 0.6632 - val_loss: 0.6184 - val_accuracy: 0.6670\n",
            "Epoch 426/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6155 - accuracy: 0.6628 - val_loss: 0.6230 - val_accuracy: 0.6570\n",
            "Epoch 427/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6156 - accuracy: 0.6632 - val_loss: 0.6249 - val_accuracy: 0.6530\n",
            "Epoch 428/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6149 - accuracy: 0.6638 - val_loss: 0.6113 - val_accuracy: 0.6680\n",
            "Epoch 429/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6166 - accuracy: 0.6634 - val_loss: 0.6150 - val_accuracy: 0.6690\n",
            "Epoch 430/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6147 - accuracy: 0.6653 - val_loss: 0.6136 - val_accuracy: 0.6700\n",
            "Epoch 431/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6164 - accuracy: 0.6645 - val_loss: 0.6114 - val_accuracy: 0.6690\n",
            "Epoch 432/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6162 - accuracy: 0.6628 - val_loss: 0.6212 - val_accuracy: 0.6550\n",
            "Epoch 433/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6155 - accuracy: 0.6647 - val_loss: 0.6175 - val_accuracy: 0.6530\n",
            "Epoch 434/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6168 - accuracy: 0.6627 - val_loss: 0.6181 - val_accuracy: 0.6750\n",
            "Epoch 435/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6160 - accuracy: 0.6629 - val_loss: 0.6181 - val_accuracy: 0.6600\n",
            "Epoch 436/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6164 - accuracy: 0.6621 - val_loss: 0.6163 - val_accuracy: 0.6630\n",
            "Epoch 437/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6160 - accuracy: 0.6629 - val_loss: 0.6169 - val_accuracy: 0.6540\n",
            "Epoch 438/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6161 - accuracy: 0.6634 - val_loss: 0.6133 - val_accuracy: 0.6770\n",
            "Epoch 439/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6167 - accuracy: 0.6639 - val_loss: 0.6202 - val_accuracy: 0.6500\n",
            "Epoch 440/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6161 - accuracy: 0.6629 - val_loss: 0.6162 - val_accuracy: 0.6690\n",
            "Epoch 441/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6158 - accuracy: 0.6622 - val_loss: 0.6109 - val_accuracy: 0.6710\n",
            "Epoch 442/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6166 - accuracy: 0.6634 - val_loss: 0.6110 - val_accuracy: 0.6700\n",
            "Epoch 443/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6156 - accuracy: 0.6651 - val_loss: 0.6173 - val_accuracy: 0.6610\n",
            "Epoch 444/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6160 - accuracy: 0.6640 - val_loss: 0.6174 - val_accuracy: 0.6600\n",
            "Epoch 445/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6159 - accuracy: 0.6658 - val_loss: 0.6148 - val_accuracy: 0.6630\n",
            "Epoch 446/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6169 - accuracy: 0.6629 - val_loss: 0.6165 - val_accuracy: 0.6630\n",
            "Epoch 447/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6161 - accuracy: 0.6630 - val_loss: 0.6155 - val_accuracy: 0.6630\n",
            "Epoch 448/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6154 - accuracy: 0.6630 - val_loss: 0.6150 - val_accuracy: 0.6600\n",
            "Epoch 449/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6161 - accuracy: 0.6632 - val_loss: 0.6197 - val_accuracy: 0.6570\n",
            "Epoch 450/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6164 - accuracy: 0.6623 - val_loss: 0.6161 - val_accuracy: 0.6610\n",
            "Epoch 451/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6151 - accuracy: 0.6628 - val_loss: 0.6149 - val_accuracy: 0.6610\n",
            "Epoch 452/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6149 - accuracy: 0.6633 - val_loss: 0.6152 - val_accuracy: 0.6670\n",
            "Epoch 453/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6152 - accuracy: 0.6650 - val_loss: 0.6131 - val_accuracy: 0.6620\n",
            "Epoch 454/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6145 - accuracy: 0.6659 - val_loss: 0.6170 - val_accuracy: 0.6750\n",
            "Epoch 455/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6148 - accuracy: 0.6669 - val_loss: 0.6138 - val_accuracy: 0.6660\n",
            "Epoch 456/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6150 - accuracy: 0.6655 - val_loss: 0.6143 - val_accuracy: 0.6630\n",
            "Epoch 457/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6151 - accuracy: 0.6645 - val_loss: 0.6228 - val_accuracy: 0.6650\n",
            "Epoch 458/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6144 - accuracy: 0.6653 - val_loss: 0.6095 - val_accuracy: 0.6710\n",
            "Epoch 459/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6157 - accuracy: 0.6660 - val_loss: 0.6143 - val_accuracy: 0.6570\n",
            "Epoch 460/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6157 - accuracy: 0.6639 - val_loss: 0.6160 - val_accuracy: 0.6560\n",
            "Epoch 461/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6148 - accuracy: 0.6648 - val_loss: 0.6156 - val_accuracy: 0.6620\n",
            "Epoch 462/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6159 - accuracy: 0.6637 - val_loss: 0.6149 - val_accuracy: 0.6590\n",
            "Epoch 463/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6148 - accuracy: 0.6651 - val_loss: 0.6220 - val_accuracy: 0.6560\n",
            "Epoch 464/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6148 - accuracy: 0.6651 - val_loss: 0.6143 - val_accuracy: 0.6670\n",
            "Epoch 465/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6145 - accuracy: 0.6646 - val_loss: 0.6143 - val_accuracy: 0.6660\n",
            "Epoch 466/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6144 - accuracy: 0.6637 - val_loss: 0.6228 - val_accuracy: 0.6540\n",
            "Epoch 467/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6142 - accuracy: 0.6632 - val_loss: 0.6144 - val_accuracy: 0.6610\n",
            "Epoch 468/1000\n",
            "2412/2412 [==============================] - 7s 3ms/step - loss: 0.6144 - accuracy: 0.6655 - val_loss: 0.6111 - val_accuracy: 0.6820\n",
            "Epoch 469/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6150 - accuracy: 0.6649 - val_loss: 0.6164 - val_accuracy: 0.6740\n",
            "Epoch 470/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6138 - accuracy: 0.6659 - val_loss: 0.6120 - val_accuracy: 0.6700\n",
            "Epoch 471/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6147 - accuracy: 0.6654 - val_loss: 0.6115 - val_accuracy: 0.6670\n",
            "Epoch 472/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6151 - accuracy: 0.6659 - val_loss: 0.6178 - val_accuracy: 0.6700\n",
            "Epoch 473/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6147 - accuracy: 0.6649 - val_loss: 0.6124 - val_accuracy: 0.6560\n",
            "Epoch 474/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6142 - accuracy: 0.6651 - val_loss: 0.6136 - val_accuracy: 0.6670\n",
            "Epoch 475/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6144 - accuracy: 0.6651 - val_loss: 0.6123 - val_accuracy: 0.6650\n",
            "Epoch 476/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6153 - accuracy: 0.6653 - val_loss: 0.6176 - val_accuracy: 0.6620\n",
            "Epoch 477/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6139 - accuracy: 0.6667 - val_loss: 0.6167 - val_accuracy: 0.6630\n",
            "Epoch 478/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6152 - accuracy: 0.6652 - val_loss: 0.6177 - val_accuracy: 0.6600\n",
            "Epoch 479/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6146 - accuracy: 0.6666 - val_loss: 0.6197 - val_accuracy: 0.6540\n",
            "Epoch 480/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6147 - accuracy: 0.6651 - val_loss: 0.6146 - val_accuracy: 0.6720\n",
            "Epoch 481/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6148 - accuracy: 0.6646 - val_loss: 0.6231 - val_accuracy: 0.6660\n",
            "Epoch 482/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6154 - accuracy: 0.6632 - val_loss: 0.6185 - val_accuracy: 0.6660\n",
            "Epoch 483/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6147 - accuracy: 0.6656 - val_loss: 0.6256 - val_accuracy: 0.6480\n",
            "Epoch 484/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6141 - accuracy: 0.6651 - val_loss: 0.6222 - val_accuracy: 0.6450\n",
            "Epoch 485/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6140 - accuracy: 0.6658 - val_loss: 0.6157 - val_accuracy: 0.6680\n",
            "Epoch 486/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6138 - accuracy: 0.6648 - val_loss: 0.6141 - val_accuracy: 0.6600\n",
            "Epoch 487/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6150 - accuracy: 0.6648 - val_loss: 0.6233 - val_accuracy: 0.6640\n",
            "Epoch 488/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6140 - accuracy: 0.6662 - val_loss: 0.6145 - val_accuracy: 0.6760\n",
            "Epoch 489/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6137 - accuracy: 0.6665 - val_loss: 0.6168 - val_accuracy: 0.6660\n",
            "Epoch 490/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6134 - accuracy: 0.6664 - val_loss: 0.6130 - val_accuracy: 0.6610\n",
            "Epoch 491/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6145 - accuracy: 0.6652 - val_loss: 0.6160 - val_accuracy: 0.6640\n",
            "Epoch 492/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6141 - accuracy: 0.6663 - val_loss: 0.6156 - val_accuracy: 0.6680\n",
            "Epoch 493/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6144 - accuracy: 0.6654 - val_loss: 0.6178 - val_accuracy: 0.6540\n",
            "Epoch 494/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6142 - accuracy: 0.6660 - val_loss: 0.6150 - val_accuracy: 0.6690\n",
            "Epoch 495/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6142 - accuracy: 0.6669 - val_loss: 0.6159 - val_accuracy: 0.6590\n",
            "Epoch 496/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6139 - accuracy: 0.6657 - val_loss: 0.6125 - val_accuracy: 0.6600\n",
            "Epoch 497/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6138 - accuracy: 0.6665 - val_loss: 0.6150 - val_accuracy: 0.6640\n",
            "Epoch 498/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6140 - accuracy: 0.6664 - val_loss: 0.6227 - val_accuracy: 0.6630\n",
            "Epoch 499/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6137 - accuracy: 0.6654 - val_loss: 0.6250 - val_accuracy: 0.6520\n",
            "Epoch 500/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6146 - accuracy: 0.6653 - val_loss: 0.6206 - val_accuracy: 0.6480\n",
            "Epoch 501/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6139 - accuracy: 0.6671 - val_loss: 0.6137 - val_accuracy: 0.6640\n",
            "Epoch 502/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6131 - accuracy: 0.6669 - val_loss: 0.6181 - val_accuracy: 0.6580\n",
            "Epoch 503/1000\n",
            "2412/2412 [==============================] - 6s 3ms/step - loss: 0.6143 - accuracy: 0.6658 - val_loss: 0.6166 - val_accuracy: 0.6740\n",
            "Epoch 504/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6136 - accuracy: 0.6675 - val_loss: 0.6141 - val_accuracy: 0.6710\n",
            "Epoch 505/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6146 - accuracy: 0.6664 - val_loss: 0.6131 - val_accuracy: 0.6720\n",
            "Epoch 506/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6133 - accuracy: 0.6649 - val_loss: 0.6132 - val_accuracy: 0.6650\n",
            "Epoch 507/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6138 - accuracy: 0.6668 - val_loss: 0.6157 - val_accuracy: 0.6490\n",
            "Epoch 508/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6138 - accuracy: 0.6655 - val_loss: 0.6179 - val_accuracy: 0.6650\n",
            "Epoch 509/1000\n",
            "2412/2412 [==============================] - 6s 2ms/step - loss: 0.6141 - accuracy: 0.6646 - val_loss: 0.6129 - val_accuracy: 0.6660\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sgxZ6qrU9-9"
      },
      "source": [
        "def eval_model(model, x, true_label, ds_name=\"Training\"):\n",
        "  loss, acc = model.evaluate(x, true_label, verbose=0)\n",
        "  print(\"{} Dataset: loss = {} and acccuracy = {}\".format(ds_name, np.round(loss, 3), np.round(acc, 3)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwcedsFqDUnm",
        "outputId": "ebaae760-22b8-4928-c064-a199f428b0a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "eval_model(model, xtrain_vec, chip_train[\"id\"], \"Training\")\n",
        "eval_model(model, xval_vec, chip_val[\"id\"], \"Validation\")\n",
        "eval_model(model, xtest_vec, chip_test[\"id\"], \"Test\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Dataset: loss = 0.605 and acccuracy = 0.676\n",
            "Validation Dataset: loss = 0.607 and acccuracy = 0.675\n",
            "Test Dataset: loss = 0.616 and acccuracy = 0.665\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsKcAZpuD1cT",
        "outputId": "cb88d55c-8226-4c3a-c7be-d3db00e86a03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "for i in range(1):\n",
        "  ax1 = axes[0]\n",
        "  ax2 = axes[1]\n",
        "\n",
        "  ax1.plot(model_hist.history['loss'], label='training')\n",
        "  ax1.plot(model_hist.history['val_loss'], label='validation')\n",
        "  ax1.set_title('NN Multiclassification loss')\n",
        "  ax1.set_xlabel('epoch')\n",
        "  ax1.set_ylabel('loss')\n",
        "  ax1.legend(['train', 'validation'], loc='upper left')\n",
        "  \n",
        "  ax2.plot(model_hist.history['accuracy'], label='training')\n",
        "  ax2.plot(model_hist.history['val_accuracy'], label='validation')\n",
        "  ax2.set_title('NN Multiclassification accuracy')\n",
        "  ax2.set_xlabel('epoch')\n",
        "  ax2.set_ylabel('accuracy')\n",
        "  ax2.legend(['train', 'validation'], loc='upper left')\n",
        "fig.tight_layout()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGS26IKAYaBt"
      },
      "source": [
        "def save_hist():\n",
        "  filename = data_path + \"ae_chip_adam1024_prediction_history.csv\"\n",
        "  hist_df = pd.DataFrame(model_hist.history) \n",
        "  with open(filename, mode='w') as f:\n",
        "    hist_df.to_csv(f)\n",
        "save_hist()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}